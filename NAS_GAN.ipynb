{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VIGyIus8Vr7"
      },
      "source": [
        "Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PhilippHa3/NAS_GAN_AU"
      ],
      "metadata": {
        "id": "cZcyK0MJmNjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to mount to your own google drive run following cell."
      ],
      "metadata": {
        "id": "4lqjR6KImHuM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn5pIc_wqSle",
        "outputId": "e51452f7-ce72-484f-fc5a-ee80b442eb7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "move to the file path where the github repo has been cloned to."
      ],
      "metadata": {
        "id": "Xe8piCypmb0u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('NAS_GAN_AU/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1EySlOXwwoa"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ... --name horse2zebra --model ...`\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sp7TCT2x9dB",
        "outputId": "aa7e88ca-441c-4608-a049-1c00e5c69cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 50                            \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 10                            \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: CycleGan                      \t[default: ReflectionPad2d_Conv2d+ReLU]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_blocks: 3                             \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_cycleGAN\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.366, data: 1.647) D_A: 0.325 G_A: 0.497 cycle_A: 0.645 idt_A: 0.999 D_B: 0.346 G_B: 0.231 cycle_B: 1.987 idt_B: 0.312 \n",
            "End of epoch 1 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.394, data: 0.710) D_A: 0.253 G_A: 0.461 cycle_A: 0.618 idt_A: 1.118 D_B: 0.065 G_B: 0.718 cycle_B: 2.632 idt_B: 0.299 \n",
            "End of epoch 2 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.376, data: 0.327) D_A: 0.194 G_A: 0.522 cycle_A: 1.636 idt_A: 1.431 D_B: 0.182 G_B: 0.387 cycle_B: 3.340 idt_B: 0.730 \n",
            "End of epoch 3 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 7.291, data: 0.408) D_A: 0.390 G_A: 0.417 cycle_A: 0.558 idt_A: 1.099 D_B: 0.167 G_B: 0.625 cycle_B: 2.463 idt_B: 0.217 \n",
            "End of epoch 4 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.368, data: 0.215) D_A: 0.288 G_A: 0.416 cycle_A: 0.600 idt_A: 1.032 D_B: 0.153 G_B: 0.811 cycle_B: 2.213 idt_B: 0.247 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.349, data: 0.209) D_A: 0.178 G_A: 0.373 cycle_A: 0.990 idt_A: 0.897 D_B: 0.294 G_B: 0.169 cycle_B: 1.897 idt_B: 0.436 \n",
            "End of epoch 6 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.348, data: 0.243) D_A: 0.335 G_A: 0.354 cycle_A: 0.687 idt_A: 1.095 D_B: 0.255 G_B: 0.132 cycle_B: 3.186 idt_B: 0.259 \n",
            "End of epoch 7 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 4.735, data: 0.255) D_A: 0.225 G_A: 0.228 cycle_A: 0.479 idt_A: 2.079 D_B: 0.154 G_B: 0.362 cycle_B: 4.090 idt_B: 0.215 \n",
            "End of epoch 8 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.351, data: 0.238) D_A: 0.186 G_A: 0.518 cycle_A: 0.810 idt_A: 0.973 D_B: 0.113 G_B: 0.969 cycle_B: 1.967 idt_B: 0.506 \n",
            "End of epoch 9 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.356, data: 0.232) D_A: 0.221 G_A: 0.678 cycle_A: 1.577 idt_A: 0.731 D_B: 0.097 G_B: 1.191 cycle_B: 1.726 idt_B: 0.877 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.346, data: 0.221) D_A: 0.166 G_A: 0.521 cycle_A: 0.842 idt_A: 1.249 D_B: 0.127 G_B: 0.288 cycle_B: 3.642 idt_B: 0.306 \n",
            "End of epoch 11 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 5.753, data: 0.213) D_A: 0.188 G_A: 0.409 cycle_A: 0.412 idt_A: 0.689 D_B: 0.136 G_B: 0.382 cycle_B: 1.951 idt_B: 0.191 \n",
            "End of epoch 12 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.352, data: 0.231) D_A: 0.192 G_A: 0.628 cycle_A: 0.749 idt_A: 0.981 D_B: 0.070 G_B: 0.044 cycle_B: 1.985 idt_B: 0.217 \n",
            "End of epoch 13 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.352, data: 0.219) D_A: 0.140 G_A: 0.576 cycle_A: 0.868 idt_A: 1.133 D_B: 0.073 G_B: 0.356 cycle_B: 2.606 idt_B: 0.233 \n",
            "End of epoch 14 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.349, data: 0.246) D_A: 0.223 G_A: 0.403 cycle_A: 0.653 idt_A: 0.822 D_B: 0.214 G_B: 0.178 cycle_B: 2.549 idt_B: 0.317 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 4.798, data: 0.365) D_A: 0.205 G_A: 0.573 cycle_A: 0.613 idt_A: 0.840 D_B: 0.240 G_B: 1.230 cycle_B: 1.940 idt_B: 0.248 \n",
            "End of epoch 16 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.359, data: 0.199) D_A: 0.267 G_A: 0.145 cycle_A: 0.628 idt_A: 1.159 D_B: 0.197 G_B: 0.733 cycle_B: 2.531 idt_B: 0.288 \n",
            "End of epoch 17 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.361, data: 0.252) D_A: 0.418 G_A: 1.059 cycle_A: 0.669 idt_A: 1.676 D_B: 0.116 G_B: 0.520 cycle_B: 3.984 idt_B: 0.317 \n",
            "End of epoch 18 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.364, data: 0.205) D_A: 0.335 G_A: 0.744 cycle_A: 1.086 idt_A: 1.234 D_B: 0.061 G_B: 0.675 cycle_B: 3.752 idt_B: 0.644 \n",
            "End of epoch 19 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 4.714, data: 0.358) D_A: 0.258 G_A: 0.730 cycle_A: 0.908 idt_A: 0.763 D_B: 0.288 G_B: 0.118 cycle_B: 1.829 idt_B: 0.489 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.347, data: 0.202) D_A: 0.257 G_A: 0.422 cycle_A: 1.903 idt_A: 0.806 D_B: 0.046 G_B: 0.875 cycle_B: 2.070 idt_B: 0.490 \n",
            "End of epoch 21 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.380, data: 0.250) D_A: 0.079 G_A: 0.534 cycle_A: 1.135 idt_A: 0.708 D_B: 0.109 G_B: 0.901 cycle_B: 1.755 idt_B: 0.379 \n",
            "End of epoch 22 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.371, data: 0.351) D_A: 0.056 G_A: 1.158 cycle_A: 0.899 idt_A: 1.312 D_B: 0.221 G_B: 0.564 cycle_B: 3.117 idt_B: 0.267 \n",
            "End of epoch 23 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 4.773, data: 0.319) D_A: 0.297 G_A: 0.096 cycle_A: 0.729 idt_A: 1.231 D_B: 0.091 G_B: 0.573 cycle_B: 2.254 idt_B: 0.273 \n",
            "End of epoch 24 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.352, data: 0.199) D_A: 0.242 G_A: 0.801 cycle_A: 0.791 idt_A: 1.079 D_B: 0.120 G_B: 0.143 cycle_B: 3.117 idt_B: 0.253 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.318, data: 0.288) D_A: 0.211 G_A: 0.459 cycle_A: 0.771 idt_A: 0.934 D_B: 0.179 G_B: 0.457 cycle_B: 2.237 idt_B: 0.258 \n",
            "End of epoch 26 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.318, data: 0.206) D_A: 0.085 G_A: 0.490 cycle_A: 0.477 idt_A: 1.077 D_B: 0.113 G_B: 0.497 cycle_B: 2.433 idt_B: 0.203 \n",
            "End of epoch 27 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 4.783, data: 0.252) D_A: 0.249 G_A: 0.741 cycle_A: 0.533 idt_A: 1.202 D_B: 0.116 G_B: 0.307 cycle_B: 2.216 idt_B: 0.197 \n",
            "End of epoch 28 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.348, data: 0.343) D_A: 0.110 G_A: 0.550 cycle_A: 0.672 idt_A: 1.856 D_B: 0.205 G_B: 1.619 cycle_B: 3.757 idt_B: 0.264 \n",
            "End of epoch 29 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.342, data: 0.314) D_A: 0.048 G_A: 0.945 cycle_A: 0.564 idt_A: 0.668 D_B: 0.135 G_B: 0.751 cycle_B: 2.362 idt_B: 0.267 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.343, data: 0.366) D_A: 0.270 G_A: 1.003 cycle_A: 0.560 idt_A: 1.562 D_B: 0.248 G_B: 0.860 cycle_B: 3.470 idt_B: 0.261 \n",
            "End of epoch 31 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 4.438, data: 0.357) D_A: 0.269 G_A: 0.932 cycle_A: 0.980 idt_A: 1.204 D_B: 0.168 G_B: 0.269 cycle_B: 2.891 idt_B: 0.427 \n",
            "End of epoch 32 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.335, data: 0.233) D_A: 0.241 G_A: 0.345 cycle_A: 0.834 idt_A: 0.875 D_B: 0.085 G_B: 0.221 cycle_B: 2.006 idt_B: 0.369 \n",
            "End of epoch 33 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.330, data: 0.194) D_A: 0.058 G_A: 0.791 cycle_A: 0.475 idt_A: 0.931 D_B: 0.214 G_B: 0.192 cycle_B: 2.349 idt_B: 0.197 \n",
            "End of epoch 34 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.335, data: 0.206) D_A: 0.143 G_A: 0.821 cycle_A: 0.855 idt_A: 1.161 D_B: 0.097 G_B: 0.644 cycle_B: 2.181 idt_B: 0.320 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 4.690, data: 0.226) D_A: 0.183 G_A: 1.197 cycle_A: 0.966 idt_A: 1.376 D_B: 0.117 G_B: 0.313 cycle_B: 2.879 idt_B: 0.367 \n",
            "End of epoch 36 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.350, data: 0.233) D_A: 0.068 G_A: 0.829 cycle_A: 0.867 idt_A: 0.740 D_B: 0.176 G_B: 0.777 cycle_B: 1.782 idt_B: 0.407 \n",
            "End of epoch 37 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.389, data: 0.298) D_A: 0.129 G_A: 0.537 cycle_A: 0.792 idt_A: 0.688 D_B: 0.047 G_B: 0.342 cycle_B: 2.756 idt_B: 0.362 \n",
            "End of epoch 38 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.361, data: 0.415) D_A: 0.066 G_A: 0.537 cycle_A: 0.636 idt_A: 0.963 D_B: 0.076 G_B: 0.530 cycle_B: 2.886 idt_B: 0.232 \n",
            "End of epoch 39 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 5.834, data: 0.338) D_A: 0.287 G_A: 0.591 cycle_A: 1.288 idt_A: 1.259 D_B: 0.128 G_B: 0.364 cycle_B: 2.751 idt_B: 0.451 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.345, data: 0.349) D_A: 0.163 G_A: 0.514 cycle_A: 0.843 idt_A: 1.012 D_B: 0.093 G_B: 0.347 cycle_B: 2.978 idt_B: 0.377 \n",
            "End of epoch 41 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.346, data: 0.351) D_A: 0.103 G_A: 0.485 cycle_A: 0.541 idt_A: 1.515 D_B: 0.066 G_B: 0.649 cycle_B: 2.537 idt_B: 0.195 \n",
            "End of epoch 42 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.330, data: 0.330) D_A: 0.064 G_A: 0.591 cycle_A: 0.836 idt_A: 0.706 D_B: 0.053 G_B: 0.594 cycle_B: 1.764 idt_B: 0.381 \n",
            "End of epoch 43 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 5.040, data: 0.306) D_A: 0.131 G_A: 0.669 cycle_A: 0.462 idt_A: 0.626 D_B: 0.034 G_B: 0.524 cycle_B: 1.698 idt_B: 0.182 \n",
            "End of epoch 44 / 200 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.334, data: 0.228) D_A: 0.081 G_A: 0.356 cycle_A: 0.380 idt_A: 0.648 D_B: 0.120 G_B: 0.091 cycle_B: 1.847 idt_B: 0.151 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.327, data: 0.238) D_A: 0.224 G_A: 0.269 cycle_A: 0.661 idt_A: 0.749 D_B: 0.058 G_B: 0.532 cycle_B: 1.583 idt_B: 0.290 \n",
            "End of epoch 46 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.348, data: 0.213) D_A: 0.155 G_A: 0.274 cycle_A: 0.711 idt_A: 0.775 D_B: 0.236 G_B: 0.551 cycle_B: 2.117 idt_B: 0.297 \n",
            "End of epoch 47 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 5.130, data: 0.233) D_A: 0.331 G_A: 0.104 cycle_A: 0.566 idt_A: 0.795 D_B: 0.099 G_B: 0.606 cycle_B: 2.027 idt_B: 0.170 \n",
            "End of epoch 48 / 200 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.350, data: 0.238) D_A: 0.063 G_A: 0.117 cycle_A: 0.722 idt_A: 1.123 D_B: 0.377 G_B: 0.500 cycle_B: 2.591 idt_B: 0.254 \n",
            "End of epoch 49 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.362, data: 0.208) D_A: 0.134 G_A: 0.567 cycle_A: 0.455 idt_A: 0.955 D_B: 0.063 G_B: 0.298 cycle_B: 2.337 idt_B: 0.204 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.439, data: 0.253) D_A: 0.217 G_A: 0.915 cycle_A: 0.485 idt_A: 0.870 D_B: 0.077 G_B: 0.948 cycle_B: 2.397 idt_B: 0.159 \n",
            "End of epoch 51 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 4.676, data: 0.376) D_A: 0.141 G_A: 0.406 cycle_A: 0.811 idt_A: 0.891 D_B: 0.031 G_B: 0.352 cycle_B: 3.128 idt_B: 0.373 \n",
            "End of epoch 52 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.327, data: 0.212) D_A: 0.200 G_A: 0.677 cycle_A: 0.480 idt_A: 0.725 D_B: 0.042 G_B: 0.784 cycle_B: 1.957 idt_B: 0.161 \n",
            "End of epoch 53 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.328, data: 0.192) D_A: 0.031 G_A: 0.475 cycle_A: 0.567 idt_A: 0.957 D_B: 0.104 G_B: 0.767 cycle_B: 1.815 idt_B: 0.159 \n",
            "End of epoch 54 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.443, data: 0.249) D_A: 0.068 G_A: 0.595 cycle_A: 0.509 idt_A: 0.761 D_B: 0.036 G_B: 0.754 cycle_B: 1.817 idt_B: 0.206 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 100, time: 4.875, data: 0.326) D_A: 0.071 G_A: 0.592 cycle_A: 0.757 idt_A: 0.959 D_B: 0.113 G_B: 0.914 cycle_B: 3.118 idt_B: 0.263 \n",
            "End of epoch 56 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.315, data: 0.209) D_A: 0.106 G_A: 0.569 cycle_A: 0.512 idt_A: 1.009 D_B: 0.151 G_B: 0.595 cycle_B: 2.363 idt_B: 0.184 \n",
            "End of epoch 57 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.357, data: 0.185) D_A: 0.246 G_A: 1.359 cycle_A: 0.952 idt_A: 0.778 D_B: 0.141 G_B: 0.294 cycle_B: 2.220 idt_B: 0.306 \n",
            "End of epoch 58 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.376, data: 0.246) D_A: 0.184 G_A: 0.549 cycle_A: 0.572 idt_A: 1.120 D_B: 0.178 G_B: 0.199 cycle_B: 2.515 idt_B: 0.199 \n",
            "End of epoch 59 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 4.810, data: 0.228) D_A: 0.104 G_A: 0.426 cycle_A: 0.682 idt_A: 0.839 D_B: 0.262 G_B: 0.581 cycle_B: 1.943 idt_B: 0.287 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.357, data: 0.261) D_A: 0.236 G_A: 0.153 cycle_A: 0.727 idt_A: 0.787 D_B: 0.054 G_B: 0.313 cycle_B: 2.079 idt_B: 0.294 \n",
            "End of epoch 61 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.344, data: 0.294) D_A: 0.032 G_A: 0.316 cycle_A: 0.558 idt_A: 0.752 D_B: 0.344 G_B: 0.564 cycle_B: 1.793 idt_B: 0.262 \n",
            "End of epoch 62 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.315, data: 0.200) D_A: 0.478 G_A: 0.504 cycle_A: 0.538 idt_A: 0.575 D_B: 0.062 G_B: 0.500 cycle_B: 1.442 idt_B: 0.245 \n",
            "End of epoch 63 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 100, time: 4.999, data: 0.233) D_A: 0.165 G_A: 0.263 cycle_A: 0.804 idt_A: 0.629 D_B: 0.141 G_B: 0.401 cycle_B: 1.818 idt_B: 0.264 \n",
            "End of epoch 64 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.378, data: 0.376) D_A: 0.082 G_A: 1.111 cycle_A: 0.626 idt_A: 0.748 D_B: 0.031 G_B: 1.103 cycle_B: 2.238 idt_B: 0.197 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 200 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.312, data: 0.324) D_A: 0.084 G_A: 0.646 cycle_A: 0.533 idt_A: 0.580 D_B: 0.193 G_B: 1.042 cycle_B: 1.658 idt_B: 0.233 \n",
            "End of epoch 66 / 200 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.331, data: 0.281) D_A: 0.175 G_A: 0.199 cycle_A: 0.526 idt_A: 0.921 D_B: 0.187 G_B: 0.417 cycle_B: 2.241 idt_B: 0.231 \n",
            "End of epoch 67 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 100, time: 4.901, data: 0.275) D_A: 0.237 G_A: 0.858 cycle_A: 0.531 idt_A: 0.988 D_B: 0.019 G_B: 0.404 cycle_B: 2.305 idt_B: 0.215 \n",
            "End of epoch 68 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.348, data: 0.232) D_A: 0.032 G_A: 0.546 cycle_A: 0.804 idt_A: 0.866 D_B: 0.031 G_B: 0.644 cycle_B: 2.175 idt_B: 0.274 \n",
            "End of epoch 69 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.429, data: 0.235) D_A: 0.044 G_A: 0.667 cycle_A: 0.613 idt_A: 0.776 D_B: 0.136 G_B: 0.581 cycle_B: 1.953 idt_B: 0.213 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 200 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.318, data: 0.377) D_A: 0.185 G_A: 0.523 cycle_A: 0.620 idt_A: 0.796 D_B: 0.065 G_B: 0.629 cycle_B: 2.374 idt_B: 0.178 \n",
            "End of epoch 71 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 100, time: 4.920, data: 0.219) D_A: 0.121 G_A: 0.746 cycle_A: 0.818 idt_A: 0.666 D_B: 0.116 G_B: 0.373 cycle_B: 2.084 idt_B: 0.219 \n",
            "End of epoch 72 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.370, data: 0.232) D_A: 0.142 G_A: 0.298 cycle_A: 0.687 idt_A: 0.852 D_B: 0.115 G_B: 0.368 cycle_B: 2.222 idt_B: 0.266 \n",
            "End of epoch 73 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.399, data: 0.343) D_A: 0.117 G_A: 0.491 cycle_A: 0.583 idt_A: 0.648 D_B: 0.207 G_B: 1.010 cycle_B: 2.045 idt_B: 0.240 \n",
            "End of epoch 74 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.315, data: 0.333) D_A: 0.084 G_A: 0.308 cycle_A: 0.433 idt_A: 0.731 D_B: 0.047 G_B: 0.636 cycle_B: 2.063 idt_B: 0.149 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 100, time: 5.011, data: 0.227) D_A: 0.040 G_A: 0.529 cycle_A: 0.443 idt_A: 0.553 D_B: 0.082 G_B: 0.717 cycle_B: 1.648 idt_B: 0.155 \n",
            "End of epoch 76 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.339, data: 0.233) D_A: 0.077 G_A: 0.470 cycle_A: 0.540 idt_A: 0.869 D_B: 0.082 G_B: 0.656 cycle_B: 2.051 idt_B: 0.182 \n",
            "End of epoch 77 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.355, data: 0.370) D_A: 0.134 G_A: 0.166 cycle_A: 0.423 idt_A: 0.774 D_B: 0.043 G_B: 1.092 cycle_B: 2.051 idt_B: 0.209 \n",
            "End of epoch 78 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.316, data: 0.381) D_A: 0.231 G_A: 0.848 cycle_A: 0.644 idt_A: 0.573 D_B: 0.088 G_B: 1.798 cycle_B: 1.597 idt_B: 0.185 \n",
            "End of epoch 79 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 100, time: 5.255, data: 0.192) D_A: 0.114 G_A: 1.495 cycle_A: 0.460 idt_A: 0.783 D_B: 0.048 G_B: 0.620 cycle_B: 1.935 idt_B: 0.148 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.389, data: 0.363) D_A: 0.041 G_A: 0.664 cycle_A: 0.544 idt_A: 0.767 D_B: 0.080 G_B: 0.720 cycle_B: 2.216 idt_B: 0.209 \n",
            "End of epoch 81 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.317, data: 0.362) D_A: 0.141 G_A: 0.344 cycle_A: 0.960 idt_A: 0.977 D_B: 0.031 G_B: 0.273 cycle_B: 3.019 idt_B: 0.297 \n",
            "End of epoch 82 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.323, data: 0.186) D_A: 0.054 G_A: 0.446 cycle_A: 0.522 idt_A: 0.779 D_B: 0.085 G_B: 0.712 cycle_B: 2.056 idt_B: 0.190 \n",
            "End of epoch 83 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 100, time: 4.973, data: 0.224) D_A: 0.243 G_A: 0.147 cycle_A: 0.440 idt_A: 0.565 D_B: 0.075 G_B: 0.494 cycle_B: 2.220 idt_B: 0.170 \n",
            "End of epoch 84 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.362, data: 0.361) D_A: 0.064 G_A: 0.522 cycle_A: 0.491 idt_A: 0.742 D_B: 0.129 G_B: 0.608 cycle_B: 2.087 idt_B: 0.179 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.331, data: 0.282) D_A: 0.141 G_A: 0.303 cycle_A: 0.442 idt_A: 0.589 D_B: 0.144 G_B: 0.488 cycle_B: 1.127 idt_B: 0.149 \n",
            "End of epoch 86 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.319, data: 0.268) D_A: 0.253 G_A: 0.820 cycle_A: 0.448 idt_A: 0.704 D_B: 0.141 G_B: 0.897 cycle_B: 2.053 idt_B: 0.137 \n",
            "End of epoch 87 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 100, time: 5.564, data: 0.193) D_A: 0.081 G_A: 0.537 cycle_A: 0.589 idt_A: 0.701 D_B: 0.022 G_B: 0.829 cycle_B: 2.161 idt_B: 0.179 \n",
            "End of epoch 88 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.348, data: 0.406) D_A: 0.097 G_A: 0.878 cycle_A: 0.492 idt_A: 0.715 D_B: 0.128 G_B: 0.276 cycle_B: 1.904 idt_B: 0.168 \n",
            "End of epoch 89 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.331, data: 0.317) D_A: 0.278 G_A: 0.328 cycle_A: 0.424 idt_A: 0.721 D_B: 0.298 G_B: 2.333 cycle_B: 1.934 idt_B: 0.172 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.314, data: 0.230) D_A: 0.129 G_A: 0.656 cycle_A: 1.144 idt_A: 0.855 D_B: 0.041 G_B: 0.705 cycle_B: 1.643 idt_B: 0.286 \n",
            "End of epoch 91 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 100, time: 5.090, data: 0.216) D_A: 0.122 G_A: 0.419 cycle_A: 0.460 idt_A: 0.504 D_B: 0.258 G_B: 0.324 cycle_B: 1.310 idt_B: 0.140 \n",
            "End of epoch 92 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.325, data: 0.397) D_A: 0.048 G_A: 0.616 cycle_A: 0.599 idt_A: 0.711 D_B: 0.166 G_B: 0.287 cycle_B: 1.797 idt_B: 0.239 \n",
            "End of epoch 93 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.312, data: 0.212) D_A: 0.065 G_A: 0.234 cycle_A: 0.525 idt_A: 0.980 D_B: 0.161 G_B: 0.678 cycle_B: 2.389 idt_B: 0.161 \n",
            "End of epoch 94 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.312, data: 0.214) D_A: 0.129 G_A: 0.483 cycle_A: 0.640 idt_A: 0.454 D_B: 0.302 G_B: 1.048 cycle_B: 1.057 idt_B: 0.196 \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 100, time: 5.237, data: 0.208) D_A: 0.048 G_A: 0.245 cycle_A: 0.670 idt_A: 0.674 D_B: 0.157 G_B: 0.533 cycle_B: 1.602 idt_B: 0.215 \n",
            "End of epoch 96 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.324, data: 0.236) D_A: 0.184 G_A: 0.275 cycle_A: 0.822 idt_A: 0.465 D_B: 0.110 G_B: 0.918 cycle_B: 1.391 idt_B: 0.225 \n",
            "End of epoch 97 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.315, data: 0.222) D_A: 0.171 G_A: 0.290 cycle_A: 0.698 idt_A: 0.557 D_B: 0.068 G_B: 0.496 cycle_B: 1.797 idt_B: 0.184 \n",
            "End of epoch 98 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.315, data: 0.220) D_A: 0.689 G_A: 1.401 cycle_A: 0.653 idt_A: 0.937 D_B: 0.095 G_B: 0.393 cycle_B: 1.955 idt_B: 0.241 \n",
            "End of epoch 99 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 100, time: 5.135, data: 0.231) D_A: 0.042 G_A: 0.190 cycle_A: 0.833 idt_A: 0.736 D_B: 0.158 G_B: 1.057 cycle_B: 2.211 idt_B: 0.189 \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.318, data: 0.246) D_A: 0.056 G_A: 0.594 cycle_A: 0.403 idt_A: 0.684 D_B: 0.046 G_B: 1.183 cycle_B: 2.028 idt_B: 0.140 \n",
            "End of epoch 101 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 100, time: 0.313, data: 0.262) D_A: 0.218 G_A: 0.750 cycle_A: 0.397 idt_A: 0.805 D_B: 0.041 G_B: 0.538 cycle_B: 2.058 idt_B: 0.178 \n",
            "End of epoch 102 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 100, time: 0.364, data: 0.219) D_A: 0.072 G_A: 0.694 cycle_A: 0.511 idt_A: 0.769 D_B: 0.068 G_B: 1.124 cycle_B: 2.409 idt_B: 0.163 \n",
            "End of epoch 103 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 100, time: 5.209, data: 0.368) D_A: 0.148 G_A: 0.567 cycle_A: 0.461 idt_A: 0.482 D_B: 0.052 G_B: 0.511 cycle_B: 1.397 idt_B: 0.141 \n",
            "End of epoch 104 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 100, time: 0.309, data: 0.192) D_A: 0.244 G_A: 0.225 cycle_A: 0.480 idt_A: 0.645 D_B: 0.040 G_B: 0.675 cycle_B: 0.947 idt_B: 0.187 \n",
            "saving the model at the end of epoch 105, iters 10500\n",
            "End of epoch 105 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 100, time: 0.316, data: 0.245) D_A: 0.042 G_A: 0.366 cycle_A: 0.629 idt_A: 0.732 D_B: 0.046 G_B: 0.583 cycle_B: 1.840 idt_B: 0.209 \n",
            "End of epoch 106 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 100, time: 0.347, data: 0.204) D_A: 0.051 G_A: 0.741 cycle_A: 0.565 idt_A: 0.808 D_B: 0.187 G_B: 1.692 cycle_B: 2.025 idt_B: 0.229 \n",
            "End of epoch 107 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 100, time: 5.252, data: 0.360) D_A: 0.032 G_A: 0.725 cycle_A: 0.774 idt_A: 0.748 D_B: 0.033 G_B: 0.099 cycle_B: 2.385 idt_B: 0.322 \n",
            "End of epoch 108 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 100, time: 0.312, data: 0.215) D_A: 0.067 G_A: 0.247 cycle_A: 0.399 idt_A: 0.698 D_B: 0.047 G_B: 0.581 cycle_B: 1.729 idt_B: 0.137 \n",
            "End of epoch 109 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.318, data: 0.223) D_A: 0.231 G_A: 1.406 cycle_A: 0.804 idt_A: 0.915 D_B: 0.048 G_B: 1.230 cycle_B: 2.248 idt_B: 0.273 \n",
            "saving the model at the end of epoch 110, iters 11000\n",
            "End of epoch 110 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 100, time: 0.381, data: 0.289) D_A: 0.161 G_A: 0.283 cycle_A: 0.373 idt_A: 0.573 D_B: 0.080 G_B: 1.536 cycle_B: 2.016 idt_B: 0.145 \n",
            "End of epoch 111 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 100, time: 5.124, data: 0.419) D_A: 0.025 G_A: 0.522 cycle_A: 0.467 idt_A: 0.842 D_B: 0.102 G_B: 0.687 cycle_B: 2.355 idt_B: 0.140 \n",
            "End of epoch 112 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 100, time: 0.345, data: 0.209) D_A: 0.090 G_A: 0.490 cycle_A: 0.330 idt_A: 0.932 D_B: 0.138 G_B: 1.292 cycle_B: 1.660 idt_B: 0.128 \n",
            "End of epoch 113 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 100, time: 0.327, data: 0.243) D_A: 0.072 G_A: 0.450 cycle_A: 0.696 idt_A: 0.628 D_B: 0.090 G_B: 0.602 cycle_B: 1.349 idt_B: 0.191 \n",
            "End of epoch 114 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 100, time: 0.412, data: 0.329) D_A: 0.046 G_A: 0.730 cycle_A: 0.393 idt_A: 0.484 D_B: 0.066 G_B: 0.687 cycle_B: 1.320 idt_B: 0.109 \n",
            "saving the model at the end of epoch 115, iters 11500\n",
            "End of epoch 115 / 200 \t Time Taken: 36 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 100, time: 5.250, data: 0.287) D_A: 0.059 G_A: 0.642 cycle_A: 0.510 idt_A: 0.795 D_B: 0.142 G_B: 0.255 cycle_B: 2.258 idt_B: 0.167 \n",
            "End of epoch 116 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 100, time: 0.363, data: 0.248) D_A: 0.030 G_A: 0.823 cycle_A: 0.502 idt_A: 0.639 D_B: 0.121 G_B: 0.969 cycle_B: 1.616 idt_B: 0.160 \n",
            "End of epoch 117 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 100, time: 0.352, data: 0.362) D_A: 0.250 G_A: 0.235 cycle_A: 0.496 idt_A: 0.586 D_B: 0.161 G_B: 0.336 cycle_B: 1.677 idt_B: 0.184 \n",
            "End of epoch 118 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 100, time: 0.326, data: 0.338) D_A: 0.051 G_A: 0.421 cycle_A: 0.561 idt_A: 0.589 D_B: 0.095 G_B: 0.695 cycle_B: 1.567 idt_B: 0.168 \n",
            "End of epoch 119 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 100, time: 5.533, data: 0.227) D_A: 0.143 G_A: 0.749 cycle_A: 0.443 idt_A: 0.615 D_B: 0.086 G_B: 0.651 cycle_B: 1.603 idt_B: 0.123 \n",
            "saving the model at the end of epoch 120, iters 12000\n",
            "End of epoch 120 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 100, time: 0.355, data: 0.404) D_A: 0.188 G_A: 0.739 cycle_A: 0.715 idt_A: 0.618 D_B: 0.137 G_B: 0.651 cycle_B: 1.672 idt_B: 0.289 \n",
            "End of epoch 121 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 100, time: 0.321, data: 0.346) D_A: 0.102 G_A: 0.451 cycle_A: 0.509 idt_A: 0.618 D_B: 0.104 G_B: 0.335 cycle_B: 1.119 idt_B: 0.167 \n",
            "End of epoch 122 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 100, time: 0.321, data: 0.242) D_A: 0.449 G_A: 1.796 cycle_A: 0.403 idt_A: 0.579 D_B: 0.022 G_B: 0.777 cycle_B: 1.658 idt_B: 0.131 \n",
            "End of epoch 123 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 100, time: 5.490, data: 0.202) D_A: 0.109 G_A: 0.572 cycle_A: 0.423 idt_A: 0.732 D_B: 0.034 G_B: 1.054 cycle_B: 1.872 idt_B: 0.119 \n",
            "End of epoch 124 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 100, time: 0.334, data: 0.351) D_A: 0.153 G_A: 0.411 cycle_A: 0.943 idt_A: 0.487 D_B: 0.031 G_B: 0.673 cycle_B: 1.202 idt_B: 0.204 \n",
            "saving the model at the end of epoch 125, iters 12500\n",
            "End of epoch 125 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 100, time: 0.324, data: 0.266) D_A: 0.167 G_A: 1.008 cycle_A: 0.761 idt_A: 0.666 D_B: 0.151 G_B: 0.590 cycle_B: 1.806 idt_B: 0.310 \n",
            "End of epoch 126 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 100, time: 0.316, data: 0.259) D_A: 0.280 G_A: 0.938 cycle_A: 0.443 idt_A: 0.445 D_B: 0.242 G_B: 0.171 cycle_B: 1.488 idt_B: 0.131 \n",
            "End of epoch 127 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 100, time: 5.608, data: 0.232) D_A: 0.092 G_A: 0.357 cycle_A: 0.533 idt_A: 0.461 D_B: 0.126 G_B: 0.325 cycle_B: 1.451 idt_B: 0.136 \n",
            "End of epoch 128 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 100, time: 0.311, data: 0.339) D_A: 0.200 G_A: 0.224 cycle_A: 0.638 idt_A: 0.332 D_B: 0.073 G_B: 0.900 cycle_B: 1.034 idt_B: 0.207 \n",
            "End of epoch 129 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 100, time: 0.320, data: 0.209) D_A: 0.025 G_A: 0.185 cycle_A: 0.536 idt_A: 0.383 D_B: 0.017 G_B: 0.774 cycle_B: 1.142 idt_B: 0.184 \n",
            "saving the model at the end of epoch 130, iters 13000\n",
            "End of epoch 130 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 100, time: 0.314, data: 0.228) D_A: 0.136 G_A: 0.404 cycle_A: 0.430 idt_A: 0.548 D_B: 0.065 G_B: 1.017 cycle_B: 1.364 idt_B: 0.157 \n",
            "End of epoch 131 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 100, time: 5.769, data: 0.233) D_A: 0.047 G_A: 0.698 cycle_A: 0.353 idt_A: 0.557 D_B: 0.011 G_B: 0.888 cycle_B: 1.499 idt_B: 0.129 \n",
            "End of epoch 132 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 100, time: 0.313, data: 0.301) D_A: 0.049 G_A: 0.374 cycle_A: 0.390 idt_A: 0.547 D_B: 0.076 G_B: 0.435 cycle_B: 1.292 idt_B: 0.147 \n",
            "End of epoch 133 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 100, time: 0.335, data: 0.234) D_A: 0.045 G_A: 0.873 cycle_A: 0.515 idt_A: 0.434 D_B: 0.035 G_B: 0.596 cycle_B: 1.313 idt_B: 0.279 \n",
            "End of epoch 134 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 100, time: 0.306, data: 0.205) D_A: 0.184 G_A: 0.332 cycle_A: 0.636 idt_A: 0.955 D_B: 0.097 G_B: 0.644 cycle_B: 2.182 idt_B: 0.125 \n",
            "saving the model at the end of epoch 135, iters 13500\n",
            "End of epoch 135 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 100, time: 5.513, data: 0.256) D_A: 0.118 G_A: 0.398 cycle_A: 0.499 idt_A: 0.657 D_B: 0.012 G_B: 0.747 cycle_B: 1.686 idt_B: 0.187 \n",
            "End of epoch 136 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 100, time: 0.314, data: 0.261) D_A: 0.029 G_A: 0.619 cycle_A: 0.327 idt_A: 0.421 D_B: 0.020 G_B: 1.309 cycle_B: 1.187 idt_B: 0.099 \n",
            "End of epoch 137 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 100, time: 0.335, data: 0.172) D_A: 0.168 G_A: 0.594 cycle_A: 0.577 idt_A: 0.696 D_B: 0.027 G_B: 0.861 cycle_B: 1.768 idt_B: 0.170 \n",
            "End of epoch 138 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 100, time: 0.316, data: 0.208) D_A: 0.088 G_A: 0.314 cycle_A: 0.451 idt_A: 0.569 D_B: 0.021 G_B: 0.951 cycle_B: 1.580 idt_B: 0.135 \n",
            "End of epoch 139 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 100, time: 6.464, data: 0.278) D_A: 0.107 G_A: 0.524 cycle_A: 0.515 idt_A: 0.745 D_B: 0.096 G_B: 1.708 cycle_B: 1.803 idt_B: 0.199 \n",
            "saving the model at the end of epoch 140, iters 14000\n",
            "End of epoch 140 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 0.324, data: 0.283) D_A: 0.094 G_A: 0.654 cycle_A: 0.636 idt_A: 0.458 D_B: 0.041 G_B: 0.648 cycle_B: 1.230 idt_B: 0.223 \n",
            "End of epoch 141 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 100, time: 0.324, data: 0.255) D_A: 0.165 G_A: 0.316 cycle_A: 0.925 idt_A: 0.559 D_B: 0.054 G_B: 0.307 cycle_B: 1.417 idt_B: 0.358 \n",
            "End of epoch 142 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 100, time: 0.389, data: 0.321) D_A: 0.063 G_A: 0.654 cycle_A: 0.409 idt_A: 0.706 D_B: 0.039 G_B: 0.708 cycle_B: 1.028 idt_B: 0.143 \n",
            "End of epoch 143 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 100, time: 5.508, data: 0.330) D_A: 0.131 G_A: 0.337 cycle_A: 0.319 idt_A: 0.900 D_B: 0.011 G_B: 0.466 cycle_B: 2.151 idt_B: 0.115 \n",
            "End of epoch 144 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 100, time: 0.316, data: 0.217) D_A: 0.085 G_A: 0.740 cycle_A: 0.379 idt_A: 0.711 D_B: 0.014 G_B: 1.515 cycle_B: 1.772 idt_B: 0.142 \n",
            "saving the model at the end of epoch 145, iters 14500\n",
            "End of epoch 145 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 100, time: 0.346, data: 0.240) D_A: 0.072 G_A: 0.487 cycle_A: 0.523 idt_A: 0.853 D_B: 0.036 G_B: 0.594 cycle_B: 2.081 idt_B: 0.186 \n",
            "End of epoch 146 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 100, time: 0.358, data: 0.388) D_A: 0.061 G_A: 0.600 cycle_A: 0.300 idt_A: 0.732 D_B: 0.027 G_B: 0.416 cycle_B: 2.021 idt_B: 0.089 \n",
            "End of epoch 147 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 100, time: 5.535, data: 0.274) D_A: 0.098 G_A: 0.700 cycle_A: 0.414 idt_A: 0.722 D_B: 0.024 G_B: 0.946 cycle_B: 1.860 idt_B: 0.137 \n",
            "End of epoch 148 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 100, time: 0.334, data: 0.216) D_A: 0.136 G_A: 0.325 cycle_A: 0.311 idt_A: 0.535 D_B: 0.019 G_B: 0.953 cycle_B: 1.335 idt_B: 0.099 \n",
            "End of epoch 149 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 100, time: 0.358, data: 0.333) D_A: 0.013 G_A: 0.299 cycle_A: 0.516 idt_A: 0.466 D_B: 0.022 G_B: 1.334 cycle_B: 1.308 idt_B: 0.122 \n",
            "saving the latest model (epoch 150, total_iters 15000)\n",
            "saving the model at the end of epoch 150, iters 15000\n",
            "End of epoch 150 / 200 \t Time Taken: 36 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 100, time: 0.316, data: 0.275) D_A: 0.135 G_A: 0.585 cycle_A: 0.712 idt_A: 0.426 D_B: 0.042 G_B: 0.575 cycle_B: 1.522 idt_B: 0.254 \n",
            "End of epoch 151 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 100, time: 5.653, data: 0.267) D_A: 0.022 G_A: 0.329 cycle_A: 0.577 idt_A: 0.497 D_B: 0.010 G_B: 1.663 cycle_B: 1.485 idt_B: 0.181 \n",
            "End of epoch 152 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 100, time: 0.352, data: 0.308) D_A: 0.064 G_A: 0.635 cycle_A: 0.350 idt_A: 0.617 D_B: 0.083 G_B: 0.909 cycle_B: 1.240 idt_B: 0.085 \n",
            "End of epoch 153 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 100, time: 0.377, data: 0.344) D_A: 0.045 G_A: 0.561 cycle_A: 0.436 idt_A: 0.648 D_B: 0.040 G_B: 0.623 cycle_B: 1.902 idt_B: 0.117 \n",
            "End of epoch 154 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 100, time: 0.313, data: 0.225) D_A: 0.049 G_A: 0.290 cycle_A: 0.453 idt_A: 0.619 D_B: 0.014 G_B: 0.914 cycle_B: 1.448 idt_B: 0.129 \n",
            "saving the model at the end of epoch 155, iters 15500\n",
            "End of epoch 155 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 100, time: 6.080, data: 0.255) D_A: 0.143 G_A: 0.377 cycle_A: 0.373 idt_A: 0.420 D_B: 0.083 G_B: 0.393 cycle_B: 1.123 idt_B: 0.125 \n",
            "End of epoch 156 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 100, time: 0.345, data: 0.295) D_A: 0.029 G_A: 0.731 cycle_A: 0.731 idt_A: 0.366 D_B: 0.013 G_B: 0.992 cycle_B: 1.144 idt_B: 0.264 \n",
            "End of epoch 157 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 100, time: 0.320, data: 0.348) D_A: 0.043 G_A: 0.317 cycle_A: 1.305 idt_A: 0.543 D_B: 0.067 G_B: 0.518 cycle_B: 1.369 idt_B: 0.415 \n",
            "End of epoch 158 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 100, time: 0.344, data: 0.229) D_A: 0.058 G_A: 0.602 cycle_A: 0.355 idt_A: 0.821 D_B: 0.019 G_B: 0.812 cycle_B: 2.031 idt_B: 0.133 \n",
            "End of epoch 159 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 5.767, data: 0.240) D_A: 0.116 G_A: 0.389 cycle_A: 0.355 idt_A: 0.398 D_B: 0.015 G_B: 0.931 cycle_B: 1.555 idt_B: 0.109 \n",
            "saving the model at the end of epoch 160, iters 16000\n",
            "End of epoch 160 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 100, time: 0.314, data: 0.320) D_A: 0.177 G_A: 0.577 cycle_A: 0.595 idt_A: 0.559 D_B: 0.234 G_B: 0.129 cycle_B: 1.470 idt_B: 0.215 \n",
            "End of epoch 161 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 100, time: 0.318, data: 0.254) D_A: 0.057 G_A: 0.529 cycle_A: 0.380 idt_A: 0.443 D_B: 0.010 G_B: 1.193 cycle_B: 0.884 idt_B: 0.199 \n",
            "End of epoch 162 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 100, time: 0.324, data: 0.214) D_A: 0.119 G_A: 0.879 cycle_A: 0.421 idt_A: 0.439 D_B: 0.014 G_B: 1.095 cycle_B: 1.552 idt_B: 0.155 \n",
            "End of epoch 163 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 100, time: 5.831, data: 0.240) D_A: 0.179 G_A: 0.619 cycle_A: 0.291 idt_A: 0.514 D_B: 0.045 G_B: 0.689 cycle_B: 1.422 idt_B: 0.102 \n",
            "End of epoch 164 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 100, time: 0.340, data: 0.250) D_A: 0.027 G_A: 0.958 cycle_A: 0.440 idt_A: 0.592 D_B: 0.084 G_B: 0.422 cycle_B: 1.523 idt_B: 0.138 \n",
            "saving the model at the end of epoch 165, iters 16500\n",
            "End of epoch 165 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 0.333, data: 0.275) D_A: 0.086 G_A: 0.531 cycle_A: 0.605 idt_A: 0.535 D_B: 0.031 G_B: 0.774 cycle_B: 1.547 idt_B: 0.159 \n",
            "End of epoch 166 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 100, time: 0.315, data: 0.203) D_A: 0.044 G_A: 0.626 cycle_A: 0.552 idt_A: 0.551 D_B: 0.049 G_B: 0.619 cycle_B: 1.332 idt_B: 0.232 \n",
            "End of epoch 167 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 100, time: 5.513, data: 0.310) D_A: 0.033 G_A: 0.814 cycle_A: 0.501 idt_A: 0.679 D_B: 0.057 G_B: 1.193 cycle_B: 1.983 idt_B: 0.192 \n",
            "End of epoch 168 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 100, time: 0.335, data: 0.208) D_A: 0.082 G_A: 0.461 cycle_A: 0.518 idt_A: 0.422 D_B: 0.094 G_B: 1.814 cycle_B: 1.147 idt_B: 0.166 \n",
            "End of epoch 169 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 100, time: 0.305, data: 0.209) D_A: 0.150 G_A: 0.362 cycle_A: 0.326 idt_A: 0.641 D_B: 0.049 G_B: 0.450 cycle_B: 1.905 idt_B: 0.119 \n",
            "saving the model at the end of epoch 170, iters 17000\n",
            "End of epoch 170 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 100, time: 0.391, data: 0.295) D_A: 0.142 G_A: 0.418 cycle_A: 0.361 idt_A: 0.381 D_B: 0.023 G_B: 0.784 cycle_B: 1.030 idt_B: 0.148 \n",
            "End of epoch 171 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 100, time: 5.590, data: 0.401) D_A: 0.030 G_A: 0.992 cycle_A: 0.355 idt_A: 0.720 D_B: 0.020 G_B: 0.777 cycle_B: 1.836 idt_B: 0.124 \n",
            "End of epoch 172 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 100, time: 0.320, data: 0.260) D_A: 0.104 G_A: 0.383 cycle_A: 0.370 idt_A: 0.308 D_B: 0.082 G_B: 1.034 cycle_B: 0.884 idt_B: 0.156 \n",
            "End of epoch 173 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 100, time: 0.339, data: 0.291) D_A: 0.024 G_A: 0.660 cycle_A: 0.452 idt_A: 0.649 D_B: 0.031 G_B: 0.629 cycle_B: 1.749 idt_B: 0.158 \n",
            "End of epoch 174 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 100, time: 0.339, data: 0.344) D_A: 0.036 G_A: 0.698 cycle_A: 0.298 idt_A: 0.702 D_B: 0.051 G_B: 1.111 cycle_B: 1.704 idt_B: 0.103 \n",
            "saving the model at the end of epoch 175, iters 17500\n",
            "End of epoch 175 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 100, time: 5.547, data: 0.355) D_A: 0.090 G_A: 0.433 cycle_A: 0.516 idt_A: 0.497 D_B: 0.029 G_B: 1.277 cycle_B: 1.364 idt_B: 0.193 \n",
            "End of epoch 176 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 100, time: 0.315, data: 0.273) D_A: 0.090 G_A: 0.524 cycle_A: 0.419 idt_A: 0.588 D_B: 0.108 G_B: 1.219 cycle_B: 1.605 idt_B: 0.117 \n",
            "End of epoch 177 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 100, time: 0.380, data: 0.234) D_A: 0.021 G_A: 0.757 cycle_A: 0.374 idt_A: 0.459 D_B: 0.067 G_B: 0.436 cycle_B: 1.294 idt_B: 0.131 \n",
            "End of epoch 178 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 100, time: 0.370, data: 0.345) D_A: 0.085 G_A: 0.439 cycle_A: 0.562 idt_A: 0.605 D_B: 0.018 G_B: 0.841 cycle_B: 1.872 idt_B: 0.188 \n",
            "End of epoch 179 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 100, time: 5.669, data: 0.339) D_A: 0.216 G_A: 0.291 cycle_A: 0.470 idt_A: 0.431 D_B: 0.116 G_B: 1.684 cycle_B: 0.961 idt_B: 0.165 \n",
            "saving the model at the end of epoch 180, iters 18000\n",
            "End of epoch 180 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 100, time: 0.349, data: 0.272) D_A: 0.037 G_A: 0.657 cycle_A: 1.511 idt_A: 0.568 D_B: 0.010 G_B: 0.902 cycle_B: 1.425 idt_B: 0.139 \n",
            "End of epoch 181 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 100, time: 0.376, data: 0.384) D_A: 0.043 G_A: 0.336 cycle_A: 0.516 idt_A: 0.500 D_B: 0.046 G_B: 1.161 cycle_B: 1.472 idt_B: 0.180 \n",
            "End of epoch 182 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 100, time: 0.318, data: 0.347) D_A: 0.063 G_A: 0.456 cycle_A: 0.335 idt_A: 0.453 D_B: 0.012 G_B: 0.669 cycle_B: 1.072 idt_B: 0.085 \n",
            "End of epoch 183 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 100, time: 6.065, data: 0.292) D_A: 0.031 G_A: 0.494 cycle_A: 0.387 idt_A: 0.373 D_B: 0.068 G_B: 0.443 cycle_B: 0.951 idt_B: 0.100 \n",
            "End of epoch 184 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 100, time: 0.357, data: 0.243) D_A: 0.093 G_A: 0.422 cycle_A: 0.369 idt_A: 0.523 D_B: 0.020 G_B: 0.896 cycle_B: 1.323 idt_B: 0.133 \n",
            "saving the model at the end of epoch 185, iters 18500\n",
            "End of epoch 185 / 200 \t Time Taken: 35 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 100, time: 0.303, data: 0.440) D_A: 0.031 G_A: 0.333 cycle_A: 0.299 idt_A: 0.771 D_B: 0.018 G_B: 0.765 cycle_B: 1.914 idt_B: 0.084 \n",
            "End of epoch 186 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 100, time: 0.305, data: 0.221) D_A: 0.184 G_A: 0.321 cycle_A: 0.505 idt_A: 0.526 D_B: 0.022 G_B: 0.735 cycle_B: 1.377 idt_B: 0.187 \n",
            "End of epoch 187 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 100, time: 5.593, data: 0.295) D_A: 0.110 G_A: 0.696 cycle_A: 0.356 idt_A: 0.491 D_B: 0.045 G_B: 1.128 cycle_B: 1.342 idt_B: 0.138 \n",
            "End of epoch 188 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 100, time: 0.352, data: 0.365) D_A: 0.056 G_A: 0.676 cycle_A: 0.352 idt_A: 0.289 D_B: 0.021 G_B: 0.476 cycle_B: 0.766 idt_B: 0.103 \n",
            "End of epoch 189 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 100, time: 0.317, data: 0.331) D_A: 0.068 G_A: 0.480 cycle_A: 0.408 idt_A: 0.294 D_B: 0.047 G_B: 1.047 cycle_B: 0.754 idt_B: 0.129 \n",
            "saving the model at the end of epoch 190, iters 19000\n",
            "End of epoch 190 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 0.319, data: 0.271) D_A: 0.052 G_A: 0.443 cycle_A: 0.475 idt_A: 0.597 D_B: 0.057 G_B: 1.053 cycle_B: 1.675 idt_B: 0.149 \n",
            "End of epoch 191 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 100, time: 6.428, data: 0.200) D_A: 0.079 G_A: 0.474 cycle_A: 0.411 idt_A: 0.532 D_B: 0.016 G_B: 0.749 cycle_B: 1.184 idt_B: 0.147 \n",
            "End of epoch 192 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 100, time: 0.334, data: 0.240) D_A: 0.087 G_A: 0.610 cycle_A: 0.298 idt_A: 0.288 D_B: 0.024 G_B: 0.682 cycle_B: 0.904 idt_B: 0.087 \n",
            "End of epoch 193 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 100, time: 0.331, data: 0.251) D_A: 0.103 G_A: 0.348 cycle_A: 0.351 idt_A: 0.309 D_B: 0.040 G_B: 0.947 cycle_B: 0.885 idt_B: 0.093 \n",
            "End of epoch 194 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 100, time: 0.322, data: 0.248) D_A: 0.054 G_A: 0.606 cycle_A: 0.308 idt_A: 0.459 D_B: 0.056 G_B: 1.425 cycle_B: 1.371 idt_B: 0.104 \n",
            "saving the model at the end of epoch 195, iters 19500\n",
            "End of epoch 195 / 200 \t Time Taken: 34 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 100, time: 2.416, data: 0.384) D_A: 0.143 G_A: 0.415 cycle_A: 0.339 idt_A: 0.325 D_B: 0.095 G_B: 0.865 cycle_B: 0.841 idt_B: 0.094 \n",
            "End of epoch 196 / 200 \t Time Taken: 37 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 100, time: 0.316, data: 0.273) D_A: 0.046 G_A: 0.989 cycle_A: 0.375 idt_A: 0.549 D_B: 0.076 G_B: 0.828 cycle_B: 1.464 idt_B: 0.084 \n",
            "End of epoch 197 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 100, time: 0.319, data: 0.253) D_A: 0.071 G_A: 0.680 cycle_A: 0.330 idt_A: 0.454 D_B: 0.037 G_B: 0.590 cycle_B: 1.118 idt_B: 0.088 \n",
            "End of epoch 198 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 100, time: 0.336, data: 0.213) D_A: 0.175 G_A: 1.299 cycle_A: 0.500 idt_A: 0.421 D_B: 0.011 G_B: 0.679 cycle_B: 0.885 idt_B: 0.173 \n",
            "End of epoch 199 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 100, time: 2.131, data: 0.198) D_A: 0.030 G_A: 0.757 cycle_A: 0.421 idt_A: 0.709 D_B: 0.042 G_B: 0.882 cycle_B: 1.872 idt_B: 0.147 \n",
            "saving the latest model (epoch 200, total_iters 20000)\n",
            "saving the model at the end of epoch 200, iters 20000\n",
            "End of epoch 200 / 200 \t Time Taken: 37 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2473, 0.2508, 0.2508, 0.2511],\n",
            "        [0.2464, 0.2508, 0.2506, 0.2523],\n",
            "        [0.2462, 0.2511, 0.2509, 0.2517],\n",
            "        [0.2465, 0.2511, 0.2510, 0.2514],\n",
            "        [0.2467, 0.2508, 0.2508, 0.2517]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2449, 0.2515, 0.2516, 0.2521],\n",
            "        [0.2429, 0.2517, 0.2512, 0.2542],\n",
            "        [0.2429, 0.2521, 0.2517, 0.2532],\n",
            "        [0.2432, 0.2523, 0.2520, 0.2525],\n",
            "        [0.2431, 0.2519, 0.2517, 0.2533]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2425, 0.2522, 0.2522, 0.2532],\n",
            "        [0.2398, 0.2524, 0.2517, 0.2561],\n",
            "        [0.2399, 0.2529, 0.2522, 0.2550],\n",
            "        [0.2404, 0.2532, 0.2526, 0.2538],\n",
            "        [0.2402, 0.2526, 0.2523, 0.2548]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2405, 0.2528, 0.2527, 0.2540],\n",
            "        [0.2375, 0.2527, 0.2518, 0.2580],\n",
            "        [0.2372, 0.2536, 0.2527, 0.2565],\n",
            "        [0.2377, 0.2539, 0.2533, 0.2551],\n",
            "        [0.2376, 0.2532, 0.2528, 0.2564]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2386, 0.2534, 0.2533, 0.2547],\n",
            "        [0.2358, 0.2529, 0.2519, 0.2594],\n",
            "        [0.2354, 0.2539, 0.2528, 0.2578],\n",
            "        [0.2361, 0.2542, 0.2534, 0.2562],\n",
            "        [0.2360, 0.2535, 0.2530, 0.2576]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2370, 0.2538, 0.2537, 0.2554],\n",
            "        [0.2340, 0.2531, 0.2519, 0.2610],\n",
            "        [0.2333, 0.2544, 0.2531, 0.2592],\n",
            "        [0.2341, 0.2547, 0.2537, 0.2575],\n",
            "        [0.2337, 0.2539, 0.2532, 0.2591]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2351, 0.2544, 0.2542, 0.2563],\n",
            "        [0.2316, 0.2535, 0.2522, 0.2628],\n",
            "        [0.2309, 0.2550, 0.2535, 0.2606],\n",
            "        [0.2322, 0.2551, 0.2540, 0.2587],\n",
            "        [0.2319, 0.2541, 0.2534, 0.2606]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2333, 0.2549, 0.2546, 0.2572],\n",
            "        [0.2292, 0.2538, 0.2522, 0.2648],\n",
            "        [0.2285, 0.2554, 0.2537, 0.2624],\n",
            "        [0.2295, 0.2560, 0.2546, 0.2600],\n",
            "        [0.2294, 0.2547, 0.2538, 0.2622]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2309, 0.2556, 0.2554, 0.2581],\n",
            "        [0.2262, 0.2544, 0.2525, 0.2669],\n",
            "        [0.2254, 0.2562, 0.2543, 0.2641],\n",
            "        [0.2261, 0.2572, 0.2556, 0.2611],\n",
            "        [0.2261, 0.2556, 0.2546, 0.2637]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2290, 0.2563, 0.2559, 0.2587],\n",
            "        [0.2244, 0.2545, 0.2524, 0.2687],\n",
            "        [0.2234, 0.2566, 0.2545, 0.2655],\n",
            "        [0.2245, 0.2575, 0.2557, 0.2624],\n",
            "        [0.2240, 0.2561, 0.2549, 0.2650]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2267, 0.2570, 0.2565, 0.2598],\n",
            "        [0.2216, 0.2548, 0.2526, 0.2710],\n",
            "        [0.2208, 0.2571, 0.2547, 0.2674],\n",
            "        [0.2217, 0.2581, 0.2561, 0.2640],\n",
            "        [0.2212, 0.2566, 0.2553, 0.2669]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2255, 0.2574, 0.2569, 0.2603],\n",
            "        [0.2203, 0.2547, 0.2523, 0.2727],\n",
            "        [0.2193, 0.2571, 0.2546, 0.2690],\n",
            "        [0.2201, 0.2584, 0.2562, 0.2654],\n",
            "        [0.2198, 0.2566, 0.2551, 0.2685]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2237, 0.2579, 0.2573, 0.2611],\n",
            "        [0.2182, 0.2550, 0.2523, 0.2745],\n",
            "        [0.2170, 0.2576, 0.2549, 0.2704],\n",
            "        [0.2180, 0.2589, 0.2565, 0.2665],\n",
            "        [0.2178, 0.2568, 0.2553, 0.2701]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2222, 0.2584, 0.2577, 0.2616],\n",
            "        [0.2167, 0.2551, 0.2522, 0.2760],\n",
            "        [0.2157, 0.2577, 0.2547, 0.2719],\n",
            "        [0.2164, 0.2592, 0.2566, 0.2677],\n",
            "        [0.2159, 0.2573, 0.2555, 0.2713]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2199, 0.2592, 0.2584, 0.2625],\n",
            "        [0.2143, 0.2553, 0.2522, 0.2782],\n",
            "        [0.2130, 0.2582, 0.2550, 0.2738],\n",
            "        [0.2136, 0.2600, 0.2570, 0.2694],\n",
            "        [0.2132, 0.2578, 0.2559, 0.2732]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2182, 0.2597, 0.2588, 0.2633],\n",
            "        [0.2123, 0.2555, 0.2521, 0.2801],\n",
            "        [0.2112, 0.2583, 0.2549, 0.2756],\n",
            "        [0.2119, 0.2602, 0.2571, 0.2709],\n",
            "        [0.2112, 0.2580, 0.2559, 0.2748]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2167, 0.2602, 0.2592, 0.2639],\n",
            "        [0.2108, 0.2554, 0.2518, 0.2819],\n",
            "        [0.2095, 0.2584, 0.2548, 0.2773],\n",
            "        [0.2102, 0.2604, 0.2571, 0.2723],\n",
            "        [0.2096, 0.2581, 0.2558, 0.2765]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2156, 0.2605, 0.2593, 0.2647],\n",
            "        [0.2093, 0.2553, 0.2515, 0.2839],\n",
            "        [0.2079, 0.2584, 0.2547, 0.2790],\n",
            "        [0.2087, 0.2606, 0.2570, 0.2737],\n",
            "        [0.2078, 0.2581, 0.2557, 0.2783]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2132, 0.2613, 0.2600, 0.2656],\n",
            "        [0.2068, 0.2554, 0.2514, 0.2864],\n",
            "        [0.2054, 0.2588, 0.2548, 0.2810],\n",
            "        [0.2062, 0.2611, 0.2573, 0.2754],\n",
            "        [0.2056, 0.2582, 0.2557, 0.2805]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2117, 0.2618, 0.2604, 0.2662],\n",
            "        [0.2053, 0.2555, 0.2513, 0.2879],\n",
            "        [0.2037, 0.2589, 0.2547, 0.2826],\n",
            "        [0.2045, 0.2615, 0.2575, 0.2766],\n",
            "        [0.2037, 0.2585, 0.2559, 0.2818]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2104, 0.2622, 0.2607, 0.2667],\n",
            "        [0.2039, 0.2555, 0.2511, 0.2896],\n",
            "        [0.2022, 0.2591, 0.2547, 0.2841],\n",
            "        [0.2029, 0.2617, 0.2575, 0.2780],\n",
            "        [0.2020, 0.2588, 0.2560, 0.2832]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2094, 0.2625, 0.2609, 0.2672],\n",
            "        [0.2025, 0.2556, 0.2510, 0.2910],\n",
            "        [0.2009, 0.2591, 0.2546, 0.2854],\n",
            "        [0.2017, 0.2619, 0.2575, 0.2789],\n",
            "        [0.2008, 0.2588, 0.2560, 0.2843]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2081, 0.2628, 0.2611, 0.2680],\n",
            "        [0.2009, 0.2555, 0.2507, 0.2930],\n",
            "        [0.1993, 0.2591, 0.2544, 0.2872],\n",
            "        [0.2000, 0.2621, 0.2575, 0.2803],\n",
            "        [0.1989, 0.2591, 0.2561, 0.2859]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2069, 0.2631, 0.2612, 0.2688],\n",
            "        [0.1993, 0.2553, 0.2503, 0.2951],\n",
            "        [0.1975, 0.2590, 0.2542, 0.2893],\n",
            "        [0.1982, 0.2623, 0.2575, 0.2819],\n",
            "        [0.1971, 0.2591, 0.2559, 0.2878]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2051, 0.2636, 0.2617, 0.2696],\n",
            "        [0.1977, 0.2552, 0.2500, 0.2970],\n",
            "        [0.1960, 0.2590, 0.2540, 0.2910],\n",
            "        [0.1968, 0.2624, 0.2575, 0.2834],\n",
            "        [0.1958, 0.2590, 0.2558, 0.2894]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2038, 0.2641, 0.2620, 0.2702],\n",
            "        [0.1961, 0.2552, 0.2498, 0.2989],\n",
            "        [0.1944, 0.2590, 0.2539, 0.2927],\n",
            "        [0.1952, 0.2626, 0.2573, 0.2849],\n",
            "        [0.1942, 0.2590, 0.2556, 0.2913]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2030, 0.2642, 0.2620, 0.2708],\n",
            "        [0.1949, 0.2551, 0.2496, 0.3004],\n",
            "        [0.1935, 0.2589, 0.2537, 0.2940],\n",
            "        [0.1942, 0.2625, 0.2572, 0.2861],\n",
            "        [0.1931, 0.2588, 0.2554, 0.2927]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2016, 0.2646, 0.2622, 0.2716],\n",
            "        [0.1935, 0.2549, 0.2491, 0.3026],\n",
            "        [0.1920, 0.2586, 0.2533, 0.2961],\n",
            "        [0.1927, 0.2625, 0.2570, 0.2878],\n",
            "        [0.1915, 0.2587, 0.2551, 0.2946]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2006, 0.2648, 0.2623, 0.2723],\n",
            "        [0.1922, 0.2547, 0.2488, 0.3044],\n",
            "        [0.1907, 0.2586, 0.2531, 0.2977],\n",
            "        [0.1914, 0.2625, 0.2568, 0.2893],\n",
            "        [0.1899, 0.2588, 0.2551, 0.2962]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1997, 0.2650, 0.2624, 0.2729],\n",
            "        [0.1912, 0.2543, 0.2483, 0.3062],\n",
            "        [0.1895, 0.2584, 0.2528, 0.2993],\n",
            "        [0.1904, 0.2624, 0.2566, 0.2906],\n",
            "        [0.1887, 0.2585, 0.2548, 0.2980]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1985, 0.2653, 0.2626, 0.2735],\n",
            "        [0.1897, 0.2542, 0.2480, 0.3081],\n",
            "        [0.1879, 0.2585, 0.2526, 0.3010],\n",
            "        [0.1885, 0.2629, 0.2568, 0.2918],\n",
            "        [0.1869, 0.2588, 0.2549, 0.2995]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1974, 0.2658, 0.2630, 0.2739],\n",
            "        [0.1888, 0.2541, 0.2477, 0.3094],\n",
            "        [0.1868, 0.2584, 0.2525, 0.3023],\n",
            "        [0.1873, 0.2630, 0.2567, 0.2930],\n",
            "        [0.1853, 0.2590, 0.2550, 0.3008]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1962, 0.2662, 0.2632, 0.2744],\n",
            "        [0.1873, 0.2539, 0.2474, 0.3113],\n",
            "        [0.1852, 0.2585, 0.2524, 0.3039],\n",
            "        [0.1859, 0.2630, 0.2565, 0.2946],\n",
            "        [0.1837, 0.2590, 0.2548, 0.3025]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1948, 0.2666, 0.2635, 0.2752],\n",
            "        [0.1855, 0.2538, 0.2471, 0.3136],\n",
            "        [0.1834, 0.2585, 0.2522, 0.3058],\n",
            "        [0.1841, 0.2632, 0.2566, 0.2961],\n",
            "        [0.1819, 0.2590, 0.2547, 0.3044]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1936, 0.2670, 0.2638, 0.2756],\n",
            "        [0.1843, 0.2535, 0.2467, 0.3155],\n",
            "        [0.1822, 0.2584, 0.2520, 0.3075],\n",
            "        [0.1828, 0.2632, 0.2563, 0.2976],\n",
            "        [0.1806, 0.2588, 0.2544, 0.3062]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1925, 0.2673, 0.2640, 0.2763],\n",
            "        [0.1829, 0.2534, 0.2465, 0.3172],\n",
            "        [0.1808, 0.2584, 0.2518, 0.3090],\n",
            "        [0.1814, 0.2635, 0.2564, 0.2988],\n",
            "        [0.1793, 0.2588, 0.2543, 0.3076]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1917, 0.2676, 0.2642, 0.2766],\n",
            "        [0.1821, 0.2532, 0.2461, 0.3186],\n",
            "        [0.1798, 0.2583, 0.2516, 0.3103],\n",
            "        [0.1805, 0.2634, 0.2562, 0.2999],\n",
            "        [0.1782, 0.2588, 0.2542, 0.3089]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1907, 0.2678, 0.2643, 0.2771],\n",
            "        [0.1808, 0.2530, 0.2458, 0.3204],\n",
            "        [0.1787, 0.2582, 0.2513, 0.3118],\n",
            "        [0.1793, 0.2635, 0.2560, 0.3012],\n",
            "        [0.1769, 0.2587, 0.2539, 0.3106]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1895, 0.2682, 0.2646, 0.2777],\n",
            "        [0.1795, 0.2528, 0.2454, 0.3224],\n",
            "        [0.1771, 0.2581, 0.2511, 0.3136],\n",
            "        [0.1777, 0.2637, 0.2561, 0.3026],\n",
            "        [0.1753, 0.2586, 0.2538, 0.3122]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1890, 0.2684, 0.2646, 0.2780],\n",
            "        [0.1789, 0.2525, 0.2450, 0.3236],\n",
            "        [0.1765, 0.2578, 0.2507, 0.3149],\n",
            "        [0.1768, 0.2637, 0.2559, 0.3036],\n",
            "        [0.1745, 0.2585, 0.2536, 0.3134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1880, 0.2687, 0.2647, 0.2786],\n",
            "        [0.1777, 0.2523, 0.2447, 0.3254],\n",
            "        [0.1754, 0.2575, 0.2503, 0.3168],\n",
            "        [0.1755, 0.2636, 0.2557, 0.3052],\n",
            "        [0.1731, 0.2583, 0.2533, 0.3153]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1871, 0.2689, 0.2648, 0.2791],\n",
            "        [0.1767, 0.2519, 0.2442, 0.3273],\n",
            "        [0.1742, 0.2573, 0.2500, 0.3186],\n",
            "        [0.1744, 0.2636, 0.2555, 0.3065],\n",
            "        [0.1721, 0.2580, 0.2529, 0.3171]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1861, 0.2693, 0.2650, 0.2796],\n",
            "        [0.1754, 0.2517, 0.2439, 0.3290],\n",
            "        [0.1729, 0.2573, 0.2498, 0.3200],\n",
            "        [0.1731, 0.2637, 0.2554, 0.3078],\n",
            "        [0.1708, 0.2578, 0.2525, 0.3189]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1853, 0.2695, 0.2652, 0.2800],\n",
            "        [0.1745, 0.2514, 0.2434, 0.3307],\n",
            "        [0.1718, 0.2572, 0.2496, 0.3213],\n",
            "        [0.1719, 0.2638, 0.2553, 0.3089],\n",
            "        [0.1697, 0.2578, 0.2524, 0.3201]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1848, 0.2696, 0.2651, 0.2804],\n",
            "        [0.1737, 0.2513, 0.2432, 0.3318],\n",
            "        [0.1710, 0.2571, 0.2494, 0.3224],\n",
            "        [0.1712, 0.2638, 0.2552, 0.3099],\n",
            "        [0.1688, 0.2576, 0.2522, 0.3214]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1840, 0.2699, 0.2653, 0.2808],\n",
            "        [0.1727, 0.2509, 0.2427, 0.3337],\n",
            "        [0.1699, 0.2570, 0.2491, 0.3240],\n",
            "        [0.1699, 0.2639, 0.2550, 0.3113],\n",
            "        [0.1678, 0.2573, 0.2518, 0.3231]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1833, 0.2701, 0.2655, 0.2811],\n",
            "        [0.1718, 0.2506, 0.2424, 0.3351],\n",
            "        [0.1690, 0.2568, 0.2488, 0.3254],\n",
            "        [0.1690, 0.2640, 0.2550, 0.3121],\n",
            "        [0.1669, 0.2572, 0.2516, 0.3244]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1825, 0.2704, 0.2656, 0.2815],\n",
            "        [0.1709, 0.2503, 0.2420, 0.3367],\n",
            "        [0.1681, 0.2566, 0.2486, 0.3267],\n",
            "        [0.1680, 0.2639, 0.2548, 0.3132],\n",
            "        [0.1659, 0.2569, 0.2513, 0.3259]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1820, 0.2706, 0.2657, 0.2818],\n",
            "        [0.1699, 0.2501, 0.2417, 0.3383],\n",
            "        [0.1669, 0.2566, 0.2484, 0.3280],\n",
            "        [0.1668, 0.2641, 0.2547, 0.3144],\n",
            "        [0.1646, 0.2569, 0.2512, 0.3273]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1811, 0.2708, 0.2658, 0.2824],\n",
            "        [0.1690, 0.2496, 0.2411, 0.3403],\n",
            "        [0.1660, 0.2561, 0.2479, 0.3300],\n",
            "        [0.1660, 0.2637, 0.2542, 0.3160],\n",
            "        [0.1637, 0.2564, 0.2506, 0.3293]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1801, 0.2712, 0.2660, 0.2827],\n",
            "        [0.1678, 0.2494, 0.2407, 0.3421],\n",
            "        [0.1647, 0.2561, 0.2477, 0.3316],\n",
            "        [0.1646, 0.2640, 0.2543, 0.3171],\n",
            "        [0.1626, 0.2562, 0.2503, 0.3309]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1796, 0.2712, 0.2660, 0.2832],\n",
            "        [0.1670, 0.2490, 0.2403, 0.3437],\n",
            "        [0.1639, 0.2556, 0.2472, 0.3334],\n",
            "        [0.1637, 0.2639, 0.2540, 0.3184],\n",
            "        [0.1615, 0.2561, 0.2501, 0.3323]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1791, 0.2713, 0.2660, 0.2836],\n",
            "        [0.1662, 0.2486, 0.2398, 0.3454],\n",
            "        [0.1630, 0.2553, 0.2468, 0.3349],\n",
            "        [0.1629, 0.2637, 0.2538, 0.3196],\n",
            "        [0.1609, 0.2556, 0.2497, 0.3338]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1786, 0.2715, 0.2660, 0.2840],\n",
            "        [0.1655, 0.2482, 0.2394, 0.3469],\n",
            "        [0.1623, 0.2550, 0.2464, 0.3363],\n",
            "        [0.1622, 0.2634, 0.2533, 0.3210],\n",
            "        [0.1601, 0.2553, 0.2492, 0.3353]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1778, 0.2716, 0.2660, 0.2845],\n",
            "        [0.1644, 0.2478, 0.2388, 0.3490],\n",
            "        [0.1611, 0.2546, 0.2460, 0.3382],\n",
            "        [0.1610, 0.2634, 0.2531, 0.3225],\n",
            "        [0.1591, 0.2550, 0.2488, 0.3372]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1773, 0.2718, 0.2661, 0.2848],\n",
            "        [0.1638, 0.2474, 0.2383, 0.3505],\n",
            "        [0.1603, 0.2544, 0.2456, 0.3397],\n",
            "        [0.1600, 0.2635, 0.2529, 0.3236],\n",
            "        [0.1580, 0.2548, 0.2485, 0.3387]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1763, 0.2722, 0.2664, 0.2852],\n",
            "        [0.1626, 0.2472, 0.2381, 0.3521],\n",
            "        [0.1591, 0.2543, 0.2454, 0.3412],\n",
            "        [0.1588, 0.2637, 0.2530, 0.3245],\n",
            "        [0.1568, 0.2547, 0.2483, 0.3402]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1760, 0.2723, 0.2664, 0.2853],\n",
            "        [0.1622, 0.2469, 0.2378, 0.3531],\n",
            "        [0.1588, 0.2540, 0.2451, 0.3422],\n",
            "        [0.1585, 0.2635, 0.2527, 0.3253],\n",
            "        [0.1565, 0.2544, 0.2479, 0.3411]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1753, 0.2726, 0.2666, 0.2855],\n",
            "        [0.1615, 0.2467, 0.2374, 0.3544],\n",
            "        [0.1580, 0.2537, 0.2447, 0.3437],\n",
            "        [0.1575, 0.2635, 0.2526, 0.3264],\n",
            "        [0.1558, 0.2543, 0.2478, 0.3422]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1748, 0.2728, 0.2666, 0.2858],\n",
            "        [0.1610, 0.2461, 0.2368, 0.3562],\n",
            "        [0.1572, 0.2534, 0.2443, 0.3450],\n",
            "        [0.1569, 0.2633, 0.2523, 0.3275],\n",
            "        [0.1552, 0.2538, 0.2472, 0.3438]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1742, 0.2730, 0.2667, 0.2861],\n",
            "        [0.1603, 0.2456, 0.2363, 0.3578],\n",
            "        [0.1565, 0.2530, 0.2439, 0.3467],\n",
            "        [0.1562, 0.2631, 0.2519, 0.3288],\n",
            "        [0.1546, 0.2534, 0.2468, 0.3452]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1735, 0.2732, 0.2668, 0.2866],\n",
            "        [0.1593, 0.2453, 0.2359, 0.3595],\n",
            "        [0.1556, 0.2527, 0.2435, 0.3483],\n",
            "        [0.1554, 0.2629, 0.2516, 0.3301],\n",
            "        [0.1537, 0.2531, 0.2464, 0.3469]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1728, 0.2733, 0.2668, 0.2870],\n",
            "        [0.1585, 0.2446, 0.2352, 0.3617],\n",
            "        [0.1546, 0.2523, 0.2430, 0.3502],\n",
            "        [0.1546, 0.2626, 0.2511, 0.3317],\n",
            "        [0.1527, 0.2527, 0.2459, 0.3487]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1725, 0.2734, 0.2668, 0.2873],\n",
            "        [0.1581, 0.2442, 0.2347, 0.3630],\n",
            "        [0.1542, 0.2517, 0.2424, 0.3517],\n",
            "        [0.1540, 0.2624, 0.2509, 0.3327],\n",
            "        [0.1522, 0.2524, 0.2455, 0.3500]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1725, 0.2734, 0.2667, 0.2874],\n",
            "        [0.1579, 0.2437, 0.2343, 0.3641],\n",
            "        [0.1540, 0.2513, 0.2420, 0.3526],\n",
            "        [0.1540, 0.2620, 0.2504, 0.3336],\n",
            "        [0.1522, 0.2518, 0.2449, 0.3510]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1718, 0.2736, 0.2669, 0.2877],\n",
            "        [0.1572, 0.2436, 0.2341, 0.3651],\n",
            "        [0.1530, 0.2513, 0.2419, 0.3538],\n",
            "        [0.1531, 0.2622, 0.2505, 0.3343],\n",
            "        [0.1512, 0.2519, 0.2450, 0.3519]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1715, 0.2738, 0.2670, 0.2878],\n",
            "        [0.1567, 0.2434, 0.2339, 0.3660],\n",
            "        [0.1526, 0.2511, 0.2417, 0.3546],\n",
            "        [0.1525, 0.2621, 0.2503, 0.3351],\n",
            "        [0.1507, 0.2517, 0.2447, 0.3529]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1710, 0.2739, 0.2670, 0.2881],\n",
            "        [0.1562, 0.2430, 0.2334, 0.3674],\n",
            "        [0.1519, 0.2507, 0.2412, 0.3561],\n",
            "        [0.1519, 0.2618, 0.2500, 0.3362],\n",
            "        [0.1503, 0.2513, 0.2442, 0.3542]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1705, 0.2740, 0.2670, 0.2884],\n",
            "        [0.1554, 0.2426, 0.2329, 0.3690],\n",
            "        [0.1512, 0.2504, 0.2408, 0.3577],\n",
            "        [0.1511, 0.2618, 0.2498, 0.3372],\n",
            "        [0.1495, 0.2510, 0.2439, 0.3555]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1700, 0.2743, 0.2672, 0.2886],\n",
            "        [0.1549, 0.2424, 0.2326, 0.3701],\n",
            "        [0.1506, 0.2503, 0.2406, 0.3585],\n",
            "        [0.1507, 0.2619, 0.2498, 0.3377],\n",
            "        [0.1490, 0.2509, 0.2438, 0.3563]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1698, 0.2744, 0.2672, 0.2886],\n",
            "        [0.1548, 0.2420, 0.2323, 0.3708],\n",
            "        [0.1503, 0.2500, 0.2403, 0.3593],\n",
            "        [0.1502, 0.2619, 0.2497, 0.3383],\n",
            "        [0.1485, 0.2508, 0.2436, 0.3571]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1700, 0.2743, 0.2670, 0.2887],\n",
            "        [0.1546, 0.2418, 0.2320, 0.3716],\n",
            "        [0.1501, 0.2498, 0.2400, 0.3601],\n",
            "        [0.1501, 0.2615, 0.2493, 0.3392],\n",
            "        [0.1485, 0.2503, 0.2431, 0.3581]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1699, 0.2743, 0.2669, 0.2889],\n",
            "        [0.1542, 0.2413, 0.2315, 0.3730],\n",
            "        [0.1497, 0.2493, 0.2396, 0.3614],\n",
            "        [0.1497, 0.2613, 0.2490, 0.3401],\n",
            "        [0.1482, 0.2499, 0.2427, 0.3593]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1695, 0.2744, 0.2669, 0.2892],\n",
            "        [0.1537, 0.2410, 0.2312, 0.3742],\n",
            "        [0.1493, 0.2489, 0.2391, 0.3628],\n",
            "        [0.1491, 0.2613, 0.2489, 0.3407],\n",
            "        [0.1479, 0.2493, 0.2421, 0.3607]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1692, 0.2745, 0.2670, 0.2893],\n",
            "        [0.1533, 0.2408, 0.2309, 0.3750],\n",
            "        [0.1489, 0.2486, 0.2388, 0.3637],\n",
            "        [0.1486, 0.2613, 0.2488, 0.3413],\n",
            "        [0.1473, 0.2492, 0.2420, 0.3615]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1693, 0.2745, 0.2669, 0.2893],\n",
            "        [0.1532, 0.2406, 0.2308, 0.3754],\n",
            "        [0.1487, 0.2484, 0.2386, 0.3644],\n",
            "        [0.1487, 0.2609, 0.2484, 0.3419],\n",
            "        [0.1473, 0.2490, 0.2417, 0.3621]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1688, 0.2746, 0.2670, 0.2895],\n",
            "        [0.1528, 0.2403, 0.2304, 0.3765],\n",
            "        [0.1481, 0.2482, 0.2383, 0.3654],\n",
            "        [0.1482, 0.2608, 0.2483, 0.3427],\n",
            "        [0.1470, 0.2488, 0.2414, 0.3628]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1683, 0.2749, 0.2671, 0.2897],\n",
            "        [0.1522, 0.2400, 0.2301, 0.3777],\n",
            "        [0.1473, 0.2480, 0.2381, 0.3666],\n",
            "        [0.1474, 0.2608, 0.2482, 0.3436],\n",
            "        [0.1463, 0.2485, 0.2412, 0.3639]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1680, 0.2749, 0.2671, 0.2900],\n",
            "        [0.1516, 0.2396, 0.2296, 0.3793],\n",
            "        [0.1468, 0.2475, 0.2375, 0.3682],\n",
            "        [0.1468, 0.2606, 0.2478, 0.3447],\n",
            "        [0.1458, 0.2482, 0.2408, 0.3653]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1679, 0.2749, 0.2671, 0.2901],\n",
            "        [0.1515, 0.2392, 0.2293, 0.3800],\n",
            "        [0.1466, 0.2472, 0.2373, 0.3689],\n",
            "        [0.1465, 0.2605, 0.2476, 0.3454],\n",
            "        [0.1454, 0.2480, 0.2405, 0.3661]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1676, 0.2750, 0.2671, 0.2902],\n",
            "        [0.1510, 0.2390, 0.2290, 0.3810],\n",
            "        [0.1462, 0.2469, 0.2369, 0.3700],\n",
            "        [0.1459, 0.2604, 0.2474, 0.3462],\n",
            "        [0.1447, 0.2479, 0.2403, 0.3671]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1675, 0.2751, 0.2672, 0.2903],\n",
            "        [0.1509, 0.2389, 0.2289, 0.3813],\n",
            "        [0.1461, 0.2468, 0.2369, 0.3702],\n",
            "        [0.1460, 0.2601, 0.2472, 0.3467],\n",
            "        [0.1445, 0.2477, 0.2402, 0.3677]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1672, 0.2752, 0.2673, 0.2903],\n",
            "        [0.1505, 0.2387, 0.2287, 0.3821],\n",
            "        [0.1457, 0.2467, 0.2366, 0.3710],\n",
            "        [0.1455, 0.2601, 0.2471, 0.3473],\n",
            "        [0.1441, 0.2476, 0.2400, 0.3683]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1673, 0.2752, 0.2671, 0.2904],\n",
            "        [0.1505, 0.2382, 0.2282, 0.3831],\n",
            "        [0.1455, 0.2463, 0.2363, 0.3719],\n",
            "        [0.1455, 0.2597, 0.2467, 0.3481],\n",
            "        [0.1443, 0.2470, 0.2395, 0.3692]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1672, 0.2753, 0.2672, 0.2904],\n",
            "        [0.1503, 0.2380, 0.2280, 0.3837],\n",
            "        [0.1452, 0.2462, 0.2361, 0.3725],\n",
            "        [0.1451, 0.2597, 0.2467, 0.3485],\n",
            "        [0.1438, 0.2468, 0.2392, 0.3701]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1672, 0.2752, 0.2671, 0.2905],\n",
            "        [0.1503, 0.2377, 0.2277, 0.3842],\n",
            "        [0.1451, 0.2460, 0.2359, 0.3730],\n",
            "        [0.1450, 0.2596, 0.2465, 0.3489],\n",
            "        [0.1437, 0.2466, 0.2390, 0.3707]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1669, 0.2753, 0.2672, 0.2906],\n",
            "        [0.1501, 0.2375, 0.2275, 0.3849],\n",
            "        [0.1449, 0.2457, 0.2356, 0.3737],\n",
            "        [0.1449, 0.2593, 0.2462, 0.3496],\n",
            "        [0.1437, 0.2462, 0.2386, 0.3715]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1667, 0.2754, 0.2672, 0.2908],\n",
            "        [0.1498, 0.2372, 0.2272, 0.3857],\n",
            "        [0.1446, 0.2454, 0.2353, 0.3748],\n",
            "        [0.1446, 0.2593, 0.2461, 0.3501],\n",
            "        [0.1435, 0.2458, 0.2382, 0.3724]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1665, 0.2755, 0.2672, 0.2909],\n",
            "        [0.1496, 0.2369, 0.2269, 0.3866],\n",
            "        [0.1443, 0.2452, 0.2351, 0.3754],\n",
            "        [0.1444, 0.2590, 0.2457, 0.3509],\n",
            "        [0.1434, 0.2454, 0.2378, 0.3733]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1666, 0.2754, 0.2671, 0.2910],\n",
            "        [0.1495, 0.2368, 0.2268, 0.3869],\n",
            "        [0.1442, 0.2449, 0.2348, 0.3760],\n",
            "        [0.1442, 0.2588, 0.2456, 0.3514],\n",
            "        [0.1431, 0.2452, 0.2376, 0.3741]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1664, 0.2755, 0.2672, 0.2910],\n",
            "        [0.1493, 0.2366, 0.2266, 0.3875],\n",
            "        [0.1439, 0.2448, 0.2347, 0.3765],\n",
            "        [0.1440, 0.2588, 0.2455, 0.3518],\n",
            "        [0.1428, 0.2450, 0.2373, 0.3749]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1666, 0.2754, 0.2670, 0.2910],\n",
            "        [0.1494, 0.2363, 0.2264, 0.3879],\n",
            "        [0.1442, 0.2445, 0.2344, 0.3770],\n",
            "        [0.1443, 0.2583, 0.2450, 0.3523],\n",
            "        [0.1431, 0.2445, 0.2369, 0.3755]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1666, 0.2753, 0.2669, 0.2912],\n",
            "        [0.1494, 0.2362, 0.2262, 0.3882],\n",
            "        [0.1440, 0.2444, 0.2342, 0.3774],\n",
            "        [0.1443, 0.2581, 0.2448, 0.3527],\n",
            "        [0.1432, 0.2442, 0.2366, 0.3761]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1664, 0.2754, 0.2670, 0.2912],\n",
            "        [0.1492, 0.2360, 0.2260, 0.3887],\n",
            "        [0.1438, 0.2442, 0.2340, 0.3780],\n",
            "        [0.1440, 0.2580, 0.2447, 0.3533],\n",
            "        [0.1427, 0.2441, 0.2364, 0.3768]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1662, 0.2754, 0.2670, 0.2913],\n",
            "        [0.1489, 0.2359, 0.2259, 0.3893],\n",
            "        [0.1435, 0.2440, 0.2338, 0.3787],\n",
            "        [0.1437, 0.2579, 0.2446, 0.3539],\n",
            "        [0.1426, 0.2439, 0.2362, 0.3773]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1662, 0.2754, 0.2670, 0.2914],\n",
            "        [0.1489, 0.2356, 0.2256, 0.3899],\n",
            "        [0.1433, 0.2438, 0.2335, 0.3794],\n",
            "        [0.1437, 0.2575, 0.2442, 0.3546],\n",
            "        [0.1425, 0.2434, 0.2358, 0.3783]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1662, 0.2755, 0.2670, 0.2913],\n",
            "        [0.1490, 0.2353, 0.2253, 0.3904],\n",
            "        [0.1432, 0.2435, 0.2332, 0.3801],\n",
            "        [0.1435, 0.2574, 0.2440, 0.3551],\n",
            "        [0.1424, 0.2431, 0.2355, 0.3790]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1662, 0.2754, 0.2669, 0.2915],\n",
            "        [0.1488, 0.2349, 0.2250, 0.3913],\n",
            "        [0.1430, 0.2431, 0.2329, 0.3810],\n",
            "        [0.1433, 0.2572, 0.2438, 0.3557],\n",
            "        [0.1422, 0.2427, 0.2351, 0.3799]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1661, 0.2754, 0.2669, 0.2916],\n",
            "        [0.1485, 0.2346, 0.2247, 0.3922],\n",
            "        [0.1426, 0.2429, 0.2326, 0.3819],\n",
            "        [0.1429, 0.2571, 0.2437, 0.3563],\n",
            "        [0.1422, 0.2424, 0.2347, 0.3808]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1660, 0.2755, 0.2669, 0.2916],\n",
            "        [0.1485, 0.2346, 0.2246, 0.3923],\n",
            "        [0.1427, 0.2427, 0.2325, 0.3821],\n",
            "        [0.1430, 0.2570, 0.2435, 0.3565],\n",
            "        [0.1421, 0.2422, 0.2346, 0.3811]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1658, 0.2756, 0.2670, 0.2916],\n",
            "        [0.1485, 0.2345, 0.2246, 0.3924],\n",
            "        [0.1426, 0.2427, 0.2325, 0.3822],\n",
            "        [0.1429, 0.2570, 0.2436, 0.3566],\n",
            "        [0.1420, 0.2421, 0.2345, 0.3814]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1660, 0.2755, 0.2669, 0.2916],\n",
            "        [0.1484, 0.2344, 0.2244, 0.3928],\n",
            "        [0.1425, 0.2425, 0.2323, 0.3826],\n",
            "        [0.1429, 0.2568, 0.2434, 0.3570],\n",
            "        [0.1420, 0.2418, 0.2343, 0.3819]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1659, 0.2755, 0.2669, 0.2917],\n",
            "        [0.1483, 0.2340, 0.2241, 0.3935],\n",
            "        [0.1424, 0.2421, 0.2320, 0.3836],\n",
            "        [0.1425, 0.2567, 0.2433, 0.3575],\n",
            "        [0.1419, 0.2415, 0.2339, 0.3826]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1660, 0.2755, 0.2668, 0.2917],\n",
            "        [0.1485, 0.2337, 0.2238, 0.3941],\n",
            "        [0.1424, 0.2420, 0.2318, 0.3838],\n",
            "        [0.1427, 0.2565, 0.2430, 0.3577],\n",
            "        [0.1422, 0.2412, 0.2336, 0.3831]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1657, 0.2756, 0.2669, 0.2918],\n",
            "        [0.1483, 0.2335, 0.2236, 0.3947],\n",
            "        [0.1421, 0.2418, 0.2316, 0.3845],\n",
            "        [0.1425, 0.2564, 0.2429, 0.3582],\n",
            "        [0.1420, 0.2409, 0.2333, 0.3838]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1660, 0.2755, 0.2668, 0.2918],\n",
            "        [0.1483, 0.2333, 0.2235, 0.3949],\n",
            "        [0.1422, 0.2417, 0.2315, 0.3847],\n",
            "        [0.1424, 0.2563, 0.2428, 0.3586],\n",
            "        [0.1418, 0.2407, 0.2331, 0.3844]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1659, 0.2755, 0.2668, 0.2919],\n",
            "        [0.1481, 0.2332, 0.2233, 0.3953],\n",
            "        [0.1420, 0.2416, 0.2313, 0.3852],\n",
            "        [0.1423, 0.2562, 0.2427, 0.3589],\n",
            "        [0.1417, 0.2406, 0.2330, 0.3848]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1661, 0.2754, 0.2666, 0.2919],\n",
            "        [0.1482, 0.2331, 0.2232, 0.3956],\n",
            "        [0.1420, 0.2414, 0.2311, 0.3855],\n",
            "        [0.1423, 0.2560, 0.2425, 0.3591],\n",
            "        [0.1418, 0.2403, 0.2327, 0.3852]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1660, 0.2755, 0.2667, 0.2919],\n",
            "        [0.1480, 0.2329, 0.2230, 0.3960],\n",
            "        [0.1418, 0.2412, 0.2310, 0.3860],\n",
            "        [0.1421, 0.2560, 0.2424, 0.3595],\n",
            "        [0.1417, 0.2402, 0.2326, 0.3855]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1659, 0.2755, 0.2667, 0.2919],\n",
            "        [0.1479, 0.2328, 0.2229, 0.3965],\n",
            "        [0.1416, 0.2410, 0.2308, 0.3866],\n",
            "        [0.1420, 0.2558, 0.2422, 0.3600],\n",
            "        [0.1417, 0.2399, 0.2323, 0.3861]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1660, 0.2755, 0.2667, 0.2919],\n",
            "        [0.1480, 0.2326, 0.2227, 0.3967],\n",
            "        [0.1417, 0.2408, 0.2306, 0.3869],\n",
            "        [0.1420, 0.2557, 0.2421, 0.3602],\n",
            "        [0.1417, 0.2398, 0.2321, 0.3865]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1660, 0.2755, 0.2666, 0.2919],\n",
            "        [0.1480, 0.2326, 0.2227, 0.3967],\n",
            "        [0.1416, 0.2409, 0.2306, 0.3869],\n",
            "        [0.1419, 0.2558, 0.2422, 0.3601],\n",
            "        [0.1418, 0.2397, 0.2321, 0.3865]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1660, 0.2754, 0.2666, 0.2919],\n",
            "        [0.1480, 0.2325, 0.2226, 0.3970],\n",
            "        [0.1416, 0.2407, 0.2305, 0.3872],\n",
            "        [0.1421, 0.2555, 0.2419, 0.3605],\n",
            "        [0.1418, 0.2395, 0.2318, 0.3868]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1663, 0.2754, 0.2665, 0.2918],\n",
            "        [0.1483, 0.2323, 0.2225, 0.3970],\n",
            "        [0.1417, 0.2407, 0.2304, 0.3872],\n",
            "        [0.1422, 0.2555, 0.2418, 0.3605],\n",
            "        [0.1421, 0.2393, 0.2317, 0.3869]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1661, 0.2754, 0.2666, 0.2919],\n",
            "        [0.1481, 0.2322, 0.2224, 0.3973],\n",
            "        [0.1415, 0.2406, 0.2303, 0.3876],\n",
            "        [0.1420, 0.2554, 0.2418, 0.3609],\n",
            "        [0.1419, 0.2393, 0.2316, 0.3873]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1661, 0.2755, 0.2666, 0.2918],\n",
            "        [0.1481, 0.2323, 0.2224, 0.3972],\n",
            "        [0.1415, 0.2406, 0.2303, 0.3876],\n",
            "        [0.1419, 0.2554, 0.2418, 0.3609],\n",
            "        [0.1418, 0.2393, 0.2317, 0.3872]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1662, 0.2754, 0.2666, 0.2918],\n",
            "        [0.1482, 0.2322, 0.2224, 0.3973],\n",
            "        [0.1415, 0.2405, 0.2303, 0.3877],\n",
            "        [0.1420, 0.2554, 0.2417, 0.3609],\n",
            "        [0.1420, 0.2392, 0.2315, 0.3873]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1665, 0.2753, 0.2665, 0.2917],\n",
            "        [0.1485, 0.2321, 0.2222, 0.3972],\n",
            "        [0.1418, 0.2404, 0.2301, 0.3877],\n",
            "        [0.1422, 0.2553, 0.2416, 0.3609],\n",
            "        [0.1422, 0.2390, 0.2314, 0.3873]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1664, 0.2754, 0.2665, 0.2918],\n",
            "        [0.1482, 0.2319, 0.2221, 0.3978],\n",
            "        [0.1415, 0.2403, 0.2301, 0.3881],\n",
            "        [0.1421, 0.2552, 0.2415, 0.3611],\n",
            "        [0.1422, 0.2388, 0.2312, 0.3878]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1663, 0.2754, 0.2665, 0.2918],\n",
            "        [0.1483, 0.2318, 0.2219, 0.3980],\n",
            "        [0.1414, 0.2402, 0.2299, 0.3884],\n",
            "        [0.1421, 0.2551, 0.2414, 0.3614],\n",
            "        [0.1421, 0.2386, 0.2310, 0.3882]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1664, 0.2754, 0.2665, 0.2918],\n",
            "        [0.1482, 0.2317, 0.2219, 0.3981],\n",
            "        [0.1414, 0.2402, 0.2299, 0.3885],\n",
            "        [0.1420, 0.2552, 0.2414, 0.3614],\n",
            "        [0.1421, 0.2386, 0.2310, 0.3883]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1665, 0.2753, 0.2664, 0.2918],\n",
            "        [0.1484, 0.2316, 0.2218, 0.3981],\n",
            "        [0.1415, 0.2401, 0.2299, 0.3885],\n",
            "        [0.1421, 0.2550, 0.2414, 0.3615],\n",
            "        [0.1422, 0.2385, 0.2309, 0.3884]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1665, 0.2753, 0.2664, 0.2917],\n",
            "        [0.1484, 0.2315, 0.2218, 0.3983],\n",
            "        [0.1415, 0.2401, 0.2298, 0.3886],\n",
            "        [0.1420, 0.2550, 0.2414, 0.3616],\n",
            "        [0.1422, 0.2384, 0.2308, 0.3886]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1665, 0.2753, 0.2664, 0.2918],\n",
            "        [0.1484, 0.2315, 0.2217, 0.3984],\n",
            "        [0.1415, 0.2400, 0.2297, 0.3888],\n",
            "        [0.1421, 0.2550, 0.2413, 0.3617],\n",
            "        [0.1423, 0.2383, 0.2307, 0.3887]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1664, 0.2754, 0.2664, 0.2918],\n",
            "        [0.1484, 0.2314, 0.2216, 0.3986],\n",
            "        [0.1415, 0.2399, 0.2296, 0.3890],\n",
            "        [0.1422, 0.2549, 0.2412, 0.3617],\n",
            "        [0.1424, 0.2381, 0.2305, 0.3890]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1666, 0.2753, 0.2664, 0.2917],\n",
            "        [0.1486, 0.2314, 0.2216, 0.3984],\n",
            "        [0.1416, 0.2398, 0.2295, 0.3891],\n",
            "        [0.1423, 0.2549, 0.2412, 0.3616],\n",
            "        [0.1425, 0.2380, 0.2303, 0.3891]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1667, 0.2753, 0.2663, 0.2917],\n",
            "        [0.1486, 0.2313, 0.2215, 0.3986],\n",
            "        [0.1416, 0.2397, 0.2295, 0.3892],\n",
            "        [0.1422, 0.2549, 0.2412, 0.3618],\n",
            "        [0.1424, 0.2379, 0.2303, 0.3894]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1667, 0.2753, 0.2664, 0.2916],\n",
            "        [0.1487, 0.2312, 0.2215, 0.3986],\n",
            "        [0.1417, 0.2396, 0.2294, 0.3893],\n",
            "        [0.1422, 0.2548, 0.2411, 0.3618],\n",
            "        [0.1425, 0.2378, 0.2302, 0.3895]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1669, 0.2753, 0.2663, 0.2916],\n",
            "        [0.1489, 0.2311, 0.2214, 0.3987],\n",
            "        [0.1418, 0.2396, 0.2294, 0.3892],\n",
            "        [0.1424, 0.2547, 0.2410, 0.3619],\n",
            "        [0.1427, 0.2376, 0.2300, 0.3896]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1669, 0.2752, 0.2663, 0.2915],\n",
            "        [0.1490, 0.2310, 0.2213, 0.3986],\n",
            "        [0.1418, 0.2396, 0.2294, 0.3892],\n",
            "        [0.1425, 0.2547, 0.2410, 0.3618],\n",
            "        [0.1428, 0.2376, 0.2300, 0.3896]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1668, 0.2753, 0.2663, 0.2915],\n",
            "        [0.1489, 0.2311, 0.2214, 0.3987],\n",
            "        [0.1417, 0.2396, 0.2294, 0.3893],\n",
            "        [0.1425, 0.2547, 0.2410, 0.3618],\n",
            "        [0.1428, 0.2375, 0.2299, 0.3897]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1670, 0.2752, 0.2662, 0.2916],\n",
            "        [0.1489, 0.2311, 0.2213, 0.3987],\n",
            "        [0.1418, 0.2395, 0.2293, 0.3894],\n",
            "        [0.1425, 0.2546, 0.2409, 0.3619],\n",
            "        [0.1429, 0.2374, 0.2299, 0.3899]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1669, 0.2752, 0.2663, 0.2916],\n",
            "        [0.1489, 0.2310, 0.2213, 0.3988],\n",
            "        [0.1418, 0.2394, 0.2292, 0.3895],\n",
            "        [0.1425, 0.2546, 0.2409, 0.3620],\n",
            "        [0.1429, 0.2373, 0.2297, 0.3901]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1671, 0.2752, 0.2662, 0.2915],\n",
            "        [0.1490, 0.2310, 0.2213, 0.3987],\n",
            "        [0.1420, 0.2394, 0.2292, 0.3894],\n",
            "        [0.1427, 0.2545, 0.2408, 0.3620],\n",
            "        [0.1431, 0.2372, 0.2296, 0.3901]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1670, 0.2752, 0.2662, 0.2916],\n",
            "        [0.1490, 0.2310, 0.2213, 0.3988],\n",
            "        [0.1419, 0.2394, 0.2292, 0.3895],\n",
            "        [0.1425, 0.2545, 0.2408, 0.3621],\n",
            "        [0.1430, 0.2372, 0.2296, 0.3902]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1671, 0.2752, 0.2662, 0.2915],\n",
            "        [0.1491, 0.2309, 0.2212, 0.3988],\n",
            "        [0.1420, 0.2394, 0.2292, 0.3895],\n",
            "        [0.1426, 0.2546, 0.2409, 0.3620],\n",
            "        [0.1432, 0.2371, 0.2295, 0.3902]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1672, 0.2751, 0.2662, 0.2915],\n",
            "        [0.1493, 0.2309, 0.2212, 0.3986],\n",
            "        [0.1422, 0.2393, 0.2291, 0.3894],\n",
            "        [0.1428, 0.2545, 0.2408, 0.3619],\n",
            "        [0.1434, 0.2370, 0.2295, 0.3902]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1672, 0.2751, 0.2662, 0.2915],\n",
            "        [0.1493, 0.2309, 0.2212, 0.3986],\n",
            "        [0.1421, 0.2393, 0.2291, 0.3894],\n",
            "        [0.1428, 0.2544, 0.2408, 0.3620],\n",
            "        [0.1434, 0.2369, 0.2295, 0.3902]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1672, 0.2751, 0.2662, 0.2915],\n",
            "        [0.1492, 0.2309, 0.2212, 0.3987],\n",
            "        [0.1421, 0.2393, 0.2291, 0.3895],\n",
            "        [0.1428, 0.2544, 0.2408, 0.3620],\n",
            "        [0.1434, 0.2369, 0.2294, 0.3903]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1673, 0.2751, 0.2662, 0.2915],\n",
            "        [0.1493, 0.2308, 0.2211, 0.3988],\n",
            "        [0.1421, 0.2392, 0.2290, 0.3896],\n",
            "        [0.1428, 0.2544, 0.2407, 0.3620],\n",
            "        [0.1435, 0.2368, 0.2293, 0.3903]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1674, 0.2751, 0.2661, 0.2914],\n",
            "        [0.1493, 0.2308, 0.2211, 0.3988],\n",
            "        [0.1422, 0.2392, 0.2290, 0.3896],\n",
            "        [0.1429, 0.2543, 0.2407, 0.3620],\n",
            "        [0.1436, 0.2367, 0.2293, 0.3903]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1674, 0.2751, 0.2661, 0.2914],\n",
            "        [0.1494, 0.2308, 0.2211, 0.3987],\n",
            "        [0.1422, 0.2392, 0.2290, 0.3896],\n",
            "        [0.1430, 0.2543, 0.2407, 0.3620],\n",
            "        [0.1438, 0.2367, 0.2292, 0.3903]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1674, 0.2750, 0.2661, 0.2914],\n",
            "        [0.1495, 0.2307, 0.2211, 0.3987],\n",
            "        [0.1423, 0.2391, 0.2289, 0.3897],\n",
            "        [0.1431, 0.2542, 0.2406, 0.3621],\n",
            "        [0.1438, 0.2366, 0.2292, 0.3904]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1675, 0.2750, 0.2661, 0.2914],\n",
            "        [0.1496, 0.2307, 0.2211, 0.3987],\n",
            "        [0.1424, 0.2391, 0.2289, 0.3896],\n",
            "        [0.1432, 0.2542, 0.2406, 0.3620],\n",
            "        [0.1440, 0.2366, 0.2291, 0.3903]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1676, 0.2750, 0.2661, 0.2913],\n",
            "        [0.1497, 0.2307, 0.2210, 0.3986],\n",
            "        [0.1425, 0.2391, 0.2289, 0.3895],\n",
            "        [0.1433, 0.2542, 0.2406, 0.3619],\n",
            "        [0.1441, 0.2366, 0.2291, 0.3902]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1676, 0.2750, 0.2661, 0.2913],\n",
            "        [0.1497, 0.2306, 0.2210, 0.3986],\n",
            "        [0.1426, 0.2390, 0.2289, 0.3895],\n",
            "        [0.1434, 0.2542, 0.2405, 0.3619],\n",
            "        [0.1441, 0.2365, 0.2291, 0.3903]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1676, 0.2750, 0.2661, 0.2913],\n",
            "        [0.1498, 0.2306, 0.2210, 0.3986],\n",
            "        [0.1426, 0.2391, 0.2289, 0.3895],\n",
            "        [0.1434, 0.2542, 0.2405, 0.3619],\n",
            "        [0.1442, 0.2365, 0.2290, 0.3903]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1677, 0.2750, 0.2660, 0.2913],\n",
            "        [0.1498, 0.2306, 0.2210, 0.3986],\n",
            "        [0.1426, 0.2391, 0.2289, 0.3894],\n",
            "        [0.1434, 0.2542, 0.2405, 0.3619],\n",
            "        [0.1442, 0.2365, 0.2290, 0.3902]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1677, 0.2750, 0.2660, 0.2913],\n",
            "        [0.1498, 0.2307, 0.2210, 0.3986],\n",
            "        [0.1425, 0.2391, 0.2289, 0.3894],\n",
            "        [0.1435, 0.2542, 0.2405, 0.3619],\n",
            "        [0.1443, 0.2365, 0.2290, 0.3902]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1677, 0.2750, 0.2660, 0.2913],\n",
            "        [0.1498, 0.2307, 0.2210, 0.3986],\n",
            "        [0.1425, 0.2391, 0.2289, 0.3894],\n",
            "        [0.1435, 0.2542, 0.2405, 0.3619],\n",
            "        [0.1443, 0.2365, 0.2290, 0.3902]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)], 'cell_netG_B': [tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2474, 0.2505, 0.2505, 0.2516],\n",
            "        [0.2468, 0.2509, 0.2508, 0.2515],\n",
            "        [0.2472, 0.2508, 0.2507, 0.2513],\n",
            "        [0.2473, 0.2507, 0.2507, 0.2513],\n",
            "        [0.2478, 0.2505, 0.2504, 0.2513]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2459, 0.2506, 0.2505, 0.2529],\n",
            "        [0.2443, 0.2513, 0.2512, 0.2531],\n",
            "        [0.2449, 0.2513, 0.2511, 0.2528],\n",
            "        [0.2451, 0.2512, 0.2511, 0.2526],\n",
            "        [0.2462, 0.2507, 0.2506, 0.2526]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2432, 0.2511, 0.2509, 0.2548],\n",
            "        [0.2409, 0.2521, 0.2518, 0.2552],\n",
            "        [0.2417, 0.2519, 0.2517, 0.2547],\n",
            "        [0.2421, 0.2520, 0.2517, 0.2542],\n",
            "        [0.2438, 0.2511, 0.2509, 0.2542]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2414, 0.2515, 0.2512, 0.2560],\n",
            "        [0.2383, 0.2527, 0.2523, 0.2567],\n",
            "        [0.2392, 0.2526, 0.2522, 0.2560],\n",
            "        [0.2397, 0.2527, 0.2523, 0.2553],\n",
            "        [0.2419, 0.2515, 0.2512, 0.2554]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2398, 0.2518, 0.2514, 0.2569],\n",
            "        [0.2367, 0.2530, 0.2525, 0.2579],\n",
            "        [0.2377, 0.2529, 0.2524, 0.2570],\n",
            "        [0.2382, 0.2530, 0.2525, 0.2563],\n",
            "        [0.2407, 0.2516, 0.2513, 0.2564]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2383, 0.2520, 0.2516, 0.2581],\n",
            "        [0.2347, 0.2532, 0.2526, 0.2595],\n",
            "        [0.2357, 0.2533, 0.2527, 0.2584],\n",
            "        [0.2364, 0.2533, 0.2528, 0.2575],\n",
            "        [0.2390, 0.2519, 0.2515, 0.2576]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2367, 0.2523, 0.2518, 0.2592],\n",
            "        [0.2324, 0.2538, 0.2531, 0.2608],\n",
            "        [0.2336, 0.2538, 0.2532, 0.2594],\n",
            "        [0.2345, 0.2539, 0.2532, 0.2584],\n",
            "        [0.2374, 0.2523, 0.2519, 0.2585]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2354, 0.2524, 0.2519, 0.2603],\n",
            "        [0.2309, 0.2539, 0.2531, 0.2622],\n",
            "        [0.2323, 0.2539, 0.2532, 0.2607],\n",
            "        [0.2331, 0.2541, 0.2534, 0.2594],\n",
            "        [0.2365, 0.2522, 0.2518, 0.2595]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2330, 0.2527, 0.2521, 0.2621],\n",
            "        [0.2278, 0.2543, 0.2534, 0.2646],\n",
            "        [0.2295, 0.2543, 0.2535, 0.2627],\n",
            "        [0.2305, 0.2546, 0.2538, 0.2611],\n",
            "        [0.2342, 0.2525, 0.2521, 0.2612]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2315, 0.2529, 0.2522, 0.2634],\n",
            "        [0.2255, 0.2547, 0.2536, 0.2663],\n",
            "        [0.2273, 0.2548, 0.2539, 0.2640],\n",
            "        [0.2285, 0.2550, 0.2542, 0.2622],\n",
            "        [0.2326, 0.2528, 0.2523, 0.2623]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2298, 0.2530, 0.2522, 0.2649],\n",
            "        [0.2233, 0.2548, 0.2536, 0.2683],\n",
            "        [0.2251, 0.2551, 0.2541, 0.2657],\n",
            "        [0.2263, 0.2555, 0.2545, 0.2636],\n",
            "        [0.2306, 0.2531, 0.2525, 0.2638]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2288, 0.2531, 0.2522, 0.2659],\n",
            "        [0.2219, 0.2548, 0.2535, 0.2698],\n",
            "        [0.2237, 0.2552, 0.2541, 0.2669],\n",
            "        [0.2250, 0.2557, 0.2546, 0.2647],\n",
            "        [0.2296, 0.2531, 0.2525, 0.2648]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2270, 0.2533, 0.2524, 0.2673],\n",
            "        [0.2197, 0.2550, 0.2535, 0.2717],\n",
            "        [0.2216, 0.2556, 0.2543, 0.2685],\n",
            "        [0.2229, 0.2561, 0.2549, 0.2660],\n",
            "        [0.2278, 0.2533, 0.2526, 0.2662]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2267, 0.2532, 0.2522, 0.2680],\n",
            "        [0.2192, 0.2549, 0.2533, 0.2727],\n",
            "        [0.2211, 0.2555, 0.2541, 0.2694],\n",
            "        [0.2222, 0.2562, 0.2549, 0.2667],\n",
            "        [0.2272, 0.2534, 0.2526, 0.2669]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2242, 0.2537, 0.2525, 0.2696],\n",
            "        [0.2159, 0.2556, 0.2538, 0.2748],\n",
            "        [0.2183, 0.2561, 0.2546, 0.2710],\n",
            "        [0.2196, 0.2569, 0.2555, 0.2681],\n",
            "        [0.2250, 0.2537, 0.2528, 0.2685]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2233, 0.2536, 0.2524, 0.2707],\n",
            "        [0.2145, 0.2556, 0.2537, 0.2763],\n",
            "        [0.2169, 0.2562, 0.2546, 0.2723],\n",
            "        [0.2182, 0.2570, 0.2556, 0.2692],\n",
            "        [0.2238, 0.2537, 0.2528, 0.2696]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2221, 0.2537, 0.2524, 0.2718],\n",
            "        [0.2130, 0.2556, 0.2536, 0.2778],\n",
            "        [0.2155, 0.2563, 0.2546, 0.2735],\n",
            "        [0.2170, 0.2571, 0.2556, 0.2704],\n",
            "        [0.2226, 0.2538, 0.2528, 0.2708]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2212, 0.2537, 0.2524, 0.2727],\n",
            "        [0.2118, 0.2556, 0.2534, 0.2791],\n",
            "        [0.2144, 0.2565, 0.2546, 0.2745],\n",
            "        [0.2159, 0.2573, 0.2557, 0.2711],\n",
            "        [0.2217, 0.2538, 0.2528, 0.2717]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2196, 0.2539, 0.2524, 0.2741],\n",
            "        [0.2096, 0.2558, 0.2535, 0.2811],\n",
            "        [0.2122, 0.2568, 0.2549, 0.2761],\n",
            "        [0.2137, 0.2578, 0.2560, 0.2726],\n",
            "        [0.2199, 0.2540, 0.2529, 0.2732]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2183, 0.2540, 0.2524, 0.2753],\n",
            "        [0.2075, 0.2561, 0.2536, 0.2828],\n",
            "        [0.2101, 0.2573, 0.2551, 0.2774],\n",
            "        [0.2115, 0.2583, 0.2564, 0.2738],\n",
            "        [0.2181, 0.2542, 0.2530, 0.2747]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2178, 0.2538, 0.2522, 0.2762],\n",
            "        [0.2067, 0.2559, 0.2533, 0.2841],\n",
            "        [0.2095, 0.2571, 0.2549, 0.2785],\n",
            "        [0.2108, 0.2583, 0.2563, 0.2746],\n",
            "        [0.2175, 0.2541, 0.2528, 0.2756]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2166, 0.2539, 0.2522, 0.2772],\n",
            "        [0.2052, 0.2560, 0.2533, 0.2855],\n",
            "        [0.2082, 0.2572, 0.2549, 0.2797],\n",
            "        [0.2094, 0.2585, 0.2564, 0.2756],\n",
            "        [0.2164, 0.2542, 0.2529, 0.2766]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2154, 0.2539, 0.2522, 0.2785],\n",
            "        [0.2032, 0.2562, 0.2533, 0.2873],\n",
            "        [0.2064, 0.2574, 0.2550, 0.2812],\n",
            "        [0.2076, 0.2589, 0.2567, 0.2768],\n",
            "        [0.2148, 0.2544, 0.2530, 0.2778]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2141, 0.2541, 0.2522, 0.2796],\n",
            "        [0.2014, 0.2564, 0.2534, 0.2889],\n",
            "        [0.2046, 0.2577, 0.2552, 0.2825],\n",
            "        [0.2059, 0.2592, 0.2570, 0.2779],\n",
            "        [0.2134, 0.2545, 0.2531, 0.2790]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2133, 0.2540, 0.2521, 0.2806],\n",
            "        [0.2002, 0.2564, 0.2532, 0.2902],\n",
            "        [0.2036, 0.2577, 0.2551, 0.2835],\n",
            "        [0.2050, 0.2593, 0.2569, 0.2788],\n",
            "        [0.2126, 0.2544, 0.2530, 0.2800]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2122, 0.2540, 0.2520, 0.2818],\n",
            "        [0.1987, 0.2562, 0.2530, 0.2921],\n",
            "        [0.2021, 0.2578, 0.2551, 0.2850],\n",
            "        [0.2036, 0.2594, 0.2570, 0.2800],\n",
            "        [0.2111, 0.2545, 0.2530, 0.2814]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2106, 0.2541, 0.2520, 0.2833],\n",
            "        [0.1966, 0.2563, 0.2528, 0.2942],\n",
            "        [0.2002, 0.2580, 0.2551, 0.2867],\n",
            "        [0.2020, 0.2596, 0.2570, 0.2815],\n",
            "        [0.2100, 0.2544, 0.2527, 0.2829]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2092, 0.2542, 0.2520, 0.2845],\n",
            "        [0.1949, 0.2564, 0.2527, 0.2960],\n",
            "        [0.1985, 0.2582, 0.2552, 0.2881],\n",
            "        [0.2001, 0.2600, 0.2573, 0.2826],\n",
            "        [0.2083, 0.2546, 0.2529, 0.2841]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2086, 0.2541, 0.2518, 0.2854],\n",
            "        [0.1944, 0.2560, 0.2522, 0.2975],\n",
            "        [0.1978, 0.2580, 0.2548, 0.2894],\n",
            "        [0.1995, 0.2599, 0.2570, 0.2836],\n",
            "        [0.2076, 0.2544, 0.2527, 0.2853]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2075, 0.2541, 0.2518, 0.2865],\n",
            "        [0.1928, 0.2560, 0.2522, 0.2991],\n",
            "        [0.1963, 0.2582, 0.2549, 0.2906],\n",
            "        [0.1982, 0.2600, 0.2571, 0.2847],\n",
            "        [0.2064, 0.2545, 0.2527, 0.2864]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2065, 0.2542, 0.2517, 0.2876],\n",
            "        [0.1918, 0.2557, 0.2517, 0.3008],\n",
            "        [0.1955, 0.2580, 0.2546, 0.2920],\n",
            "        [0.1973, 0.2600, 0.2569, 0.2858],\n",
            "        [0.2056, 0.2543, 0.2524, 0.2876]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2058, 0.2541, 0.2516, 0.2885],\n",
            "        [0.1907, 0.2556, 0.2514, 0.3024],\n",
            "        [0.1942, 0.2581, 0.2545, 0.2932],\n",
            "        [0.1961, 0.2602, 0.2569, 0.2868],\n",
            "        [0.2046, 0.2544, 0.2523, 0.2887]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2052, 0.2540, 0.2514, 0.2894],\n",
            "        [0.1900, 0.2552, 0.2509, 0.3040],\n",
            "        [0.1933, 0.2580, 0.2543, 0.2945],\n",
            "        [0.1950, 0.2603, 0.2569, 0.2879],\n",
            "        [0.2037, 0.2543, 0.2521, 0.2899]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2039, 0.2541, 0.2514, 0.2906],\n",
            "        [0.1880, 0.2553, 0.2508, 0.3059],\n",
            "        [0.1913, 0.2582, 0.2544, 0.2961],\n",
            "        [0.1931, 0.2606, 0.2571, 0.2892],\n",
            "        [0.2019, 0.2546, 0.2523, 0.2912]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2032, 0.2540, 0.2513, 0.2915],\n",
            "        [0.1873, 0.2548, 0.2502, 0.3076],\n",
            "        [0.1905, 0.2579, 0.2540, 0.2976],\n",
            "        [0.1923, 0.2604, 0.2568, 0.2905],\n",
            "        [0.2014, 0.2542, 0.2519, 0.2925]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2019, 0.2541, 0.2513, 0.2927],\n",
            "        [0.1853, 0.2550, 0.2502, 0.3094],\n",
            "        [0.1888, 0.2581, 0.2540, 0.2991],\n",
            "        [0.1907, 0.2607, 0.2570, 0.2916],\n",
            "        [0.2001, 0.2542, 0.2519, 0.2938]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2012, 0.2540, 0.2511, 0.2937],\n",
            "        [0.1841, 0.2547, 0.2499, 0.3113],\n",
            "        [0.1875, 0.2580, 0.2539, 0.3006],\n",
            "        [0.1893, 0.2609, 0.2571, 0.2928],\n",
            "        [0.1990, 0.2542, 0.2518, 0.2950]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2000, 0.2540, 0.2511, 0.2949],\n",
            "        [0.1829, 0.2544, 0.2494, 0.3133],\n",
            "        [0.1863, 0.2579, 0.2536, 0.3022],\n",
            "        [0.1881, 0.2609, 0.2570, 0.2940],\n",
            "        [0.1979, 0.2541, 0.2516, 0.2964]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1990, 0.2540, 0.2509, 0.2961],\n",
            "        [0.1816, 0.2541, 0.2490, 0.3153],\n",
            "        [0.1853, 0.2576, 0.2532, 0.3039],\n",
            "        [0.1870, 0.2608, 0.2567, 0.2955],\n",
            "        [0.1968, 0.2539, 0.2513, 0.2980]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1988, 0.2538, 0.2507, 0.2967],\n",
            "        [0.1814, 0.2537, 0.2485, 0.3164],\n",
            "        [0.1849, 0.2574, 0.2529, 0.3048],\n",
            "        [0.1864, 0.2607, 0.2565, 0.2964],\n",
            "        [0.1965, 0.2536, 0.2509, 0.2989]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1976, 0.2538, 0.2506, 0.2980],\n",
            "        [0.1797, 0.2535, 0.2482, 0.3186],\n",
            "        [0.1833, 0.2575, 0.2528, 0.3064],\n",
            "        [0.1848, 0.2609, 0.2566, 0.2977],\n",
            "        [0.1953, 0.2535, 0.2507, 0.3006]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1970, 0.2536, 0.2503, 0.2990],\n",
            "        [0.1786, 0.2533, 0.2477, 0.3204],\n",
            "        [0.1823, 0.2573, 0.2525, 0.3079],\n",
            "        [0.1837, 0.2610, 0.2564, 0.2989],\n",
            "        [0.1942, 0.2534, 0.2505, 0.3019]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1959, 0.2538, 0.2505, 0.2999],\n",
            "        [0.1771, 0.2534, 0.2478, 0.3217],\n",
            "        [0.1809, 0.2576, 0.2527, 0.3087],\n",
            "        [0.1820, 0.2616, 0.2569, 0.2995],\n",
            "        [0.1925, 0.2539, 0.2509, 0.3027]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1956, 0.2538, 0.2504, 0.3002],\n",
            "        [0.1764, 0.2536, 0.2478, 0.3222],\n",
            "        [0.1804, 0.2577, 0.2527, 0.3092],\n",
            "        [0.1812, 0.2619, 0.2571, 0.2999],\n",
            "        [0.1917, 0.2541, 0.2511, 0.3031]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1951, 0.2539, 0.2504, 0.3006],\n",
            "        [0.1759, 0.2534, 0.2476, 0.3231],\n",
            "        [0.1798, 0.2578, 0.2527, 0.3098],\n",
            "        [0.1805, 0.2620, 0.2571, 0.3004],\n",
            "        [0.1908, 0.2543, 0.2512, 0.3036]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1946, 0.2539, 0.2504, 0.3012],\n",
            "        [0.1752, 0.2533, 0.2474, 0.3241],\n",
            "        [0.1792, 0.2577, 0.2526, 0.3106],\n",
            "        [0.1799, 0.2620, 0.2571, 0.3010],\n",
            "        [0.1904, 0.2543, 0.2511, 0.3043]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1941, 0.2539, 0.2504, 0.3016],\n",
            "        [0.1745, 0.2533, 0.2473, 0.3248],\n",
            "        [0.1785, 0.2578, 0.2526, 0.3112],\n",
            "        [0.1792, 0.2621, 0.2571, 0.3015],\n",
            "        [0.1898, 0.2542, 0.2510, 0.3051]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1933, 0.2540, 0.2504, 0.3024],\n",
            "        [0.1738, 0.2530, 0.2469, 0.3263],\n",
            "        [0.1778, 0.2576, 0.2523, 0.3123],\n",
            "        [0.1784, 0.2621, 0.2570, 0.3024],\n",
            "        [0.1891, 0.2540, 0.2508, 0.3061]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1930, 0.2538, 0.2501, 0.3030],\n",
            "        [0.1734, 0.2526, 0.2464, 0.3276],\n",
            "        [0.1774, 0.2574, 0.2520, 0.3133],\n",
            "        [0.1781, 0.2619, 0.2567, 0.3033],\n",
            "        [0.1889, 0.2537, 0.2503, 0.3071]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1919, 0.2538, 0.2500, 0.3042],\n",
            "        [0.1721, 0.2520, 0.2457, 0.3301],\n",
            "        [0.1761, 0.2573, 0.2517, 0.3149],\n",
            "        [0.1766, 0.2622, 0.2568, 0.3044],\n",
            "        [0.1876, 0.2537, 0.2503, 0.3085]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1912, 0.2536, 0.2497, 0.3054],\n",
            "        [0.1707, 0.2518, 0.2453, 0.3322],\n",
            "        [0.1751, 0.2571, 0.2514, 0.3165],\n",
            "        [0.1751, 0.2624, 0.2568, 0.3057],\n",
            "        [0.1866, 0.2534, 0.2499, 0.3101]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1903, 0.2537, 0.2497, 0.3063],\n",
            "        [0.1694, 0.2516, 0.2450, 0.3341],\n",
            "        [0.1736, 0.2572, 0.2513, 0.3179],\n",
            "        [0.1739, 0.2624, 0.2568, 0.3069],\n",
            "        [0.1855, 0.2533, 0.2497, 0.3115]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1895, 0.2537, 0.2497, 0.3071],\n",
            "        [0.1682, 0.2513, 0.2446, 0.3358],\n",
            "        [0.1724, 0.2572, 0.2513, 0.3192],\n",
            "        [0.1726, 0.2626, 0.2568, 0.3079],\n",
            "        [0.1845, 0.2532, 0.2495, 0.3127]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1888, 0.2537, 0.2496, 0.3079],\n",
            "        [0.1677, 0.2510, 0.2443, 0.3370],\n",
            "        [0.1719, 0.2570, 0.2510, 0.3201],\n",
            "        [0.1720, 0.2625, 0.2566, 0.3089],\n",
            "        [0.1838, 0.2530, 0.2493, 0.3138]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1883, 0.2535, 0.2494, 0.3088],\n",
            "        [0.1666, 0.2507, 0.2439, 0.3387],\n",
            "        [0.1709, 0.2569, 0.2508, 0.3214],\n",
            "        [0.1708, 0.2626, 0.2567, 0.3098],\n",
            "        [0.1827, 0.2531, 0.2493, 0.3149]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1875, 0.2535, 0.2492, 0.3098],\n",
            "        [0.1658, 0.2502, 0.2431, 0.3409],\n",
            "        [0.1702, 0.2565, 0.2502, 0.3231],\n",
            "        [0.1700, 0.2625, 0.2563, 0.3112],\n",
            "        [0.1821, 0.2527, 0.2487, 0.3165]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1870, 0.2535, 0.2491, 0.3104],\n",
            "        [0.1651, 0.2499, 0.2427, 0.3422],\n",
            "        [0.1695, 0.2563, 0.2499, 0.3243],\n",
            "        [0.1692, 0.2624, 0.2561, 0.3122],\n",
            "        [0.1815, 0.2525, 0.2485, 0.3176]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1864, 0.2535, 0.2490, 0.3112],\n",
            "        [0.1645, 0.2494, 0.2421, 0.3440],\n",
            "        [0.1688, 0.2561, 0.2495, 0.3256],\n",
            "        [0.1685, 0.2623, 0.2559, 0.3133],\n",
            "        [0.1808, 0.2522, 0.2481, 0.3189]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1859, 0.2533, 0.2488, 0.3120],\n",
            "        [0.1639, 0.2490, 0.2417, 0.3455],\n",
            "        [0.1683, 0.2557, 0.2491, 0.3269],\n",
            "        [0.1679, 0.2622, 0.2557, 0.3143],\n",
            "        [0.1802, 0.2520, 0.2479, 0.3199]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1854, 0.2531, 0.2486, 0.3129],\n",
            "        [0.1630, 0.2485, 0.2412, 0.3473],\n",
            "        [0.1673, 0.2555, 0.2489, 0.3283],\n",
            "        [0.1670, 0.2621, 0.2556, 0.3153],\n",
            "        [0.1795, 0.2519, 0.2477, 0.3210]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1851, 0.2529, 0.2484, 0.3136],\n",
            "        [0.1625, 0.2480, 0.2406, 0.3489],\n",
            "        [0.1666, 0.2552, 0.2485, 0.3297],\n",
            "        [0.1662, 0.2621, 0.2555, 0.3162],\n",
            "        [0.1787, 0.2518, 0.2475, 0.3220]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1841, 0.2530, 0.2484, 0.3144],\n",
            "        [0.1612, 0.2479, 0.2404, 0.3504],\n",
            "        [0.1654, 0.2552, 0.2484, 0.3309],\n",
            "        [0.1648, 0.2624, 0.2557, 0.3171],\n",
            "        [0.1774, 0.2518, 0.2474, 0.3234]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1838, 0.2529, 0.2482, 0.3151],\n",
            "        [0.1610, 0.2473, 0.2398, 0.3519],\n",
            "        [0.1651, 0.2546, 0.2479, 0.3324],\n",
            "        [0.1644, 0.2620, 0.2553, 0.3182],\n",
            "        [0.1770, 0.2514, 0.2471, 0.3245]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1840, 0.2526, 0.2479, 0.3155],\n",
            "        [0.1608, 0.2468, 0.2392, 0.3532],\n",
            "        [0.1649, 0.2544, 0.2475, 0.3333],\n",
            "        [0.1642, 0.2619, 0.2550, 0.3189],\n",
            "        [0.1768, 0.2511, 0.2466, 0.3254]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1836, 0.2526, 0.2478, 0.3160],\n",
            "        [0.1602, 0.2465, 0.2389, 0.3543],\n",
            "        [0.1642, 0.2542, 0.2472, 0.3344],\n",
            "        [0.1634, 0.2619, 0.2549, 0.3198],\n",
            "        [0.1761, 0.2509, 0.2464, 0.3265]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1832, 0.2525, 0.2477, 0.3166],\n",
            "        [0.1595, 0.2463, 0.2385, 0.3557],\n",
            "        [0.1636, 0.2540, 0.2470, 0.3355],\n",
            "        [0.1628, 0.2619, 0.2548, 0.3206],\n",
            "        [0.1756, 0.2508, 0.2462, 0.3274]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1824, 0.2526, 0.2477, 0.3173],\n",
            "        [0.1589, 0.2458, 0.2381, 0.3571],\n",
            "        [0.1630, 0.2537, 0.2466, 0.3367],\n",
            "        [0.1621, 0.2618, 0.2547, 0.3214],\n",
            "        [0.1751, 0.2506, 0.2460, 0.3283]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1822, 0.2525, 0.2475, 0.3178],\n",
            "        [0.1586, 0.2454, 0.2376, 0.3584],\n",
            "        [0.1627, 0.2534, 0.2462, 0.3377],\n",
            "        [0.1616, 0.2617, 0.2545, 0.3222],\n",
            "        [0.1747, 0.2503, 0.2457, 0.3293]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1817, 0.2524, 0.2474, 0.3184],\n",
            "        [0.1580, 0.2451, 0.2372, 0.3597],\n",
            "        [0.1620, 0.2532, 0.2460, 0.3388],\n",
            "        [0.1611, 0.2617, 0.2544, 0.3228],\n",
            "        [0.1744, 0.2501, 0.2454, 0.3301]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1815, 0.2523, 0.2473, 0.3189],\n",
            "        [0.1576, 0.2446, 0.2366, 0.3611],\n",
            "        [0.1616, 0.2529, 0.2456, 0.3399],\n",
            "        [0.1608, 0.2615, 0.2540, 0.3237],\n",
            "        [0.1740, 0.2499, 0.2451, 0.3310]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1809, 0.2523, 0.2471, 0.3196],\n",
            "        [0.1569, 0.2442, 0.2362, 0.3627],\n",
            "        [0.1610, 0.2525, 0.2452, 0.3413],\n",
            "        [0.1601, 0.2613, 0.2538, 0.3247],\n",
            "        [0.1736, 0.2495, 0.2447, 0.3323]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1810, 0.2522, 0.2470, 0.3198],\n",
            "        [0.1570, 0.2438, 0.2358, 0.3635],\n",
            "        [0.1610, 0.2523, 0.2448, 0.3419],\n",
            "        [0.1601, 0.2611, 0.2535, 0.3254],\n",
            "        [0.1734, 0.2493, 0.2444, 0.3330]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1805, 0.2521, 0.2469, 0.3204],\n",
            "        [0.1565, 0.2435, 0.2355, 0.3645],\n",
            "        [0.1605, 0.2520, 0.2446, 0.3429],\n",
            "        [0.1596, 0.2610, 0.2534, 0.3260],\n",
            "        [0.1730, 0.2490, 0.2441, 0.3338]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1801, 0.2522, 0.2468, 0.3209],\n",
            "        [0.1557, 0.2431, 0.2349, 0.3662],\n",
            "        [0.1597, 0.2520, 0.2443, 0.3440],\n",
            "        [0.1588, 0.2611, 0.2533, 0.3268],\n",
            "        [0.1725, 0.2489, 0.2438, 0.3348]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1800, 0.2521, 0.2467, 0.3211],\n",
            "        [0.1556, 0.2429, 0.2346, 0.3669],\n",
            "        [0.1595, 0.2518, 0.2442, 0.3445],\n",
            "        [0.1584, 0.2611, 0.2532, 0.3272],\n",
            "        [0.1720, 0.2488, 0.2437, 0.3354]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1797, 0.2521, 0.2467, 0.3215],\n",
            "        [0.1551, 0.2426, 0.2344, 0.3679],\n",
            "        [0.1591, 0.2516, 0.2439, 0.3453],\n",
            "        [0.1581, 0.2610, 0.2530, 0.3278],\n",
            "        [0.1720, 0.2485, 0.2433, 0.3362]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1795, 0.2520, 0.2466, 0.3220],\n",
            "        [0.1549, 0.2423, 0.2341, 0.3687],\n",
            "        [0.1589, 0.2514, 0.2437, 0.3461],\n",
            "        [0.1579, 0.2609, 0.2529, 0.3283],\n",
            "        [0.1718, 0.2482, 0.2431, 0.3370]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1788, 0.2520, 0.2465, 0.3228],\n",
            "        [0.1538, 0.2421, 0.2338, 0.3703],\n",
            "        [0.1580, 0.2513, 0.2435, 0.3472],\n",
            "        [0.1570, 0.2610, 0.2529, 0.3291],\n",
            "        [0.1708, 0.2483, 0.2431, 0.3379]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1787, 0.2517, 0.2462, 0.3234],\n",
            "        [0.1535, 0.2415, 0.2331, 0.3719],\n",
            "        [0.1575, 0.2508, 0.2430, 0.3486],\n",
            "        [0.1565, 0.2608, 0.2526, 0.3302],\n",
            "        [0.1705, 0.2478, 0.2426, 0.3391]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1786, 0.2516, 0.2461, 0.3237],\n",
            "        [0.1534, 0.2411, 0.2328, 0.3727],\n",
            "        [0.1574, 0.2506, 0.2427, 0.3492],\n",
            "        [0.1564, 0.2605, 0.2524, 0.3307],\n",
            "        [0.1704, 0.2475, 0.2423, 0.3398]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1787, 0.2515, 0.2460, 0.3238],\n",
            "        [0.1534, 0.2409, 0.2325, 0.3732],\n",
            "        [0.1574, 0.2504, 0.2425, 0.3497],\n",
            "        [0.1562, 0.2605, 0.2522, 0.3311],\n",
            "        [0.1702, 0.2473, 0.2420, 0.3404]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1787, 0.2514, 0.2458, 0.3242],\n",
            "        [0.1532, 0.2405, 0.2320, 0.3743],\n",
            "        [0.1572, 0.2502, 0.2421, 0.3505],\n",
            "        [0.1561, 0.2601, 0.2517, 0.3320],\n",
            "        [0.1702, 0.2469, 0.2414, 0.3415]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1788, 0.2513, 0.2456, 0.3243],\n",
            "        [0.1533, 0.2403, 0.2318, 0.3747],\n",
            "        [0.1573, 0.2501, 0.2419, 0.3508],\n",
            "        [0.1559, 0.2603, 0.2517, 0.3322],\n",
            "        [0.1702, 0.2468, 0.2412, 0.3419]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1785, 0.2513, 0.2456, 0.3246],\n",
            "        [0.1531, 0.2401, 0.2316, 0.3751],\n",
            "        [0.1571, 0.2499, 0.2417, 0.3513],\n",
            "        [0.1556, 0.2603, 0.2517, 0.3325],\n",
            "        [0.1699, 0.2467, 0.2411, 0.3423]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1783, 0.2513, 0.2455, 0.3249],\n",
            "        [0.1528, 0.2399, 0.2314, 0.3759],\n",
            "        [0.1567, 0.2498, 0.2416, 0.3519],\n",
            "        [0.1552, 0.2602, 0.2516, 0.3330],\n",
            "        [0.1695, 0.2466, 0.2410, 0.3428]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1781, 0.2513, 0.2455, 0.3252],\n",
            "        [0.1527, 0.2396, 0.2311, 0.3766],\n",
            "        [0.1565, 0.2496, 0.2414, 0.3525],\n",
            "        [0.1550, 0.2601, 0.2514, 0.3335],\n",
            "        [0.1694, 0.2464, 0.2408, 0.3434]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1782, 0.2511, 0.2454, 0.3253],\n",
            "        [0.1527, 0.2394, 0.2309, 0.3770],\n",
            "        [0.1565, 0.2494, 0.2412, 0.3529],\n",
            "        [0.1550, 0.2599, 0.2512, 0.3339],\n",
            "        [0.1693, 0.2462, 0.2406, 0.3439]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1780, 0.2510, 0.2453, 0.3257],\n",
            "        [0.1524, 0.2392, 0.2306, 0.3778],\n",
            "        [0.1562, 0.2492, 0.2410, 0.3537],\n",
            "        [0.1547, 0.2598, 0.2511, 0.3344],\n",
            "        [0.1691, 0.2460, 0.2403, 0.3446]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1780, 0.2509, 0.2452, 0.3259],\n",
            "        [0.1524, 0.2388, 0.2304, 0.3784],\n",
            "        [0.1561, 0.2489, 0.2407, 0.3543],\n",
            "        [0.1546, 0.2596, 0.2509, 0.3349],\n",
            "        [0.1690, 0.2458, 0.2401, 0.3451]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1780, 0.2509, 0.2451, 0.3261],\n",
            "        [0.1523, 0.2385, 0.2301, 0.3790],\n",
            "        [0.1561, 0.2486, 0.2404, 0.3549],\n",
            "        [0.1546, 0.2594, 0.2507, 0.3353],\n",
            "        [0.1690, 0.2455, 0.2398, 0.3457]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1781, 0.2507, 0.2449, 0.3262],\n",
            "        [0.1524, 0.2383, 0.2298, 0.3796],\n",
            "        [0.1561, 0.2484, 0.2401, 0.3553],\n",
            "        [0.1545, 0.2593, 0.2505, 0.3357],\n",
            "        [0.1690, 0.2452, 0.2395, 0.3463]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1781, 0.2507, 0.2448, 0.3264],\n",
            "        [0.1522, 0.2380, 0.2295, 0.3803],\n",
            "        [0.1558, 0.2483, 0.2399, 0.3560],\n",
            "        [0.1542, 0.2592, 0.2503, 0.3364],\n",
            "        [0.1688, 0.2450, 0.2392, 0.3470]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1780, 0.2506, 0.2448, 0.3266],\n",
            "        [0.1522, 0.2377, 0.2292, 0.3808],\n",
            "        [0.1557, 0.2481, 0.2398, 0.3564],\n",
            "        [0.1542, 0.2590, 0.2501, 0.3367],\n",
            "        [0.1688, 0.2448, 0.2390, 0.3474]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1781, 0.2505, 0.2447, 0.3268],\n",
            "        [0.1521, 0.2375, 0.2290, 0.3814],\n",
            "        [0.1557, 0.2478, 0.2395, 0.3570],\n",
            "        [0.1542, 0.2588, 0.2499, 0.3371],\n",
            "        [0.1687, 0.2445, 0.2388, 0.3479]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1779, 0.2505, 0.2446, 0.3269],\n",
            "        [0.1522, 0.2372, 0.2288, 0.3818],\n",
            "        [0.1556, 0.2476, 0.2393, 0.3575],\n",
            "        [0.1540, 0.2587, 0.2498, 0.3375],\n",
            "        [0.1687, 0.2443, 0.2385, 0.3485]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1776, 0.2505, 0.2446, 0.3272],\n",
            "        [0.1519, 0.2371, 0.2286, 0.3825],\n",
            "        [0.1552, 0.2475, 0.2391, 0.3582],\n",
            "        [0.1536, 0.2587, 0.2498, 0.3379],\n",
            "        [0.1685, 0.2441, 0.2384, 0.3490]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1777, 0.2504, 0.2445, 0.3273],\n",
            "        [0.1519, 0.2368, 0.2283, 0.3831],\n",
            "        [0.1551, 0.2473, 0.2389, 0.3587],\n",
            "        [0.1536, 0.2586, 0.2496, 0.3383],\n",
            "        [0.1684, 0.2439, 0.2381, 0.3496]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1776, 0.2504, 0.2444, 0.3275],\n",
            "        [0.1517, 0.2366, 0.2281, 0.3837],\n",
            "        [0.1548, 0.2472, 0.2388, 0.3592],\n",
            "        [0.1533, 0.2585, 0.2495, 0.3387],\n",
            "        [0.1681, 0.2438, 0.2380, 0.3501]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1776, 0.2503, 0.2444, 0.3277],\n",
            "        [0.1517, 0.2363, 0.2279, 0.3840],\n",
            "        [0.1548, 0.2470, 0.2386, 0.3596],\n",
            "        [0.1533, 0.2584, 0.2494, 0.3389],\n",
            "        [0.1681, 0.2436, 0.2378, 0.3504]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1776, 0.2503, 0.2443, 0.3278],\n",
            "        [0.1518, 0.2361, 0.2277, 0.3844],\n",
            "        [0.1548, 0.2468, 0.2384, 0.3601],\n",
            "        [0.1533, 0.2582, 0.2492, 0.3393],\n",
            "        [0.1681, 0.2434, 0.2376, 0.3510]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1773, 0.2503, 0.2443, 0.3281],\n",
            "        [0.1514, 0.2359, 0.2274, 0.3853],\n",
            "        [0.1545, 0.2466, 0.2382, 0.3606],\n",
            "        [0.1531, 0.2582, 0.2491, 0.3397],\n",
            "        [0.1680, 0.2432, 0.2373, 0.3515]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1773, 0.2502, 0.2442, 0.3283],\n",
            "        [0.1513, 0.2357, 0.2273, 0.3857],\n",
            "        [0.1544, 0.2464, 0.2380, 0.3612],\n",
            "        [0.1529, 0.2580, 0.2490, 0.3400],\n",
            "        [0.1679, 0.2430, 0.2372, 0.3519]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1772, 0.2502, 0.2442, 0.3284],\n",
            "        [0.1512, 0.2355, 0.2271, 0.3862],\n",
            "        [0.1542, 0.2463, 0.2379, 0.3616],\n",
            "        [0.1527, 0.2580, 0.2490, 0.3403],\n",
            "        [0.1679, 0.2428, 0.2370, 0.3524]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1776, 0.2500, 0.2440, 0.3284],\n",
            "        [0.1515, 0.2351, 0.2267, 0.3867],\n",
            "        [0.1544, 0.2460, 0.2375, 0.3621],\n",
            "        [0.1529, 0.2577, 0.2486, 0.3408],\n",
            "        [0.1680, 0.2425, 0.2367, 0.3528]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1777, 0.2499, 0.2439, 0.3285],\n",
            "        [0.1516, 0.2348, 0.2264, 0.3872],\n",
            "        [0.1546, 0.2457, 0.2373, 0.3624],\n",
            "        [0.1530, 0.2575, 0.2484, 0.3412],\n",
            "        [0.1683, 0.2422, 0.2363, 0.3533]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1776, 0.2499, 0.2439, 0.3286],\n",
            "        [0.1514, 0.2347, 0.2263, 0.3875],\n",
            "        [0.1544, 0.2457, 0.2372, 0.3627],\n",
            "        [0.1527, 0.2575, 0.2484, 0.3414],\n",
            "        [0.1680, 0.2421, 0.2362, 0.3537]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1776, 0.2499, 0.2438, 0.3287],\n",
            "        [0.1514, 0.2346, 0.2262, 0.3877],\n",
            "        [0.1544, 0.2456, 0.2371, 0.3628],\n",
            "        [0.1527, 0.2574, 0.2483, 0.3415],\n",
            "        [0.1681, 0.2420, 0.2361, 0.3538]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1775, 0.2498, 0.2438, 0.3289],\n",
            "        [0.1514, 0.2344, 0.2261, 0.3881],\n",
            "        [0.1542, 0.2454, 0.2370, 0.3633],\n",
            "        [0.1525, 0.2574, 0.2483, 0.3418],\n",
            "        [0.1680, 0.2418, 0.2360, 0.3542]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1777, 0.2497, 0.2437, 0.3289],\n",
            "        [0.1515, 0.2342, 0.2259, 0.3885],\n",
            "        [0.1544, 0.2452, 0.2368, 0.3636],\n",
            "        [0.1526, 0.2572, 0.2481, 0.3421],\n",
            "        [0.1680, 0.2416, 0.2357, 0.3546]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1776, 0.2497, 0.2437, 0.3291],\n",
            "        [0.1514, 0.2341, 0.2257, 0.3888],\n",
            "        [0.1542, 0.2451, 0.2367, 0.3640],\n",
            "        [0.1525, 0.2572, 0.2480, 0.3424],\n",
            "        [0.1679, 0.2415, 0.2356, 0.3550]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1777, 0.2496, 0.2436, 0.3291],\n",
            "        [0.1514, 0.2339, 0.2256, 0.3892],\n",
            "        [0.1542, 0.2449, 0.2365, 0.3644],\n",
            "        [0.1525, 0.2570, 0.2479, 0.3426],\n",
            "        [0.1682, 0.2412, 0.2353, 0.3553]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1779, 0.2495, 0.2435, 0.3291],\n",
            "        [0.1517, 0.2336, 0.2253, 0.3894],\n",
            "        [0.1543, 0.2447, 0.2363, 0.3647],\n",
            "        [0.1526, 0.2569, 0.2477, 0.3428],\n",
            "        [0.1683, 0.2410, 0.2351, 0.3556]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1777, 0.2495, 0.2435, 0.3293],\n",
            "        [0.1514, 0.2335, 0.2253, 0.3898],\n",
            "        [0.1541, 0.2446, 0.2362, 0.3651],\n",
            "        [0.1524, 0.2569, 0.2477, 0.3430],\n",
            "        [0.1681, 0.2409, 0.2350, 0.3559]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1779, 0.2494, 0.2434, 0.3293],\n",
            "        [0.1516, 0.2333, 0.2251, 0.3900],\n",
            "        [0.1541, 0.2444, 0.2361, 0.3654],\n",
            "        [0.1524, 0.2568, 0.2476, 0.3432],\n",
            "        [0.1682, 0.2407, 0.2349, 0.3562]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1778, 0.2494, 0.2434, 0.3294],\n",
            "        [0.1516, 0.2332, 0.2250, 0.3903],\n",
            "        [0.1541, 0.2443, 0.2359, 0.3656],\n",
            "        [0.1524, 0.2566, 0.2475, 0.3434],\n",
            "        [0.1683, 0.2406, 0.2347, 0.3565]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1778, 0.2493, 0.2433, 0.3296],\n",
            "        [0.1515, 0.2331, 0.2249, 0.3906],\n",
            "        [0.1540, 0.2442, 0.2359, 0.3659],\n",
            "        [0.1523, 0.2566, 0.2475, 0.3437],\n",
            "        [0.1682, 0.2404, 0.2346, 0.3569]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1778, 0.2493, 0.2433, 0.3296],\n",
            "        [0.1516, 0.2329, 0.2247, 0.3909],\n",
            "        [0.1540, 0.2441, 0.2357, 0.3662],\n",
            "        [0.1522, 0.2565, 0.2474, 0.3438],\n",
            "        [0.1683, 0.2402, 0.2344, 0.3571]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1779, 0.2493, 0.2432, 0.3296],\n",
            "        [0.1516, 0.2328, 0.2246, 0.3910],\n",
            "        [0.1541, 0.2440, 0.2356, 0.3663],\n",
            "        [0.1524, 0.2564, 0.2472, 0.3440],\n",
            "        [0.1683, 0.2400, 0.2342, 0.3574]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1780, 0.2492, 0.2431, 0.3297],\n",
            "        [0.1517, 0.2326, 0.2244, 0.3913],\n",
            "        [0.1541, 0.2438, 0.2355, 0.3666],\n",
            "        [0.1523, 0.2563, 0.2471, 0.3442],\n",
            "        [0.1684, 0.2399, 0.2341, 0.3577]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1782, 0.2491, 0.2431, 0.3296],\n",
            "        [0.1519, 0.2324, 0.2242, 0.3915],\n",
            "        [0.1542, 0.2437, 0.2353, 0.3668],\n",
            "        [0.1524, 0.2562, 0.2470, 0.3444],\n",
            "        [0.1687, 0.2396, 0.2338, 0.3579]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1781, 0.2491, 0.2431, 0.3297],\n",
            "        [0.1518, 0.2323, 0.2242, 0.3917],\n",
            "        [0.1542, 0.2436, 0.2352, 0.3671],\n",
            "        [0.1523, 0.2562, 0.2470, 0.3445],\n",
            "        [0.1686, 0.2396, 0.2338, 0.3581]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1782, 0.2490, 0.2430, 0.3298],\n",
            "        [0.1519, 0.2321, 0.2240, 0.3920],\n",
            "        [0.1542, 0.2434, 0.2351, 0.3674],\n",
            "        [0.1523, 0.2561, 0.2469, 0.3447],\n",
            "        [0.1687, 0.2394, 0.2336, 0.3583]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1783, 0.2489, 0.2429, 0.3298],\n",
            "        [0.1521, 0.2319, 0.2238, 0.3922],\n",
            "        [0.1542, 0.2433, 0.2349, 0.3676],\n",
            "        [0.1524, 0.2559, 0.2467, 0.3449],\n",
            "        [0.1688, 0.2392, 0.2334, 0.3586]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1783, 0.2489, 0.2429, 0.3298],\n",
            "        [0.1520, 0.2318, 0.2238, 0.3924],\n",
            "        [0.1542, 0.2432, 0.2349, 0.3677],\n",
            "        [0.1524, 0.2559, 0.2467, 0.3450],\n",
            "        [0.1688, 0.2391, 0.2333, 0.3588]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1786, 0.2488, 0.2428, 0.3298],\n",
            "        [0.1522, 0.2317, 0.2237, 0.3924],\n",
            "        [0.1543, 0.2431, 0.2348, 0.3678],\n",
            "        [0.1525, 0.2558, 0.2466, 0.3451],\n",
            "        [0.1689, 0.2390, 0.2332, 0.3589]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1784, 0.2489, 0.2428, 0.3299],\n",
            "        [0.1522, 0.2316, 0.2236, 0.3926],\n",
            "        [0.1542, 0.2431, 0.2347, 0.3680],\n",
            "        [0.1523, 0.2558, 0.2466, 0.3453],\n",
            "        [0.1688, 0.2389, 0.2331, 0.3592]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1784, 0.2488, 0.2428, 0.3300],\n",
            "        [0.1522, 0.2315, 0.2236, 0.3927],\n",
            "        [0.1542, 0.2429, 0.2346, 0.3683],\n",
            "        [0.1524, 0.2557, 0.2466, 0.3453],\n",
            "        [0.1690, 0.2388, 0.2330, 0.3593]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1785, 0.2488, 0.2428, 0.3300],\n",
            "        [0.1522, 0.2314, 0.2235, 0.3929],\n",
            "        [0.1542, 0.2428, 0.2345, 0.3685],\n",
            "        [0.1524, 0.2557, 0.2465, 0.3454],\n",
            "        [0.1691, 0.2386, 0.2329, 0.3594]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1786, 0.2487, 0.2427, 0.3301],\n",
            "        [0.1523, 0.2312, 0.2233, 0.3931],\n",
            "        [0.1542, 0.2427, 0.2344, 0.3687],\n",
            "        [0.1524, 0.2556, 0.2464, 0.3456],\n",
            "        [0.1692, 0.2385, 0.2328, 0.3596]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1785, 0.2487, 0.2427, 0.3301],\n",
            "        [0.1523, 0.2311, 0.2232, 0.3934],\n",
            "        [0.1542, 0.2426, 0.2343, 0.3689],\n",
            "        [0.1523, 0.2555, 0.2463, 0.3458],\n",
            "        [0.1691, 0.2384, 0.2327, 0.3599]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1787, 0.2486, 0.2426, 0.3301],\n",
            "        [0.1524, 0.2310, 0.2231, 0.3935],\n",
            "        [0.1543, 0.2425, 0.2342, 0.3690],\n",
            "        [0.1524, 0.2554, 0.2462, 0.3460],\n",
            "        [0.1692, 0.2382, 0.2325, 0.3601]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1788, 0.2485, 0.2426, 0.3301],\n",
            "        [0.1525, 0.2309, 0.2231, 0.3935],\n",
            "        [0.1543, 0.2424, 0.2341, 0.3692],\n",
            "        [0.1525, 0.2553, 0.2461, 0.3462],\n",
            "        [0.1692, 0.2381, 0.2324, 0.3603]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1788, 0.2485, 0.2426, 0.3302],\n",
            "        [0.1525, 0.2308, 0.2230, 0.3937],\n",
            "        [0.1543, 0.2423, 0.2340, 0.3694],\n",
            "        [0.1525, 0.2552, 0.2461, 0.3462],\n",
            "        [0.1694, 0.2380, 0.2323, 0.3604]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1787, 0.2485, 0.2425, 0.3302],\n",
            "        [0.1525, 0.2307, 0.2229, 0.3938],\n",
            "        [0.1543, 0.2422, 0.2340, 0.3695],\n",
            "        [0.1525, 0.2552, 0.2460, 0.3463],\n",
            "        [0.1693, 0.2379, 0.2322, 0.3605]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1788, 0.2485, 0.2425, 0.3302],\n",
            "        [0.1526, 0.2306, 0.2228, 0.3940],\n",
            "        [0.1543, 0.2422, 0.2339, 0.3696],\n",
            "        [0.1525, 0.2551, 0.2459, 0.3464],\n",
            "        [0.1695, 0.2377, 0.2321, 0.3607]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1790, 0.2484, 0.2424, 0.3302],\n",
            "        [0.1527, 0.2306, 0.2227, 0.3940],\n",
            "        [0.1545, 0.2421, 0.2338, 0.3697],\n",
            "        [0.1526, 0.2550, 0.2458, 0.3465],\n",
            "        [0.1696, 0.2376, 0.2320, 0.3608]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1790, 0.2484, 0.2424, 0.3302],\n",
            "        [0.1528, 0.2305, 0.2227, 0.3940],\n",
            "        [0.1545, 0.2420, 0.2337, 0.3698],\n",
            "        [0.1527, 0.2549, 0.2458, 0.3466],\n",
            "        [0.1696, 0.2376, 0.2319, 0.3609]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1790, 0.2484, 0.2424, 0.3302],\n",
            "        [0.1528, 0.2304, 0.2227, 0.3941],\n",
            "        [0.1545, 0.2419, 0.2337, 0.3699],\n",
            "        [0.1527, 0.2549, 0.2458, 0.3467],\n",
            "        [0.1697, 0.2375, 0.2319, 0.3610]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1790, 0.2484, 0.2424, 0.3302],\n",
            "        [0.1528, 0.2304, 0.2226, 0.3942],\n",
            "        [0.1545, 0.2419, 0.2336, 0.3700],\n",
            "        [0.1527, 0.2549, 0.2457, 0.3467],\n",
            "        [0.1697, 0.2374, 0.2318, 0.3611]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1790, 0.2484, 0.2424, 0.3302],\n",
            "        [0.1529, 0.2303, 0.2226, 0.3942],\n",
            "        [0.1545, 0.2418, 0.2336, 0.3700],\n",
            "        [0.1527, 0.2548, 0.2457, 0.3468],\n",
            "        [0.1698, 0.2373, 0.2317, 0.3612]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1791, 0.2483, 0.2423, 0.3302],\n",
            "        [0.1529, 0.2303, 0.2225, 0.3943],\n",
            "        [0.1546, 0.2418, 0.2336, 0.3701],\n",
            "        [0.1528, 0.2547, 0.2456, 0.3469],\n",
            "        [0.1699, 0.2372, 0.2316, 0.3613]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1792, 0.2483, 0.2423, 0.3303],\n",
            "        [0.1530, 0.2302, 0.2225, 0.3944],\n",
            "        [0.1546, 0.2417, 0.2335, 0.3702],\n",
            "        [0.1528, 0.2547, 0.2456, 0.3469],\n",
            "        [0.1700, 0.2371, 0.2316, 0.3613]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1793, 0.2482, 0.2423, 0.3302],\n",
            "        [0.1530, 0.2301, 0.2224, 0.3944],\n",
            "        [0.1547, 0.2417, 0.2335, 0.3702],\n",
            "        [0.1528, 0.2547, 0.2456, 0.3469],\n",
            "        [0.1700, 0.2371, 0.2315, 0.3614]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1793, 0.2482, 0.2423, 0.3302],\n",
            "        [0.1531, 0.2301, 0.2224, 0.3944],\n",
            "        [0.1547, 0.2416, 0.2334, 0.3702],\n",
            "        [0.1529, 0.2546, 0.2455, 0.3470],\n",
            "        [0.1701, 0.2370, 0.2315, 0.3614]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1793, 0.2482, 0.2423, 0.3302],\n",
            "        [0.1531, 0.2301, 0.2224, 0.3944],\n",
            "        [0.1548, 0.2416, 0.2334, 0.3702],\n",
            "        [0.1529, 0.2546, 0.2455, 0.3469],\n",
            "        [0.1702, 0.2370, 0.2314, 0.3614]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1793, 0.2482, 0.2422, 0.3302],\n",
            "        [0.1531, 0.2301, 0.2224, 0.3944],\n",
            "        [0.1548, 0.2416, 0.2334, 0.3703],\n",
            "        [0.1529, 0.2546, 0.2455, 0.3469],\n",
            "        [0.1702, 0.2370, 0.2314, 0.3614]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1794, 0.2482, 0.2422, 0.3302],\n",
            "        [0.1532, 0.2301, 0.2224, 0.3944],\n",
            "        [0.1548, 0.2416, 0.2334, 0.3703],\n",
            "        [0.1529, 0.2546, 0.2455, 0.3470],\n",
            "        [0.1702, 0.2369, 0.2314, 0.3615]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1794, 0.2482, 0.2422, 0.3302],\n",
            "        [0.1532, 0.2300, 0.2224, 0.3944],\n",
            "        [0.1548, 0.2415, 0.2334, 0.3703],\n",
            "        [0.1529, 0.2546, 0.2455, 0.3470],\n",
            "        [0.1702, 0.2369, 0.2314, 0.3615]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1794, 0.2482, 0.2422, 0.3302],\n",
            "        [0.1532, 0.2300, 0.2223, 0.3944],\n",
            "        [0.1548, 0.2415, 0.2334, 0.3703],\n",
            "        [0.1529, 0.2546, 0.2455, 0.3470],\n",
            "        [0.1703, 0.2369, 0.2314, 0.3615]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.1794, 0.2482, 0.2422, 0.3302],\n",
            "        [0.1532, 0.2300, 0.2223, 0.3944],\n",
            "        [0.1548, 0.2415, 0.2333, 0.3703],\n",
            "        [0.1529, 0.2546, 0.2455, 0.3470],\n",
            "        [0.1703, 0.2369, 0.2314, 0.3615]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN --train_name truck_nas_project_layer_types_cycleGAN --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 50 --n_epochs 100 --n_epochs_decay 100 --layer_types CycleGan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydysTofzVeRL",
        "outputId": "2cdeafb7-95a5-4c66-8d1e-7b6eadbbc1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 50                            \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: PixelDa                       \t[default: CycleGan]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_PixelDa\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_PixelDa\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 9.615 M\n",
            "[Network G_B] Total number of parameters : 9.615 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_PixelDa/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.292, data: 1.088) D_A: 0.298 G_A: 0.448 cycle_A: 1.476 idt_A: 1.732 D_B: 0.220 G_B: 0.502 cycle_B: 3.791 idt_B: 0.627 \n",
            "End of epoch 1 / 200 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.295, data: 0.160) D_A: 0.166 G_A: 0.284 cycle_A: 0.702 idt_A: 1.095 D_B: 0.116 G_B: 0.719 cycle_B: 2.656 idt_B: 0.319 \n",
            "End of epoch 2 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.291, data: 0.646) D_A: 0.301 G_A: 0.448 cycle_A: 1.384 idt_A: 1.284 D_B: 0.247 G_B: 0.316 cycle_B: 2.783 idt_B: 0.564 \n",
            "End of epoch 3 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.491, data: 0.166) D_A: 0.230 G_A: 0.376 cycle_A: 3.099 idt_A: 0.932 D_B: 0.151 G_B: 0.653 cycle_B: 3.096 idt_B: 1.004 \n",
            "End of epoch 4 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.308, data: 0.152) D_A: 0.242 G_A: 0.230 cycle_A: 1.006 idt_A: 1.250 D_B: 0.263 G_B: 0.307 cycle_B: 2.652 idt_B: 0.439 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.296, data: 0.168) D_A: 0.234 G_A: 0.269 cycle_A: 0.542 idt_A: 1.076 D_B: 0.184 G_B: 0.430 cycle_B: 2.208 idt_B: 0.258 \n",
            "End of epoch 6 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.308, data: 0.173) D_A: 0.263 G_A: 0.356 cycle_A: 0.840 idt_A: 1.472 D_B: 0.093 G_B: 0.232 cycle_B: 3.242 idt_B: 0.329 \n",
            "End of epoch 7 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.537, data: 0.187) D_A: 0.324 G_A: 0.414 cycle_A: 1.249 idt_A: 0.959 D_B: 0.121 G_B: 0.516 cycle_B: 2.404 idt_B: 0.437 \n",
            "End of epoch 8 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.297, data: 0.192) D_A: 0.238 G_A: 0.399 cycle_A: 0.839 idt_A: 1.194 D_B: 0.093 G_B: 0.422 cycle_B: 2.846 idt_B: 0.399 \n",
            "End of epoch 9 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.302, data: 0.154) D_A: 0.254 G_A: 0.403 cycle_A: 0.885 idt_A: 1.006 D_B: 0.193 G_B: 0.486 cycle_B: 2.376 idt_B: 0.357 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.290, data: 0.163) D_A: 0.138 G_A: 0.620 cycle_A: 1.310 idt_A: 0.898 D_B: 0.173 G_B: 0.358 cycle_B: 1.715 idt_B: 0.405 \n",
            "End of epoch 11 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.531, data: 0.161) D_A: 0.132 G_A: 0.508 cycle_A: 1.151 idt_A: 1.735 D_B: 0.253 G_B: 0.792 cycle_B: 3.349 idt_B: 0.560 \n",
            "End of epoch 12 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.296, data: 0.166) D_A: 0.186 G_A: 0.530 cycle_A: 0.710 idt_A: 1.049 D_B: 0.116 G_B: 0.924 cycle_B: 2.595 idt_B: 0.301 \n",
            "End of epoch 13 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.292, data: 0.178) D_A: 0.236 G_A: 0.304 cycle_A: 0.496 idt_A: 0.864 D_B: 0.167 G_B: 0.435 cycle_B: 2.242 idt_B: 0.189 \n",
            "End of epoch 14 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.292, data: 0.182) D_A: 0.365 G_A: 0.312 cycle_A: 0.819 idt_A: 1.270 D_B: 0.225 G_B: 0.221 cycle_B: 2.920 idt_B: 0.215 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.559, data: 0.165) D_A: 0.151 G_A: 0.515 cycle_A: 0.703 idt_A: 0.981 D_B: 0.063 G_B: 1.072 cycle_B: 2.126 idt_B: 0.241 \n",
            "End of epoch 16 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.294, data: 0.159) D_A: 0.116 G_A: 0.203 cycle_A: 0.794 idt_A: 1.000 D_B: 0.118 G_B: 0.376 cycle_B: 2.375 idt_B: 0.171 \n",
            "End of epoch 17 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.296, data: 0.167) D_A: 0.092 G_A: 0.616 cycle_A: 0.794 idt_A: 0.952 D_B: 0.202 G_B: 1.016 cycle_B: 2.354 idt_B: 0.233 \n",
            "End of epoch 18 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.296, data: 0.186) D_A: 0.087 G_A: 0.329 cycle_A: 0.726 idt_A: 1.148 D_B: 0.241 G_B: 0.141 cycle_B: 3.076 idt_B: 0.229 \n",
            "End of epoch 19 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.593, data: 0.189) D_A: 0.131 G_A: 0.487 cycle_A: 0.798 idt_A: 1.535 D_B: 0.104 G_B: 0.402 cycle_B: 3.439 idt_B: 0.384 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.295, data: 0.191) D_A: 0.205 G_A: 0.493 cycle_A: 0.645 idt_A: 1.223 D_B: 0.187 G_B: 0.197 cycle_B: 2.651 idt_B: 0.427 \n",
            "End of epoch 21 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.303, data: 0.181) D_A: 0.371 G_A: 0.151 cycle_A: 0.969 idt_A: 1.279 D_B: 0.365 G_B: 0.645 cycle_B: 2.568 idt_B: 0.605 \n",
            "End of epoch 22 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.289, data: 0.177) D_A: 0.186 G_A: 0.388 cycle_A: 0.823 idt_A: 1.166 D_B: 0.080 G_B: 0.539 cycle_B: 2.685 idt_B: 0.271 \n",
            "End of epoch 23 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.608, data: 0.181) D_A: 0.392 G_A: 0.820 cycle_A: 1.052 idt_A: 1.441 D_B: 0.141 G_B: 0.692 cycle_B: 2.963 idt_B: 0.383 \n",
            "End of epoch 24 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.287, data: 0.188) D_A: 0.108 G_A: 0.419 cycle_A: 0.542 idt_A: 1.454 D_B: 0.144 G_B: 0.831 cycle_B: 3.774 idt_B: 0.196 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.285, data: 0.167) D_A: 0.110 G_A: 0.511 cycle_A: 2.091 idt_A: 1.127 D_B: 0.122 G_B: 0.583 cycle_B: 2.543 idt_B: 0.706 \n",
            "End of epoch 26 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.296, data: 0.161) D_A: 0.123 G_A: 0.576 cycle_A: 0.514 idt_A: 1.040 D_B: 0.129 G_B: 0.992 cycle_B: 2.323 idt_B: 0.189 \n",
            "End of epoch 27 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.640, data: 0.175) D_A: 0.129 G_A: 1.125 cycle_A: 0.719 idt_A: 1.044 D_B: 0.143 G_B: 0.392 cycle_B: 2.281 idt_B: 0.329 \n",
            "End of epoch 28 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.293, data: 0.175) D_A: 0.235 G_A: 0.967 cycle_A: 0.548 idt_A: 0.884 D_B: 0.171 G_B: 0.353 cycle_B: 1.917 idt_B: 0.163 \n",
            "End of epoch 29 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.288, data: 0.164) D_A: 0.068 G_A: 0.603 cycle_A: 1.353 idt_A: 0.996 D_B: 0.245 G_B: 1.255 cycle_B: 2.077 idt_B: 0.448 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.291, data: 0.180) D_A: 0.185 G_A: 0.446 cycle_A: 0.460 idt_A: 1.268 D_B: 0.044 G_B: 0.258 cycle_B: 3.351 idt_B: 0.174 \n",
            "End of epoch 31 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.648, data: 0.172) D_A: 0.117 G_A: 0.518 cycle_A: 0.989 idt_A: 0.944 D_B: 0.132 G_B: 0.609 cycle_B: 1.978 idt_B: 0.378 \n",
            "End of epoch 32 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.284, data: 0.168) D_A: 0.113 G_A: 0.693 cycle_A: 0.685 idt_A: 0.803 D_B: 0.093 G_B: 0.980 cycle_B: 1.823 idt_B: 0.259 \n",
            "End of epoch 33 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.286, data: 0.176) D_A: 0.205 G_A: 1.171 cycle_A: 0.544 idt_A: 1.457 D_B: 0.293 G_B: 0.246 cycle_B: 2.627 idt_B: 0.193 \n",
            "End of epoch 34 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.292, data: 0.180) D_A: 0.070 G_A: 0.926 cycle_A: 0.567 idt_A: 1.026 D_B: 0.116 G_B: 0.451 cycle_B: 2.637 idt_B: 0.226 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.667, data: 0.180) D_A: 0.245 G_A: 0.833 cycle_A: 0.617 idt_A: 1.138 D_B: 0.198 G_B: 0.348 cycle_B: 2.142 idt_B: 0.222 \n",
            "End of epoch 36 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.286, data: 0.177) D_A: 0.052 G_A: 0.805 cycle_A: 0.600 idt_A: 1.429 D_B: 0.183 G_B: 0.636 cycle_B: 3.445 idt_B: 0.200 \n",
            "End of epoch 37 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.289, data: 0.191) D_A: 0.073 G_A: 0.853 cycle_A: 0.676 idt_A: 0.708 D_B: 0.108 G_B: 0.739 cycle_B: 1.844 idt_B: 0.224 \n",
            "End of epoch 38 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.283, data: 0.205) D_A: 0.125 G_A: 0.238 cycle_A: 0.413 idt_A: 1.010 D_B: 0.065 G_B: 0.507 cycle_B: 2.262 idt_B: 0.165 \n",
            "End of epoch 39 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.684, data: 0.157) D_A: 0.062 G_A: 0.406 cycle_A: 0.623 idt_A: 0.873 D_B: 0.116 G_B: 0.476 cycle_B: 1.885 idt_B: 0.264 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.281, data: 0.170) D_A: 0.134 G_A: 0.413 cycle_A: 0.568 idt_A: 0.925 D_B: 0.269 G_B: 1.347 cycle_B: 2.434 idt_B: 0.225 \n",
            "End of epoch 41 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.279, data: 0.184) D_A: 0.103 G_A: 0.860 cycle_A: 0.622 idt_A: 0.782 D_B: 0.153 G_B: 0.279 cycle_B: 1.996 idt_B: 0.178 \n",
            "End of epoch 42 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.282, data: 0.166) D_A: 0.291 G_A: 0.175 cycle_A: 0.712 idt_A: 1.040 D_B: 0.066 G_B: 0.582 cycle_B: 2.593 idt_B: 0.253 \n",
            "End of epoch 43 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.727, data: 0.172) D_A: 0.143 G_A: 0.820 cycle_A: 0.757 idt_A: 0.669 D_B: 0.197 G_B: 0.497 cycle_B: 1.922 idt_B: 0.334 \n",
            "End of epoch 44 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.281, data: 0.184) D_A: 0.231 G_A: 1.363 cycle_A: 0.849 idt_A: 0.921 D_B: 0.094 G_B: 0.872 cycle_B: 1.938 idt_B: 0.339 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.280, data: 0.188) D_A: 0.069 G_A: 0.654 cycle_A: 0.805 idt_A: 1.159 D_B: 0.116 G_B: 0.564 cycle_B: 2.659 idt_B: 0.279 \n",
            "End of epoch 46 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.286, data: 0.163) D_A: 0.060 G_A: 0.761 cycle_A: 0.789 idt_A: 0.859 D_B: 0.107 G_B: 0.359 cycle_B: 1.779 idt_B: 0.306 \n",
            "End of epoch 47 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 0.735, data: 0.180) D_A: 0.179 G_A: 0.336 cycle_A: 0.765 idt_A: 0.828 D_B: 0.144 G_B: 0.509 cycle_B: 2.135 idt_B: 0.361 \n",
            "End of epoch 48 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.285, data: 0.199) D_A: 0.203 G_A: 0.586 cycle_A: 0.717 idt_A: 0.936 D_B: 0.135 G_B: 0.300 cycle_B: 2.084 idt_B: 0.213 \n",
            "End of epoch 49 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.316, data: 0.161) D_A: 0.123 G_A: 0.373 cycle_A: 1.017 idt_A: 0.901 D_B: 0.075 G_B: 0.770 cycle_B: 2.683 idt_B: 0.210 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.296, data: 0.170) D_A: 0.092 G_A: 0.502 cycle_A: 0.615 idt_A: 1.013 D_B: 0.146 G_B: 0.189 cycle_B: 1.800 idt_B: 0.223 \n",
            "End of epoch 51 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 0.773, data: 0.165) D_A: 0.149 G_A: 0.549 cycle_A: 0.907 idt_A: 1.143 D_B: 0.306 G_B: 0.186 cycle_B: 2.482 idt_B: 0.331 \n",
            "End of epoch 52 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.290, data: 0.170) D_A: 0.154 G_A: 1.031 cycle_A: 1.135 idt_A: 0.718 D_B: 0.179 G_B: 0.346 cycle_B: 1.971 idt_B: 0.165 \n",
            "End of epoch 53 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.287, data: 0.168) D_A: 0.033 G_A: 0.277 cycle_A: 0.851 idt_A: 1.269 D_B: 0.132 G_B: 0.355 cycle_B: 2.312 idt_B: 0.401 \n",
            "End of epoch 54 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.452, data: 0.176) D_A: 0.388 G_A: 1.168 cycle_A: 0.728 idt_A: 0.730 D_B: 0.085 G_B: 0.299 cycle_B: 1.990 idt_B: 0.307 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 100, time: 0.814, data: 0.186) D_A: 0.173 G_A: 1.134 cycle_A: 0.729 idt_A: 1.240 D_B: 0.163 G_B: 1.054 cycle_B: 3.212 idt_B: 0.272 \n",
            "End of epoch 56 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.288, data: 0.162) D_A: 0.068 G_A: 0.401 cycle_A: 0.546 idt_A: 0.713 D_B: 0.033 G_B: 1.261 cycle_B: 1.859 idt_B: 0.244 \n",
            "End of epoch 57 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.287, data: 0.188) D_A: 0.189 G_A: 0.256 cycle_A: 0.930 idt_A: 0.599 D_B: 0.114 G_B: 0.331 cycle_B: 1.635 idt_B: 0.237 \n",
            "End of epoch 58 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.291, data: 0.167) D_A: 0.121 G_A: 0.532 cycle_A: 0.502 idt_A: 0.864 D_B: 0.244 G_B: 0.236 cycle_B: 2.045 idt_B: 0.288 \n",
            "End of epoch 59 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.837, data: 0.193) D_A: 0.117 G_A: 0.694 cycle_A: 0.657 idt_A: 0.854 D_B: 0.231 G_B: 0.555 cycle_B: 2.183 idt_B: 0.256 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.290, data: 0.174) D_A: 0.218 G_A: 0.211 cycle_A: 0.596 idt_A: 0.548 D_B: 0.055 G_B: 0.962 cycle_B: 1.438 idt_B: 0.287 \n",
            "End of epoch 61 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.289, data: 0.181) D_A: 0.100 G_A: 0.397 cycle_A: 0.579 idt_A: 0.941 D_B: 0.077 G_B: 1.327 cycle_B: 2.271 idt_B: 0.189 \n",
            "End of epoch 62 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.285, data: 0.184) D_A: 0.097 G_A: 0.570 cycle_A: 0.627 idt_A: 0.974 D_B: 0.226 G_B: 0.239 cycle_B: 2.072 idt_B: 0.275 \n",
            "End of epoch 63 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 100, time: 0.885, data: 0.190) D_A: 0.037 G_A: 0.266 cycle_A: 0.648 idt_A: 1.043 D_B: 0.108 G_B: 0.601 cycle_B: 2.150 idt_B: 0.141 \n",
            "End of epoch 64 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.294, data: 0.168) D_A: 0.161 G_A: 0.308 cycle_A: 0.956 idt_A: 1.188 D_B: 0.155 G_B: 0.891 cycle_B: 3.757 idt_B: 0.277 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.290, data: 0.177) D_A: 0.394 G_A: 0.074 cycle_A: 0.640 idt_A: 0.947 D_B: 0.168 G_B: 0.923 cycle_B: 2.540 idt_B: 0.299 \n",
            "End of epoch 66 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.286, data: 0.179) D_A: 0.061 G_A: 0.567 cycle_A: 0.637 idt_A: 0.848 D_B: 0.110 G_B: 0.388 cycle_B: 2.407 idt_B: 0.187 \n",
            "End of epoch 67 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 100, time: 0.886, data: 0.185) D_A: 0.202 G_A: 0.228 cycle_A: 0.675 idt_A: 0.964 D_B: 0.484 G_B: 0.100 cycle_B: 2.471 idt_B: 0.236 \n",
            "End of epoch 68 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.286, data: 0.195) D_A: 0.194 G_A: 0.205 cycle_A: 0.865 idt_A: 0.593 D_B: 0.093 G_B: 0.647 cycle_B: 1.720 idt_B: 0.339 \n",
            "End of epoch 69 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.293, data: 0.192) D_A: 0.271 G_A: 0.144 cycle_A: 0.403 idt_A: 0.643 D_B: 0.112 G_B: 0.576 cycle_B: 1.971 idt_B: 0.143 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.288, data: 0.211) D_A: 0.107 G_A: 0.074 cycle_A: 0.775 idt_A: 1.134 D_B: 0.091 G_B: 0.356 cycle_B: 2.763 idt_B: 0.336 \n",
            "End of epoch 71 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 100, time: 0.930, data: 0.212) D_A: 0.108 G_A: 0.463 cycle_A: 0.361 idt_A: 0.917 D_B: 0.090 G_B: 0.831 cycle_B: 2.310 idt_B: 0.134 \n",
            "End of epoch 72 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.297, data: 0.211) D_A: 0.034 G_A: 0.528 cycle_A: 0.737 idt_A: 0.600 D_B: 0.087 G_B: 0.491 cycle_B: 1.937 idt_B: 0.176 \n",
            "End of epoch 73 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.311, data: 0.194) D_A: 0.101 G_A: 0.389 cycle_A: 0.816 idt_A: 1.012 D_B: 0.162 G_B: 0.624 cycle_B: 2.952 idt_B: 0.371 \n",
            "End of epoch 74 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.294, data: 0.200) D_A: 0.148 G_A: 0.295 cycle_A: 0.546 idt_A: 0.715 D_B: 0.228 G_B: 0.177 cycle_B: 2.027 idt_B: 0.154 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 100, time: 1.082, data: 0.193) D_A: 0.131 G_A: 0.771 cycle_A: 0.481 idt_A: 1.164 D_B: 0.107 G_B: 0.779 cycle_B: 1.692 idt_B: 0.225 \n",
            "End of epoch 76 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.283, data: 0.185) D_A: 0.077 G_A: 0.445 cycle_A: 0.608 idt_A: 0.939 D_B: 0.221 G_B: 0.609 cycle_B: 2.175 idt_B: 0.254 \n",
            "End of epoch 77 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.286, data: 0.193) D_A: 0.088 G_A: 0.766 cycle_A: 0.988 idt_A: 0.780 D_B: 0.139 G_B: 0.914 cycle_B: 2.640 idt_B: 0.413 \n",
            "End of epoch 78 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.290, data: 0.201) D_A: 0.286 G_A: 0.137 cycle_A: 0.457 idt_A: 0.682 D_B: 0.132 G_B: 0.357 cycle_B: 1.915 idt_B: 0.127 \n",
            "End of epoch 79 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 100, time: 0.977, data: 0.198) D_A: 0.239 G_A: 0.274 cycle_A: 0.591 idt_A: 1.080 D_B: 0.070 G_B: 0.509 cycle_B: 2.158 idt_B: 0.200 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.283, data: 0.191) D_A: 0.116 G_A: 0.192 cycle_A: 0.530 idt_A: 0.827 D_B: 0.043 G_B: 0.704 cycle_B: 1.733 idt_B: 0.214 \n",
            "End of epoch 81 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.292, data: 0.173) D_A: 0.095 G_A: 0.401 cycle_A: 0.506 idt_A: 0.827 D_B: 0.043 G_B: 0.716 cycle_B: 2.255 idt_B: 0.150 \n",
            "End of epoch 82 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.299, data: 0.185) D_A: 0.052 G_A: 0.736 cycle_A: 0.503 idt_A: 0.958 D_B: 0.152 G_B: 0.571 cycle_B: 2.169 idt_B: 0.126 \n",
            "End of epoch 83 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 100, time: 1.012, data: 0.188) D_A: 0.111 G_A: 0.427 cycle_A: 0.698 idt_A: 1.038 D_B: 0.197 G_B: 0.331 cycle_B: 2.948 idt_B: 0.224 \n",
            "End of epoch 84 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.289, data: 0.186) D_A: 0.075 G_A: 0.749 cycle_A: 1.225 idt_A: 1.011 D_B: 0.216 G_B: 0.553 cycle_B: 2.351 idt_B: 0.495 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.279, data: 0.193) D_A: 0.063 G_A: 0.306 cycle_A: 0.636 idt_A: 0.819 D_B: 0.064 G_B: 0.600 cycle_B: 1.965 idt_B: 0.215 \n",
            "End of epoch 86 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.283, data: 0.196) D_A: 0.133 G_A: 0.519 cycle_A: 0.612 idt_A: 0.962 D_B: 0.145 G_B: 0.314 cycle_B: 2.080 idt_B: 0.329 \n",
            "End of epoch 87 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 100, time: 1.031, data: 0.185) D_A: 0.147 G_A: 0.258 cycle_A: 0.397 idt_A: 0.819 D_B: 0.089 G_B: 0.463 cycle_B: 2.102 idt_B: 0.131 \n",
            "End of epoch 88 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.291, data: 0.190) D_A: 0.218 G_A: 0.536 cycle_A: 0.604 idt_A: 0.733 D_B: 0.291 G_B: 0.165 cycle_B: 1.566 idt_B: 0.243 \n",
            "End of epoch 89 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.287, data: 0.178) D_A: 0.221 G_A: 0.537 cycle_A: 0.587 idt_A: 1.084 D_B: 0.091 G_B: 0.491 cycle_B: 2.970 idt_B: 0.167 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.284, data: 0.188) D_A: 0.138 G_A: 0.331 cycle_A: 0.453 idt_A: 0.776 D_B: 0.063 G_B: 0.520 cycle_B: 1.964 idt_B: 0.272 \n",
            "End of epoch 91 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 100, time: 1.027, data: 0.178) D_A: 0.130 G_A: 0.505 cycle_A: 0.628 idt_A: 0.490 D_B: 1.094 G_B: 1.360 cycle_B: 1.388 idt_B: 0.237 \n",
            "End of epoch 92 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.292, data: 0.176) D_A: 0.053 G_A: 0.139 cycle_A: 0.458 idt_A: 0.894 D_B: 0.183 G_B: 0.325 cycle_B: 2.168 idt_B: 0.184 \n",
            "End of epoch 93 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.292, data: 0.204) D_A: 0.127 G_A: 0.623 cycle_A: 0.573 idt_A: 0.582 D_B: 0.035 G_B: 0.949 cycle_B: 1.708 idt_B: 0.233 \n",
            "End of epoch 94 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.283, data: 0.175) D_A: 0.175 G_A: 0.499 cycle_A: 0.432 idt_A: 0.935 D_B: 0.097 G_B: 0.398 cycle_B: 1.818 idt_B: 0.178 \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 100, time: 1.048, data: 0.184) D_A: 0.057 G_A: 0.359 cycle_A: 0.566 idt_A: 0.908 D_B: 0.287 G_B: 1.110 cycle_B: 2.308 idt_B: 0.254 \n",
            "End of epoch 96 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.282, data: 0.190) D_A: 0.094 G_A: 0.531 cycle_A: 0.468 idt_A: 0.557 D_B: 0.196 G_B: 1.318 cycle_B: 1.134 idt_B: 0.152 \n",
            "End of epoch 97 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.281, data: 0.178) D_A: 0.242 G_A: 0.148 cycle_A: 0.439 idt_A: 0.615 D_B: 0.223 G_B: 0.965 cycle_B: 1.555 idt_B: 0.143 \n",
            "End of epoch 98 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.281, data: 0.174) D_A: 0.047 G_A: 0.349 cycle_A: 0.730 idt_A: 0.556 D_B: 0.263 G_B: 0.273 cycle_B: 1.459 idt_B: 0.262 \n",
            "End of epoch 99 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 100, time: 1.070, data: 0.186) D_A: 0.096 G_A: 0.350 cycle_A: 0.550 idt_A: 0.766 D_B: 0.269 G_B: 0.242 cycle_B: 2.064 idt_B: 0.230 \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.288, data: 0.196) D_A: 0.140 G_A: 0.814 cycle_A: 0.499 idt_A: 0.967 D_B: 0.253 G_B: 0.274 cycle_B: 1.432 idt_B: 0.187 \n",
            "End of epoch 101 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 100, time: 0.284, data: 0.176) D_A: 0.153 G_A: 0.374 cycle_A: 0.334 idt_A: 0.550 D_B: 0.267 G_B: 0.227 cycle_B: 1.810 idt_B: 0.141 \n",
            "End of epoch 102 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 100, time: 0.287, data: 0.189) D_A: 0.147 G_A: 0.550 cycle_A: 0.447 idt_A: 0.585 D_B: 0.258 G_B: 0.261 cycle_B: 1.525 idt_B: 0.198 \n",
            "End of epoch 103 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 100, time: 1.135, data: 0.189) D_A: 0.057 G_A: 0.822 cycle_A: 0.385 idt_A: 0.741 D_B: 0.249 G_B: 0.303 cycle_B: 2.091 idt_B: 0.146 \n",
            "End of epoch 104 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 100, time: 0.289, data: 0.178) D_A: 0.056 G_A: 0.629 cycle_A: 0.445 idt_A: 0.793 D_B: 0.233 G_B: 0.252 cycle_B: 2.478 idt_B: 0.186 \n",
            "saving the model at the end of epoch 105, iters 10500\n",
            "End of epoch 105 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 100, time: 0.281, data: 0.187) D_A: 0.087 G_A: 0.298 cycle_A: 0.359 idt_A: 0.834 D_B: 0.255 G_B: 0.275 cycle_B: 1.792 idt_B: 0.122 \n",
            "End of epoch 106 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 100, time: 0.281, data: 0.187) D_A: 0.096 G_A: 0.823 cycle_A: 0.584 idt_A: 0.986 D_B: 0.244 G_B: 0.283 cycle_B: 1.362 idt_B: 0.159 \n",
            "End of epoch 107 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 100, time: 1.114, data: 0.225) D_A: 0.102 G_A: 0.073 cycle_A: 0.566 idt_A: 0.690 D_B: 0.216 G_B: 0.234 cycle_B: 1.818 idt_B: 0.199 \n",
            "End of epoch 108 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 100, time: 0.290, data: 0.190) D_A: 0.072 G_A: 0.396 cycle_A: 0.368 idt_A: 0.731 D_B: 0.241 G_B: 0.284 cycle_B: 1.619 idt_B: 0.143 \n",
            "End of epoch 109 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.280, data: 0.199) D_A: 0.257 G_A: 0.182 cycle_A: 0.473 idt_A: 0.641 D_B: 0.235 G_B: 0.280 cycle_B: 1.327 idt_B: 0.146 \n",
            "saving the model at the end of epoch 110, iters 11000\n",
            "End of epoch 110 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 100, time: 0.288, data: 0.184) D_A: 0.149 G_A: 0.412 cycle_A: 0.682 idt_A: 0.875 D_B: 0.290 G_B: 0.292 cycle_B: 2.095 idt_B: 0.209 \n",
            "End of epoch 111 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 100, time: 1.343, data: 0.189) D_A: 0.131 G_A: 0.659 cycle_A: 0.339 idt_A: 0.464 D_B: 0.229 G_B: 0.280 cycle_B: 1.357 idt_B: 0.115 \n",
            "End of epoch 112 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 100, time: 0.283, data: 0.191) D_A: 0.066 G_A: 0.693 cycle_A: 0.596 idt_A: 0.554 D_B: 0.204 G_B: 0.254 cycle_B: 1.420 idt_B: 0.203 \n",
            "End of epoch 113 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 100, time: 0.285, data: 0.201) D_A: 0.169 G_A: 0.445 cycle_A: 0.674 idt_A: 0.608 D_B: 0.229 G_B: 0.260 cycle_B: 1.981 idt_B: 0.264 \n",
            "End of epoch 114 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 100, time: 0.282, data: 0.193) D_A: 0.059 G_A: 0.156 cycle_A: 0.435 idt_A: 0.831 D_B: 0.242 G_B: 0.371 cycle_B: 1.382 idt_B: 0.123 \n",
            "saving the model at the end of epoch 115, iters 11500\n",
            "End of epoch 115 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 100, time: 1.128, data: 0.200) D_A: 0.037 G_A: 0.168 cycle_A: 0.398 idt_A: 0.819 D_B: 0.235 G_B: 0.350 cycle_B: 1.584 idt_B: 0.135 \n",
            "End of epoch 116 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 100, time: 0.273, data: 0.193) D_A: 0.174 G_A: 0.413 cycle_A: 0.349 idt_A: 0.627 D_B: 0.216 G_B: 0.298 cycle_B: 1.871 idt_B: 0.133 \n",
            "End of epoch 117 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 100, time: 0.284, data: 0.186) D_A: 0.042 G_A: 0.227 cycle_A: 0.872 idt_A: 0.778 D_B: 0.262 G_B: 0.405 cycle_B: 2.049 idt_B: 0.360 \n",
            "End of epoch 118 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 100, time: 0.283, data: 0.176) D_A: 0.135 G_A: 0.629 cycle_A: 0.547 idt_A: 0.645 D_B: 0.228 G_B: 0.354 cycle_B: 1.437 idt_B: 0.249 \n",
            "End of epoch 119 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 100, time: 1.201, data: 0.197) D_A: 0.356 G_A: 0.090 cycle_A: 0.682 idt_A: 0.501 D_B: 0.303 G_B: 0.279 cycle_B: 1.300 idt_B: 0.200 \n",
            "saving the model at the end of epoch 120, iters 12000\n",
            "End of epoch 120 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 100, time: 0.284, data: 0.183) D_A: 0.207 G_A: 1.291 cycle_A: 0.595 idt_A: 0.679 D_B: 0.160 G_B: 0.234 cycle_B: 1.514 idt_B: 0.222 \n",
            "End of epoch 121 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 100, time: 0.281, data: 0.192) D_A: 0.141 G_A: 0.557 cycle_A: 0.689 idt_A: 0.445 D_B: 0.317 G_B: 0.294 cycle_B: 0.952 idt_B: 0.277 \n",
            "End of epoch 122 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 100, time: 0.282, data: 0.213) D_A: 0.134 G_A: 0.920 cycle_A: 0.571 idt_A: 0.495 D_B: 0.171 G_B: 0.244 cycle_B: 0.725 idt_B: 0.244 \n",
            "End of epoch 123 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 100, time: 1.365, data: 0.190) D_A: 0.183 G_A: 0.919 cycle_A: 0.321 idt_A: 0.785 D_B: 0.196 G_B: 0.249 cycle_B: 2.038 idt_B: 0.106 \n",
            "End of epoch 124 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 100, time: 0.315, data: 0.217) D_A: 0.137 G_A: 0.394 cycle_A: 0.341 idt_A: 0.917 D_B: 0.199 G_B: 0.429 cycle_B: 2.064 idt_B: 0.107 \n",
            "saving the model at the end of epoch 125, iters 12500\n",
            "End of epoch 125 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 100, time: 0.290, data: 0.203) D_A: 0.249 G_A: 0.209 cycle_A: 0.504 idt_A: 0.967 D_B: 0.146 G_B: 0.255 cycle_B: 2.566 idt_B: 0.184 \n",
            "End of epoch 126 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 100, time: 0.294, data: 0.173) D_A: 0.082 G_A: 0.564 cycle_A: 1.243 idt_A: 0.594 D_B: 0.159 G_B: 0.246 cycle_B: 1.469 idt_B: 0.458 \n",
            "End of epoch 127 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 100, time: 1.333, data: 0.207) D_A: 0.061 G_A: 0.628 cycle_A: 0.634 idt_A: 0.707 D_B: 0.275 G_B: 0.423 cycle_B: 0.926 idt_B: 0.172 \n",
            "End of epoch 128 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 100, time: 0.290, data: 0.187) D_A: 0.057 G_A: 0.676 cycle_A: 0.435 idt_A: 0.715 D_B: 0.156 G_B: 0.271 cycle_B: 1.654 idt_B: 0.165 \n",
            "End of epoch 129 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 100, time: 0.296, data: 0.180) D_A: 0.149 G_A: 0.785 cycle_A: 0.359 idt_A: 0.556 D_B: 0.247 G_B: 0.258 cycle_B: 1.419 idt_B: 0.118 \n",
            "saving the model at the end of epoch 130, iters 13000\n",
            "End of epoch 130 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 100, time: 0.281, data: 0.214) D_A: 0.045 G_A: 0.568 cycle_A: 0.459 idt_A: 0.632 D_B: 0.199 G_B: 0.223 cycle_B: 1.827 idt_B: 0.130 \n",
            "End of epoch 131 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 100, time: 1.248, data: 0.169) D_A: 0.079 G_A: 0.458 cycle_A: 0.482 idt_A: 0.487 D_B: 0.245 G_B: 0.438 cycle_B: 1.122 idt_B: 0.101 \n",
            "End of epoch 132 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 100, time: 0.283, data: 0.200) D_A: 0.124 G_A: 0.690 cycle_A: 0.673 idt_A: 0.711 D_B: 0.199 G_B: 0.449 cycle_B: 1.511 idt_B: 0.241 \n",
            "End of epoch 133 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 100, time: 0.295, data: 0.213) D_A: 0.254 G_A: 0.175 cycle_A: 0.503 idt_A: 0.637 D_B: 0.147 G_B: 0.359 cycle_B: 1.641 idt_B: 0.125 \n",
            "End of epoch 134 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 100, time: 0.282, data: 0.215) D_A: 0.062 G_A: 0.757 cycle_A: 0.853 idt_A: 0.585 D_B: 0.239 G_B: 0.575 cycle_B: 1.330 idt_B: 0.156 \n",
            "saving the model at the end of epoch 135, iters 13500\n",
            "End of epoch 135 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 100, time: 1.531, data: 0.214) D_A: 0.251 G_A: 0.155 cycle_A: 0.516 idt_A: 0.768 D_B: 0.241 G_B: 0.221 cycle_B: 1.638 idt_B: 0.167 \n",
            "End of epoch 136 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 100, time: 0.285, data: 0.193) D_A: 0.090 G_A: 0.643 cycle_A: 0.436 idt_A: 0.636 D_B: 0.174 G_B: 0.338 cycle_B: 1.327 idt_B: 0.151 \n",
            "End of epoch 137 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 100, time: 0.265, data: 0.193) D_A: 0.030 G_A: 0.865 cycle_A: 0.534 idt_A: 0.815 D_B: 0.269 G_B: 0.144 cycle_B: 1.826 idt_B: 0.141 \n",
            "End of epoch 138 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 100, time: 0.284, data: 0.206) D_A: 0.198 G_A: 0.512 cycle_A: 0.548 idt_A: 0.691 D_B: 0.178 G_B: 0.317 cycle_B: 1.709 idt_B: 0.172 \n",
            "End of epoch 139 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 100, time: 1.461, data: 0.196) D_A: 0.035 G_A: 0.736 cycle_A: 0.399 idt_A: 1.107 D_B: 0.087 G_B: 0.684 cycle_B: 2.181 idt_B: 0.119 \n",
            "saving the model at the end of epoch 140, iters 14000\n",
            "End of epoch 140 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 0.285, data: 0.186) D_A: 0.055 G_A: 0.587 cycle_A: 0.318 idt_A: 0.519 D_B: 0.164 G_B: 0.253 cycle_B: 1.218 idt_B: 0.103 \n",
            "End of epoch 141 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 100, time: 0.283, data: 0.187) D_A: 0.148 G_A: 0.291 cycle_A: 0.389 idt_A: 0.604 D_B: 0.191 G_B: 0.232 cycle_B: 1.427 idt_B: 0.116 \n",
            "End of epoch 142 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 100, time: 0.285, data: 0.219) D_A: 0.296 G_A: 1.257 cycle_A: 0.509 idt_A: 0.641 D_B: 0.290 G_B: 0.482 cycle_B: 1.470 idt_B: 0.201 \n",
            "End of epoch 143 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 100, time: 1.301, data: 0.183) D_A: 0.130 G_A: 0.509 cycle_A: 0.397 idt_A: 0.585 D_B: 0.150 G_B: 0.178 cycle_B: 1.546 idt_B: 0.131 \n",
            "End of epoch 144 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 100, time: 0.284, data: 0.198) D_A: 0.040 G_A: 0.425 cycle_A: 0.533 idt_A: 0.399 D_B: 0.152 G_B: 0.498 cycle_B: 1.253 idt_B: 0.168 \n",
            "saving the model at the end of epoch 145, iters 14500\n",
            "End of epoch 145 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 100, time: 0.283, data: 0.210) D_A: 0.039 G_A: 0.370 cycle_A: 0.300 idt_A: 0.471 D_B: 0.119 G_B: 0.582 cycle_B: 1.201 idt_B: 0.098 \n",
            "End of epoch 146 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 100, time: 0.283, data: 0.187) D_A: 0.203 G_A: 0.649 cycle_A: 0.400 idt_A: 0.561 D_B: 0.118 G_B: 0.315 cycle_B: 1.367 idt_B: 0.160 \n",
            "End of epoch 147 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 100, time: 1.431, data: 0.191) D_A: 0.029 G_A: 0.440 cycle_A: 0.421 idt_A: 0.565 D_B: 0.210 G_B: 0.263 cycle_B: 1.477 idt_B: 0.119 \n",
            "End of epoch 148 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 100, time: 0.290, data: 0.196) D_A: 0.270 G_A: 0.112 cycle_A: 0.517 idt_A: 0.503 D_B: 0.122 G_B: 0.499 cycle_B: 1.345 idt_B: 0.198 \n",
            "End of epoch 149 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 100, time: 0.281, data: 0.211) D_A: 0.163 G_A: 1.280 cycle_A: 0.306 idt_A: 0.671 D_B: 0.135 G_B: 0.469 cycle_B: 1.345 idt_B: 0.088 \n",
            "saving the latest model (epoch 150, total_iters 15000)\n",
            "saving the model at the end of epoch 150, iters 15000\n",
            "End of epoch 150 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 100, time: 0.283, data: 0.198) D_A: 0.239 G_A: 0.164 cycle_A: 0.474 idt_A: 0.470 D_B: 0.102 G_B: 0.537 cycle_B: 1.053 idt_B: 0.173 \n",
            "End of epoch 151 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 100, time: 1.533, data: 0.176) D_A: 0.088 G_A: 0.179 cycle_A: 0.378 idt_A: 0.613 D_B: 0.103 G_B: 0.729 cycle_B: 1.293 idt_B: 0.131 \n",
            "End of epoch 152 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 100, time: 0.288, data: 0.183) D_A: 0.226 G_A: 0.184 cycle_A: 0.454 idt_A: 0.616 D_B: 0.187 G_B: 0.508 cycle_B: 1.358 idt_B: 0.152 \n",
            "End of epoch 153 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 100, time: 0.268, data: 0.183) D_A: 0.191 G_A: 0.247 cycle_A: 0.617 idt_A: 0.502 D_B: 0.221 G_B: 0.646 cycle_B: 1.519 idt_B: 0.199 \n",
            "End of epoch 154 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 100, time: 0.284, data: 0.191) D_A: 0.062 G_A: 0.246 cycle_A: 0.315 idt_A: 0.411 D_B: 0.042 G_B: 0.350 cycle_B: 1.178 idt_B: 0.106 \n",
            "saving the model at the end of epoch 155, iters 15500\n",
            "End of epoch 155 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 100, time: 1.612, data: 0.206) D_A: 0.171 G_A: 0.232 cycle_A: 0.593 idt_A: 0.531 D_B: 0.141 G_B: 0.308 cycle_B: 1.284 idt_B: 0.188 \n",
            "End of epoch 156 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 100, time: 0.281, data: 0.198) D_A: 0.030 G_A: 0.624 cycle_A: 0.656 idt_A: 0.665 D_B: 0.161 G_B: 0.507 cycle_B: 1.562 idt_B: 0.179 \n",
            "End of epoch 157 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 100, time: 0.281, data: 0.198) D_A: 0.129 G_A: 0.315 cycle_A: 0.374 idt_A: 0.495 D_B: 0.150 G_B: 0.123 cycle_B: 0.988 idt_B: 0.159 \n",
            "End of epoch 158 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 100, time: 0.282, data: 0.191) D_A: 0.096 G_A: 0.986 cycle_A: 0.268 idt_A: 0.603 D_B: 0.052 G_B: 0.549 cycle_B: 1.392 idt_B: 0.094 \n",
            "End of epoch 159 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 1.421, data: 0.185) D_A: 0.068 G_A: 0.512 cycle_A: 0.425 idt_A: 0.515 D_B: 0.071 G_B: 0.683 cycle_B: 1.229 idt_B: 0.157 \n",
            "saving the model at the end of epoch 160, iters 16000\n",
            "End of epoch 160 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 100, time: 0.286, data: 0.221) D_A: 0.083 G_A: 0.368 cycle_A: 0.228 idt_A: 0.658 D_B: 0.069 G_B: 0.558 cycle_B: 1.433 idt_B: 0.086 \n",
            "End of epoch 161 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 100, time: 0.289, data: 0.189) D_A: 0.038 G_A: 0.382 cycle_A: 0.263 idt_A: 0.881 D_B: 0.214 G_B: 0.473 cycle_B: 2.077 idt_B: 0.116 \n",
            "End of epoch 162 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 100, time: 0.282, data: 0.197) D_A: 0.111 G_A: 0.665 cycle_A: 0.666 idt_A: 0.584 D_B: 0.142 G_B: 0.474 cycle_B: 1.434 idt_B: 0.226 \n",
            "End of epoch 163 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 100, time: 1.483, data: 0.186) D_A: 0.126 G_A: 0.363 cycle_A: 0.505 idt_A: 0.546 D_B: 0.207 G_B: 1.002 cycle_B: 1.342 idt_B: 0.200 \n",
            "End of epoch 164 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 100, time: 0.284, data: 0.191) D_A: 0.092 G_A: 0.413 cycle_A: 0.299 idt_A: 0.384 D_B: 0.085 G_B: 0.517 cycle_B: 1.407 idt_B: 0.121 \n",
            "saving the model at the end of epoch 165, iters 16500\n",
            "End of epoch 165 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 0.284, data: 0.219) D_A: 0.183 G_A: 0.230 cycle_A: 0.252 idt_A: 0.640 D_B: 0.113 G_B: 0.344 cycle_B: 1.319 idt_B: 0.087 \n",
            "End of epoch 166 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 100, time: 0.279, data: 0.206) D_A: 0.202 G_A: 0.438 cycle_A: 0.340 idt_A: 0.481 D_B: 0.089 G_B: 0.429 cycle_B: 1.184 idt_B: 0.118 \n",
            "End of epoch 167 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 100, time: 1.483, data: 0.203) D_A: 0.060 G_A: 0.553 cycle_A: 0.291 idt_A: 0.474 D_B: 0.207 G_B: 0.447 cycle_B: 1.175 idt_B: 0.091 \n",
            "End of epoch 168 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 100, time: 0.286, data: 0.183) D_A: 0.102 G_A: 0.378 cycle_A: 0.397 idt_A: 0.797 D_B: 0.089 G_B: 0.614 cycle_B: 1.943 idt_B: 0.114 \n",
            "End of epoch 169 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 100, time: 0.285, data: 0.201) D_A: 0.079 G_A: 0.304 cycle_A: 0.710 idt_A: 0.441 D_B: 0.191 G_B: 0.572 cycle_B: 0.984 idt_B: 0.171 \n",
            "saving the model at the end of epoch 170, iters 17000\n",
            "End of epoch 170 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 100, time: 0.285, data: 0.206) D_A: 0.141 G_A: 0.645 cycle_A: 0.427 idt_A: 0.490 D_B: 0.051 G_B: 0.539 cycle_B: 0.990 idt_B: 0.158 \n",
            "End of epoch 171 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 100, time: 1.528, data: 0.196) D_A: 0.155 G_A: 0.552 cycle_A: 0.357 idt_A: 0.579 D_B: 0.167 G_B: 0.280 cycle_B: 1.353 idt_B: 0.112 \n",
            "End of epoch 172 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 100, time: 0.283, data: 0.195) D_A: 0.373 G_A: 0.099 cycle_A: 0.547 idt_A: 0.431 D_B: 0.092 G_B: 0.680 cycle_B: 1.094 idt_B: 0.206 \n",
            "End of epoch 173 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 100, time: 0.281, data: 0.189) D_A: 0.217 G_A: 0.761 cycle_A: 0.542 idt_A: 1.315 D_B: 0.047 G_B: 0.848 cycle_B: 1.378 idt_B: 0.186 \n",
            "End of epoch 174 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 100, time: 0.309, data: 0.180) D_A: 0.112 G_A: 0.384 cycle_A: 0.287 idt_A: 0.466 D_B: 0.116 G_B: 0.950 cycle_B: 1.002 idt_B: 0.103 \n",
            "saving the model at the end of epoch 175, iters 17500\n",
            "End of epoch 175 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 100, time: 1.801, data: 0.193) D_A: 0.167 G_A: 0.273 cycle_A: 0.423 idt_A: 0.513 D_B: 0.122 G_B: 0.495 cycle_B: 1.202 idt_B: 0.136 \n",
            "End of epoch 176 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 100, time: 0.293, data: 0.191) D_A: 0.133 G_A: 0.612 cycle_A: 0.391 idt_A: 0.550 D_B: 0.077 G_B: 0.668 cycle_B: 1.426 idt_B: 0.149 \n",
            "End of epoch 177 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 100, time: 0.287, data: 0.195) D_A: 0.034 G_A: 0.372 cycle_A: 0.328 idt_A: 0.358 D_B: 0.097 G_B: 0.508 cycle_B: 0.956 idt_B: 0.117 \n",
            "End of epoch 178 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 100, time: 0.281, data: 0.180) D_A: 0.109 G_A: 0.487 cycle_A: 0.322 idt_A: 0.460 D_B: 0.114 G_B: 0.336 cycle_B: 1.148 idt_B: 0.101 \n",
            "End of epoch 179 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 100, time: 1.744, data: 0.198) D_A: 0.066 G_A: 0.627 cycle_A: 0.494 idt_A: 0.499 D_B: 0.060 G_B: 0.572 cycle_B: 1.395 idt_B: 0.183 \n",
            "saving the model at the end of epoch 180, iters 18000\n",
            "End of epoch 180 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 100, time: 0.277, data: 0.210) D_A: 0.041 G_A: 0.598 cycle_A: 0.314 idt_A: 0.575 D_B: 0.047 G_B: 0.600 cycle_B: 1.508 idt_B: 0.094 \n",
            "End of epoch 181 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 100, time: 0.273, data: 0.189) D_A: 0.025 G_A: 0.412 cycle_A: 0.294 idt_A: 0.761 D_B: 0.043 G_B: 0.490 cycle_B: 1.887 idt_B: 0.103 \n",
            "End of epoch 182 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 100, time: 0.286, data: 0.196) D_A: 0.032 G_A: 0.804 cycle_A: 0.430 idt_A: 0.492 D_B: 0.113 G_B: 0.394 cycle_B: 1.373 idt_B: 0.144 \n",
            "End of epoch 183 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 100, time: 1.854, data: 0.200) D_A: 0.076 G_A: 0.439 cycle_A: 0.424 idt_A: 0.639 D_B: 0.041 G_B: 1.052 cycle_B: 1.530 idt_B: 0.187 \n",
            "End of epoch 184 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 100, time: 0.287, data: 0.203) D_A: 0.072 G_A: 0.704 cycle_A: 0.410 idt_A: 0.544 D_B: 0.050 G_B: 0.486 cycle_B: 1.329 idt_B: 0.155 \n",
            "saving the model at the end of epoch 185, iters 18500\n",
            "End of epoch 185 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 100, time: 0.290, data: 0.193) D_A: 0.106 G_A: 0.484 cycle_A: 0.491 idt_A: 0.760 D_B: 0.133 G_B: 0.367 cycle_B: 1.742 idt_B: 0.185 \n",
            "End of epoch 186 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 100, time: 0.278, data: 0.199) D_A: 0.078 G_A: 0.519 cycle_A: 0.551 idt_A: 0.810 D_B: 0.065 G_B: 0.497 cycle_B: 1.945 idt_B: 0.199 \n",
            "End of epoch 187 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 100, time: 1.572, data: 0.208) D_A: 0.075 G_A: 0.598 cycle_A: 0.255 idt_A: 0.433 D_B: 0.031 G_B: 0.570 cycle_B: 1.177 idt_B: 0.092 \n",
            "End of epoch 188 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 100, time: 0.283, data: 0.176) D_A: 0.134 G_A: 0.326 cycle_A: 0.297 idt_A: 0.465 D_B: 0.060 G_B: 0.540 cycle_B: 1.095 idt_B: 0.091 \n",
            "End of epoch 189 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 100, time: 0.284, data: 0.194) D_A: 0.194 G_A: 0.434 cycle_A: 0.518 idt_A: 0.541 D_B: 0.030 G_B: 0.618 cycle_B: 1.431 idt_B: 0.201 \n",
            "saving the model at the end of epoch 190, iters 19000\n",
            "End of epoch 190 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 0.289, data: 0.216) D_A: 0.164 G_A: 0.360 cycle_A: 0.385 idt_A: 0.461 D_B: 0.021 G_B: 0.574 cycle_B: 1.218 idt_B: 0.133 \n",
            "End of epoch 191 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 100, time: 1.613, data: 0.183) D_A: 0.078 G_A: 0.453 cycle_A: 0.272 idt_A: 0.715 D_B: 0.157 G_B: 0.536 cycle_B: 1.705 idt_B: 0.097 \n",
            "End of epoch 192 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 100, time: 0.292, data: 0.202) D_A: 0.089 G_A: 0.476 cycle_A: 0.342 idt_A: 0.492 D_B: 0.087 G_B: 0.606 cycle_B: 1.185 idt_B: 0.112 \n",
            "End of epoch 193 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 100, time: 0.280, data: 0.202) D_A: 0.272 G_A: 0.545 cycle_A: 0.327 idt_A: 0.528 D_B: 0.040 G_B: 0.713 cycle_B: 1.078 idt_B: 0.143 \n",
            "End of epoch 194 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 100, time: 0.271, data: 0.173) D_A: 0.041 G_A: 0.537 cycle_A: 0.265 idt_A: 0.306 D_B: 0.036 G_B: 0.481 cycle_B: 0.861 idt_B: 0.089 \n",
            "saving the model at the end of epoch 195, iters 19500\n",
            "End of epoch 195 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 100, time: 1.678, data: 0.189) D_A: 0.128 G_A: 0.698 cycle_A: 0.293 idt_A: 0.382 D_B: 0.026 G_B: 0.609 cycle_B: 0.843 idt_B: 0.088 \n",
            "End of epoch 196 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 100, time: 0.287, data: 0.192) D_A: 0.049 G_A: 0.659 cycle_A: 0.270 idt_A: 0.501 D_B: 0.081 G_B: 0.403 cycle_B: 1.358 idt_B: 0.095 \n",
            "End of epoch 197 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 100, time: 0.283, data: 0.200) D_A: 0.043 G_A: 0.348 cycle_A: 0.273 idt_A: 0.668 D_B: 0.141 G_B: 0.826 cycle_B: 1.376 idt_B: 0.086 \n",
            "End of epoch 198 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 100, time: 0.288, data: 0.196) D_A: 0.143 G_A: 0.391 cycle_A: 0.414 idt_A: 0.384 D_B: 0.099 G_B: 0.678 cycle_B: 1.008 idt_B: 0.130 \n",
            "End of epoch 199 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 100, time: 1.687, data: 0.191) D_A: 0.065 G_A: 0.504 cycle_A: 0.437 idt_A: 0.746 D_B: 0.087 G_B: 0.594 cycle_B: 1.737 idt_B: 0.155 \n",
            "saving the latest model (epoch 200, total_iters 20000)\n",
            "saving the model at the end of epoch 200, iters 20000\n",
            "End of epoch 200 / 200 \t Time Taken: 30 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3307, 0.3344, 0.3348],\n",
            "        [0.3296, 0.3336, 0.3368],\n",
            "        [0.3292, 0.3339, 0.3369],\n",
            "        [0.3292, 0.3341, 0.3367],\n",
            "        [0.3290, 0.3341, 0.3369]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3279, 0.3360, 0.3362],\n",
            "        [0.3254, 0.3344, 0.3402],\n",
            "        [0.3250, 0.3350, 0.3401],\n",
            "        [0.3246, 0.3353, 0.3401],\n",
            "        [0.3247, 0.3353, 0.3400]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3256, 0.3371, 0.3373],\n",
            "        [0.3222, 0.3346, 0.3432],\n",
            "        [0.3214, 0.3357, 0.3429],\n",
            "        [0.3209, 0.3360, 0.3431],\n",
            "        [0.3209, 0.3359, 0.3432]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3239, 0.3379, 0.3382],\n",
            "        [0.3194, 0.3348, 0.3458],\n",
            "        [0.3186, 0.3362, 0.3452],\n",
            "        [0.3178, 0.3366, 0.3456],\n",
            "        [0.3179, 0.3363, 0.3457]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3219, 0.3389, 0.3392],\n",
            "        [0.3168, 0.3348, 0.3484],\n",
            "        [0.3157, 0.3365, 0.3478],\n",
            "        [0.3147, 0.3371, 0.3481],\n",
            "        [0.3150, 0.3368, 0.3483]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3201, 0.3398, 0.3402],\n",
            "        [0.3142, 0.3351, 0.3507],\n",
            "        [0.3133, 0.3368, 0.3499],\n",
            "        [0.3121, 0.3375, 0.3504],\n",
            "        [0.3121, 0.3371, 0.3508]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3178, 0.3409, 0.3413],\n",
            "        [0.3112, 0.3351, 0.3536],\n",
            "        [0.3101, 0.3373, 0.3526],\n",
            "        [0.3087, 0.3379, 0.3535],\n",
            "        [0.3084, 0.3375, 0.3540]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3161, 0.3419, 0.3420],\n",
            "        [0.3088, 0.3351, 0.3561],\n",
            "        [0.3074, 0.3376, 0.3550],\n",
            "        [0.3058, 0.3383, 0.3558],\n",
            "        [0.3057, 0.3378, 0.3564]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3144, 0.3427, 0.3429],\n",
            "        [0.3065, 0.3350, 0.3585],\n",
            "        [0.3051, 0.3377, 0.3572],\n",
            "        [0.3030, 0.3386, 0.3584],\n",
            "        [0.3027, 0.3382, 0.3591]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3120, 0.3439, 0.3441],\n",
            "        [0.3031, 0.3350, 0.3619],\n",
            "        [0.3014, 0.3382, 0.3604],\n",
            "        [0.2995, 0.3389, 0.3616],\n",
            "        [0.2993, 0.3384, 0.3623]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3098, 0.3450, 0.3452],\n",
            "        [0.3000, 0.3352, 0.3648],\n",
            "        [0.2985, 0.3385, 0.3630],\n",
            "        [0.2962, 0.3393, 0.3645],\n",
            "        [0.2956, 0.3391, 0.3653]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3080, 0.3460, 0.3460],\n",
            "        [0.2979, 0.3348, 0.3673],\n",
            "        [0.2962, 0.3382, 0.3655],\n",
            "        [0.2938, 0.3392, 0.3670],\n",
            "        [0.2932, 0.3390, 0.3677]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3059, 0.3471, 0.3470],\n",
            "        [0.2947, 0.3349, 0.3704],\n",
            "        [0.2928, 0.3388, 0.3685],\n",
            "        [0.2904, 0.3396, 0.3700],\n",
            "        [0.2900, 0.3391, 0.3709]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3038, 0.3482, 0.3480],\n",
            "        [0.2921, 0.3347, 0.3732],\n",
            "        [0.2902, 0.3386, 0.3712],\n",
            "        [0.2875, 0.3396, 0.3729],\n",
            "        [0.2870, 0.3390, 0.3739]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3020, 0.3491, 0.3489],\n",
            "        [0.2898, 0.3345, 0.3757],\n",
            "        [0.2877, 0.3387, 0.3736],\n",
            "        [0.2850, 0.3398, 0.3752],\n",
            "        [0.2844, 0.3392, 0.3764]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3008, 0.3495, 0.3496],\n",
            "        [0.2878, 0.3343, 0.3779],\n",
            "        [0.2857, 0.3386, 0.3757],\n",
            "        [0.2830, 0.3397, 0.3773],\n",
            "        [0.2823, 0.3389, 0.3788]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2979, 0.3514, 0.3507],\n",
            "        [0.2843, 0.3341, 0.3815],\n",
            "        [0.2821, 0.3389, 0.3790],\n",
            "        [0.2797, 0.3395, 0.3808],\n",
            "        [0.2790, 0.3387, 0.3824]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2959, 0.3524, 0.3516],\n",
            "        [0.2819, 0.3340, 0.3841],\n",
            "        [0.2798, 0.3386, 0.3816],\n",
            "        [0.2769, 0.3397, 0.3834],\n",
            "        [0.2762, 0.3386, 0.3852]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2945, 0.3530, 0.3525],\n",
            "        [0.2801, 0.3331, 0.3868],\n",
            "        [0.2775, 0.3382, 0.3844],\n",
            "        [0.2747, 0.3391, 0.3863],\n",
            "        [0.2740, 0.3378, 0.3882]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2926, 0.3539, 0.3535],\n",
            "        [0.2777, 0.3331, 0.3892],\n",
            "        [0.2754, 0.3381, 0.3865],\n",
            "        [0.2725, 0.3389, 0.3885],\n",
            "        [0.2718, 0.3374, 0.3907]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2908, 0.3548, 0.3544],\n",
            "        [0.2753, 0.3329, 0.3918],\n",
            "        [0.2729, 0.3381, 0.3890],\n",
            "        [0.2703, 0.3385, 0.3912],\n",
            "        [0.2697, 0.3369, 0.3934]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2888, 0.3559, 0.3553],\n",
            "        [0.2728, 0.3327, 0.3945],\n",
            "        [0.2706, 0.3380, 0.3915],\n",
            "        [0.2679, 0.3383, 0.3937],\n",
            "        [0.2673, 0.3363, 0.3963]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2866, 0.3572, 0.3562],\n",
            "        [0.2702, 0.3325, 0.3974],\n",
            "        [0.2679, 0.3380, 0.3941],\n",
            "        [0.2651, 0.3382, 0.3966],\n",
            "        [0.2640, 0.3367, 0.3993]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2840, 0.3587, 0.3574],\n",
            "        [0.2670, 0.3318, 0.4012],\n",
            "        [0.2647, 0.3377, 0.3976],\n",
            "        [0.2618, 0.3381, 0.4000],\n",
            "        [0.2606, 0.3361, 0.4032]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2821, 0.3596, 0.3583],\n",
            "        [0.2648, 0.3314, 0.4038],\n",
            "        [0.2622, 0.3374, 0.4003],\n",
            "        [0.2593, 0.3380, 0.4026],\n",
            "        [0.2582, 0.3355, 0.4063]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2804, 0.3605, 0.3591],\n",
            "        [0.2625, 0.3310, 0.4065],\n",
            "        [0.2598, 0.3372, 0.4030],\n",
            "        [0.2571, 0.3374, 0.4055],\n",
            "        [0.2560, 0.3349, 0.4091]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2785, 0.3613, 0.3601],\n",
            "        [0.2598, 0.3307, 0.4094],\n",
            "        [0.2575, 0.3369, 0.4057],\n",
            "        [0.2547, 0.3370, 0.4083],\n",
            "        [0.2535, 0.3342, 0.4123]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2772, 0.3621, 0.3607],\n",
            "        [0.2583, 0.3302, 0.4114],\n",
            "        [0.2559, 0.3364, 0.4077],\n",
            "        [0.2531, 0.3365, 0.4104],\n",
            "        [0.2517, 0.3334, 0.4149]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2749, 0.3632, 0.3619],\n",
            "        [0.2553, 0.3297, 0.4150],\n",
            "        [0.2530, 0.3361, 0.4109],\n",
            "        [0.2503, 0.3360, 0.4137],\n",
            "        [0.2491, 0.3325, 0.4184]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2731, 0.3641, 0.3627],\n",
            "        [0.2529, 0.3291, 0.4180],\n",
            "        [0.2506, 0.3357, 0.4137],\n",
            "        [0.2475, 0.3360, 0.4165],\n",
            "        [0.2465, 0.3316, 0.4219]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2706, 0.3654, 0.3640],\n",
            "        [0.2497, 0.3290, 0.4213],\n",
            "        [0.2477, 0.3357, 0.4166],\n",
            "        [0.2450, 0.3357, 0.4194],\n",
            "        [0.2433, 0.3312, 0.4255]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2692, 0.3662, 0.3646],\n",
            "        [0.2482, 0.3282, 0.4236],\n",
            "        [0.2462, 0.3351, 0.4186],\n",
            "        [0.2436, 0.3350, 0.4213],\n",
            "        [0.2418, 0.3304, 0.4278]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2676, 0.3672, 0.3653],\n",
            "        [0.2463, 0.3276, 0.4260],\n",
            "        [0.2445, 0.3348, 0.4207],\n",
            "        [0.2417, 0.3348, 0.4235],\n",
            "        [0.2400, 0.3297, 0.4303]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2659, 0.3681, 0.3661],\n",
            "        [0.2443, 0.3272, 0.4285],\n",
            "        [0.2426, 0.3346, 0.4228],\n",
            "        [0.2398, 0.3344, 0.4258],\n",
            "        [0.2380, 0.3289, 0.4331]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2650, 0.3684, 0.3666],\n",
            "        [0.2431, 0.3266, 0.4302],\n",
            "        [0.2416, 0.3338, 0.4246],\n",
            "        [0.2387, 0.3336, 0.4278],\n",
            "        [0.2364, 0.3283, 0.4353]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2639, 0.3691, 0.3671],\n",
            "        [0.2419, 0.3260, 0.4321],\n",
            "        [0.2401, 0.3333, 0.4265],\n",
            "        [0.2373, 0.3329, 0.4298],\n",
            "        [0.2349, 0.3276, 0.4375]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2625, 0.3697, 0.3678],\n",
            "        [0.2403, 0.3255, 0.4342],\n",
            "        [0.2385, 0.3330, 0.4284],\n",
            "        [0.2359, 0.3324, 0.4317],\n",
            "        [0.2333, 0.3270, 0.4397]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2614, 0.3702, 0.3684],\n",
            "        [0.2386, 0.3252, 0.4362],\n",
            "        [0.2371, 0.3327, 0.4302],\n",
            "        [0.2344, 0.3322, 0.4334],\n",
            "        [0.2319, 0.3264, 0.4417]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2601, 0.3710, 0.3689],\n",
            "        [0.2374, 0.3247, 0.4379],\n",
            "        [0.2360, 0.3323, 0.4317],\n",
            "        [0.2332, 0.3318, 0.4350],\n",
            "        [0.2303, 0.3261, 0.4437]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2590, 0.3716, 0.3695],\n",
            "        [0.2357, 0.3240, 0.4403],\n",
            "        [0.2344, 0.3319, 0.4337],\n",
            "        [0.2316, 0.3313, 0.4371],\n",
            "        [0.2288, 0.3250, 0.4462]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2575, 0.3723, 0.3702],\n",
            "        [0.2338, 0.3233, 0.4429],\n",
            "        [0.2327, 0.3316, 0.4357],\n",
            "        [0.2301, 0.3307, 0.4392],\n",
            "        [0.2270, 0.3244, 0.4487]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2557, 0.3734, 0.3709],\n",
            "        [0.2321, 0.3225, 0.4454],\n",
            "        [0.2309, 0.3310, 0.4381],\n",
            "        [0.2282, 0.3300, 0.4418],\n",
            "        [0.2251, 0.3233, 0.4516]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2553, 0.3733, 0.3714],\n",
            "        [0.2311, 0.3217, 0.4472],\n",
            "        [0.2298, 0.3304, 0.4398],\n",
            "        [0.2272, 0.3290, 0.4437],\n",
            "        [0.2238, 0.3221, 0.4541]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2530, 0.3747, 0.3723],\n",
            "        [0.2289, 0.3212, 0.4500],\n",
            "        [0.2281, 0.3300, 0.4419],\n",
            "        [0.2254, 0.3284, 0.4462],\n",
            "        [0.2215, 0.3215, 0.4570]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2511, 0.3757, 0.3732],\n",
            "        [0.2268, 0.3205, 0.4527],\n",
            "        [0.2262, 0.3294, 0.4444],\n",
            "        [0.2234, 0.3278, 0.4488],\n",
            "        [0.2194, 0.3204, 0.4603]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2501, 0.3766, 0.3734],\n",
            "        [0.2259, 0.3195, 0.4546],\n",
            "        [0.2252, 0.3287, 0.4461],\n",
            "        [0.2220, 0.3270, 0.4510],\n",
            "        [0.2179, 0.3191, 0.4629]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2493, 0.3771, 0.3736],\n",
            "        [0.2251, 0.3189, 0.4560],\n",
            "        [0.2242, 0.3283, 0.4474],\n",
            "        [0.2211, 0.3263, 0.4526],\n",
            "        [0.2169, 0.3182, 0.4649]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2485, 0.3776, 0.3739],\n",
            "        [0.2243, 0.3183, 0.4574],\n",
            "        [0.2236, 0.3277, 0.4487],\n",
            "        [0.2203, 0.3255, 0.4542],\n",
            "        [0.2158, 0.3173, 0.4669]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2474, 0.3780, 0.3746],\n",
            "        [0.2226, 0.3180, 0.4594],\n",
            "        [0.2219, 0.3276, 0.4504],\n",
            "        [0.2186, 0.3254, 0.4560],\n",
            "        [0.2139, 0.3168, 0.4694]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2462, 0.3788, 0.3750],\n",
            "        [0.2213, 0.3174, 0.4613],\n",
            "        [0.2208, 0.3274, 0.4518],\n",
            "        [0.2174, 0.3251, 0.4575],\n",
            "        [0.2128, 0.3162, 0.4710]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2454, 0.3791, 0.3755],\n",
            "        [0.2204, 0.3170, 0.4626],\n",
            "        [0.2199, 0.3273, 0.4529],\n",
            "        [0.2166, 0.3247, 0.4587],\n",
            "        [0.2115, 0.3157, 0.4728]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2441, 0.3799, 0.3760],\n",
            "        [0.2190, 0.3166, 0.4644],\n",
            "        [0.2185, 0.3272, 0.4543],\n",
            "        [0.2150, 0.3248, 0.4603],\n",
            "        [0.2097, 0.3154, 0.4749]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2434, 0.3804, 0.3762],\n",
            "        [0.2183, 0.3161, 0.4656],\n",
            "        [0.2178, 0.3269, 0.4553],\n",
            "        [0.2143, 0.3243, 0.4615],\n",
            "        [0.2087, 0.3146, 0.4767]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2425, 0.3810, 0.3765],\n",
            "        [0.2173, 0.3157, 0.4671],\n",
            "        [0.2168, 0.3268, 0.4564],\n",
            "        [0.2133, 0.3242, 0.4625],\n",
            "        [0.2077, 0.3141, 0.4783]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2413, 0.3814, 0.3773],\n",
            "        [0.2155, 0.3151, 0.4694],\n",
            "        [0.2151, 0.3266, 0.4583],\n",
            "        [0.2115, 0.3238, 0.4647],\n",
            "        [0.2058, 0.3136, 0.4806]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2404, 0.3819, 0.3777],\n",
            "        [0.2145, 0.3144, 0.4711],\n",
            "        [0.2141, 0.3263, 0.4596],\n",
            "        [0.2104, 0.3235, 0.4661],\n",
            "        [0.2043, 0.3128, 0.4829]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2397, 0.3823, 0.3780],\n",
            "        [0.2138, 0.3141, 0.4721],\n",
            "        [0.2136, 0.3260, 0.4604],\n",
            "        [0.2097, 0.3230, 0.4672],\n",
            "        [0.2038, 0.3122, 0.4840]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2386, 0.3830, 0.3785],\n",
            "        [0.2126, 0.3138, 0.4736],\n",
            "        [0.2125, 0.3260, 0.4615],\n",
            "        [0.2085, 0.3230, 0.4685],\n",
            "        [0.2025, 0.3118, 0.4857]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2382, 0.3832, 0.3786],\n",
            "        [0.2121, 0.3134, 0.4746],\n",
            "        [0.2120, 0.3255, 0.4625],\n",
            "        [0.2077, 0.3226, 0.4697],\n",
            "        [0.2014, 0.3112, 0.4874]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2371, 0.3836, 0.3793],\n",
            "        [0.2109, 0.3131, 0.4761],\n",
            "        [0.2109, 0.3253, 0.4638],\n",
            "        [0.2067, 0.3225, 0.4708],\n",
            "        [0.2003, 0.3106, 0.4891]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2364, 0.3839, 0.3797],\n",
            "        [0.2098, 0.3126, 0.4776],\n",
            "        [0.2099, 0.3251, 0.4650],\n",
            "        [0.2055, 0.3223, 0.4722],\n",
            "        [0.1990, 0.3099, 0.4911]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2354, 0.3844, 0.3802],\n",
            "        [0.2086, 0.3122, 0.4792],\n",
            "        [0.2088, 0.3249, 0.4663],\n",
            "        [0.2045, 0.3220, 0.4736],\n",
            "        [0.1980, 0.3093, 0.4927]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2348, 0.3847, 0.3805],\n",
            "        [0.2077, 0.3118, 0.4804],\n",
            "        [0.2080, 0.3248, 0.4672],\n",
            "        [0.2038, 0.3217, 0.4745],\n",
            "        [0.1972, 0.3087, 0.4941]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2341, 0.3850, 0.3809],\n",
            "        [0.2070, 0.3112, 0.4819],\n",
            "        [0.2071, 0.3245, 0.4684],\n",
            "        [0.2030, 0.3212, 0.4758],\n",
            "        [0.1957, 0.3081, 0.4962]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2329, 0.3855, 0.3816],\n",
            "        [0.2056, 0.3106, 0.4838],\n",
            "        [0.2060, 0.3241, 0.4700],\n",
            "        [0.2017, 0.3206, 0.4776],\n",
            "        [0.1940, 0.3073, 0.4986]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2322, 0.3859, 0.3819],\n",
            "        [0.2047, 0.3101, 0.4852],\n",
            "        [0.2051, 0.3237, 0.4713],\n",
            "        [0.2008, 0.3203, 0.4789],\n",
            "        [0.1930, 0.3066, 0.5004]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2318, 0.3861, 0.3822],\n",
            "        [0.2041, 0.3098, 0.4861],\n",
            "        [0.2046, 0.3234, 0.4720],\n",
            "        [0.2002, 0.3198, 0.4800],\n",
            "        [0.1922, 0.3059, 0.5019]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2313, 0.3863, 0.3824],\n",
            "        [0.2033, 0.3095, 0.4872],\n",
            "        [0.2040, 0.3231, 0.4730],\n",
            "        [0.1997, 0.3196, 0.4808],\n",
            "        [0.1917, 0.3054, 0.5029]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2306, 0.3865, 0.3829],\n",
            "        [0.2025, 0.3091, 0.4884],\n",
            "        [0.2034, 0.3226, 0.4740],\n",
            "        [0.1990, 0.3191, 0.4820],\n",
            "        [0.1908, 0.3044, 0.5048]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2298, 0.3870, 0.3833],\n",
            "        [0.2015, 0.3086, 0.4898],\n",
            "        [0.2024, 0.3226, 0.4750],\n",
            "        [0.1979, 0.3189, 0.4832],\n",
            "        [0.1899, 0.3040, 0.5061]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2293, 0.3872, 0.3834],\n",
            "        [0.2010, 0.3082, 0.4908],\n",
            "        [0.2016, 0.3223, 0.4761],\n",
            "        [0.1972, 0.3186, 0.4842],\n",
            "        [0.1890, 0.3033, 0.5077]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2289, 0.3875, 0.3836],\n",
            "        [0.2006, 0.3079, 0.4915],\n",
            "        [0.2014, 0.3221, 0.4765],\n",
            "        [0.1968, 0.3184, 0.4848],\n",
            "        [0.1884, 0.3029, 0.5087]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2285, 0.3876, 0.3839],\n",
            "        [0.2001, 0.3074, 0.4925],\n",
            "        [0.2011, 0.3217, 0.4772],\n",
            "        [0.1965, 0.3179, 0.4856],\n",
            "        [0.1879, 0.3019, 0.5102]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2276, 0.3883, 0.3841],\n",
            "        [0.1989, 0.3070, 0.4941],\n",
            "        [0.2000, 0.3216, 0.4785],\n",
            "        [0.1954, 0.3177, 0.4869],\n",
            "        [0.1868, 0.3015, 0.5118]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2267, 0.3886, 0.3847],\n",
            "        [0.1979, 0.3065, 0.4955],\n",
            "        [0.1990, 0.3215, 0.4795],\n",
            "        [0.1945, 0.3175, 0.4880],\n",
            "        [0.1857, 0.3009, 0.5133]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2264, 0.3888, 0.3848],\n",
            "        [0.1976, 0.3063, 0.4961],\n",
            "        [0.1989, 0.3213, 0.4798],\n",
            "        [0.1942, 0.3171, 0.4887],\n",
            "        [0.1853, 0.3004, 0.5143]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2258, 0.3893, 0.3850],\n",
            "        [0.1967, 0.3056, 0.4977],\n",
            "        [0.1978, 0.3207, 0.4814],\n",
            "        [0.1932, 0.3166, 0.4902],\n",
            "        [0.1841, 0.2996, 0.5163]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2253, 0.3894, 0.3853],\n",
            "        [0.1960, 0.3052, 0.4987],\n",
            "        [0.1973, 0.3204, 0.4823],\n",
            "        [0.1927, 0.3164, 0.4909],\n",
            "        [0.1835, 0.2991, 0.5174]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.3896, 0.3855],\n",
            "        [0.1956, 0.3051, 0.4993],\n",
            "        [0.1971, 0.3200, 0.4829],\n",
            "        [0.1923, 0.3160, 0.4917],\n",
            "        [0.1830, 0.2988, 0.5182]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2248, 0.3897, 0.3855],\n",
            "        [0.1953, 0.3046, 0.5001],\n",
            "        [0.1967, 0.3199, 0.4834],\n",
            "        [0.1919, 0.3158, 0.4923],\n",
            "        [0.1826, 0.2983, 0.5191]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2239, 0.3902, 0.3859],\n",
            "        [0.1944, 0.3042, 0.5013],\n",
            "        [0.1960, 0.3195, 0.4845],\n",
            "        [0.1913, 0.3152, 0.4935],\n",
            "        [0.1816, 0.2976, 0.5208]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2232, 0.3906, 0.3861],\n",
            "        [0.1938, 0.3037, 0.5024],\n",
            "        [0.1953, 0.3191, 0.4855],\n",
            "        [0.1906, 0.3150, 0.4944],\n",
            "        [0.1812, 0.2969, 0.5219]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2235, 0.3905, 0.3860],\n",
            "        [0.1938, 0.3033, 0.5029],\n",
            "        [0.1952, 0.3186, 0.4861],\n",
            "        [0.1904, 0.3144, 0.4952],\n",
            "        [0.1807, 0.2961, 0.5231]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2229, 0.3909, 0.3862],\n",
            "        [0.1934, 0.3030, 0.5035],\n",
            "        [0.1949, 0.3185, 0.4867],\n",
            "        [0.1899, 0.3142, 0.4959],\n",
            "        [0.1803, 0.2956, 0.5242]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2228, 0.3911, 0.3862],\n",
            "        [0.1932, 0.3026, 0.5041],\n",
            "        [0.1946, 0.3181, 0.4872],\n",
            "        [0.1896, 0.3138, 0.4966],\n",
            "        [0.1797, 0.2952, 0.5252]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2224, 0.3915, 0.3861],\n",
            "        [0.1930, 0.3023, 0.5047],\n",
            "        [0.1943, 0.3178, 0.4878],\n",
            "        [0.1893, 0.3134, 0.4973],\n",
            "        [0.1795, 0.2944, 0.5261]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2217, 0.3919, 0.3864],\n",
            "        [0.1921, 0.3020, 0.5059],\n",
            "        [0.1936, 0.3176, 0.4888],\n",
            "        [0.1886, 0.3132, 0.4983],\n",
            "        [0.1788, 0.2939, 0.5273]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2214, 0.3922, 0.3863],\n",
            "        [0.1918, 0.3015, 0.5067],\n",
            "        [0.1932, 0.3173, 0.4895],\n",
            "        [0.1883, 0.3126, 0.4991],\n",
            "        [0.1785, 0.2928, 0.5288]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2208, 0.3925, 0.3867],\n",
            "        [0.1911, 0.3012, 0.5077],\n",
            "        [0.1926, 0.3172, 0.4902],\n",
            "        [0.1877, 0.3124, 0.4999],\n",
            "        [0.1779, 0.2924, 0.5297]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2202, 0.3930, 0.3868],\n",
            "        [0.1906, 0.3011, 0.5083],\n",
            "        [0.1921, 0.3169, 0.4910],\n",
            "        [0.1871, 0.3121, 0.5008],\n",
            "        [0.1773, 0.2920, 0.5307]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2202, 0.3932, 0.3867],\n",
            "        [0.1904, 0.3007, 0.5090],\n",
            "        [0.1917, 0.3167, 0.4916],\n",
            "        [0.1866, 0.3119, 0.5015],\n",
            "        [0.1766, 0.2917, 0.5317]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2202, 0.3933, 0.3865],\n",
            "        [0.1903, 0.3005, 0.5092],\n",
            "        [0.1916, 0.3166, 0.4919],\n",
            "        [0.1865, 0.3118, 0.5017],\n",
            "        [0.1766, 0.2913, 0.5321]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2202, 0.3933, 0.3864],\n",
            "        [0.1906, 0.3001, 0.5093],\n",
            "        [0.1916, 0.3163, 0.4920],\n",
            "        [0.1867, 0.3113, 0.5020],\n",
            "        [0.1766, 0.2907, 0.5326]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2201, 0.3934, 0.3864],\n",
            "        [0.1905, 0.2999, 0.5096],\n",
            "        [0.1915, 0.3161, 0.4924],\n",
            "        [0.1864, 0.3110, 0.5025],\n",
            "        [0.1764, 0.2902, 0.5334]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2199, 0.3935, 0.3866],\n",
            "        [0.1903, 0.2997, 0.5100],\n",
            "        [0.1914, 0.3157, 0.4929],\n",
            "        [0.1862, 0.3108, 0.5030],\n",
            "        [0.1759, 0.2898, 0.5343]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2197, 0.3937, 0.3866],\n",
            "        [0.1901, 0.2995, 0.5104],\n",
            "        [0.1911, 0.3155, 0.4934],\n",
            "        [0.1859, 0.3105, 0.5036],\n",
            "        [0.1757, 0.2893, 0.5351]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2196, 0.3940, 0.3864],\n",
            "        [0.1900, 0.2992, 0.5107],\n",
            "        [0.1911, 0.3153, 0.4937],\n",
            "        [0.1860, 0.3102, 0.5038],\n",
            "        [0.1758, 0.2886, 0.5355]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2193, 0.3943, 0.3864],\n",
            "        [0.1895, 0.2988, 0.5117],\n",
            "        [0.1906, 0.3148, 0.4946],\n",
            "        [0.1857, 0.3097, 0.5046],\n",
            "        [0.1755, 0.2879, 0.5366]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2192, 0.3944, 0.3864],\n",
            "        [0.1893, 0.2985, 0.5121],\n",
            "        [0.1905, 0.3144, 0.4951],\n",
            "        [0.1854, 0.3094, 0.5052],\n",
            "        [0.1751, 0.2873, 0.5376]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2194, 0.3944, 0.3861],\n",
            "        [0.1895, 0.2983, 0.5121],\n",
            "        [0.1908, 0.3141, 0.4951],\n",
            "        [0.1858, 0.3091, 0.5051],\n",
            "        [0.1753, 0.2869, 0.5377]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2188, 0.3949, 0.3863],\n",
            "        [0.1890, 0.2981, 0.5129],\n",
            "        [0.1903, 0.3139, 0.4958],\n",
            "        [0.1853, 0.3088, 0.5059],\n",
            "        [0.1745, 0.2866, 0.5389]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2188, 0.3949, 0.3863],\n",
            "        [0.1890, 0.2979, 0.5131],\n",
            "        [0.1901, 0.3139, 0.4960],\n",
            "        [0.1850, 0.3087, 0.5063],\n",
            "        [0.1743, 0.2864, 0.5393]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2187, 0.3950, 0.3863],\n",
            "        [0.1887, 0.2977, 0.5135],\n",
            "        [0.1899, 0.3137, 0.4964],\n",
            "        [0.1849, 0.3084, 0.5067],\n",
            "        [0.1742, 0.2859, 0.5400]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2188, 0.3951, 0.3860],\n",
            "        [0.1890, 0.2975, 0.5134],\n",
            "        [0.1901, 0.3135, 0.4965],\n",
            "        [0.1850, 0.3083, 0.5067],\n",
            "        [0.1742, 0.2855, 0.5403]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2189, 0.3951, 0.3860],\n",
            "        [0.1889, 0.2972, 0.5138],\n",
            "        [0.1899, 0.3131, 0.4970],\n",
            "        [0.1847, 0.3080, 0.5074],\n",
            "        [0.1739, 0.2849, 0.5412]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2186, 0.3955, 0.3860],\n",
            "        [0.1888, 0.2970, 0.5141],\n",
            "        [0.1895, 0.3130, 0.4975],\n",
            "        [0.1846, 0.3077, 0.5077],\n",
            "        [0.1740, 0.2844, 0.5416]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2186, 0.3955, 0.3860],\n",
            "        [0.1887, 0.2968, 0.5145],\n",
            "        [0.1896, 0.3128, 0.4976],\n",
            "        [0.1846, 0.3075, 0.5079],\n",
            "        [0.1740, 0.2839, 0.5421]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2186, 0.3955, 0.3859],\n",
            "        [0.1886, 0.2968, 0.5145],\n",
            "        [0.1897, 0.3127, 0.4976],\n",
            "        [0.1846, 0.3073, 0.5081],\n",
            "        [0.1738, 0.2837, 0.5425]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2187, 0.3955, 0.3858],\n",
            "        [0.1888, 0.2966, 0.5146],\n",
            "        [0.1896, 0.3125, 0.4978],\n",
            "        [0.1847, 0.3072, 0.5081],\n",
            "        [0.1740, 0.2833, 0.5427]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2185, 0.3956, 0.3858],\n",
            "        [0.1886, 0.2965, 0.5149],\n",
            "        [0.1896, 0.3124, 0.4980],\n",
            "        [0.1847, 0.3069, 0.5085],\n",
            "        [0.1738, 0.2830, 0.5432]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2188, 0.3956, 0.3856],\n",
            "        [0.1888, 0.2963, 0.5149],\n",
            "        [0.1898, 0.3122, 0.4981],\n",
            "        [0.1848, 0.3066, 0.5085],\n",
            "        [0.1738, 0.2828, 0.5434]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2190, 0.3957, 0.3854],\n",
            "        [0.1891, 0.2962, 0.5147],\n",
            "        [0.1900, 0.3119, 0.4981],\n",
            "        [0.1849, 0.3064, 0.5087],\n",
            "        [0.1738, 0.2826, 0.5436]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2192, 0.3956, 0.3851],\n",
            "        [0.1896, 0.2963, 0.5142],\n",
            "        [0.1904, 0.3119, 0.4976],\n",
            "        [0.1853, 0.3063, 0.5083],\n",
            "        [0.1741, 0.2824, 0.5435]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2191, 0.3957, 0.3852],\n",
            "        [0.1895, 0.2962, 0.5143],\n",
            "        [0.1904, 0.3118, 0.4978],\n",
            "        [0.1853, 0.3061, 0.5086],\n",
            "        [0.1741, 0.2822, 0.5437]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2191, 0.3958, 0.3851],\n",
            "        [0.1894, 0.2961, 0.5145],\n",
            "        [0.1902, 0.3116, 0.4982],\n",
            "        [0.1851, 0.3061, 0.5088],\n",
            "        [0.1740, 0.2820, 0.5440]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2191, 0.3958, 0.3851],\n",
            "        [0.1895, 0.2959, 0.5146],\n",
            "        [0.1902, 0.3115, 0.4982],\n",
            "        [0.1851, 0.3059, 0.5090],\n",
            "        [0.1740, 0.2817, 0.5443]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2194, 0.3957, 0.3850],\n",
            "        [0.1896, 0.2957, 0.5147],\n",
            "        [0.1903, 0.3113, 0.4984],\n",
            "        [0.1852, 0.3057, 0.5092],\n",
            "        [0.1740, 0.2814, 0.5446]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2192, 0.3957, 0.3851],\n",
            "        [0.1894, 0.2957, 0.5148],\n",
            "        [0.1902, 0.3113, 0.4985],\n",
            "        [0.1850, 0.3056, 0.5094],\n",
            "        [0.1739, 0.2811, 0.5450]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2191, 0.3959, 0.3850],\n",
            "        [0.1894, 0.2956, 0.5151],\n",
            "        [0.1901, 0.3111, 0.4988],\n",
            "        [0.1848, 0.3055, 0.5097],\n",
            "        [0.1736, 0.2808, 0.5456]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2192, 0.3960, 0.3848],\n",
            "        [0.1895, 0.2955, 0.5150],\n",
            "        [0.1902, 0.3110, 0.4988],\n",
            "        [0.1848, 0.3055, 0.5097],\n",
            "        [0.1736, 0.2806, 0.5458]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2192, 0.3960, 0.3848],\n",
            "        [0.1896, 0.2955, 0.5149],\n",
            "        [0.1902, 0.3111, 0.4987],\n",
            "        [0.1848, 0.3053, 0.5098],\n",
            "        [0.1737, 0.2805, 0.5459]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2190, 0.3963, 0.3848],\n",
            "        [0.1896, 0.2955, 0.5149],\n",
            "        [0.1902, 0.3110, 0.4987],\n",
            "        [0.1848, 0.3052, 0.5100],\n",
            "        [0.1737, 0.2803, 0.5461]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2190, 0.3963, 0.3847],\n",
            "        [0.1896, 0.2953, 0.5151],\n",
            "        [0.1901, 0.3109, 0.4990],\n",
            "        [0.1847, 0.3051, 0.5102],\n",
            "        [0.1736, 0.2800, 0.5464]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2192, 0.3962, 0.3845],\n",
            "        [0.1897, 0.2952, 0.5151],\n",
            "        [0.1903, 0.3107, 0.4990],\n",
            "        [0.1849, 0.3049, 0.5102],\n",
            "        [0.1737, 0.2797, 0.5465]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2193, 0.3962, 0.3845],\n",
            "        [0.1897, 0.2951, 0.5151],\n",
            "        [0.1903, 0.3106, 0.4990],\n",
            "        [0.1849, 0.3047, 0.5104],\n",
            "        [0.1738, 0.2794, 0.5467]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2192, 0.3963, 0.3845],\n",
            "        [0.1897, 0.2951, 0.5152],\n",
            "        [0.1904, 0.3106, 0.4990],\n",
            "        [0.1850, 0.3045, 0.5105],\n",
            "        [0.1738, 0.2791, 0.5471]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2193, 0.3963, 0.3845],\n",
            "        [0.1899, 0.2950, 0.5151],\n",
            "        [0.1905, 0.3104, 0.4991],\n",
            "        [0.1849, 0.3044, 0.5106],\n",
            "        [0.1738, 0.2790, 0.5472]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2194, 0.3963, 0.3844],\n",
            "        [0.1900, 0.2950, 0.5150],\n",
            "        [0.1906, 0.3104, 0.4990],\n",
            "        [0.1850, 0.3045, 0.5105],\n",
            "        [0.1739, 0.2789, 0.5472]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2196, 0.3962, 0.3842],\n",
            "        [0.1902, 0.2950, 0.5148],\n",
            "        [0.1908, 0.3103, 0.4989],\n",
            "        [0.1852, 0.3045, 0.5103],\n",
            "        [0.1740, 0.2788, 0.5472]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2200, 0.3961, 0.3840],\n",
            "        [0.1906, 0.2949, 0.5145],\n",
            "        [0.1913, 0.3101, 0.4986],\n",
            "        [0.1857, 0.3043, 0.5100],\n",
            "        [0.1743, 0.2786, 0.5471]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2201, 0.3960, 0.3840],\n",
            "        [0.1908, 0.2949, 0.5143],\n",
            "        [0.1915, 0.3101, 0.4985],\n",
            "        [0.1858, 0.3042, 0.5100],\n",
            "        [0.1743, 0.2785, 0.5472]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2201, 0.3960, 0.3839],\n",
            "        [0.1909, 0.2949, 0.5142],\n",
            "        [0.1917, 0.3100, 0.4983],\n",
            "        [0.1860, 0.3041, 0.5099],\n",
            "        [0.1744, 0.2783, 0.5473]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2203, 0.3959, 0.3838],\n",
            "        [0.1911, 0.2949, 0.5140],\n",
            "        [0.1919, 0.3099, 0.4982],\n",
            "        [0.1862, 0.3040, 0.5098],\n",
            "        [0.1745, 0.2781, 0.5474]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2204, 0.3959, 0.3837],\n",
            "        [0.1912, 0.2949, 0.5139],\n",
            "        [0.1920, 0.3098, 0.4982],\n",
            "        [0.1863, 0.3040, 0.5097],\n",
            "        [0.1746, 0.2780, 0.5473]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2203, 0.3960, 0.3837],\n",
            "        [0.1912, 0.2948, 0.5140],\n",
            "        [0.1919, 0.3098, 0.4983],\n",
            "        [0.1861, 0.3039, 0.5100],\n",
            "        [0.1745, 0.2780, 0.5475]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2206, 0.3958, 0.3836],\n",
            "        [0.1914, 0.2948, 0.5138],\n",
            "        [0.1921, 0.3097, 0.4982],\n",
            "        [0.1862, 0.3039, 0.5098],\n",
            "        [0.1747, 0.2778, 0.5475]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2206, 0.3959, 0.3836],\n",
            "        [0.1915, 0.2948, 0.5138],\n",
            "        [0.1921, 0.3097, 0.4982],\n",
            "        [0.1863, 0.3038, 0.5098],\n",
            "        [0.1747, 0.2777, 0.5475]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2210, 0.3957, 0.3834],\n",
            "        [0.1918, 0.2947, 0.5135],\n",
            "        [0.1925, 0.3096, 0.4979],\n",
            "        [0.1868, 0.3038, 0.5094],\n",
            "        [0.1752, 0.2775, 0.5473]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2211, 0.3957, 0.3832],\n",
            "        [0.1919, 0.2946, 0.5135],\n",
            "        [0.1926, 0.3096, 0.4979],\n",
            "        [0.1869, 0.3037, 0.5094],\n",
            "        [0.1753, 0.2774, 0.5474]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2209, 0.3957, 0.3833],\n",
            "        [0.1918, 0.2946, 0.5135],\n",
            "        [0.1926, 0.3095, 0.4979],\n",
            "        [0.1868, 0.3037, 0.5095],\n",
            "        [0.1752, 0.2773, 0.5475]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2211, 0.3957, 0.3833],\n",
            "        [0.1919, 0.2946, 0.5135],\n",
            "        [0.1927, 0.3095, 0.4979],\n",
            "        [0.1870, 0.3036, 0.5094],\n",
            "        [0.1753, 0.2772, 0.5475]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2211, 0.3956, 0.3832],\n",
            "        [0.1920, 0.2946, 0.5134],\n",
            "        [0.1928, 0.3095, 0.4978],\n",
            "        [0.1871, 0.3035, 0.5094],\n",
            "        [0.1754, 0.2771, 0.5475]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2212, 0.3956, 0.3832],\n",
            "        [0.1921, 0.2946, 0.5133],\n",
            "        [0.1928, 0.3094, 0.4978],\n",
            "        [0.1872, 0.3034, 0.5094],\n",
            "        [0.1755, 0.2770, 0.5475]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2214, 0.3956, 0.3831],\n",
            "        [0.1923, 0.2946, 0.5132],\n",
            "        [0.1930, 0.3094, 0.4976],\n",
            "        [0.1873, 0.3034, 0.5093],\n",
            "        [0.1755, 0.2770, 0.5475]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2215, 0.3955, 0.3830],\n",
            "        [0.1924, 0.2945, 0.5131],\n",
            "        [0.1931, 0.3093, 0.4976],\n",
            "        [0.1874, 0.3034, 0.5093],\n",
            "        [0.1756, 0.2770, 0.5474]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2216, 0.3954, 0.3830],\n",
            "        [0.1925, 0.2946, 0.5130],\n",
            "        [0.1932, 0.3093, 0.4975],\n",
            "        [0.1875, 0.3034, 0.5091],\n",
            "        [0.1757, 0.2770, 0.5473]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2216, 0.3954, 0.3830],\n",
            "        [0.1925, 0.2946, 0.5129],\n",
            "        [0.1932, 0.3093, 0.4974],\n",
            "        [0.1875, 0.3034, 0.5091],\n",
            "        [0.1757, 0.2770, 0.5474]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2216, 0.3954, 0.3830],\n",
            "        [0.1925, 0.2946, 0.5129],\n",
            "        [0.1932, 0.3094, 0.4974],\n",
            "        [0.1875, 0.3034, 0.5091],\n",
            "        [0.1757, 0.2770, 0.5473]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2216, 0.3954, 0.3830],\n",
            "        [0.1925, 0.2946, 0.5129],\n",
            "        [0.1933, 0.3094, 0.4973],\n",
            "        [0.1875, 0.3034, 0.5090],\n",
            "        [0.1757, 0.2770, 0.5473]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2217, 0.3954, 0.3830],\n",
            "        [0.1926, 0.2946, 0.5129],\n",
            "        [0.1933, 0.3094, 0.4973],\n",
            "        [0.1876, 0.3034, 0.5090],\n",
            "        [0.1757, 0.2770, 0.5473]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>)], 'cell_netG_B': [tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64), tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3303, 0.3339, 0.3358],\n",
            "        [0.3291, 0.3343, 0.3366],\n",
            "        [0.3285, 0.3347, 0.3368],\n",
            "        [0.3290, 0.3348, 0.3363],\n",
            "        [0.3293, 0.3345, 0.3362]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3277, 0.3347, 0.3377],\n",
            "        [0.3260, 0.3348, 0.3392],\n",
            "        [0.3254, 0.3354, 0.3392],\n",
            "        [0.3259, 0.3355, 0.3385],\n",
            "        [0.3266, 0.3349, 0.3385]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3247, 0.3355, 0.3398],\n",
            "        [0.3224, 0.3357, 0.3419],\n",
            "        [0.3217, 0.3363, 0.3420],\n",
            "        [0.3223, 0.3366, 0.3411],\n",
            "        [0.3231, 0.3359, 0.3410]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3225, 0.3362, 0.3412],\n",
            "        [0.3200, 0.3361, 0.3439],\n",
            "        [0.3192, 0.3369, 0.3439],\n",
            "        [0.3197, 0.3374, 0.3429],\n",
            "        [0.3208, 0.3364, 0.3429]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3208, 0.3368, 0.3425],\n",
            "        [0.3179, 0.3366, 0.3455],\n",
            "        [0.3171, 0.3374, 0.3455],\n",
            "        [0.3178, 0.3377, 0.3444],\n",
            "        [0.3189, 0.3367, 0.3444]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3188, 0.3372, 0.3440],\n",
            "        [0.3155, 0.3369, 0.3476],\n",
            "        [0.3145, 0.3378, 0.3477],\n",
            "        [0.3154, 0.3383, 0.3463],\n",
            "        [0.3164, 0.3372, 0.3464]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3162, 0.3379, 0.3459],\n",
            "        [0.3125, 0.3373, 0.3502],\n",
            "        [0.3116, 0.3382, 0.3502],\n",
            "        [0.3124, 0.3390, 0.3486],\n",
            "        [0.3133, 0.3378, 0.3488]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3141, 0.3384, 0.3474],\n",
            "        [0.3098, 0.3377, 0.3525],\n",
            "        [0.3087, 0.3387, 0.3526],\n",
            "        [0.3095, 0.3397, 0.3508],\n",
            "        [0.3106, 0.3384, 0.3510]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3126, 0.3388, 0.3487],\n",
            "        [0.3081, 0.3377, 0.3542],\n",
            "        [0.3066, 0.3389, 0.3544],\n",
            "        [0.3077, 0.3398, 0.3525],\n",
            "        [0.3086, 0.3385, 0.3529]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3102, 0.3392, 0.3507],\n",
            "        [0.3049, 0.3378, 0.3573],\n",
            "        [0.3031, 0.3392, 0.3577],\n",
            "        [0.3042, 0.3404, 0.3554],\n",
            "        [0.3052, 0.3391, 0.3557]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3078, 0.3398, 0.3524],\n",
            "        [0.3020, 0.3382, 0.3598],\n",
            "        [0.3001, 0.3398, 0.3601],\n",
            "        [0.3011, 0.3411, 0.3577],\n",
            "        [0.3024, 0.3394, 0.3582]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3057, 0.3402, 0.3541],\n",
            "        [0.2996, 0.3382, 0.3622],\n",
            "        [0.2974, 0.3400, 0.3626],\n",
            "        [0.2986, 0.3415, 0.3598],\n",
            "        [0.3000, 0.3395, 0.3605]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3033, 0.3408, 0.3559],\n",
            "        [0.2968, 0.3385, 0.3647],\n",
            "        [0.2944, 0.3405, 0.3651],\n",
            "        [0.2959, 0.3420, 0.3622],\n",
            "        [0.2972, 0.3398, 0.3630]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.3011, 0.3413, 0.3576],\n",
            "        [0.2942, 0.3386, 0.3672],\n",
            "        [0.2918, 0.3406, 0.3675],\n",
            "        [0.2932, 0.3423, 0.3645],\n",
            "        [0.2948, 0.3400, 0.3652]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2996, 0.3414, 0.3590],\n",
            "        [0.2920, 0.3387, 0.3693],\n",
            "        [0.2895, 0.3406, 0.3699],\n",
            "        [0.2907, 0.3424, 0.3668],\n",
            "        [0.2923, 0.3402, 0.3675]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2978, 0.3417, 0.3605],\n",
            "        [0.2897, 0.3387, 0.3716],\n",
            "        [0.2869, 0.3410, 0.3722],\n",
            "        [0.2884, 0.3427, 0.3689],\n",
            "        [0.2900, 0.3403, 0.3697]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2955, 0.3423, 0.3622],\n",
            "        [0.2873, 0.3388, 0.3739],\n",
            "        [0.2840, 0.3415, 0.3745],\n",
            "        [0.2857, 0.3432, 0.3711],\n",
            "        [0.2873, 0.3405, 0.3721]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2940, 0.3425, 0.3635],\n",
            "        [0.2852, 0.3387, 0.3761],\n",
            "        [0.2818, 0.3413, 0.3769],\n",
            "        [0.2835, 0.3431, 0.3734],\n",
            "        [0.2853, 0.3403, 0.3744]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2925, 0.3428, 0.3647],\n",
            "        [0.2834, 0.3389, 0.3778],\n",
            "        [0.2798, 0.3415, 0.3787],\n",
            "        [0.2814, 0.3435, 0.3751],\n",
            "        [0.2832, 0.3406, 0.3762]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2909, 0.3431, 0.3660],\n",
            "        [0.2815, 0.3388, 0.3797],\n",
            "        [0.2779, 0.3413, 0.3808],\n",
            "        [0.2794, 0.3433, 0.3772],\n",
            "        [0.2812, 0.3405, 0.3783]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2893, 0.3433, 0.3674],\n",
            "        [0.2795, 0.3389, 0.3816],\n",
            "        [0.2757, 0.3415, 0.3828],\n",
            "        [0.2771, 0.3436, 0.3792],\n",
            "        [0.2787, 0.3409, 0.3804]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2874, 0.3437, 0.3689],\n",
            "        [0.2773, 0.3388, 0.3839],\n",
            "        [0.2735, 0.3415, 0.3850],\n",
            "        [0.2750, 0.3437, 0.3813],\n",
            "        [0.2766, 0.3408, 0.3826]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2861, 0.3437, 0.3702],\n",
            "        [0.2752, 0.3388, 0.3860],\n",
            "        [0.2710, 0.3417, 0.3873],\n",
            "        [0.2725, 0.3439, 0.3835],\n",
            "        [0.2744, 0.3407, 0.3849]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2834, 0.3443, 0.3723],\n",
            "        [0.2721, 0.3390, 0.3889],\n",
            "        [0.2679, 0.3418, 0.3902],\n",
            "        [0.2693, 0.3443, 0.3864],\n",
            "        [0.2714, 0.3409, 0.3877]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2822, 0.3444, 0.3733],\n",
            "        [0.2708, 0.3386, 0.3906],\n",
            "        [0.2667, 0.3412, 0.3922],\n",
            "        [0.2678, 0.3438, 0.3884],\n",
            "        [0.2699, 0.3404, 0.3897]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2807, 0.3447, 0.3746],\n",
            "        [0.2690, 0.3385, 0.3925],\n",
            "        [0.2648, 0.3411, 0.3941],\n",
            "        [0.2657, 0.3439, 0.3904],\n",
            "        [0.2679, 0.3404, 0.3917]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2789, 0.3450, 0.3761],\n",
            "        [0.2669, 0.3384, 0.3948],\n",
            "        [0.2623, 0.3411, 0.3966],\n",
            "        [0.2634, 0.3438, 0.3927],\n",
            "        [0.2655, 0.3403, 0.3942]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2772, 0.3452, 0.3776],\n",
            "        [0.2648, 0.3382, 0.3970],\n",
            "        [0.2600, 0.3411, 0.3989],\n",
            "        [0.2613, 0.3438, 0.3950],\n",
            "        [0.2635, 0.3401, 0.3965]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2758, 0.3455, 0.3787],\n",
            "        [0.2632, 0.3380, 0.3989],\n",
            "        [0.2583, 0.3409, 0.4008],\n",
            "        [0.2595, 0.3437, 0.3969],\n",
            "        [0.2617, 0.3399, 0.3984]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2744, 0.3457, 0.3799],\n",
            "        [0.2614, 0.3380, 0.4006],\n",
            "        [0.2564, 0.3409, 0.4026],\n",
            "        [0.2578, 0.3435, 0.3987],\n",
            "        [0.2599, 0.3398, 0.4003]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2727, 0.3462, 0.3811],\n",
            "        [0.2596, 0.3383, 0.4022],\n",
            "        [0.2546, 0.3409, 0.4044],\n",
            "        [0.2559, 0.3436, 0.4004],\n",
            "        [0.2580, 0.3399, 0.4021]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2713, 0.3465, 0.3822],\n",
            "        [0.2581, 0.3380, 0.4039],\n",
            "        [0.2529, 0.3407, 0.4063],\n",
            "        [0.2543, 0.3436, 0.4022],\n",
            "        [0.2565, 0.3398, 0.4037]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2699, 0.3465, 0.3835],\n",
            "        [0.2562, 0.3377, 0.4061],\n",
            "        [0.2507, 0.3405, 0.4088],\n",
            "        [0.2521, 0.3434, 0.4046],\n",
            "        [0.2541, 0.3398, 0.4061]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2684, 0.3467, 0.3848],\n",
            "        [0.2544, 0.3377, 0.4079],\n",
            "        [0.2488, 0.3405, 0.4107],\n",
            "        [0.2502, 0.3434, 0.4065],\n",
            "        [0.2522, 0.3396, 0.4082]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2674, 0.3468, 0.3858],\n",
            "        [0.2530, 0.3374, 0.4096],\n",
            "        [0.2473, 0.3403, 0.4124],\n",
            "        [0.2488, 0.3431, 0.4081],\n",
            "        [0.2509, 0.3393, 0.4098]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2663, 0.3470, 0.3867],\n",
            "        [0.2516, 0.3374, 0.4110],\n",
            "        [0.2459, 0.3402, 0.4138],\n",
            "        [0.2474, 0.3431, 0.4096],\n",
            "        [0.2494, 0.3392, 0.4114]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2653, 0.3470, 0.3877],\n",
            "        [0.2503, 0.3372, 0.4125],\n",
            "        [0.2444, 0.3399, 0.4156],\n",
            "        [0.2457, 0.3427, 0.4116],\n",
            "        [0.2478, 0.3389, 0.4133]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2645, 0.3471, 0.3884],\n",
            "        [0.2491, 0.3372, 0.4137],\n",
            "        [0.2433, 0.3396, 0.4172],\n",
            "        [0.2445, 0.3424, 0.4130],\n",
            "        [0.2467, 0.3387, 0.4146]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2632, 0.3472, 0.3895],\n",
            "        [0.2475, 0.3371, 0.4155],\n",
            "        [0.2414, 0.3397, 0.4189],\n",
            "        [0.2428, 0.3424, 0.4149],\n",
            "        [0.2449, 0.3386, 0.4165]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2617, 0.3475, 0.3908],\n",
            "        [0.2459, 0.3367, 0.4174],\n",
            "        [0.2398, 0.3393, 0.4210],\n",
            "        [0.2412, 0.3419, 0.4168],\n",
            "        [0.2433, 0.3381, 0.4186]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2601, 0.3477, 0.3921],\n",
            "        [0.2438, 0.3364, 0.4198],\n",
            "        [0.2373, 0.3390, 0.4236],\n",
            "        [0.2387, 0.3419, 0.4195],\n",
            "        [0.2409, 0.3380, 0.4211]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2589, 0.3477, 0.3934],\n",
            "        [0.2421, 0.3362, 0.4217],\n",
            "        [0.2354, 0.3388, 0.4258],\n",
            "        [0.2371, 0.3414, 0.4214],\n",
            "        [0.2394, 0.3375, 0.4231]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2579, 0.3479, 0.3943],\n",
            "        [0.2408, 0.3360, 0.4232],\n",
            "        [0.2341, 0.3385, 0.4274],\n",
            "        [0.2358, 0.3412, 0.4230],\n",
            "        [0.2381, 0.3374, 0.4245]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2558, 0.3484, 0.3958],\n",
            "        [0.2385, 0.3361, 0.4254],\n",
            "        [0.2316, 0.3385, 0.4299],\n",
            "        [0.2335, 0.3411, 0.4254],\n",
            "        [0.2359, 0.3374, 0.4268]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2542, 0.3488, 0.3970],\n",
            "        [0.2366, 0.3359, 0.4275],\n",
            "        [0.2296, 0.3384, 0.4320],\n",
            "        [0.2318, 0.3412, 0.4270],\n",
            "        [0.2342, 0.3372, 0.4287]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2535, 0.3487, 0.3979],\n",
            "        [0.2356, 0.3354, 0.4291],\n",
            "        [0.2284, 0.3375, 0.4340],\n",
            "        [0.2304, 0.3406, 0.4291],\n",
            "        [0.2328, 0.3366, 0.4306]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2521, 0.3491, 0.3988],\n",
            "        [0.2340, 0.3353, 0.4307],\n",
            "        [0.2268, 0.3374, 0.4358],\n",
            "        [0.2291, 0.3404, 0.4305],\n",
            "        [0.2316, 0.3363, 0.4321]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2514, 0.3491, 0.3995],\n",
            "        [0.2329, 0.3350, 0.4320],\n",
            "        [0.2256, 0.3370, 0.4374],\n",
            "        [0.2278, 0.3402, 0.4321],\n",
            "        [0.2301, 0.3362, 0.4336]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2506, 0.3491, 0.4002],\n",
            "        [0.2318, 0.3347, 0.4334],\n",
            "        [0.2246, 0.3364, 0.4390],\n",
            "        [0.2265, 0.3396, 0.4339],\n",
            "        [0.2289, 0.3357, 0.4354]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2483, 0.3499, 0.4018],\n",
            "        [0.2295, 0.3349, 0.4356],\n",
            "        [0.2222, 0.3368, 0.4411],\n",
            "        [0.2242, 0.3402, 0.4356],\n",
            "        [0.2263, 0.3364, 0.4373]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2473, 0.3503, 0.4024],\n",
            "        [0.2285, 0.3351, 0.4365],\n",
            "        [0.2211, 0.3371, 0.4418],\n",
            "        [0.2232, 0.3404, 0.4364],\n",
            "        [0.2254, 0.3364, 0.4382]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2469, 0.3505, 0.4027],\n",
            "        [0.2279, 0.3349, 0.4372],\n",
            "        [0.2203, 0.3372, 0.4425],\n",
            "        [0.2225, 0.3406, 0.4369],\n",
            "        [0.2248, 0.3365, 0.4387]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2461, 0.3507, 0.4032],\n",
            "        [0.2272, 0.3350, 0.4378],\n",
            "        [0.2195, 0.3374, 0.4431],\n",
            "        [0.2219, 0.3406, 0.4375],\n",
            "        [0.2242, 0.3365, 0.4394]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2454, 0.3509, 0.4037],\n",
            "        [0.2264, 0.3349, 0.4387],\n",
            "        [0.2187, 0.3374, 0.4440],\n",
            "        [0.2209, 0.3408, 0.4383],\n",
            "        [0.2234, 0.3364, 0.4402]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2445, 0.3511, 0.4044],\n",
            "        [0.2254, 0.3350, 0.4396],\n",
            "        [0.2176, 0.3375, 0.4450],\n",
            "        [0.2200, 0.3409, 0.4391],\n",
            "        [0.2225, 0.3366, 0.4409]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2439, 0.3513, 0.4048],\n",
            "        [0.2246, 0.3350, 0.4404],\n",
            "        [0.2165, 0.3377, 0.4457],\n",
            "        [0.2192, 0.3411, 0.4397],\n",
            "        [0.2217, 0.3368, 0.4415]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2427, 0.3517, 0.4056],\n",
            "        [0.2234, 0.3351, 0.4415],\n",
            "        [0.2152, 0.3379, 0.4469],\n",
            "        [0.2180, 0.3414, 0.4406],\n",
            "        [0.2208, 0.3369, 0.4423]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2421, 0.3518, 0.4061],\n",
            "        [0.2225, 0.3352, 0.4423],\n",
            "        [0.2142, 0.3380, 0.4478],\n",
            "        [0.2171, 0.3415, 0.4414],\n",
            "        [0.2200, 0.3370, 0.4430]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2413, 0.3520, 0.4066],\n",
            "        [0.2217, 0.3352, 0.4432],\n",
            "        [0.2134, 0.3380, 0.4486],\n",
            "        [0.2164, 0.3415, 0.4421],\n",
            "        [0.2193, 0.3370, 0.4438]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2409, 0.3521, 0.4070],\n",
            "        [0.2211, 0.3351, 0.4437],\n",
            "        [0.2128, 0.3378, 0.4495],\n",
            "        [0.2156, 0.3414, 0.4430],\n",
            "        [0.2186, 0.3371, 0.4443]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2400, 0.3524, 0.4076],\n",
            "        [0.2202, 0.3352, 0.4445],\n",
            "        [0.2117, 0.3379, 0.4503],\n",
            "        [0.2146, 0.3416, 0.4437],\n",
            "        [0.2178, 0.3371, 0.4451]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2394, 0.3526, 0.4080],\n",
            "        [0.2194, 0.3354, 0.4453],\n",
            "        [0.2108, 0.3381, 0.4511],\n",
            "        [0.2138, 0.3419, 0.4444],\n",
            "        [0.2171, 0.3373, 0.4455]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2386, 0.3529, 0.4085],\n",
            "        [0.2185, 0.3353, 0.4462],\n",
            "        [0.2100, 0.3379, 0.4522],\n",
            "        [0.2129, 0.3417, 0.4454],\n",
            "        [0.2162, 0.3374, 0.4464]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2380, 0.3529, 0.4090],\n",
            "        [0.2179, 0.3354, 0.4467],\n",
            "        [0.2095, 0.3378, 0.4527],\n",
            "        [0.2124, 0.3416, 0.4460],\n",
            "        [0.2157, 0.3374, 0.4469]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2371, 0.3533, 0.4097],\n",
            "        [0.2168, 0.3354, 0.4478],\n",
            "        [0.2084, 0.3378, 0.4538],\n",
            "        [0.2114, 0.3416, 0.4470],\n",
            "        [0.2148, 0.3375, 0.4477]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2366, 0.3534, 0.4101],\n",
            "        [0.2161, 0.3353, 0.4485],\n",
            "        [0.2075, 0.3376, 0.4548],\n",
            "        [0.2104, 0.3416, 0.4480],\n",
            "        [0.2139, 0.3375, 0.4486]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2355, 0.3538, 0.4107],\n",
            "        [0.2152, 0.3354, 0.4494],\n",
            "        [0.2065, 0.3378, 0.4556],\n",
            "        [0.2095, 0.3417, 0.4488],\n",
            "        [0.2130, 0.3377, 0.4492]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2348, 0.3540, 0.4112],\n",
            "        [0.2145, 0.3354, 0.4501],\n",
            "        [0.2058, 0.3378, 0.4564],\n",
            "        [0.2087, 0.3417, 0.4496],\n",
            "        [0.2122, 0.3378, 0.4500]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2344, 0.3541, 0.4115],\n",
            "        [0.2140, 0.3354, 0.4506],\n",
            "        [0.2051, 0.3377, 0.4572],\n",
            "        [0.2082, 0.3416, 0.4503],\n",
            "        [0.2116, 0.3378, 0.4506]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2336, 0.3544, 0.4120],\n",
            "        [0.2130, 0.3353, 0.4517],\n",
            "        [0.2041, 0.3376, 0.4583],\n",
            "        [0.2073, 0.3414, 0.4514],\n",
            "        [0.2105, 0.3379, 0.4516]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2329, 0.3546, 0.4126],\n",
            "        [0.2123, 0.3354, 0.4523],\n",
            "        [0.2034, 0.3377, 0.4589],\n",
            "        [0.2066, 0.3415, 0.4519],\n",
            "        [0.2101, 0.3378, 0.4521]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2325, 0.3548, 0.4128],\n",
            "        [0.2119, 0.3355, 0.4526],\n",
            "        [0.2028, 0.3377, 0.4595],\n",
            "        [0.2061, 0.3415, 0.4524],\n",
            "        [0.2096, 0.3379, 0.4525]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2321, 0.3549, 0.4131],\n",
            "        [0.2113, 0.3353, 0.4534],\n",
            "        [0.2022, 0.3375, 0.4603],\n",
            "        [0.2055, 0.3415, 0.4530],\n",
            "        [0.2093, 0.3378, 0.4530]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2315, 0.3550, 0.4135],\n",
            "        [0.2105, 0.3352, 0.4543],\n",
            "        [0.2013, 0.3373, 0.4613],\n",
            "        [0.2046, 0.3415, 0.4539],\n",
            "        [0.2083, 0.3379, 0.4538]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2310, 0.3552, 0.4138],\n",
            "        [0.2100, 0.3352, 0.4548],\n",
            "        [0.2009, 0.3372, 0.4618],\n",
            "        [0.2042, 0.3414, 0.4544],\n",
            "        [0.2080, 0.3377, 0.4543]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2301, 0.3555, 0.4144],\n",
            "        [0.2091, 0.3352, 0.4558],\n",
            "        [0.1999, 0.3372, 0.4629],\n",
            "        [0.2032, 0.3414, 0.4554],\n",
            "        [0.2070, 0.3378, 0.4552]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2299, 0.3555, 0.4146],\n",
            "        [0.2087, 0.3351, 0.4562],\n",
            "        [0.1994, 0.3371, 0.4636],\n",
            "        [0.2027, 0.3412, 0.4560],\n",
            "        [0.2065, 0.3377, 0.4558]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2295, 0.3556, 0.4150],\n",
            "        [0.2081, 0.3350, 0.4569],\n",
            "        [0.1986, 0.3370, 0.4644],\n",
            "        [0.2020, 0.3413, 0.4567],\n",
            "        [0.2059, 0.3378, 0.4563]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2292, 0.3557, 0.4151],\n",
            "        [0.2079, 0.3350, 0.4572],\n",
            "        [0.1982, 0.3370, 0.4648],\n",
            "        [0.2016, 0.3413, 0.4571],\n",
            "        [0.2055, 0.3378, 0.4567]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2287, 0.3558, 0.4155],\n",
            "        [0.2072, 0.3350, 0.4579],\n",
            "        [0.1976, 0.3369, 0.4656],\n",
            "        [0.2009, 0.3412, 0.4579],\n",
            "        [0.2048, 0.3378, 0.4574]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2283, 0.3560, 0.4157],\n",
            "        [0.2068, 0.3349, 0.4583],\n",
            "        [0.1972, 0.3368, 0.4661],\n",
            "        [0.2005, 0.3413, 0.4583],\n",
            "        [0.2044, 0.3379, 0.4578]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2281, 0.3561, 0.4158],\n",
            "        [0.2064, 0.3349, 0.4587],\n",
            "        [0.1969, 0.3368, 0.4663],\n",
            "        [0.2002, 0.3412, 0.4585],\n",
            "        [0.2041, 0.3379, 0.4581]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2277, 0.3562, 0.4161],\n",
            "        [0.2059, 0.3349, 0.4592],\n",
            "        [0.1964, 0.3365, 0.4671],\n",
            "        [0.1996, 0.3412, 0.4592],\n",
            "        [0.2036, 0.3377, 0.4587]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2270, 0.3564, 0.4166],\n",
            "        [0.2052, 0.3349, 0.4599],\n",
            "        [0.1957, 0.3364, 0.4679],\n",
            "        [0.1989, 0.3411, 0.4600],\n",
            "        [0.2029, 0.3378, 0.4594]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2267, 0.3565, 0.4168],\n",
            "        [0.2049, 0.3348, 0.4603],\n",
            "        [0.1953, 0.3363, 0.4684],\n",
            "        [0.1985, 0.3411, 0.4604],\n",
            "        [0.2023, 0.3378, 0.4599]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2262, 0.3567, 0.4171],\n",
            "        [0.2045, 0.3347, 0.4608],\n",
            "        [0.1947, 0.3363, 0.4690],\n",
            "        [0.1980, 0.3410, 0.4610],\n",
            "        [0.2017, 0.3379, 0.4604]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2261, 0.3567, 0.4172],\n",
            "        [0.2041, 0.3346, 0.4613],\n",
            "        [0.1941, 0.3362, 0.4697],\n",
            "        [0.1974, 0.3410, 0.4616],\n",
            "        [0.2013, 0.3378, 0.4609]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2257, 0.3568, 0.4175],\n",
            "        [0.2036, 0.3345, 0.4619],\n",
            "        [0.1936, 0.3360, 0.4704],\n",
            "        [0.1969, 0.3409, 0.4623],\n",
            "        [0.2008, 0.3376, 0.4616]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2257, 0.3568, 0.4175],\n",
            "        [0.2035, 0.3344, 0.4621],\n",
            "        [0.1934, 0.3359, 0.4707],\n",
            "        [0.1968, 0.3408, 0.4624],\n",
            "        [0.2007, 0.3376, 0.4617]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2253, 0.3569, 0.4178],\n",
            "        [0.2030, 0.3344, 0.4626],\n",
            "        [0.1929, 0.3358, 0.4712],\n",
            "        [0.1961, 0.3408, 0.4630],\n",
            "        [0.2001, 0.3376, 0.4623]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.3571, 0.4179],\n",
            "        [0.2026, 0.3343, 0.4631],\n",
            "        [0.1925, 0.3356, 0.4719],\n",
            "        [0.1959, 0.3406, 0.4635],\n",
            "        [0.1997, 0.3375, 0.4628]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2246, 0.3572, 0.4182],\n",
            "        [0.2021, 0.3342, 0.4637],\n",
            "        [0.1917, 0.3358, 0.4725],\n",
            "        [0.1950, 0.3408, 0.4642],\n",
            "        [0.1989, 0.3377, 0.4635]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2247, 0.3570, 0.4183],\n",
            "        [0.2020, 0.3342, 0.4638],\n",
            "        [0.1915, 0.3357, 0.4728],\n",
            "        [0.1949, 0.3406, 0.4645],\n",
            "        [0.1986, 0.3376, 0.4639]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2246, 0.3570, 0.4184],\n",
            "        [0.2019, 0.3341, 0.4641],\n",
            "        [0.1914, 0.3355, 0.4731],\n",
            "        [0.1946, 0.3406, 0.4648],\n",
            "        [0.1982, 0.3375, 0.4643]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2242, 0.3571, 0.4187],\n",
            "        [0.2015, 0.3340, 0.4645],\n",
            "        [0.1909, 0.3354, 0.4736],\n",
            "        [0.1943, 0.3404, 0.4652],\n",
            "        [0.1980, 0.3373, 0.4648]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2241, 0.3571, 0.4188],\n",
            "        [0.2012, 0.3340, 0.4647],\n",
            "        [0.1907, 0.3352, 0.4741],\n",
            "        [0.1940, 0.3403, 0.4657],\n",
            "        [0.1976, 0.3372, 0.4652]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2240, 0.3571, 0.4189],\n",
            "        [0.2010, 0.3339, 0.4651],\n",
            "        [0.1904, 0.3352, 0.4745],\n",
            "        [0.1937, 0.3402, 0.4661],\n",
            "        [0.1974, 0.3371, 0.4655]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2238, 0.3572, 0.4191],\n",
            "        [0.2008, 0.3337, 0.4654],\n",
            "        [0.1902, 0.3348, 0.4750],\n",
            "        [0.1934, 0.3399, 0.4666],\n",
            "        [0.1972, 0.3368, 0.4660]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2238, 0.3570, 0.4192],\n",
            "        [0.2006, 0.3337, 0.4657],\n",
            "        [0.1900, 0.3346, 0.4754],\n",
            "        [0.1933, 0.3396, 0.4671],\n",
            "        [0.1970, 0.3367, 0.4663]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2235, 0.3571, 0.4194],\n",
            "        [0.2004, 0.3337, 0.4660],\n",
            "        [0.1896, 0.3346, 0.4757],\n",
            "        [0.1931, 0.3395, 0.4674],\n",
            "        [0.1968, 0.3366, 0.4666]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2234, 0.3571, 0.4194],\n",
            "        [0.2002, 0.3335, 0.4663],\n",
            "        [0.1893, 0.3344, 0.4762],\n",
            "        [0.1927, 0.3396, 0.4677],\n",
            "        [0.1966, 0.3366, 0.4668]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2234, 0.3571, 0.4195],\n",
            "        [0.2003, 0.3334, 0.4663],\n",
            "        [0.1894, 0.3342, 0.4764],\n",
            "        [0.1929, 0.3393, 0.4678],\n",
            "        [0.1968, 0.3363, 0.4669]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2235, 0.3571, 0.4195],\n",
            "        [0.2002, 0.3332, 0.4665],\n",
            "        [0.1893, 0.3339, 0.4768],\n",
            "        [0.1927, 0.3391, 0.4682],\n",
            "        [0.1965, 0.3362, 0.4673]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2236, 0.3569, 0.4195],\n",
            "        [0.2002, 0.3330, 0.4668],\n",
            "        [0.1892, 0.3336, 0.4772],\n",
            "        [0.1926, 0.3389, 0.4686],\n",
            "        [0.1965, 0.3358, 0.4676]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2234, 0.3570, 0.4196],\n",
            "        [0.2000, 0.3329, 0.4670],\n",
            "        [0.1889, 0.3333, 0.4777],\n",
            "        [0.1922, 0.3387, 0.4691],\n",
            "        [0.1960, 0.3359, 0.4681]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2233, 0.3570, 0.4197],\n",
            "        [0.1999, 0.3328, 0.4673],\n",
            "        [0.1888, 0.3331, 0.4782],\n",
            "        [0.1920, 0.3385, 0.4696],\n",
            "        [0.1958, 0.3356, 0.4686]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2234, 0.3568, 0.4198],\n",
            "        [0.1999, 0.3326, 0.4675],\n",
            "        [0.1888, 0.3328, 0.4785],\n",
            "        [0.1919, 0.3381, 0.4700],\n",
            "        [0.1957, 0.3354, 0.4689]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2235, 0.3567, 0.4198],\n",
            "        [0.1999, 0.3325, 0.4676],\n",
            "        [0.1888, 0.3324, 0.4789],\n",
            "        [0.1918, 0.3379, 0.4703],\n",
            "        [0.1956, 0.3352, 0.4693]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2236, 0.3566, 0.4198],\n",
            "        [0.2000, 0.3325, 0.4675],\n",
            "        [0.1889, 0.3323, 0.4788],\n",
            "        [0.1919, 0.3378, 0.4703],\n",
            "        [0.1957, 0.3350, 0.4692]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2237, 0.3564, 0.4199],\n",
            "        [0.2000, 0.3322, 0.4678],\n",
            "        [0.1889, 0.3320, 0.4792],\n",
            "        [0.1918, 0.3375, 0.4707],\n",
            "        [0.1957, 0.3346, 0.4697]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2236, 0.3565, 0.4200],\n",
            "        [0.1998, 0.3321, 0.4680],\n",
            "        [0.1889, 0.3316, 0.4796],\n",
            "        [0.1917, 0.3371, 0.4712],\n",
            "        [0.1954, 0.3344, 0.4702]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2237, 0.3564, 0.4199],\n",
            "        [0.2000, 0.3320, 0.4680],\n",
            "        [0.1890, 0.3314, 0.4796],\n",
            "        [0.1919, 0.3369, 0.4712],\n",
            "        [0.1956, 0.3342, 0.4702]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2237, 0.3563, 0.4200],\n",
            "        [0.1999, 0.3319, 0.4682],\n",
            "        [0.1890, 0.3312, 0.4799],\n",
            "        [0.1917, 0.3367, 0.4716],\n",
            "        [0.1954, 0.3341, 0.4706]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2239, 0.3561, 0.4200],\n",
            "        [0.1999, 0.3317, 0.4684],\n",
            "        [0.1889, 0.3310, 0.4802],\n",
            "        [0.1917, 0.3364, 0.4719],\n",
            "        [0.1954, 0.3337, 0.4708]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2238, 0.3561, 0.4201],\n",
            "        [0.1999, 0.3316, 0.4685],\n",
            "        [0.1889, 0.3306, 0.4805],\n",
            "        [0.1916, 0.3361, 0.4723],\n",
            "        [0.1953, 0.3336, 0.4711]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2240, 0.3559, 0.4200],\n",
            "        [0.2000, 0.3314, 0.4686],\n",
            "        [0.1890, 0.3303, 0.4807],\n",
            "        [0.1917, 0.3357, 0.4726],\n",
            "        [0.1954, 0.3332, 0.4714]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2241, 0.3558, 0.4201],\n",
            "        [0.1998, 0.3313, 0.4688],\n",
            "        [0.1888, 0.3301, 0.4811],\n",
            "        [0.1916, 0.3355, 0.4729],\n",
            "        [0.1952, 0.3331, 0.4717]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2244, 0.3556, 0.4200],\n",
            "        [0.1999, 0.3311, 0.4689],\n",
            "        [0.1889, 0.3298, 0.4813],\n",
            "        [0.1917, 0.3351, 0.4732],\n",
            "        [0.1952, 0.3328, 0.4720]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2245, 0.3554, 0.4200],\n",
            "        [0.2000, 0.3310, 0.4690],\n",
            "        [0.1889, 0.3296, 0.4815],\n",
            "        [0.1916, 0.3349, 0.4735],\n",
            "        [0.1951, 0.3327, 0.4722]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2245, 0.3554, 0.4201],\n",
            "        [0.1999, 0.3309, 0.4692],\n",
            "        [0.1887, 0.3294, 0.4819],\n",
            "        [0.1915, 0.3347, 0.4738],\n",
            "        [0.1950, 0.3324, 0.4726]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2244, 0.3554, 0.4202],\n",
            "        [0.1999, 0.3308, 0.4694],\n",
            "        [0.1887, 0.3292, 0.4822],\n",
            "        [0.1914, 0.3345, 0.4741],\n",
            "        [0.1949, 0.3322, 0.4729]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2246, 0.3553, 0.4201],\n",
            "        [0.2000, 0.3306, 0.4694],\n",
            "        [0.1888, 0.3289, 0.4823],\n",
            "        [0.1915, 0.3342, 0.4743],\n",
            "        [0.1951, 0.3319, 0.4730]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2246, 0.3552, 0.4201],\n",
            "        [0.2001, 0.3305, 0.4694],\n",
            "        [0.1889, 0.3286, 0.4825],\n",
            "        [0.1915, 0.3339, 0.4746],\n",
            "        [0.1951, 0.3317, 0.4732]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2248, 0.3551, 0.4201],\n",
            "        [0.2001, 0.3304, 0.4695],\n",
            "        [0.1890, 0.3284, 0.4825],\n",
            "        [0.1917, 0.3336, 0.4748],\n",
            "        [0.1952, 0.3314, 0.4734]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.3549, 0.4201],\n",
            "        [0.2002, 0.3303, 0.4696],\n",
            "        [0.1891, 0.3282, 0.4827],\n",
            "        [0.1917, 0.3333, 0.4749],\n",
            "        [0.1952, 0.3312, 0.4736]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.3549, 0.4201],\n",
            "        [0.2002, 0.3302, 0.4696],\n",
            "        [0.1891, 0.3280, 0.4829],\n",
            "        [0.1917, 0.3332, 0.4751],\n",
            "        [0.1952, 0.3311, 0.4737]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.3548, 0.4202],\n",
            "        [0.2002, 0.3300, 0.4697],\n",
            "        [0.1891, 0.3278, 0.4831],\n",
            "        [0.1916, 0.3330, 0.4754],\n",
            "        [0.1952, 0.3308, 0.4740]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2253, 0.3545, 0.4202],\n",
            "        [0.2003, 0.3299, 0.4698],\n",
            "        [0.1892, 0.3276, 0.4832],\n",
            "        [0.1917, 0.3327, 0.4757],\n",
            "        [0.1952, 0.3306, 0.4742]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2254, 0.3544, 0.4202],\n",
            "        [0.2003, 0.3298, 0.4699],\n",
            "        [0.1892, 0.3274, 0.4835],\n",
            "        [0.1916, 0.3325, 0.4759],\n",
            "        [0.1951, 0.3305, 0.4744]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2255, 0.3543, 0.4202],\n",
            "        [0.2004, 0.3296, 0.4700],\n",
            "        [0.1892, 0.3272, 0.4836],\n",
            "        [0.1917, 0.3323, 0.4761],\n",
            "        [0.1951, 0.3303, 0.4746]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2257, 0.3542, 0.4201],\n",
            "        [0.2005, 0.3295, 0.4699],\n",
            "        [0.1894, 0.3270, 0.4836],\n",
            "        [0.1918, 0.3320, 0.4762],\n",
            "        [0.1952, 0.3301, 0.4747]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2258, 0.3541, 0.4201],\n",
            "        [0.2007, 0.3294, 0.4699],\n",
            "        [0.1895, 0.3268, 0.4837],\n",
            "        [0.1919, 0.3319, 0.4762],\n",
            "        [0.1953, 0.3299, 0.4748]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2258, 0.3541, 0.4201],\n",
            "        [0.2006, 0.3293, 0.4701],\n",
            "        [0.1894, 0.3267, 0.4839],\n",
            "        [0.1918, 0.3317, 0.4765],\n",
            "        [0.1953, 0.3297, 0.4750]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2260, 0.3539, 0.4201],\n",
            "        [0.2007, 0.3292, 0.4701],\n",
            "        [0.1895, 0.3265, 0.4839],\n",
            "        [0.1919, 0.3315, 0.4766],\n",
            "        [0.1953, 0.3295, 0.4752]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2261, 0.3538, 0.4201],\n",
            "        [0.2008, 0.3291, 0.4701],\n",
            "        [0.1896, 0.3264, 0.4841],\n",
            "        [0.1919, 0.3313, 0.4768],\n",
            "        [0.1953, 0.3293, 0.4754]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2261, 0.3538, 0.4201],\n",
            "        [0.2009, 0.3290, 0.4701],\n",
            "        [0.1897, 0.3262, 0.4841],\n",
            "        [0.1920, 0.3311, 0.4769],\n",
            "        [0.1954, 0.3291, 0.4755]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2263, 0.3537, 0.4200],\n",
            "        [0.2010, 0.3290, 0.4700],\n",
            "        [0.1899, 0.3261, 0.4841],\n",
            "        [0.1921, 0.3310, 0.4769],\n",
            "        [0.1955, 0.3289, 0.4755]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2263, 0.3537, 0.4200],\n",
            "        [0.2010, 0.3289, 0.4701],\n",
            "        [0.1899, 0.3259, 0.4842],\n",
            "        [0.1921, 0.3308, 0.4771],\n",
            "        [0.1955, 0.3288, 0.4757]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2264, 0.3536, 0.4200],\n",
            "        [0.2011, 0.3289, 0.4700],\n",
            "        [0.1900, 0.3258, 0.4842],\n",
            "        [0.1922, 0.3308, 0.4770],\n",
            "        [0.1956, 0.3287, 0.4757]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2265, 0.3535, 0.4200],\n",
            "        [0.2012, 0.3288, 0.4700],\n",
            "        [0.1900, 0.3257, 0.4842],\n",
            "        [0.1922, 0.3306, 0.4771],\n",
            "        [0.1956, 0.3286, 0.4758]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2266, 0.3534, 0.4199],\n",
            "        [0.2013, 0.3287, 0.4700],\n",
            "        [0.1901, 0.3256, 0.4842],\n",
            "        [0.1923, 0.3305, 0.4772],\n",
            "        [0.1957, 0.3285, 0.4758]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2268, 0.3533, 0.4198],\n",
            "        [0.2014, 0.3286, 0.4699],\n",
            "        [0.1902, 0.3256, 0.4842],\n",
            "        [0.1924, 0.3304, 0.4772],\n",
            "        [0.1958, 0.3284, 0.4759]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2269, 0.3533, 0.4198],\n",
            "        [0.2015, 0.3286, 0.4699],\n",
            "        [0.1904, 0.3254, 0.4842],\n",
            "        [0.1925, 0.3303, 0.4773],\n",
            "        [0.1958, 0.3282, 0.4760]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2270, 0.3532, 0.4198],\n",
            "        [0.2016, 0.3285, 0.4699],\n",
            "        [0.1904, 0.3254, 0.4842],\n",
            "        [0.1925, 0.3302, 0.4773],\n",
            "        [0.1958, 0.3282, 0.4760]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2271, 0.3532, 0.4197],\n",
            "        [0.2016, 0.3285, 0.4699],\n",
            "        [0.1905, 0.3253, 0.4842],\n",
            "        [0.1925, 0.3302, 0.4773],\n",
            "        [0.1959, 0.3281, 0.4760]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2271, 0.3531, 0.4197],\n",
            "        [0.2017, 0.3285, 0.4698],\n",
            "        [0.1905, 0.3252, 0.4842],\n",
            "        [0.1926, 0.3301, 0.4773],\n",
            "        [0.1959, 0.3280, 0.4760]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2271, 0.3531, 0.4197],\n",
            "        [0.2017, 0.3285, 0.4699],\n",
            "        [0.1905, 0.3252, 0.4842],\n",
            "        [0.1926, 0.3301, 0.4774],\n",
            "        [0.1959, 0.3280, 0.4761]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2272, 0.3531, 0.4197],\n",
            "        [0.2017, 0.3284, 0.4698],\n",
            "        [0.1906, 0.3252, 0.4842],\n",
            "        [0.1926, 0.3300, 0.4773],\n",
            "        [0.1960, 0.3280, 0.4760]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2272, 0.3531, 0.4197],\n",
            "        [0.2018, 0.3284, 0.4698],\n",
            "        [0.1906, 0.3252, 0.4842],\n",
            "        [0.1927, 0.3300, 0.4773],\n",
            "        [0.1960, 0.3279, 0.4760]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.2272, 0.3531, 0.4197],\n",
            "        [0.2018, 0.3284, 0.4698],\n",
            "        [0.1906, 0.3252, 0.4842],\n",
            "        [0.1927, 0.3300, 0.4773],\n",
            "        [0.1960, 0.3279, 0.4760]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_PixelDa --train_name truck_nas_project_layer_types_PixelDa --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 50 --n_epochs 100 --n_epochs_decay 100 --layer_types PixelDa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsKUnM-lVd15",
        "outputId": "fb1f787b-0bc1-4588-83f8-973ba1f5ed45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 50                            \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: CycleGan+ReLU                 \t[default: CycleGan]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_cycleGAN_ReLU\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_ReLU\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 9.611 M\n",
            "[Network G_B] Total number of parameters : 9.611 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_ReLU/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.325, data: 0.130) D_A: 0.302 G_A: 0.460 cycle_A: 1.580 idt_A: 1.345 D_B: 0.295 G_B: 0.453 cycle_B: 3.113 idt_B: 0.716 \n",
            "End of epoch 1 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.321, data: 0.197) D_A: 0.223 G_A: 0.536 cycle_A: 0.768 idt_A: 0.902 D_B: 0.087 G_B: 0.207 cycle_B: 1.976 idt_B: 0.333 \n",
            "End of epoch 2 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.319, data: 0.196) D_A: 0.362 G_A: 0.153 cycle_A: 0.541 idt_A: 2.574 D_B: 0.106 G_B: 1.354 cycle_B: 4.691 idt_B: 0.187 \n",
            "End of epoch 3 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.534, data: 0.187) D_A: 0.202 G_A: 0.495 cycle_A: 0.471 idt_A: 1.539 D_B: 0.182 G_B: 0.865 cycle_B: 3.201 idt_B: 0.288 \n",
            "End of epoch 4 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.324, data: 0.203) D_A: 0.521 G_A: 0.401 cycle_A: 0.750 idt_A: 1.268 D_B: 0.070 G_B: 0.333 cycle_B: 2.847 idt_B: 0.268 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.347, data: 0.190) D_A: 0.207 G_A: 0.272 cycle_A: 0.709 idt_A: 1.565 D_B: 0.281 G_B: 0.217 cycle_B: 3.606 idt_B: 0.405 \n",
            "End of epoch 6 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.337, data: 0.216) D_A: 0.198 G_A: 0.410 cycle_A: 0.723 idt_A: 0.517 D_B: 0.138 G_B: 0.715 cycle_B: 1.340 idt_B: 0.334 \n",
            "End of epoch 7 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.549, data: 0.220) D_A: 0.184 G_A: 0.270 cycle_A: 1.072 idt_A: 1.051 D_B: 0.140 G_B: 0.365 cycle_B: 2.538 idt_B: 0.450 \n",
            "End of epoch 8 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.322, data: 0.172) D_A: 0.220 G_A: 0.595 cycle_A: 0.414 idt_A: 0.925 D_B: 0.132 G_B: 0.277 cycle_B: 2.487 idt_B: 0.200 \n",
            "End of epoch 9 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.339, data: 0.196) D_A: 0.125 G_A: 0.625 cycle_A: 0.493 idt_A: 1.789 D_B: 0.225 G_B: 0.188 cycle_B: 4.229 idt_B: 0.244 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.324, data: 0.194) D_A: 0.126 G_A: 0.457 cycle_A: 0.607 idt_A: 0.705 D_B: 0.109 G_B: 1.210 cycle_B: 2.035 idt_B: 0.258 \n",
            "End of epoch 11 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.611, data: 0.191) D_A: 0.151 G_A: 0.343 cycle_A: 0.634 idt_A: 0.656 D_B: 0.126 G_B: 0.859 cycle_B: 1.464 idt_B: 0.287 \n",
            "End of epoch 12 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.320, data: 0.200) D_A: 0.117 G_A: 0.375 cycle_A: 0.489 idt_A: 0.740 D_B: 0.413 G_B: 0.072 cycle_B: 1.963 idt_B: 0.221 \n",
            "End of epoch 13 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.348, data: 0.198) D_A: 0.232 G_A: 0.472 cycle_A: 1.360 idt_A: 0.934 D_B: 0.168 G_B: 0.542 cycle_B: 2.558 idt_B: 0.633 \n",
            "End of epoch 14 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.325, data: 0.200) D_A: 0.181 G_A: 0.431 cycle_A: 0.436 idt_A: 1.114 D_B: 0.158 G_B: 0.442 cycle_B: 2.124 idt_B: 0.176 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.629, data: 0.199) D_A: 0.178 G_A: 0.373 cycle_A: 1.049 idt_A: 0.739 D_B: 0.154 G_B: 0.272 cycle_B: 1.758 idt_B: 0.477 \n",
            "End of epoch 16 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.315, data: 0.189) D_A: 0.167 G_A: 0.293 cycle_A: 0.459 idt_A: 0.695 D_B: 0.095 G_B: 0.549 cycle_B: 2.083 idt_B: 0.157 \n",
            "End of epoch 17 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.317, data: 0.202) D_A: 0.078 G_A: 0.675 cycle_A: 0.759 idt_A: 0.814 D_B: 0.188 G_B: 0.214 cycle_B: 2.293 idt_B: 0.302 \n",
            "End of epoch 18 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.307, data: 0.192) D_A: 0.429 G_A: 0.400 cycle_A: 0.448 idt_A: 1.501 D_B: 0.104 G_B: 0.836 cycle_B: 2.956 idt_B: 0.210 \n",
            "End of epoch 19 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.634, data: 0.196) D_A: 0.119 G_A: 0.231 cycle_A: 0.556 idt_A: 1.181 D_B: 0.197 G_B: 0.317 cycle_B: 2.901 idt_B: 0.259 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.311, data: 0.194) D_A: 0.271 G_A: 0.111 cycle_A: 0.546 idt_A: 0.659 D_B: 0.159 G_B: 0.294 cycle_B: 1.680 idt_B: 0.210 \n",
            "End of epoch 21 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.315, data: 0.175) D_A: 0.240 G_A: 0.315 cycle_A: 0.547 idt_A: 0.478 D_B: 0.217 G_B: 0.100 cycle_B: 1.132 idt_B: 0.166 \n",
            "End of epoch 22 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.312, data: 0.177) D_A: 0.098 G_A: 0.773 cycle_A: 0.498 idt_A: 0.595 D_B: 0.169 G_B: 0.390 cycle_B: 1.546 idt_B: 0.202 \n",
            "End of epoch 23 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.683, data: 0.186) D_A: 0.116 G_A: 0.431 cycle_A: 0.455 idt_A: 0.790 D_B: 0.135 G_B: 0.354 cycle_B: 2.152 idt_B: 0.184 \n",
            "End of epoch 24 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.316, data: 0.206) D_A: 0.332 G_A: 0.492 cycle_A: 0.443 idt_A: 0.888 D_B: 0.109 G_B: 0.169 cycle_B: 1.535 idt_B: 0.195 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.321, data: 0.190) D_A: 0.199 G_A: 0.422 cycle_A: 0.897 idt_A: 0.720 D_B: 0.260 G_B: 1.084 cycle_B: 2.589 idt_B: 0.327 \n",
            "End of epoch 26 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.320, data: 0.193) D_A: 0.101 G_A: 0.411 cycle_A: 1.015 idt_A: 0.566 D_B: 0.208 G_B: 0.702 cycle_B: 1.740 idt_B: 0.262 \n",
            "End of epoch 27 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.662, data: 0.203) D_A: 0.119 G_A: 0.608 cycle_A: 0.615 idt_A: 0.936 D_B: 0.040 G_B: 0.722 cycle_B: 2.622 idt_B: 0.260 \n",
            "End of epoch 28 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.313, data: 0.169) D_A: 0.093 G_A: 0.786 cycle_A: 0.655 idt_A: 0.717 D_B: 0.078 G_B: 0.862 cycle_B: 2.002 idt_B: 0.318 \n",
            "End of epoch 29 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.314, data: 0.172) D_A: 0.347 G_A: 0.112 cycle_A: 0.409 idt_A: 0.632 D_B: 0.264 G_B: 0.669 cycle_B: 1.508 idt_B: 0.130 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.312, data: 0.174) D_A: 0.070 G_A: 0.556 cycle_A: 0.388 idt_A: 0.584 D_B: 0.285 G_B: 0.706 cycle_B: 1.467 idt_B: 0.144 \n",
            "End of epoch 31 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.688, data: 0.190) D_A: 0.152 G_A: 0.369 cycle_A: 0.514 idt_A: 0.886 D_B: 0.130 G_B: 1.013 cycle_B: 2.243 idt_B: 0.200 \n",
            "End of epoch 32 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.311, data: 0.170) D_A: 0.119 G_A: 0.175 cycle_A: 0.786 idt_A: 0.758 D_B: 0.139 G_B: 0.368 cycle_B: 2.422 idt_B: 0.459 \n",
            "End of epoch 33 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.314, data: 0.171) D_A: 0.198 G_A: 0.412 cycle_A: 0.402 idt_A: 0.679 D_B: 0.220 G_B: 0.190 cycle_B: 1.549 idt_B: 0.127 \n",
            "End of epoch 34 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.312, data: 0.180) D_A: 0.315 G_A: 0.184 cycle_A: 0.603 idt_A: 0.924 D_B: 0.112 G_B: 0.833 cycle_B: 2.034 idt_B: 0.152 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.734, data: 0.201) D_A: 0.109 G_A: 0.524 cycle_A: 0.324 idt_A: 0.562 D_B: 0.343 G_B: 0.100 cycle_B: 1.757 idt_B: 0.165 \n",
            "End of epoch 36 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.312, data: 0.185) D_A: 0.244 G_A: 0.664 cycle_A: 0.602 idt_A: 0.680 D_B: 0.253 G_B: 0.137 cycle_B: 1.983 idt_B: 0.312 \n",
            "End of epoch 37 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.311, data: 0.184) D_A: 0.103 G_A: 0.406 cycle_A: 0.530 idt_A: 0.909 D_B: 0.186 G_B: 0.346 cycle_B: 1.449 idt_B: 0.215 \n",
            "End of epoch 38 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.311, data: 0.166) D_A: 0.204 G_A: 1.087 cycle_A: 0.514 idt_A: 0.927 D_B: 0.146 G_B: 0.722 cycle_B: 3.171 idt_B: 0.221 \n",
            "End of epoch 39 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.743, data: 0.184) D_A: 0.174 G_A: 0.363 cycle_A: 0.309 idt_A: 0.613 D_B: 0.258 G_B: 0.165 cycle_B: 1.513 idt_B: 0.128 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.329, data: 0.196) D_A: 0.108 G_A: 0.125 cycle_A: 0.445 idt_A: 0.596 D_B: 1.279 G_B: 1.341 cycle_B: 1.438 idt_B: 0.167 \n",
            "End of epoch 41 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.321, data: 0.175) D_A: 0.135 G_A: 1.005 cycle_A: 0.524 idt_A: 0.515 D_B: 0.220 G_B: 0.200 cycle_B: 1.580 idt_B: 0.253 \n",
            "End of epoch 42 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.316, data: 0.222) D_A: 0.149 G_A: 0.745 cycle_A: 0.434 idt_A: 0.826 D_B: 0.198 G_B: 0.120 cycle_B: 2.515 idt_B: 0.205 \n",
            "End of epoch 43 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.754, data: 0.194) D_A: 0.166 G_A: 0.258 cycle_A: 0.543 idt_A: 0.863 D_B: 0.108 G_B: 0.645 cycle_B: 2.143 idt_B: 0.240 \n",
            "End of epoch 44 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.323, data: 0.175) D_A: 0.098 G_A: 0.697 cycle_A: 0.697 idt_A: 0.407 D_B: 0.059 G_B: 0.359 cycle_B: 1.095 idt_B: 0.364 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.313, data: 0.172) D_A: 0.093 G_A: 0.294 cycle_A: 0.513 idt_A: 0.582 D_B: 0.261 G_B: 0.311 cycle_B: 1.674 idt_B: 0.176 \n",
            "End of epoch 46 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.312, data: 0.194) D_A: 0.157 G_A: 0.346 cycle_A: 0.428 idt_A: 0.577 D_B: 0.250 G_B: 0.270 cycle_B: 1.885 idt_B: 0.182 \n",
            "End of epoch 47 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 0.794, data: 0.183) D_A: 0.088 G_A: 0.764 cycle_A: 0.332 idt_A: 0.616 D_B: 0.253 G_B: 0.290 cycle_B: 1.262 idt_B: 0.132 \n",
            "End of epoch 48 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.317, data: 0.171) D_A: 0.177 G_A: 0.408 cycle_A: 0.442 idt_A: 0.430 D_B: 0.254 G_B: 0.283 cycle_B: 1.407 idt_B: 0.160 \n",
            "End of epoch 49 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.324, data: 0.174) D_A: 0.178 G_A: 0.581 cycle_A: 0.694 idt_A: 0.684 D_B: 0.243 G_B: 0.285 cycle_B: 1.710 idt_B: 0.303 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.320, data: 0.182) D_A: 0.133 G_A: 0.479 cycle_A: 0.572 idt_A: 0.733 D_B: 0.280 G_B: 0.305 cycle_B: 1.729 idt_B: 0.184 \n",
            "End of epoch 51 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 0.818, data: 0.187) D_A: 0.299 G_A: 0.635 cycle_A: 0.938 idt_A: 0.882 D_B: 0.237 G_B: 0.298 cycle_B: 1.798 idt_B: 0.254 \n",
            "End of epoch 52 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.310, data: 0.175) D_A: 0.071 G_A: 0.286 cycle_A: 0.387 idt_A: 0.435 D_B: 0.275 G_B: 0.299 cycle_B: 1.248 idt_B: 0.143 \n",
            "End of epoch 53 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.311, data: 0.181) D_A: 0.077 G_A: 0.353 cycle_A: 0.309 idt_A: 0.372 D_B: 0.240 G_B: 0.260 cycle_B: 0.768 idt_B: 0.110 \n",
            "End of epoch 54 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.309, data: 0.184) D_A: 0.101 G_A: 0.237 cycle_A: 0.530 idt_A: 0.543 D_B: 0.232 G_B: 0.358 cycle_B: 2.047 idt_B: 0.175 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 100, time: 0.831, data: 0.194) D_A: 0.223 G_A: 0.499 cycle_A: 0.650 idt_A: 0.546 D_B: 0.194 G_B: 0.280 cycle_B: 1.386 idt_B: 0.214 \n",
            "End of epoch 56 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.306, data: 0.168) D_A: 0.147 G_A: 0.091 cycle_A: 0.445 idt_A: 0.687 D_B: 0.230 G_B: 0.394 cycle_B: 1.366 idt_B: 0.165 \n",
            "End of epoch 57 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.324, data: 0.179) D_A: 0.248 G_A: 0.179 cycle_A: 0.610 idt_A: 0.485 D_B: 0.211 G_B: 0.242 cycle_B: 1.078 idt_B: 0.210 \n",
            "End of epoch 58 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.312, data: 0.186) D_A: 0.139 G_A: 0.736 cycle_A: 0.430 idt_A: 0.344 D_B: 0.301 G_B: 0.264 cycle_B: 0.907 idt_B: 0.136 \n",
            "End of epoch 59 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.883, data: 0.185) D_A: 0.246 G_A: 0.100 cycle_A: 0.593 idt_A: 0.557 D_B: 0.323 G_B: 0.587 cycle_B: 1.647 idt_B: 0.254 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.312, data: 0.195) D_A: 0.161 G_A: 0.582 cycle_A: 0.588 idt_A: 0.353 D_B: 0.243 G_B: 0.381 cycle_B: 0.976 idt_B: 0.120 \n",
            "End of epoch 61 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.311, data: 0.163) D_A: 0.135 G_A: 0.341 cycle_A: 0.359 idt_A: 0.474 D_B: 0.252 G_B: 0.421 cycle_B: 1.314 idt_B: 0.132 \n",
            "End of epoch 62 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.313, data: 0.184) D_A: 0.115 G_A: 0.422 cycle_A: 0.755 idt_A: 0.536 D_B: 0.241 G_B: 0.195 cycle_B: 1.520 idt_B: 0.297 \n",
            "End of epoch 63 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 100, time: 0.905, data: 0.190) D_A: 0.068 G_A: 0.358 cycle_A: 0.499 idt_A: 0.678 D_B: 0.160 G_B: 0.528 cycle_B: 1.466 idt_B: 0.183 \n",
            "End of epoch 64 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.319, data: 0.204) D_A: 0.101 G_A: 0.405 cycle_A: 0.586 idt_A: 0.375 D_B: 0.223 G_B: 0.304 cycle_B: 1.042 idt_B: 0.305 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.309, data: 0.200) D_A: 0.084 G_A: 0.275 cycle_A: 0.219 idt_A: 0.536 D_B: 0.210 G_B: 0.252 cycle_B: 1.292 idt_B: 0.109 \n",
            "End of epoch 66 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.331, data: 0.177) D_A: 0.153 G_A: 0.505 cycle_A: 0.236 idt_A: 0.494 D_B: 0.283 G_B: 0.436 cycle_B: 1.360 idt_B: 0.076 \n",
            "End of epoch 67 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 100, time: 0.933, data: 0.186) D_A: 0.142 G_A: 0.153 cycle_A: 0.529 idt_A: 0.457 D_B: 0.117 G_B: 0.536 cycle_B: 1.350 idt_B: 0.169 \n",
            "End of epoch 68 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.319, data: 0.186) D_A: 0.177 G_A: 1.047 cycle_A: 0.282 idt_A: 0.586 D_B: 0.259 G_B: 0.144 cycle_B: 2.130 idt_B: 0.111 \n",
            "End of epoch 69 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.311, data: 0.207) D_A: 0.220 G_A: 0.362 cycle_A: 0.624 idt_A: 0.496 D_B: 0.126 G_B: 0.370 cycle_B: 1.451 idt_B: 0.215 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.308, data: 0.186) D_A: 0.096 G_A: 0.108 cycle_A: 0.313 idt_A: 0.443 D_B: 0.146 G_B: 0.412 cycle_B: 1.318 idt_B: 0.165 \n",
            "End of epoch 71 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 100, time: 0.919, data: 0.192) D_A: 0.264 G_A: 0.209 cycle_A: 0.478 idt_A: 0.543 D_B: 0.253 G_B: 1.016 cycle_B: 1.397 idt_B: 0.174 \n",
            "End of epoch 72 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.332, data: 0.174) D_A: 0.170 G_A: 0.557 cycle_A: 0.353 idt_A: 0.411 D_B: 0.211 G_B: 0.513 cycle_B: 1.011 idt_B: 0.138 \n",
            "End of epoch 73 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.317, data: 0.188) D_A: 0.082 G_A: 0.258 cycle_A: 0.415 idt_A: 0.795 D_B: 0.139 G_B: 0.597 cycle_B: 1.737 idt_B: 0.168 \n",
            "End of epoch 74 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.304, data: 0.183) D_A: 0.114 G_A: 0.150 cycle_A: 0.350 idt_A: 0.402 D_B: 0.147 G_B: 0.697 cycle_B: 1.284 idt_B: 0.132 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 100, time: 0.946, data: 0.181) D_A: 0.248 G_A: 0.702 cycle_A: 0.344 idt_A: 0.595 D_B: 0.171 G_B: 0.459 cycle_B: 1.541 idt_B: 0.125 \n",
            "End of epoch 76 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.305, data: 0.181) D_A: 0.225 G_A: 0.214 cycle_A: 0.575 idt_A: 0.504 D_B: 0.131 G_B: 0.282 cycle_B: 1.515 idt_B: 0.225 \n",
            "End of epoch 77 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.315, data: 0.185) D_A: 0.093 G_A: 0.402 cycle_A: 0.508 idt_A: 0.524 D_B: 0.235 G_B: 0.253 cycle_B: 1.504 idt_B: 0.145 \n",
            "End of epoch 78 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.310, data: 0.202) D_A: 0.167 G_A: 0.351 cycle_A: 0.333 idt_A: 0.416 D_B: 0.150 G_B: 0.331 cycle_B: 1.091 idt_B: 0.103 \n",
            "End of epoch 79 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 100, time: 0.956, data: 0.177) D_A: 0.141 G_A: 0.492 cycle_A: 0.540 idt_A: 0.566 D_B: 0.263 G_B: 0.503 cycle_B: 1.828 idt_B: 0.218 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.478, data: 0.189) D_A: 0.175 G_A: 0.575 cycle_A: 0.294 idt_A: 0.534 D_B: 0.142 G_B: 0.297 cycle_B: 1.441 idt_B: 0.127 \n",
            "End of epoch 81 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.312, data: 0.194) D_A: 0.144 G_A: 0.637 cycle_A: 0.457 idt_A: 0.326 D_B: 0.090 G_B: 0.545 cycle_B: 1.141 idt_B: 0.131 \n",
            "End of epoch 82 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.311, data: 0.200) D_A: 0.230 G_A: 0.632 cycle_A: 0.358 idt_A: 0.767 D_B: 0.166 G_B: 0.270 cycle_B: 1.471 idt_B: 0.137 \n",
            "End of epoch 83 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 100, time: 1.023, data: 0.187) D_A: 0.086 G_A: 0.471 cycle_A: 0.467 idt_A: 0.284 D_B: 0.053 G_B: 0.829 cycle_B: 0.930 idt_B: 0.197 \n",
            "End of epoch 84 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.307, data: 0.181) D_A: 0.076 G_A: 0.262 cycle_A: 0.702 idt_A: 0.401 D_B: 0.254 G_B: 0.182 cycle_B: 1.295 idt_B: 0.247 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.329, data: 0.198) D_A: 0.177 G_A: 0.232 cycle_A: 0.380 idt_A: 0.559 D_B: 0.219 G_B: 0.322 cycle_B: 1.382 idt_B: 0.164 \n",
            "End of epoch 86 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.322, data: 0.206) D_A: 0.226 G_A: 0.975 cycle_A: 0.316 idt_A: 0.392 D_B: 0.029 G_B: 0.377 cycle_B: 1.153 idt_B: 0.096 \n",
            "End of epoch 87 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 100, time: 1.185, data: 0.185) D_A: 0.350 G_A: 0.071 cycle_A: 0.236 idt_A: 0.638 D_B: 0.172 G_B: 0.233 cycle_B: 1.675 idt_B: 0.087 \n",
            "End of epoch 88 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.311, data: 0.197) D_A: 0.192 G_A: 0.244 cycle_A: 0.752 idt_A: 0.380 D_B: 0.177 G_B: 0.282 cycle_B: 1.580 idt_B: 0.153 \n",
            "End of epoch 89 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.309, data: 0.200) D_A: 0.122 G_A: 0.425 cycle_A: 0.263 idt_A: 0.507 D_B: 0.200 G_B: 0.202 cycle_B: 1.647 idt_B: 0.107 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.316, data: 0.200) D_A: 0.049 G_A: 0.451 cycle_A: 0.351 idt_A: 0.535 D_B: 0.213 G_B: 0.494 cycle_B: 2.010 idt_B: 0.131 \n",
            "End of epoch 91 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 100, time: 1.040, data: 0.192) D_A: 0.106 G_A: 0.117 cycle_A: 0.443 idt_A: 0.502 D_B: 0.304 G_B: 0.669 cycle_B: 1.450 idt_B: 0.166 \n",
            "End of epoch 92 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.311, data: 0.184) D_A: 0.080 G_A: 0.561 cycle_A: 0.318 idt_A: 0.442 D_B: 0.167 G_B: 0.609 cycle_B: 1.753 idt_B: 0.092 \n",
            "End of epoch 93 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.327, data: 0.179) D_A: 0.266 G_A: 0.274 cycle_A: 0.368 idt_A: 0.485 D_B: 0.315 G_B: 0.624 cycle_B: 1.093 idt_B: 0.187 \n",
            "End of epoch 94 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.326, data: 0.187) D_A: 0.403 G_A: 0.081 cycle_A: 0.371 idt_A: 0.406 D_B: 0.157 G_B: 0.346 cycle_B: 1.195 idt_B: 0.110 \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 100, time: 1.020, data: 0.197) D_A: 0.083 G_A: 0.646 cycle_A: 0.267 idt_A: 0.417 D_B: 0.147 G_B: 0.276 cycle_B: 1.133 idt_B: 0.112 \n",
            "End of epoch 96 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.328, data: 0.181) D_A: 0.097 G_A: 0.404 cycle_A: 0.286 idt_A: 0.349 D_B: 0.115 G_B: 0.361 cycle_B: 0.983 idt_B: 0.115 \n",
            "End of epoch 97 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.308, data: 0.181) D_A: 0.074 G_A: 0.809 cycle_A: 0.381 idt_A: 0.397 D_B: 0.233 G_B: 0.076 cycle_B: 1.177 idt_B: 0.182 \n",
            "End of epoch 98 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.325, data: 0.186) D_A: 0.255 G_A: 0.312 cycle_A: 0.520 idt_A: 0.662 D_B: 0.110 G_B: 0.523 cycle_B: 1.908 idt_B: 0.201 \n",
            "End of epoch 99 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 100, time: 1.228, data: 0.173) D_A: 0.183 G_A: 0.323 cycle_A: 0.999 idt_A: 0.452 D_B: 0.146 G_B: 0.566 cycle_B: 1.425 idt_B: 0.153 \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 200 \t Time Taken: 33 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.312, data: 0.185) D_A: 0.358 G_A: 0.084 cycle_A: 0.349 idt_A: 0.715 D_B: 0.100 G_B: 0.529 cycle_B: 1.864 idt_B: 0.127 \n",
            "End of epoch 101 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 100, time: 0.320, data: 0.176) D_A: 0.060 G_A: 0.245 cycle_A: 0.457 idt_A: 0.378 D_B: 0.180 G_B: 0.514 cycle_B: 1.091 idt_B: 0.219 \n",
            "End of epoch 102 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 100, time: 0.315, data: 0.179) D_A: 0.215 G_A: 0.308 cycle_A: 0.579 idt_A: 0.781 D_B: 0.170 G_B: 0.347 cycle_B: 2.001 idt_B: 0.242 \n",
            "End of epoch 103 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 100, time: 1.156, data: 0.176) D_A: 0.130 G_A: 0.592 cycle_A: 0.408 idt_A: 0.498 D_B: 0.258 G_B: 0.661 cycle_B: 1.447 idt_B: 0.135 \n",
            "End of epoch 104 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 100, time: 0.316, data: 0.214) D_A: 0.081 G_A: 0.507 cycle_A: 0.604 idt_A: 0.809 D_B: 0.096 G_B: 0.734 cycle_B: 1.830 idt_B: 0.247 \n",
            "saving the model at the end of epoch 105, iters 10500\n",
            "End of epoch 105 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 100, time: 0.333, data: 0.185) D_A: 0.197 G_A: 0.364 cycle_A: 0.377 idt_A: 0.502 D_B: 0.137 G_B: 0.435 cycle_B: 1.713 idt_B: 0.118 \n",
            "End of epoch 106 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 100, time: 0.312, data: 0.176) D_A: 0.081 G_A: 0.205 cycle_A: 0.421 idt_A: 0.555 D_B: 0.093 G_B: 0.714 cycle_B: 0.997 idt_B: 0.147 \n",
            "End of epoch 107 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 100, time: 1.168, data: 0.180) D_A: 0.138 G_A: 0.181 cycle_A: 0.409 idt_A: 0.403 D_B: 0.299 G_B: 0.361 cycle_B: 0.981 idt_B: 0.162 \n",
            "End of epoch 108 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 100, time: 0.317, data: 0.200) D_A: 0.175 G_A: 0.599 cycle_A: 0.543 idt_A: 0.448 D_B: 0.250 G_B: 0.337 cycle_B: 1.348 idt_B: 0.240 \n",
            "End of epoch 109 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.334, data: 0.184) D_A: 0.158 G_A: 0.265 cycle_A: 0.342 idt_A: 0.310 D_B: 0.045 G_B: 0.569 cycle_B: 1.245 idt_B: 0.138 \n",
            "saving the model at the end of epoch 110, iters 11000\n",
            "End of epoch 110 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 100, time: 0.310, data: 0.185) D_A: 0.265 G_A: 0.224 cycle_A: 0.450 idt_A: 0.413 D_B: 0.087 G_B: 0.992 cycle_B: 1.161 idt_B: 0.161 \n",
            "End of epoch 111 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 100, time: 1.303, data: 0.186) D_A: 0.176 G_A: 0.558 cycle_A: 0.291 idt_A: 0.420 D_B: 0.097 G_B: 0.640 cycle_B: 1.674 idt_B: 0.080 \n",
            "End of epoch 112 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 100, time: 0.328, data: 0.181) D_A: 0.071 G_A: 0.202 cycle_A: 0.292 idt_A: 0.449 D_B: 0.182 G_B: 0.667 cycle_B: 1.301 idt_B: 0.088 \n",
            "End of epoch 113 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 100, time: 0.313, data: 0.192) D_A: 0.066 G_A: 0.409 cycle_A: 0.389 idt_A: 0.430 D_B: 0.088 G_B: 0.701 cycle_B: 1.490 idt_B: 0.152 \n",
            "End of epoch 114 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 100, time: 0.323, data: 0.206) D_A: 0.101 G_A: 0.438 cycle_A: 0.434 idt_A: 0.451 D_B: 0.141 G_B: 0.565 cycle_B: 1.535 idt_B: 0.144 \n",
            "saving the model at the end of epoch 115, iters 11500\n",
            "End of epoch 115 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 100, time: 1.198, data: 0.187) D_A: 0.164 G_A: 0.751 cycle_A: 0.458 idt_A: 0.466 D_B: 0.082 G_B: 0.171 cycle_B: 1.413 idt_B: 0.162 \n",
            "End of epoch 116 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 100, time: 0.325, data: 0.207) D_A: 0.142 G_A: 1.579 cycle_A: 0.324 idt_A: 0.467 D_B: 0.202 G_B: 0.169 cycle_B: 1.367 idt_B: 0.105 \n",
            "End of epoch 117 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 100, time: 0.309, data: 0.210) D_A: 0.110 G_A: 0.229 cycle_A: 0.707 idt_A: 0.403 D_B: 0.294 G_B: 0.181 cycle_B: 0.921 idt_B: 0.256 \n",
            "End of epoch 118 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 100, time: 0.312, data: 0.177) D_A: 0.183 G_A: 0.698 cycle_A: 0.391 idt_A: 0.365 D_B: 0.065 G_B: 0.407 cycle_B: 0.986 idt_B: 0.140 \n",
            "End of epoch 119 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 100, time: 1.190, data: 0.176) D_A: 0.134 G_A: 0.649 cycle_A: 0.420 idt_A: 0.567 D_B: 0.127 G_B: 0.358 cycle_B: 0.749 idt_B: 0.207 \n",
            "saving the model at the end of epoch 120, iters 12000\n",
            "End of epoch 120 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 100, time: 0.324, data: 0.177) D_A: 0.070 G_A: 0.588 cycle_A: 0.396 idt_A: 0.422 D_B: 0.320 G_B: 1.067 cycle_B: 1.331 idt_B: 0.187 \n",
            "End of epoch 121 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 100, time: 0.303, data: 0.187) D_A: 0.080 G_A: 0.565 cycle_A: 0.416 idt_A: 0.453 D_B: 0.204 G_B: 0.192 cycle_B: 1.463 idt_B: 0.151 \n",
            "End of epoch 122 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 100, time: 0.308, data: 0.189) D_A: 0.064 G_A: 0.615 cycle_A: 0.434 idt_A: 0.575 D_B: 0.116 G_B: 0.972 cycle_B: 1.398 idt_B: 0.146 \n",
            "End of epoch 123 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 100, time: 1.220, data: 0.184) D_A: 0.153 G_A: 0.404 cycle_A: 0.287 idt_A: 0.392 D_B: 0.040 G_B: 0.479 cycle_B: 1.139 idt_B: 0.086 \n",
            "End of epoch 124 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 100, time: 0.329, data: 0.190) D_A: 0.066 G_A: 0.401 cycle_A: 0.274 idt_A: 0.641 D_B: 0.068 G_B: 0.133 cycle_B: 1.914 idt_B: 0.110 \n",
            "saving the model at the end of epoch 125, iters 12500\n",
            "End of epoch 125 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 100, time: 0.311, data: 0.195) D_A: 0.364 G_A: 0.109 cycle_A: 0.517 idt_A: 0.432 D_B: 0.162 G_B: 0.571 cycle_B: 1.091 idt_B: 0.137 \n",
            "End of epoch 126 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 100, time: 0.292, data: 0.180) D_A: 0.171 G_A: 0.329 cycle_A: 0.317 idt_A: 0.393 D_B: 0.081 G_B: 0.471 cycle_B: 1.106 idt_B: 0.099 \n",
            "End of epoch 127 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 100, time: 1.398, data: 0.193) D_A: 0.264 G_A: 0.520 cycle_A: 0.384 idt_A: 0.412 D_B: 0.243 G_B: 0.332 cycle_B: 1.047 idt_B: 0.176 \n",
            "End of epoch 128 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 100, time: 0.307, data: 0.178) D_A: 0.077 G_A: 0.548 cycle_A: 0.285 idt_A: 0.633 D_B: 0.065 G_B: 0.093 cycle_B: 1.740 idt_B: 0.085 \n",
            "End of epoch 129 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 100, time: 0.313, data: 0.175) D_A: 0.262 G_A: 0.168 cycle_A: 0.266 idt_A: 0.359 D_B: 0.152 G_B: 0.342 cycle_B: 1.284 idt_B: 0.108 \n",
            "saving the model at the end of epoch 130, iters 13000\n",
            "End of epoch 130 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 100, time: 0.310, data: 0.187) D_A: 0.145 G_A: 0.598 cycle_A: 0.440 idt_A: 0.344 D_B: 0.168 G_B: 0.730 cycle_B: 1.110 idt_B: 0.179 \n",
            "End of epoch 131 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 100, time: 1.246, data: 0.187) D_A: 0.126 G_A: 0.621 cycle_A: 0.325 idt_A: 0.381 D_B: 0.068 G_B: 0.557 cycle_B: 1.066 idt_B: 0.147 \n",
            "End of epoch 132 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 100, time: 0.307, data: 0.171) D_A: 0.147 G_A: 0.322 cycle_A: 0.376 idt_A: 0.421 D_B: 0.196 G_B: 0.261 cycle_B: 1.192 idt_B: 0.133 \n",
            "End of epoch 133 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 100, time: 0.300, data: 0.180) D_A: 0.051 G_A: 0.218 cycle_A: 0.423 idt_A: 0.285 D_B: 0.152 G_B: 0.127 cycle_B: 0.798 idt_B: 0.144 \n",
            "End of epoch 134 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 100, time: 0.309, data: 0.193) D_A: 0.109 G_A: 0.643 cycle_A: 0.327 idt_A: 0.416 D_B: 0.245 G_B: 0.313 cycle_B: 1.219 idt_B: 0.096 \n",
            "saving the model at the end of epoch 135, iters 13500\n",
            "End of epoch 135 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 100, time: 1.393, data: 0.180) D_A: 0.266 G_A: 1.161 cycle_A: 0.256 idt_A: 0.442 D_B: 0.113 G_B: 0.512 cycle_B: 1.383 idt_B: 0.090 \n",
            "End of epoch 136 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 100, time: 0.322, data: 0.174) D_A: 0.204 G_A: 0.617 cycle_A: 0.265 idt_A: 0.313 D_B: 0.141 G_B: 0.612 cycle_B: 1.206 idt_B: 0.104 \n",
            "End of epoch 137 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 100, time: 0.329, data: 0.181) D_A: 0.109 G_A: 0.246 cycle_A: 0.231 idt_A: 0.420 D_B: 0.135 G_B: 0.487 cycle_B: 1.276 idt_B: 0.092 \n",
            "End of epoch 138 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 100, time: 0.318, data: 0.196) D_A: 0.162 G_A: 0.292 cycle_A: 0.329 idt_A: 0.233 D_B: 0.207 G_B: 0.267 cycle_B: 1.232 idt_B: 0.094 \n",
            "End of epoch 139 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 100, time: 1.291, data: 0.182) D_A: 0.142 G_A: 0.430 cycle_A: 0.308 idt_A: 0.262 D_B: 0.168 G_B: 0.536 cycle_B: 0.733 idt_B: 0.126 \n",
            "saving the model at the end of epoch 140, iters 14000\n",
            "End of epoch 140 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 0.311, data: 0.200) D_A: 0.044 G_A: 0.624 cycle_A: 0.452 idt_A: 0.308 D_B: 0.090 G_B: 1.463 cycle_B: 1.081 idt_B: 0.185 \n",
            "End of epoch 141 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 100, time: 0.296, data: 0.182) D_A: 0.053 G_A: 0.796 cycle_A: 0.314 idt_A: 0.236 D_B: 0.125 G_B: 0.397 cycle_B: 1.204 idt_B: 0.101 \n",
            "End of epoch 142 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 100, time: 0.317, data: 0.182) D_A: 0.047 G_A: 0.344 cycle_A: 0.738 idt_A: 0.409 D_B: 0.116 G_B: 0.415 cycle_B: 1.141 idt_B: 0.144 \n",
            "End of epoch 143 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 100, time: 1.549, data: 0.184) D_A: 0.445 G_A: 0.037 cycle_A: 0.313 idt_A: 0.308 D_B: 0.358 G_B: 1.363 cycle_B: 1.024 idt_B: 0.121 \n",
            "End of epoch 144 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 100, time: 0.310, data: 0.183) D_A: 0.081 G_A: 0.453 cycle_A: 0.337 idt_A: 0.583 D_B: 0.063 G_B: 0.849 cycle_B: 1.589 idt_B: 0.112 \n",
            "saving the model at the end of epoch 145, iters 14500\n",
            "End of epoch 145 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 100, time: 0.311, data: 0.181) D_A: 0.308 G_A: 0.767 cycle_A: 0.379 idt_A: 0.426 D_B: 0.087 G_B: 0.527 cycle_B: 1.130 idt_B: 0.110 \n",
            "End of epoch 146 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 100, time: 0.309, data: 0.197) D_A: 0.101 G_A: 0.567 cycle_A: 0.287 idt_A: 0.439 D_B: 0.090 G_B: 0.537 cycle_B: 1.277 idt_B: 0.098 \n",
            "End of epoch 147 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 100, time: 1.409, data: 0.186) D_A: 0.102 G_A: 0.321 cycle_A: 0.248 idt_A: 0.403 D_B: 0.092 G_B: 0.733 cycle_B: 1.328 idt_B: 0.087 \n",
            "End of epoch 148 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 100, time: 0.334, data: 0.186) D_A: 0.172 G_A: 0.397 cycle_A: 0.407 idt_A: 0.366 D_B: 0.208 G_B: 0.460 cycle_B: 1.247 idt_B: 0.135 \n",
            "End of epoch 149 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 100, time: 0.310, data: 0.173) D_A: 0.082 G_A: 0.814 cycle_A: 0.545 idt_A: 0.365 D_B: 0.179 G_B: 0.276 cycle_B: 1.286 idt_B: 0.184 \n",
            "saving the latest model (epoch 150, total_iters 15000)\n",
            "saving the model at the end of epoch 150, iters 15000\n",
            "End of epoch 150 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 100, time: 0.322, data: 0.196) D_A: 0.103 G_A: 0.482 cycle_A: 0.221 idt_A: 0.269 D_B: 0.088 G_B: 0.613 cycle_B: 0.955 idt_B: 0.056 \n",
            "End of epoch 151 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 100, time: 1.430, data: 0.200) D_A: 0.073 G_A: 0.419 cycle_A: 0.287 idt_A: 0.332 D_B: 0.105 G_B: 0.678 cycle_B: 1.037 idt_B: 0.088 \n",
            "End of epoch 152 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 100, time: 0.308, data: 0.195) D_A: 0.181 G_A: 0.243 cycle_A: 0.241 idt_A: 0.323 D_B: 0.090 G_B: 0.234 cycle_B: 0.875 idt_B: 0.078 \n",
            "End of epoch 153 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 100, time: 0.294, data: 0.195) D_A: 0.086 G_A: 0.442 cycle_A: 0.234 idt_A: 0.258 D_B: 0.114 G_B: 0.458 cycle_B: 0.755 idt_B: 0.065 \n",
            "End of epoch 154 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 100, time: 0.311, data: 0.190) D_A: 0.057 G_A: 0.593 cycle_A: 0.347 idt_A: 0.319 D_B: 0.122 G_B: 0.466 cycle_B: 0.942 idt_B: 0.121 \n",
            "saving the model at the end of epoch 155, iters 15500\n",
            "End of epoch 155 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 100, time: 1.436, data: 0.198) D_A: 0.303 G_A: 0.474 cycle_A: 0.386 idt_A: 0.357 D_B: 0.091 G_B: 0.478 cycle_B: 1.196 idt_B: 0.125 \n",
            "End of epoch 156 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 100, time: 0.302, data: 0.192) D_A: 0.126 G_A: 0.516 cycle_A: 0.243 idt_A: 0.366 D_B: 0.119 G_B: 0.647 cycle_B: 1.012 idt_B: 0.083 \n",
            "End of epoch 157 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 100, time: 0.309, data: 0.202) D_A: 0.235 G_A: 0.320 cycle_A: 0.255 idt_A: 0.594 D_B: 0.037 G_B: 0.560 cycle_B: 1.793 idt_B: 0.085 \n",
            "End of epoch 158 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 100, time: 0.312, data: 0.178) D_A: 0.062 G_A: 0.772 cycle_A: 0.441 idt_A: 0.305 D_B: 0.066 G_B: 0.369 cycle_B: 1.032 idt_B: 0.146 \n",
            "End of epoch 159 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 1.457, data: 0.176) D_A: 0.150 G_A: 0.482 cycle_A: 0.306 idt_A: 0.302 D_B: 0.149 G_B: 0.557 cycle_B: 1.128 idt_B: 0.094 \n",
            "saving the model at the end of epoch 160, iters 16000\n",
            "End of epoch 160 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 100, time: 0.308, data: 0.193) D_A: 0.173 G_A: 0.230 cycle_A: 0.385 idt_A: 0.269 D_B: 0.123 G_B: 0.337 cycle_B: 0.828 idt_B: 0.136 \n",
            "End of epoch 161 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 100, time: 0.308, data: 0.183) D_A: 0.174 G_A: 0.328 cycle_A: 0.434 idt_A: 0.270 D_B: 0.362 G_B: 0.211 cycle_B: 0.887 idt_B: 0.186 \n",
            "End of epoch 162 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 100, time: 0.294, data: 0.188) D_A: 0.221 G_A: 1.177 cycle_A: 0.414 idt_A: 0.371 D_B: 0.105 G_B: 0.485 cycle_B: 1.240 idt_B: 0.077 \n",
            "End of epoch 163 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 100, time: 1.446, data: 0.184) D_A: 0.125 G_A: 0.999 cycle_A: 0.249 idt_A: 0.225 D_B: 0.159 G_B: 0.264 cycle_B: 0.805 idt_B: 0.084 \n",
            "End of epoch 164 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 100, time: 0.330, data: 0.208) D_A: 0.025 G_A: 0.556 cycle_A: 0.215 idt_A: 0.331 D_B: 0.209 G_B: 0.411 cycle_B: 1.086 idt_B: 0.069 \n",
            "saving the model at the end of epoch 165, iters 16500\n",
            "End of epoch 165 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 0.313, data: 0.197) D_A: 0.147 G_A: 0.301 cycle_A: 0.366 idt_A: 0.197 D_B: 0.236 G_B: 0.527 cycle_B: 0.725 idt_B: 0.131 \n",
            "End of epoch 166 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 100, time: 0.313, data: 0.182) D_A: 0.132 G_A: 0.800 cycle_A: 0.290 idt_A: 0.570 D_B: 0.081 G_B: 0.723 cycle_B: 1.457 idt_B: 0.080 \n",
            "End of epoch 167 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 100, time: 1.613, data: 0.188) D_A: 0.134 G_A: 0.308 cycle_A: 0.280 idt_A: 0.332 D_B: 0.111 G_B: 0.418 cycle_B: 1.185 idt_B: 0.089 \n",
            "End of epoch 168 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 100, time: 0.333, data: 0.188) D_A: 0.090 G_A: 0.390 cycle_A: 0.355 idt_A: 0.587 D_B: 0.092 G_B: 0.466 cycle_B: 1.772 idt_B: 0.113 \n",
            "End of epoch 169 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 100, time: 0.311, data: 0.207) D_A: 0.030 G_A: 0.254 cycle_A: 0.340 idt_A: 0.245 D_B: 0.046 G_B: 0.428 cycle_B: 1.085 idt_B: 0.072 \n",
            "saving the model at the end of epoch 170, iters 17000\n",
            "End of epoch 170 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 100, time: 0.314, data: 0.178) D_A: 0.087 G_A: 0.558 cycle_A: 0.209 idt_A: 0.318 D_B: 0.197 G_B: 0.359 cycle_B: 1.016 idt_B: 0.074 \n",
            "End of epoch 171 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 100, time: 1.628, data: 0.180) D_A: 0.160 G_A: 0.316 cycle_A: 0.362 idt_A: 0.398 D_B: 0.136 G_B: 0.805 cycle_B: 1.263 idt_B: 0.145 \n",
            "End of epoch 172 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 100, time: 0.316, data: 0.187) D_A: 0.107 G_A: 0.943 cycle_A: 0.341 idt_A: 0.396 D_B: 0.138 G_B: 0.491 cycle_B: 1.336 idt_B: 0.170 \n",
            "End of epoch 173 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 100, time: 0.324, data: 0.210) D_A: 0.201 G_A: 0.642 cycle_A: 0.219 idt_A: 0.338 D_B: 0.093 G_B: 0.814 cycle_B: 0.944 idt_B: 0.093 \n",
            "End of epoch 174 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 100, time: 0.313, data: 0.186) D_A: 0.115 G_A: 0.847 cycle_A: 0.314 idt_A: 0.361 D_B: 0.165 G_B: 0.317 cycle_B: 0.913 idt_B: 0.108 \n",
            "saving the model at the end of epoch 175, iters 17500\n",
            "End of epoch 175 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 100, time: 1.908, data: 0.184) D_A: 0.244 G_A: 0.167 cycle_A: 0.357 idt_A: 0.360 D_B: 0.046 G_B: 0.617 cycle_B: 1.187 idt_B: 0.158 \n",
            "End of epoch 176 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 100, time: 0.317, data: 0.178) D_A: 0.050 G_A: 0.483 cycle_A: 0.385 idt_A: 0.326 D_B: 0.368 G_B: 0.704 cycle_B: 1.212 idt_B: 0.140 \n",
            "End of epoch 177 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 100, time: 0.333, data: 0.187) D_A: 0.054 G_A: 0.299 cycle_A: 0.360 idt_A: 0.265 D_B: 0.257 G_B: 0.266 cycle_B: 0.762 idt_B: 0.142 \n",
            "End of epoch 178 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 100, time: 0.308, data: 0.209) D_A: 0.244 G_A: 0.176 cycle_A: 0.303 idt_A: 0.389 D_B: 0.051 G_B: 0.526 cycle_B: 1.147 idt_B: 0.077 \n",
            "End of epoch 179 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 100, time: 1.530, data: 0.180) D_A: 0.104 G_A: 0.224 cycle_A: 0.240 idt_A: 0.416 D_B: 0.176 G_B: 0.554 cycle_B: 1.296 idt_B: 0.069 \n",
            "saving the model at the end of epoch 180, iters 18000\n",
            "End of epoch 180 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 100, time: 0.309, data: 0.195) D_A: 0.254 G_A: 0.649 cycle_A: 0.311 idt_A: 0.321 D_B: 0.173 G_B: 0.357 cycle_B: 0.978 idt_B: 0.096 \n",
            "End of epoch 181 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 100, time: 0.310, data: 0.191) D_A: 0.133 G_A: 0.547 cycle_A: 0.393 idt_A: 0.246 D_B: 0.051 G_B: 0.607 cycle_B: 0.848 idt_B: 0.132 \n",
            "End of epoch 182 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 100, time: 0.314, data: 0.192) D_A: 0.145 G_A: 0.366 cycle_A: 0.340 idt_A: 0.302 D_B: 0.130 G_B: 0.321 cycle_B: 0.722 idt_B: 0.126 \n",
            "End of epoch 183 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 100, time: 1.535, data: 0.188) D_A: 0.115 G_A: 0.323 cycle_A: 0.232 idt_A: 0.215 D_B: 0.167 G_B: 0.394 cycle_B: 1.083 idt_B: 0.072 \n",
            "End of epoch 184 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 100, time: 0.317, data: 0.185) D_A: 0.108 G_A: 0.300 cycle_A: 0.343 idt_A: 0.386 D_B: 0.114 G_B: 0.651 cycle_B: 1.112 idt_B: 0.117 \n",
            "saving the model at the end of epoch 185, iters 18500\n",
            "End of epoch 185 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 100, time: 0.311, data: 0.181) D_A: 0.149 G_A: 0.354 cycle_A: 0.378 idt_A: 0.304 D_B: 0.212 G_B: 0.722 cycle_B: 0.938 idt_B: 0.116 \n",
            "End of epoch 186 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 100, time: 0.308, data: 0.219) D_A: 0.124 G_A: 0.545 cycle_A: 0.296 idt_A: 0.203 D_B: 0.047 G_B: 0.969 cycle_B: 0.622 idt_B: 0.127 \n",
            "End of epoch 187 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 100, time: 1.660, data: 0.172) D_A: 0.278 G_A: 0.690 cycle_A: 0.264 idt_A: 0.275 D_B: 0.093 G_B: 0.572 cycle_B: 0.876 idt_B: 0.077 \n",
            "End of epoch 188 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 100, time: 0.316, data: 0.189) D_A: 0.155 G_A: 0.343 cycle_A: 0.221 idt_A: 0.356 D_B: 0.128 G_B: 0.726 cycle_B: 1.096 idt_B: 0.065 \n",
            "End of epoch 189 / 200 \t Time Taken: 30 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 100, time: 0.315, data: 0.201) D_A: 0.141 G_A: 0.491 cycle_A: 0.291 idt_A: 0.454 D_B: 0.162 G_B: 0.383 cycle_B: 1.226 idt_B: 0.083 \n",
            "saving the model at the end of epoch 190, iters 19000\n",
            "End of epoch 190 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 0.315, data: 0.251) D_A: 0.059 G_A: 0.579 cycle_A: 0.187 idt_A: 0.201 D_B: 0.078 G_B: 0.290 cycle_B: 0.658 idt_B: 0.068 \n",
            "End of epoch 191 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 100, time: 1.710, data: 0.208) D_A: 0.037 G_A: 0.497 cycle_A: 0.308 idt_A: 0.311 D_B: 0.178 G_B: 0.633 cycle_B: 1.035 idt_B: 0.109 \n",
            "End of epoch 192 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 100, time: 0.321, data: 0.191) D_A: 0.034 G_A: 0.344 cycle_A: 0.225 idt_A: 0.373 D_B: 0.073 G_B: 0.509 cycle_B: 1.154 idt_B: 0.070 \n",
            "End of epoch 193 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 100, time: 0.310, data: 0.209) D_A: 0.191 G_A: 0.332 cycle_A: 0.361 idt_A: 0.302 D_B: 0.163 G_B: 0.575 cycle_B: 0.896 idt_B: 0.130 \n",
            "End of epoch 194 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 100, time: 0.315, data: 0.213) D_A: 0.134 G_A: 0.446 cycle_A: 0.168 idt_A: 0.378 D_B: 0.085 G_B: 0.387 cycle_B: 1.191 idt_B: 0.056 \n",
            "saving the model at the end of epoch 195, iters 19500\n",
            "End of epoch 195 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 100, time: 1.735, data: 0.188) D_A: 0.148 G_A: 0.435 cycle_A: 0.256 idt_A: 0.379 D_B: 0.127 G_B: 0.703 cycle_B: 1.193 idt_B: 0.064 \n",
            "End of epoch 196 / 200 \t Time Taken: 32 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 100, time: 0.307, data: 0.208) D_A: 0.126 G_A: 0.392 cycle_A: 0.219 idt_A: 0.258 D_B: 0.160 G_B: 0.327 cycle_B: 0.777 idt_B: 0.070 \n",
            "End of epoch 197 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 100, time: 0.334, data: 0.201) D_A: 0.075 G_A: 0.495 cycle_A: 0.244 idt_A: 0.336 D_B: 0.092 G_B: 0.402 cycle_B: 1.161 idt_B: 0.077 \n",
            "End of epoch 198 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 100, time: 0.312, data: 0.224) D_A: 0.049 G_A: 0.687 cycle_A: 0.327 idt_A: 0.176 D_B: 0.077 G_B: 0.600 cycle_B: 0.624 idt_B: 0.131 \n",
            "End of epoch 199 / 200 \t Time Taken: 31 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 100, time: 1.703, data: 0.197) D_A: 0.060 G_A: 0.379 cycle_A: 0.214 idt_A: 0.261 D_B: 0.150 G_B: 0.762 cycle_B: 0.882 idt_B: 0.064 \n",
            "saving the latest model (epoch 200, total_iters 20000)\n",
            "saving the model at the end of epoch 200, iters 20000\n",
            "End of epoch 200 / 200 \t Time Taken: 34 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2500, 0.2501, 0.2501, 0.2498],\n",
            "        [0.2496, 0.2505, 0.2504, 0.2495],\n",
            "        [0.2494, 0.2506, 0.2506, 0.2493],\n",
            "        [0.2503, 0.2501, 0.2500, 0.2496],\n",
            "        [0.2503, 0.2501, 0.2501, 0.2495]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2500, 0.2502, 0.2501, 0.2497],\n",
            "        [0.2506, 0.2501, 0.2498, 0.2495],\n",
            "        [0.2501, 0.2503, 0.2501, 0.2495],\n",
            "        [0.2506, 0.2501, 0.2499, 0.2494],\n",
            "        [0.2512, 0.2498, 0.2496, 0.2493]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2496, 0.2504, 0.2502, 0.2498],\n",
            "        [0.2496, 0.2505, 0.2502, 0.2496],\n",
            "        [0.2494, 0.2506, 0.2504, 0.2497],\n",
            "        [0.2500, 0.2505, 0.2501, 0.2494],\n",
            "        [0.2511, 0.2498, 0.2496, 0.2494]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2498, 0.2505, 0.2502, 0.2495],\n",
            "        [0.2498, 0.2507, 0.2504, 0.2491],\n",
            "        [0.2496, 0.2509, 0.2505, 0.2490],\n",
            "        [0.2506, 0.2503, 0.2499, 0.2492],\n",
            "        [0.2515, 0.2497, 0.2494, 0.2493]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2499, 0.2504, 0.2501, 0.2496],\n",
            "        [0.2499, 0.2506, 0.2502, 0.2493],\n",
            "        [0.2498, 0.2508, 0.2504, 0.2490],\n",
            "        [0.2506, 0.2505, 0.2500, 0.2489],\n",
            "        [0.2518, 0.2497, 0.2494, 0.2492]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2497, 0.2505, 0.2502, 0.2497],\n",
            "        [0.2488, 0.2512, 0.2507, 0.2493],\n",
            "        [0.2493, 0.2512, 0.2506, 0.2489],\n",
            "        [0.2502, 0.2509, 0.2502, 0.2488],\n",
            "        [0.2519, 0.2497, 0.2493, 0.2491]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2497, 0.2507, 0.2503, 0.2493],\n",
            "        [0.2491, 0.2513, 0.2506, 0.2490],\n",
            "        [0.2494, 0.2512, 0.2505, 0.2489],\n",
            "        [0.2501, 0.2510, 0.2502, 0.2486],\n",
            "        [0.2525, 0.2496, 0.2490, 0.2489]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2497, 0.2507, 0.2503, 0.2493],\n",
            "        [0.2487, 0.2517, 0.2509, 0.2487],\n",
            "        [0.2496, 0.2513, 0.2504, 0.2488],\n",
            "        [0.2506, 0.2509, 0.2499, 0.2487],\n",
            "        [0.2527, 0.2497, 0.2490, 0.2486]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2494, 0.2509, 0.2504, 0.2494],\n",
            "        [0.2484, 0.2518, 0.2509, 0.2488],\n",
            "        [0.2495, 0.2514, 0.2505, 0.2485],\n",
            "        [0.2507, 0.2508, 0.2498, 0.2487],\n",
            "        [0.2529, 0.2495, 0.2488, 0.2487]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2492, 0.2510, 0.2505, 0.2492],\n",
            "        [0.2485, 0.2520, 0.2512, 0.2483],\n",
            "        [0.2497, 0.2515, 0.2506, 0.2482],\n",
            "        [0.2506, 0.2511, 0.2500, 0.2484],\n",
            "        [0.2533, 0.2495, 0.2488, 0.2484]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2485, 0.2514, 0.2508, 0.2493],\n",
            "        [0.2474, 0.2526, 0.2516, 0.2485],\n",
            "        [0.2496, 0.2516, 0.2506, 0.2482],\n",
            "        [0.2503, 0.2514, 0.2502, 0.2481],\n",
            "        [0.2532, 0.2495, 0.2487, 0.2485]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2482, 0.2517, 0.2511, 0.2491],\n",
            "        [0.2470, 0.2530, 0.2520, 0.2481],\n",
            "        [0.2501, 0.2515, 0.2503, 0.2481],\n",
            "        [0.2506, 0.2516, 0.2502, 0.2476],\n",
            "        [0.2537, 0.2495, 0.2486, 0.2482]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2490, 0.2516, 0.2509, 0.2486],\n",
            "        [0.2485, 0.2523, 0.2511, 0.2481],\n",
            "        [0.2504, 0.2515, 0.2501, 0.2479],\n",
            "        [0.2512, 0.2515, 0.2499, 0.2473],\n",
            "        [0.2548, 0.2491, 0.2481, 0.2481]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2489, 0.2516, 0.2509, 0.2486],\n",
            "        [0.2478, 0.2528, 0.2515, 0.2479],\n",
            "        [0.2502, 0.2517, 0.2503, 0.2478],\n",
            "        [0.2507, 0.2519, 0.2502, 0.2471],\n",
            "        [0.2551, 0.2491, 0.2481, 0.2477]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2488, 0.2518, 0.2510, 0.2484],\n",
            "        [0.2480, 0.2528, 0.2515, 0.2477],\n",
            "        [0.2504, 0.2518, 0.2503, 0.2475],\n",
            "        [0.2512, 0.2517, 0.2500, 0.2471],\n",
            "        [0.2553, 0.2491, 0.2480, 0.2476]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2490, 0.2519, 0.2510, 0.2481],\n",
            "        [0.2481, 0.2529, 0.2514, 0.2476],\n",
            "        [0.2510, 0.2518, 0.2502, 0.2471],\n",
            "        [0.2516, 0.2518, 0.2499, 0.2466],\n",
            "        [0.2557, 0.2490, 0.2479, 0.2474]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2490, 0.2519, 0.2511, 0.2480],\n",
            "        [0.2476, 0.2533, 0.2517, 0.2474],\n",
            "        [0.2512, 0.2517, 0.2500, 0.2472],\n",
            "        [0.2515, 0.2520, 0.2499, 0.2466],\n",
            "        [0.2559, 0.2490, 0.2478, 0.2472]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2492, 0.2520, 0.2510, 0.2478],\n",
            "        [0.2474, 0.2535, 0.2519, 0.2471],\n",
            "        [0.2516, 0.2516, 0.2497, 0.2471],\n",
            "        [0.2516, 0.2521, 0.2499, 0.2464],\n",
            "        [0.2563, 0.2489, 0.2477, 0.2470]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2490, 0.2520, 0.2510, 0.2480],\n",
            "        [0.2475, 0.2536, 0.2519, 0.2471],\n",
            "        [0.2510, 0.2521, 0.2501, 0.2468],\n",
            "        [0.2517, 0.2523, 0.2500, 0.2461],\n",
            "        [0.2567, 0.2489, 0.2476, 0.2468]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2489, 0.2522, 0.2512, 0.2477],\n",
            "        [0.2474, 0.2538, 0.2520, 0.2468],\n",
            "        [0.2516, 0.2519, 0.2498, 0.2467],\n",
            "        [0.2517, 0.2524, 0.2500, 0.2459],\n",
            "        [0.2568, 0.2490, 0.2477, 0.2465]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2493, 0.2522, 0.2511, 0.2474],\n",
            "        [0.2479, 0.2537, 0.2518, 0.2465],\n",
            "        [0.2521, 0.2518, 0.2497, 0.2463],\n",
            "        [0.2520, 0.2525, 0.2499, 0.2456],\n",
            "        [0.2574, 0.2489, 0.2475, 0.2462]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2492, 0.2523, 0.2511, 0.2474],\n",
            "        [0.2470, 0.2543, 0.2523, 0.2464],\n",
            "        [0.2520, 0.2521, 0.2498, 0.2461],\n",
            "        [0.2524, 0.2522, 0.2497, 0.2457],\n",
            "        [0.2572, 0.2491, 0.2477, 0.2460]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2492, 0.2525, 0.2513, 0.2469],\n",
            "        [0.2479, 0.2539, 0.2518, 0.2463],\n",
            "        [0.2520, 0.2523, 0.2499, 0.2457],\n",
            "        [0.2529, 0.2522, 0.2495, 0.2455],\n",
            "        [0.2576, 0.2490, 0.2476, 0.2458]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2495, 0.2525, 0.2513, 0.2468],\n",
            "        [0.2477, 0.2543, 0.2520, 0.2460],\n",
            "        [0.2526, 0.2522, 0.2497, 0.2455],\n",
            "        [0.2534, 0.2522, 0.2493, 0.2451],\n",
            "        [0.2584, 0.2488, 0.2473, 0.2456]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2496, 0.2525, 0.2512, 0.2467],\n",
            "        [0.2471, 0.2547, 0.2523, 0.2459],\n",
            "        [0.2527, 0.2522, 0.2496, 0.2455],\n",
            "        [0.2536, 0.2524, 0.2494, 0.2446],\n",
            "        [0.2588, 0.2488, 0.2472, 0.2451]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2501, 0.2526, 0.2512, 0.2461],\n",
            "        [0.2476, 0.2546, 0.2520, 0.2458],\n",
            "        [0.2530, 0.2524, 0.2495, 0.2450],\n",
            "        [0.2540, 0.2524, 0.2492, 0.2445],\n",
            "        [0.2594, 0.2488, 0.2471, 0.2446]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2501, 0.2528, 0.2513, 0.2458],\n",
            "        [0.2481, 0.2545, 0.2518, 0.2455],\n",
            "        [0.2535, 0.2525, 0.2495, 0.2444],\n",
            "        [0.2549, 0.2522, 0.2488, 0.2441],\n",
            "        [0.2601, 0.2485, 0.2468, 0.2446]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2502, 0.2529, 0.2514, 0.2455],\n",
            "        [0.2476, 0.2551, 0.2522, 0.2451],\n",
            "        [0.2538, 0.2528, 0.2496, 0.2438],\n",
            "        [0.2554, 0.2522, 0.2486, 0.2438],\n",
            "        [0.2606, 0.2485, 0.2467, 0.2442]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2503, 0.2531, 0.2514, 0.2452],\n",
            "        [0.2478, 0.2552, 0.2521, 0.2449],\n",
            "        [0.2539, 0.2528, 0.2495, 0.2438],\n",
            "        [0.2557, 0.2522, 0.2485, 0.2436],\n",
            "        [0.2608, 0.2486, 0.2467, 0.2439]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2503, 0.2533, 0.2516, 0.2449],\n",
            "        [0.2474, 0.2556, 0.2525, 0.2445],\n",
            "        [0.2547, 0.2524, 0.2491, 0.2437],\n",
            "        [0.2559, 0.2522, 0.2484, 0.2436],\n",
            "        [0.2615, 0.2483, 0.2464, 0.2438]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2501, 0.2534, 0.2517, 0.2448],\n",
            "        [0.2463, 0.2561, 0.2529, 0.2448],\n",
            "        [0.2544, 0.2526, 0.2492, 0.2438],\n",
            "        [0.2551, 0.2528, 0.2488, 0.2433],\n",
            "        [0.2615, 0.2485, 0.2465, 0.2436]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2503, 0.2536, 0.2517, 0.2444],\n",
            "        [0.2468, 0.2559, 0.2526, 0.2447],\n",
            "        [0.2543, 0.2528, 0.2491, 0.2438],\n",
            "        [0.2554, 0.2528, 0.2486, 0.2432],\n",
            "        [0.2618, 0.2485, 0.2464, 0.2432]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2505, 0.2536, 0.2517, 0.2442],\n",
            "        [0.2468, 0.2561, 0.2527, 0.2444],\n",
            "        [0.2547, 0.2527, 0.2490, 0.2435],\n",
            "        [0.2555, 0.2531, 0.2488, 0.2427],\n",
            "        [0.2624, 0.2483, 0.2462, 0.2430]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2506, 0.2538, 0.2518, 0.2438],\n",
            "        [0.2473, 0.2563, 0.2527, 0.2438],\n",
            "        [0.2548, 0.2530, 0.2492, 0.2430],\n",
            "        [0.2560, 0.2531, 0.2487, 0.2423],\n",
            "        [0.2628, 0.2484, 0.2462, 0.2426]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2504, 0.2540, 0.2520, 0.2436],\n",
            "        [0.2473, 0.2564, 0.2527, 0.2436],\n",
            "        [0.2546, 0.2534, 0.2494, 0.2426],\n",
            "        [0.2563, 0.2531, 0.2486, 0.2420],\n",
            "        [0.2634, 0.2482, 0.2460, 0.2423]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2505, 0.2539, 0.2519, 0.2437],\n",
            "        [0.2469, 0.2566, 0.2528, 0.2437],\n",
            "        [0.2544, 0.2534, 0.2494, 0.2428],\n",
            "        [0.2560, 0.2534, 0.2487, 0.2419],\n",
            "        [0.2637, 0.2482, 0.2459, 0.2422]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2502, 0.2542, 0.2521, 0.2436],\n",
            "        [0.2465, 0.2568, 0.2529, 0.2438],\n",
            "        [0.2542, 0.2536, 0.2494, 0.2428],\n",
            "        [0.2565, 0.2532, 0.2484, 0.2420],\n",
            "        [0.2641, 0.2480, 0.2457, 0.2421]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2503, 0.2544, 0.2523, 0.2430],\n",
            "        [0.2473, 0.2567, 0.2527, 0.2433],\n",
            "        [0.2541, 0.2540, 0.2496, 0.2422],\n",
            "        [0.2564, 0.2536, 0.2486, 0.2413],\n",
            "        [0.2647, 0.2479, 0.2456, 0.2418]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2503, 0.2546, 0.2523, 0.2428],\n",
            "        [0.2471, 0.2570, 0.2528, 0.2432],\n",
            "        [0.2549, 0.2537, 0.2491, 0.2423],\n",
            "        [0.2566, 0.2537, 0.2486, 0.2411],\n",
            "        [0.2648, 0.2481, 0.2457, 0.2413]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2506, 0.2545, 0.2522, 0.2426],\n",
            "        [0.2471, 0.2571, 0.2528, 0.2430],\n",
            "        [0.2548, 0.2540, 0.2495, 0.2417],\n",
            "        [0.2573, 0.2536, 0.2483, 0.2407],\n",
            "        [0.2653, 0.2480, 0.2456, 0.2410]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2506, 0.2547, 0.2523, 0.2424],\n",
            "        [0.2471, 0.2571, 0.2527, 0.2431],\n",
            "        [0.2550, 0.2542, 0.2496, 0.2412],\n",
            "        [0.2580, 0.2534, 0.2480, 0.2405],\n",
            "        [0.2656, 0.2480, 0.2455, 0.2409]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2506, 0.2547, 0.2523, 0.2423],\n",
            "        [0.2471, 0.2573, 0.2528, 0.2428],\n",
            "        [0.2559, 0.2538, 0.2490, 0.2413],\n",
            "        [0.2585, 0.2534, 0.2478, 0.2403],\n",
            "        [0.2664, 0.2478, 0.2452, 0.2406]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2506, 0.2549, 0.2524, 0.2421],\n",
            "        [0.2469, 0.2575, 0.2529, 0.2428],\n",
            "        [0.2556, 0.2541, 0.2492, 0.2412],\n",
            "        [0.2587, 0.2534, 0.2477, 0.2402],\n",
            "        [0.2663, 0.2480, 0.2454, 0.2403]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2504, 0.2552, 0.2526, 0.2418],\n",
            "        [0.2475, 0.2574, 0.2527, 0.2425],\n",
            "        [0.2558, 0.2541, 0.2491, 0.2410],\n",
            "        [0.2586, 0.2537, 0.2480, 0.2397],\n",
            "        [0.2667, 0.2480, 0.2453, 0.2400]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2508, 0.2551, 0.2525, 0.2416],\n",
            "        [0.2468, 0.2579, 0.2530, 0.2423],\n",
            "        [0.2565, 0.2537, 0.2487, 0.2410],\n",
            "        [0.2587, 0.2538, 0.2480, 0.2394],\n",
            "        [0.2672, 0.2479, 0.2451, 0.2398]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2506, 0.2554, 0.2527, 0.2413],\n",
            "        [0.2469, 0.2579, 0.2529, 0.2422],\n",
            "        [0.2564, 0.2540, 0.2489, 0.2407],\n",
            "        [0.2586, 0.2541, 0.2482, 0.2390],\n",
            "        [0.2674, 0.2480, 0.2453, 0.2394]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2506, 0.2557, 0.2529, 0.2408],\n",
            "        [0.2473, 0.2579, 0.2528, 0.2420],\n",
            "        [0.2567, 0.2541, 0.2487, 0.2405],\n",
            "        [0.2595, 0.2538, 0.2477, 0.2390],\n",
            "        [0.2679, 0.2480, 0.2451, 0.2390]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2504, 0.2558, 0.2530, 0.2408],\n",
            "        [0.2471, 0.2581, 0.2529, 0.2420],\n",
            "        [0.2564, 0.2544, 0.2490, 0.2403],\n",
            "        [0.2595, 0.2540, 0.2477, 0.2387],\n",
            "        [0.2683, 0.2477, 0.2448, 0.2392]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2503, 0.2560, 0.2532, 0.2404],\n",
            "        [0.2478, 0.2581, 0.2528, 0.2414],\n",
            "        [0.2566, 0.2545, 0.2491, 0.2398],\n",
            "        [0.2600, 0.2540, 0.2477, 0.2383],\n",
            "        [0.2688, 0.2478, 0.2448, 0.2386]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2504, 0.2562, 0.2534, 0.2400],\n",
            "        [0.2479, 0.2581, 0.2526, 0.2414],\n",
            "        [0.2573, 0.2543, 0.2487, 0.2396],\n",
            "        [0.2596, 0.2546, 0.2481, 0.2377],\n",
            "        [0.2695, 0.2476, 0.2447, 0.2382]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2504, 0.2562, 0.2532, 0.2402],\n",
            "        [0.2469, 0.2586, 0.2531, 0.2414],\n",
            "        [0.2568, 0.2547, 0.2491, 0.2395],\n",
            "        [0.2595, 0.2547, 0.2480, 0.2378],\n",
            "        [0.2694, 0.2477, 0.2447, 0.2382]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2504, 0.2562, 0.2533, 0.2401],\n",
            "        [0.2465, 0.2591, 0.2535, 0.2409],\n",
            "        [0.2573, 0.2545, 0.2488, 0.2394],\n",
            "        [0.2595, 0.2549, 0.2481, 0.2375],\n",
            "        [0.2701, 0.2475, 0.2445, 0.2379]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2513, 0.2561, 0.2530, 0.2396],\n",
            "        [0.2469, 0.2590, 0.2530, 0.2411],\n",
            "        [0.2575, 0.2547, 0.2487, 0.2390],\n",
            "        [0.2599, 0.2551, 0.2481, 0.2370],\n",
            "        [0.2706, 0.2476, 0.2445, 0.2373]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2514, 0.2562, 0.2529, 0.2395],\n",
            "        [0.2469, 0.2592, 0.2530, 0.2408],\n",
            "        [0.2579, 0.2548, 0.2486, 0.2386],\n",
            "        [0.2604, 0.2552, 0.2480, 0.2364],\n",
            "        [0.2712, 0.2476, 0.2444, 0.2367]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2509, 0.2567, 0.2534, 0.2390],\n",
            "        [0.2469, 0.2594, 0.2531, 0.2405],\n",
            "        [0.2584, 0.2548, 0.2485, 0.2383],\n",
            "        [0.2605, 0.2553, 0.2480, 0.2362],\n",
            "        [0.2714, 0.2476, 0.2444, 0.2366]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2509, 0.2566, 0.2532, 0.2392],\n",
            "        [0.2467, 0.2597, 0.2533, 0.2403],\n",
            "        [0.2585, 0.2550, 0.2486, 0.2379],\n",
            "        [0.2605, 0.2554, 0.2481, 0.2360],\n",
            "        [0.2721, 0.2475, 0.2443, 0.2362]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2511, 0.2568, 0.2534, 0.2386],\n",
            "        [0.2470, 0.2596, 0.2531, 0.2403],\n",
            "        [0.2583, 0.2553, 0.2487, 0.2378],\n",
            "        [0.2613, 0.2553, 0.2478, 0.2356],\n",
            "        [0.2725, 0.2476, 0.2442, 0.2357]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2517, 0.2569, 0.2534, 0.2380],\n",
            "        [0.2475, 0.2596, 0.2530, 0.2399],\n",
            "        [0.2589, 0.2553, 0.2486, 0.2372],\n",
            "        [0.2617, 0.2554, 0.2477, 0.2352],\n",
            "        [0.2736, 0.2472, 0.2438, 0.2354]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2514, 0.2571, 0.2535, 0.2380],\n",
            "        [0.2475, 0.2599, 0.2531, 0.2395],\n",
            "        [0.2594, 0.2553, 0.2485, 0.2368],\n",
            "        [0.2622, 0.2553, 0.2475, 0.2349],\n",
            "        [0.2741, 0.2471, 0.2436, 0.2352]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2515, 0.2572, 0.2536, 0.2377],\n",
            "        [0.2478, 0.2598, 0.2529, 0.2395],\n",
            "        [0.2591, 0.2557, 0.2488, 0.2363],\n",
            "        [0.2628, 0.2553, 0.2474, 0.2345],\n",
            "        [0.2744, 0.2470, 0.2436, 0.2350]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2517, 0.2573, 0.2536, 0.2375],\n",
            "        [0.2475, 0.2604, 0.2534, 0.2387],\n",
            "        [0.2599, 0.2555, 0.2486, 0.2360],\n",
            "        [0.2628, 0.2555, 0.2475, 0.2342],\n",
            "        [0.2748, 0.2470, 0.2435, 0.2346]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2517, 0.2575, 0.2538, 0.2371],\n",
            "        [0.2475, 0.2605, 0.2534, 0.2386],\n",
            "        [0.2597, 0.2557, 0.2488, 0.2357],\n",
            "        [0.2624, 0.2560, 0.2479, 0.2337],\n",
            "        [0.2752, 0.2469, 0.2434, 0.2345]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2517, 0.2574, 0.2537, 0.2371],\n",
            "        [0.2475, 0.2606, 0.2534, 0.2385],\n",
            "        [0.2598, 0.2558, 0.2488, 0.2357],\n",
            "        [0.2627, 0.2560, 0.2478, 0.2335],\n",
            "        [0.2762, 0.2466, 0.2430, 0.2343]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2516, 0.2577, 0.2539, 0.2368],\n",
            "        [0.2478, 0.2605, 0.2532, 0.2384],\n",
            "        [0.2596, 0.2561, 0.2489, 0.2354],\n",
            "        [0.2634, 0.2558, 0.2475, 0.2333],\n",
            "        [0.2759, 0.2468, 0.2432, 0.2341]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2521, 0.2578, 0.2539, 0.2362],\n",
            "        [0.2486, 0.2604, 0.2530, 0.2380],\n",
            "        [0.2606, 0.2558, 0.2486, 0.2350],\n",
            "        [0.2639, 0.2557, 0.2474, 0.2329],\n",
            "        [0.2768, 0.2466, 0.2430, 0.2335]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2521, 0.2579, 0.2541, 0.2359],\n",
            "        [0.2488, 0.2605, 0.2530, 0.2377],\n",
            "        [0.2610, 0.2555, 0.2483, 0.2351],\n",
            "        [0.2640, 0.2559, 0.2475, 0.2325],\n",
            "        [0.2771, 0.2465, 0.2430, 0.2334]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2521, 0.2580, 0.2541, 0.2357],\n",
            "        [0.2491, 0.2606, 0.2530, 0.2374],\n",
            "        [0.2614, 0.2556, 0.2482, 0.2348],\n",
            "        [0.2644, 0.2557, 0.2474, 0.2325],\n",
            "        [0.2775, 0.2466, 0.2429, 0.2330]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2528, 0.2579, 0.2538, 0.2355],\n",
            "        [0.2495, 0.2606, 0.2529, 0.2369],\n",
            "        [0.2620, 0.2557, 0.2481, 0.2341],\n",
            "        [0.2661, 0.2553, 0.2468, 0.2319],\n",
            "        [0.2788, 0.2463, 0.2426, 0.2323]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2529, 0.2582, 0.2540, 0.2349],\n",
            "        [0.2505, 0.2606, 0.2527, 0.2362],\n",
            "        [0.2630, 0.2554, 0.2477, 0.2339],\n",
            "        [0.2664, 0.2555, 0.2467, 0.2314],\n",
            "        [0.2795, 0.2462, 0.2424, 0.2319]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2532, 0.2582, 0.2540, 0.2346],\n",
            "        [0.2503, 0.2608, 0.2528, 0.2361],\n",
            "        [0.2628, 0.2559, 0.2480, 0.2333],\n",
            "        [0.2671, 0.2554, 0.2466, 0.2309],\n",
            "        [0.2798, 0.2462, 0.2424, 0.2316]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2533, 0.2582, 0.2540, 0.2345],\n",
            "        [0.2507, 0.2609, 0.2528, 0.2356],\n",
            "        [0.2634, 0.2557, 0.2478, 0.2331],\n",
            "        [0.2674, 0.2555, 0.2466, 0.2305],\n",
            "        [0.2805, 0.2461, 0.2423, 0.2310]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2535, 0.2582, 0.2539, 0.2343],\n",
            "        [0.2510, 0.2609, 0.2527, 0.2354],\n",
            "        [0.2635, 0.2559, 0.2479, 0.2327],\n",
            "        [0.2677, 0.2555, 0.2465, 0.2303],\n",
            "        [0.2810, 0.2461, 0.2422, 0.2307]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2536, 0.2584, 0.2540, 0.2340],\n",
            "        [0.2515, 0.2608, 0.2526, 0.2351],\n",
            "        [0.2639, 0.2558, 0.2478, 0.2325],\n",
            "        [0.2678, 0.2557, 0.2466, 0.2299],\n",
            "        [0.2812, 0.2460, 0.2422, 0.2306]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2539, 0.2583, 0.2539, 0.2339],\n",
            "        [0.2515, 0.2611, 0.2528, 0.2347],\n",
            "        [0.2643, 0.2559, 0.2478, 0.2321],\n",
            "        [0.2685, 0.2555, 0.2463, 0.2297],\n",
            "        [0.2816, 0.2460, 0.2421, 0.2303]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2539, 0.2585, 0.2540, 0.2336],\n",
            "        [0.2517, 0.2612, 0.2528, 0.2343],\n",
            "        [0.2646, 0.2559, 0.2479, 0.2316],\n",
            "        [0.2691, 0.2552, 0.2461, 0.2295],\n",
            "        [0.2818, 0.2460, 0.2421, 0.2301]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2542, 0.2585, 0.2540, 0.2333],\n",
            "        [0.2520, 0.2612, 0.2527, 0.2342],\n",
            "        [0.2648, 0.2559, 0.2477, 0.2315],\n",
            "        [0.2691, 0.2556, 0.2463, 0.2290],\n",
            "        [0.2823, 0.2461, 0.2422, 0.2295]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2544, 0.2586, 0.2540, 0.2331],\n",
            "        [0.2519, 0.2615, 0.2529, 0.2338],\n",
            "        [0.2652, 0.2559, 0.2477, 0.2312],\n",
            "        [0.2696, 0.2555, 0.2462, 0.2287],\n",
            "        [0.2829, 0.2460, 0.2420, 0.2291]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2545, 0.2586, 0.2540, 0.2329],\n",
            "        [0.2518, 0.2617, 0.2531, 0.2335],\n",
            "        [0.2655, 0.2558, 0.2475, 0.2312],\n",
            "        [0.2692, 0.2558, 0.2465, 0.2285],\n",
            "        [0.2829, 0.2461, 0.2421, 0.2290]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2545, 0.2587, 0.2541, 0.2326],\n",
            "        [0.2524, 0.2614, 0.2528, 0.2334],\n",
            "        [0.2660, 0.2557, 0.2474, 0.2309],\n",
            "        [0.2696, 0.2558, 0.2463, 0.2283],\n",
            "        [0.2833, 0.2460, 0.2420, 0.2287]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2546, 0.2588, 0.2541, 0.2325],\n",
            "        [0.2524, 0.2616, 0.2529, 0.2332],\n",
            "        [0.2662, 0.2558, 0.2474, 0.2307],\n",
            "        [0.2700, 0.2557, 0.2462, 0.2281],\n",
            "        [0.2836, 0.2460, 0.2420, 0.2284]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2543, 0.2590, 0.2543, 0.2324],\n",
            "        [0.2522, 0.2619, 0.2531, 0.2328],\n",
            "        [0.2659, 0.2562, 0.2477, 0.2301],\n",
            "        [0.2704, 0.2556, 0.2460, 0.2279],\n",
            "        [0.2840, 0.2460, 0.2419, 0.2281]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2547, 0.2589, 0.2542, 0.2321],\n",
            "        [0.2526, 0.2619, 0.2530, 0.2325],\n",
            "        [0.2664, 0.2561, 0.2476, 0.2300],\n",
            "        [0.2706, 0.2557, 0.2461, 0.2276],\n",
            "        [0.2843, 0.2460, 0.2419, 0.2278]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2544, 0.2592, 0.2544, 0.2320],\n",
            "        [0.2528, 0.2619, 0.2530, 0.2323],\n",
            "        [0.2668, 0.2561, 0.2475, 0.2296],\n",
            "        [0.2708, 0.2558, 0.2462, 0.2272],\n",
            "        [0.2848, 0.2458, 0.2417, 0.2277]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2551, 0.2591, 0.2543, 0.2315],\n",
            "        [0.2533, 0.2618, 0.2528, 0.2321],\n",
            "        [0.2669, 0.2563, 0.2477, 0.2291],\n",
            "        [0.2715, 0.2557, 0.2460, 0.2267],\n",
            "        [0.2857, 0.2456, 0.2416, 0.2271]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2554, 0.2593, 0.2544, 0.2309],\n",
            "        [0.2542, 0.2616, 0.2525, 0.2316],\n",
            "        [0.2675, 0.2562, 0.2477, 0.2286],\n",
            "        [0.2723, 0.2556, 0.2459, 0.2262],\n",
            "        [0.2866, 0.2455, 0.2414, 0.2265]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2555, 0.2591, 0.2542, 0.2312],\n",
            "        [0.2534, 0.2622, 0.2530, 0.2315],\n",
            "        [0.2674, 0.2563, 0.2477, 0.2286],\n",
            "        [0.2719, 0.2559, 0.2461, 0.2261],\n",
            "        [0.2866, 0.2456, 0.2415, 0.2264]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2560, 0.2590, 0.2540, 0.2310],\n",
            "        [0.2534, 0.2624, 0.2532, 0.2310],\n",
            "        [0.2680, 0.2562, 0.2476, 0.2282],\n",
            "        [0.2725, 0.2557, 0.2460, 0.2257],\n",
            "        [0.2872, 0.2455, 0.2413, 0.2260]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2566, 0.2589, 0.2539, 0.2306],\n",
            "        [0.2540, 0.2622, 0.2530, 0.2308],\n",
            "        [0.2681, 0.2564, 0.2478, 0.2277],\n",
            "        [0.2732, 0.2556, 0.2458, 0.2254],\n",
            "        [0.2879, 0.2454, 0.2412, 0.2255]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2566, 0.2590, 0.2540, 0.2304],\n",
            "        [0.2542, 0.2623, 0.2530, 0.2305],\n",
            "        [0.2683, 0.2564, 0.2478, 0.2275],\n",
            "        [0.2732, 0.2558, 0.2459, 0.2251],\n",
            "        [0.2883, 0.2453, 0.2411, 0.2253]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2564, 0.2592, 0.2542, 0.2302],\n",
            "        [0.2544, 0.2625, 0.2531, 0.2301],\n",
            "        [0.2687, 0.2563, 0.2475, 0.2274],\n",
            "        [0.2733, 0.2560, 0.2459, 0.2247],\n",
            "        [0.2887, 0.2452, 0.2411, 0.2250]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2565, 0.2594, 0.2543, 0.2299],\n",
            "        [0.2549, 0.2623, 0.2528, 0.2300],\n",
            "        [0.2691, 0.2564, 0.2475, 0.2270],\n",
            "        [0.2740, 0.2559, 0.2457, 0.2244],\n",
            "        [0.2893, 0.2451, 0.2410, 0.2246]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2568, 0.2594, 0.2542, 0.2296],\n",
            "        [0.2550, 0.2625, 0.2529, 0.2295],\n",
            "        [0.2695, 0.2563, 0.2474, 0.2267],\n",
            "        [0.2744, 0.2558, 0.2456, 0.2243],\n",
            "        [0.2895, 0.2452, 0.2410, 0.2243]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2570, 0.2593, 0.2542, 0.2295],\n",
            "        [0.2548, 0.2627, 0.2531, 0.2294],\n",
            "        [0.2696, 0.2565, 0.2475, 0.2264],\n",
            "        [0.2747, 0.2559, 0.2457, 0.2237],\n",
            "        [0.2905, 0.2448, 0.2406, 0.2241]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2572, 0.2594, 0.2542, 0.2291],\n",
            "        [0.2558, 0.2622, 0.2526, 0.2294],\n",
            "        [0.2694, 0.2567, 0.2478, 0.2260],\n",
            "        [0.2755, 0.2556, 0.2454, 0.2236],\n",
            "        [0.2909, 0.2447, 0.2405, 0.2239]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2574, 0.2595, 0.2542, 0.2289],\n",
            "        [0.2559, 0.2622, 0.2525, 0.2293],\n",
            "        [0.2693, 0.2571, 0.2480, 0.2257],\n",
            "        [0.2763, 0.2556, 0.2451, 0.2230],\n",
            "        [0.2915, 0.2446, 0.2404, 0.2234]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2569, 0.2597, 0.2544, 0.2290],\n",
            "        [0.2554, 0.2625, 0.2528, 0.2292],\n",
            "        [0.2690, 0.2573, 0.2482, 0.2256],\n",
            "        [0.2765, 0.2555, 0.2450, 0.2230],\n",
            "        [0.2916, 0.2447, 0.2404, 0.2234]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2575, 0.2595, 0.2542, 0.2288],\n",
            "        [0.2554, 0.2627, 0.2530, 0.2288],\n",
            "        [0.2696, 0.2570, 0.2480, 0.2254],\n",
            "        [0.2764, 0.2558, 0.2453, 0.2226],\n",
            "        [0.2923, 0.2445, 0.2402, 0.2230]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2578, 0.2595, 0.2542, 0.2285],\n",
            "        [0.2560, 0.2626, 0.2528, 0.2286],\n",
            "        [0.2700, 0.2572, 0.2481, 0.2248],\n",
            "        [0.2769, 0.2557, 0.2452, 0.2222],\n",
            "        [0.2929, 0.2444, 0.2401, 0.2226]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2579, 0.2597, 0.2543, 0.2282],\n",
            "        [0.2561, 0.2627, 0.2529, 0.2282],\n",
            "        [0.2702, 0.2573, 0.2481, 0.2244],\n",
            "        [0.2776, 0.2555, 0.2449, 0.2220],\n",
            "        [0.2932, 0.2443, 0.2400, 0.2224]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2581, 0.2597, 0.2543, 0.2280],\n",
            "        [0.2567, 0.2626, 0.2528, 0.2279],\n",
            "        [0.2708, 0.2571, 0.2480, 0.2241],\n",
            "        [0.2780, 0.2555, 0.2449, 0.2216],\n",
            "        [0.2938, 0.2443, 0.2399, 0.2220]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2585, 0.2596, 0.2541, 0.2278],\n",
            "        [0.2570, 0.2625, 0.2526, 0.2279],\n",
            "        [0.2709, 0.2571, 0.2478, 0.2242],\n",
            "        [0.2778, 0.2558, 0.2450, 0.2214],\n",
            "        [0.2937, 0.2444, 0.2400, 0.2218]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2588, 0.2596, 0.2540, 0.2276],\n",
            "        [0.2573, 0.2626, 0.2525, 0.2276],\n",
            "        [0.2715, 0.2569, 0.2476, 0.2240],\n",
            "        [0.2784, 0.2557, 0.2449, 0.2210],\n",
            "        [0.2946, 0.2442, 0.2398, 0.2215]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2590, 0.2596, 0.2541, 0.2273],\n",
            "        [0.2577, 0.2625, 0.2524, 0.2275],\n",
            "        [0.2713, 0.2572, 0.2478, 0.2237],\n",
            "        [0.2788, 0.2556, 0.2448, 0.2208],\n",
            "        [0.2948, 0.2442, 0.2398, 0.2212]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2591, 0.2596, 0.2541, 0.2271],\n",
            "        [0.2577, 0.2626, 0.2526, 0.2270],\n",
            "        [0.2719, 0.2570, 0.2477, 0.2233],\n",
            "        [0.2795, 0.2553, 0.2444, 0.2208],\n",
            "        [0.2951, 0.2441, 0.2397, 0.2211]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2591, 0.2597, 0.2542, 0.2270],\n",
            "        [0.2576, 0.2629, 0.2528, 0.2266],\n",
            "        [0.2724, 0.2569, 0.2475, 0.2232],\n",
            "        [0.2797, 0.2553, 0.2444, 0.2206],\n",
            "        [0.2957, 0.2440, 0.2395, 0.2208]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2597, 0.2596, 0.2540, 0.2268],\n",
            "        [0.2579, 0.2629, 0.2528, 0.2263],\n",
            "        [0.2729, 0.2568, 0.2474, 0.2228],\n",
            "        [0.2804, 0.2551, 0.2442, 0.2202],\n",
            "        [0.2962, 0.2440, 0.2395, 0.2203]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2596, 0.2597, 0.2542, 0.2265],\n",
            "        [0.2586, 0.2627, 0.2526, 0.2260],\n",
            "        [0.2734, 0.2566, 0.2472, 0.2228],\n",
            "        [0.2803, 0.2555, 0.2445, 0.2198],\n",
            "        [0.2970, 0.2437, 0.2393, 0.2200]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2600, 0.2597, 0.2541, 0.2262],\n",
            "        [0.2592, 0.2626, 0.2525, 0.2258],\n",
            "        [0.2734, 0.2568, 0.2475, 0.2223],\n",
            "        [0.2812, 0.2550, 0.2440, 0.2198],\n",
            "        [0.2971, 0.2437, 0.2393, 0.2199]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2601, 0.2597, 0.2541, 0.2262],\n",
            "        [0.2595, 0.2626, 0.2525, 0.2255],\n",
            "        [0.2739, 0.2568, 0.2475, 0.2219],\n",
            "        [0.2814, 0.2552, 0.2441, 0.2192],\n",
            "        [0.2977, 0.2436, 0.2391, 0.2195]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2604, 0.2597, 0.2541, 0.2259],\n",
            "        [0.2598, 0.2627, 0.2525, 0.2251],\n",
            "        [0.2746, 0.2566, 0.2472, 0.2216],\n",
            "        [0.2819, 0.2551, 0.2440, 0.2190],\n",
            "        [0.2983, 0.2435, 0.2390, 0.2192]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2606, 0.2596, 0.2539, 0.2258],\n",
            "        [0.2596, 0.2630, 0.2528, 0.2247],\n",
            "        [0.2751, 0.2564, 0.2471, 0.2214],\n",
            "        [0.2823, 0.2551, 0.2439, 0.2187],\n",
            "        [0.2985, 0.2435, 0.2390, 0.2189]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2606, 0.2597, 0.2541, 0.2256],\n",
            "        [0.2603, 0.2627, 0.2525, 0.2245],\n",
            "        [0.2755, 0.2564, 0.2470, 0.2211],\n",
            "        [0.2829, 0.2550, 0.2437, 0.2183],\n",
            "        [0.2994, 0.2432, 0.2387, 0.2187]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2605, 0.2598, 0.2541, 0.2255],\n",
            "        [0.2604, 0.2627, 0.2525, 0.2244],\n",
            "        [0.2755, 0.2564, 0.2470, 0.2210],\n",
            "        [0.2829, 0.2552, 0.2439, 0.2180],\n",
            "        [0.2997, 0.2432, 0.2386, 0.2185]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2608, 0.2598, 0.2541, 0.2252],\n",
            "        [0.2607, 0.2628, 0.2526, 0.2240],\n",
            "        [0.2759, 0.2565, 0.2470, 0.2206],\n",
            "        [0.2838, 0.2548, 0.2435, 0.2179],\n",
            "        [0.3003, 0.2430, 0.2385, 0.2183]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2613, 0.2597, 0.2540, 0.2251],\n",
            "        [0.2608, 0.2628, 0.2526, 0.2239],\n",
            "        [0.2762, 0.2565, 0.2470, 0.2203],\n",
            "        [0.2840, 0.2548, 0.2435, 0.2176],\n",
            "        [0.3008, 0.2429, 0.2384, 0.2178]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2610, 0.2599, 0.2542, 0.2249],\n",
            "        [0.2615, 0.2625, 0.2523, 0.2237],\n",
            "        [0.2763, 0.2565, 0.2470, 0.2203],\n",
            "        [0.2840, 0.2551, 0.2437, 0.2172],\n",
            "        [0.3012, 0.2429, 0.2383, 0.2176]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2613, 0.2599, 0.2541, 0.2246],\n",
            "        [0.2614, 0.2628, 0.2524, 0.2234],\n",
            "        [0.2766, 0.2565, 0.2470, 0.2199],\n",
            "        [0.2845, 0.2549, 0.2435, 0.2171],\n",
            "        [0.3015, 0.2428, 0.2383, 0.2173]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2616, 0.2597, 0.2539, 0.2248],\n",
            "        [0.2610, 0.2631, 0.2527, 0.2233],\n",
            "        [0.2769, 0.2563, 0.2468, 0.2200],\n",
            "        [0.2842, 0.2551, 0.2437, 0.2170],\n",
            "        [0.3017, 0.2428, 0.2382, 0.2173]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2618, 0.2597, 0.2540, 0.2245],\n",
            "        [0.2612, 0.2630, 0.2527, 0.2231],\n",
            "        [0.2771, 0.2564, 0.2469, 0.2196],\n",
            "        [0.2849, 0.2548, 0.2435, 0.2168],\n",
            "        [0.3021, 0.2426, 0.2381, 0.2171]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2618, 0.2598, 0.2541, 0.2243],\n",
            "        [0.2617, 0.2629, 0.2525, 0.2229],\n",
            "        [0.2773, 0.2565, 0.2469, 0.2193],\n",
            "        [0.2854, 0.2548, 0.2434, 0.2164],\n",
            "        [0.3026, 0.2425, 0.2380, 0.2168]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2619, 0.2598, 0.2541, 0.2242],\n",
            "        [0.2622, 0.2627, 0.2524, 0.2227],\n",
            "        [0.2777, 0.2565, 0.2469, 0.2189],\n",
            "        [0.2859, 0.2546, 0.2432, 0.2163],\n",
            "        [0.3028, 0.2425, 0.2380, 0.2166]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2621, 0.2598, 0.2541, 0.2240],\n",
            "        [0.2624, 0.2626, 0.2523, 0.2226],\n",
            "        [0.2779, 0.2564, 0.2468, 0.2189],\n",
            "        [0.2859, 0.2547, 0.2433, 0.2161],\n",
            "        [0.3031, 0.2425, 0.2380, 0.2165]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2623, 0.2598, 0.2540, 0.2238],\n",
            "        [0.2626, 0.2627, 0.2524, 0.2223],\n",
            "        [0.2784, 0.2563, 0.2467, 0.2185],\n",
            "        [0.2864, 0.2546, 0.2432, 0.2159],\n",
            "        [0.3035, 0.2424, 0.2379, 0.2162]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2624, 0.2598, 0.2540, 0.2238],\n",
            "        [0.2626, 0.2629, 0.2526, 0.2219],\n",
            "        [0.2789, 0.2562, 0.2466, 0.2183],\n",
            "        [0.2869, 0.2544, 0.2431, 0.2157],\n",
            "        [0.3039, 0.2423, 0.2378, 0.2159]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2625, 0.2599, 0.2541, 0.2235],\n",
            "        [0.2633, 0.2627, 0.2523, 0.2217],\n",
            "        [0.2793, 0.2561, 0.2465, 0.2181],\n",
            "        [0.2872, 0.2544, 0.2430, 0.2154],\n",
            "        [0.3044, 0.2422, 0.2376, 0.2158]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2628, 0.2598, 0.2540, 0.2235],\n",
            "        [0.2634, 0.2627, 0.2523, 0.2216],\n",
            "        [0.2794, 0.2561, 0.2465, 0.2180],\n",
            "        [0.2873, 0.2545, 0.2430, 0.2152],\n",
            "        [0.3045, 0.2421, 0.2376, 0.2158]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2629, 0.2598, 0.2540, 0.2234],\n",
            "        [0.2635, 0.2627, 0.2523, 0.2215],\n",
            "        [0.2796, 0.2561, 0.2465, 0.2177],\n",
            "        [0.2879, 0.2544, 0.2429, 0.2149],\n",
            "        [0.3049, 0.2421, 0.2375, 0.2156]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2632, 0.2597, 0.2539, 0.2232],\n",
            "        [0.2637, 0.2628, 0.2523, 0.2213],\n",
            "        [0.2798, 0.2561, 0.2465, 0.2176],\n",
            "        [0.2884, 0.2542, 0.2427, 0.2147],\n",
            "        [0.3052, 0.2420, 0.2374, 0.2154]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2632, 0.2598, 0.2539, 0.2232],\n",
            "        [0.2638, 0.2627, 0.2523, 0.2212],\n",
            "        [0.2800, 0.2561, 0.2464, 0.2176],\n",
            "        [0.2883, 0.2544, 0.2428, 0.2145],\n",
            "        [0.3055, 0.2419, 0.2373, 0.2153]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2632, 0.2599, 0.2540, 0.2230],\n",
            "        [0.2641, 0.2628, 0.2523, 0.2209],\n",
            "        [0.2805, 0.2560, 0.2463, 0.2172],\n",
            "        [0.2886, 0.2544, 0.2428, 0.2142],\n",
            "        [0.3059, 0.2418, 0.2373, 0.2150]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2633, 0.2599, 0.2540, 0.2229],\n",
            "        [0.2643, 0.2626, 0.2522, 0.2208],\n",
            "        [0.2805, 0.2560, 0.2463, 0.2172],\n",
            "        [0.2888, 0.2544, 0.2428, 0.2140],\n",
            "        [0.3064, 0.2416, 0.2371, 0.2149]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2636, 0.2598, 0.2539, 0.2227],\n",
            "        [0.2647, 0.2625, 0.2520, 0.2208],\n",
            "        [0.2806, 0.2561, 0.2464, 0.2169],\n",
            "        [0.2894, 0.2541, 0.2425, 0.2140],\n",
            "        [0.3066, 0.2416, 0.2371, 0.2147]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2637, 0.2597, 0.2539, 0.2227],\n",
            "        [0.2648, 0.2624, 0.2520, 0.2207],\n",
            "        [0.2807, 0.2561, 0.2465, 0.2167],\n",
            "        [0.2899, 0.2539, 0.2424, 0.2138],\n",
            "        [0.3068, 0.2416, 0.2371, 0.2145]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2639, 0.2597, 0.2538, 0.2226],\n",
            "        [0.2651, 0.2624, 0.2519, 0.2206],\n",
            "        [0.2809, 0.2561, 0.2464, 0.2167],\n",
            "        [0.2899, 0.2540, 0.2424, 0.2136],\n",
            "        [0.3073, 0.2415, 0.2369, 0.2143]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2639, 0.2598, 0.2539, 0.2225],\n",
            "        [0.2651, 0.2626, 0.2520, 0.2203],\n",
            "        [0.2814, 0.2559, 0.2463, 0.2165],\n",
            "        [0.2902, 0.2540, 0.2424, 0.2134],\n",
            "        [0.3077, 0.2413, 0.2368, 0.2142]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2640, 0.2597, 0.2538, 0.2225],\n",
            "        [0.2649, 0.2627, 0.2522, 0.2202],\n",
            "        [0.2816, 0.2557, 0.2461, 0.2165],\n",
            "        [0.2901, 0.2541, 0.2425, 0.2133],\n",
            "        [0.3079, 0.2413, 0.2367, 0.2140]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2641, 0.2597, 0.2538, 0.2224],\n",
            "        [0.2651, 0.2626, 0.2521, 0.2202],\n",
            "        [0.2816, 0.2558, 0.2461, 0.2165],\n",
            "        [0.2903, 0.2540, 0.2424, 0.2134],\n",
            "        [0.3079, 0.2414, 0.2368, 0.2140]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2642, 0.2597, 0.2538, 0.2223],\n",
            "        [0.2653, 0.2625, 0.2520, 0.2201],\n",
            "        [0.2818, 0.2557, 0.2461, 0.2164],\n",
            "        [0.2905, 0.2540, 0.2423, 0.2133],\n",
            "        [0.3081, 0.2413, 0.2367, 0.2139]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2643, 0.2597, 0.2538, 0.2222],\n",
            "        [0.2654, 0.2625, 0.2520, 0.2201],\n",
            "        [0.2820, 0.2558, 0.2461, 0.2161],\n",
            "        [0.2908, 0.2538, 0.2422, 0.2131],\n",
            "        [0.3085, 0.2412, 0.2366, 0.2137]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2643, 0.2597, 0.2538, 0.2221],\n",
            "        [0.2655, 0.2625, 0.2520, 0.2200],\n",
            "        [0.2820, 0.2558, 0.2462, 0.2160],\n",
            "        [0.2910, 0.2539, 0.2422, 0.2130],\n",
            "        [0.3086, 0.2412, 0.2366, 0.2135]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2645, 0.2596, 0.2537, 0.2222],\n",
            "        [0.2655, 0.2625, 0.2520, 0.2200],\n",
            "        [0.2820, 0.2558, 0.2462, 0.2160],\n",
            "        [0.2911, 0.2538, 0.2422, 0.2128],\n",
            "        [0.3088, 0.2412, 0.2366, 0.2134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2645, 0.2597, 0.2537, 0.2220],\n",
            "        [0.2657, 0.2625, 0.2520, 0.2199],\n",
            "        [0.2821, 0.2558, 0.2462, 0.2160],\n",
            "        [0.2912, 0.2538, 0.2422, 0.2127],\n",
            "        [0.3090, 0.2411, 0.2365, 0.2133]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2646, 0.2597, 0.2537, 0.2220],\n",
            "        [0.2658, 0.2625, 0.2519, 0.2198],\n",
            "        [0.2822, 0.2558, 0.2461, 0.2159],\n",
            "        [0.2914, 0.2538, 0.2421, 0.2126],\n",
            "        [0.3092, 0.2411, 0.2365, 0.2133]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2647, 0.2597, 0.2537, 0.2218],\n",
            "        [0.2661, 0.2624, 0.2518, 0.2197],\n",
            "        [0.2824, 0.2558, 0.2461, 0.2157],\n",
            "        [0.2917, 0.2538, 0.2421, 0.2125],\n",
            "        [0.3094, 0.2410, 0.2364, 0.2131]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2649, 0.2597, 0.2537, 0.2218],\n",
            "        [0.2662, 0.2624, 0.2519, 0.2196],\n",
            "        [0.2826, 0.2556, 0.2460, 0.2157],\n",
            "        [0.2918, 0.2537, 0.2420, 0.2124],\n",
            "        [0.3095, 0.2410, 0.2364, 0.2131]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2648, 0.2597, 0.2538, 0.2217],\n",
            "        [0.2663, 0.2623, 0.2518, 0.2196],\n",
            "        [0.2827, 0.2556, 0.2460, 0.2157],\n",
            "        [0.2918, 0.2538, 0.2421, 0.2124],\n",
            "        [0.3097, 0.2410, 0.2364, 0.2130]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2648, 0.2597, 0.2538, 0.2217],\n",
            "        [0.2663, 0.2623, 0.2518, 0.2196],\n",
            "        [0.2828, 0.2556, 0.2459, 0.2157],\n",
            "        [0.2918, 0.2538, 0.2421, 0.2124],\n",
            "        [0.3098, 0.2410, 0.2364, 0.2129]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2649, 0.2597, 0.2537, 0.2217],\n",
            "        [0.2664, 0.2623, 0.2518, 0.2195],\n",
            "        [0.2828, 0.2556, 0.2459, 0.2156],\n",
            "        [0.2918, 0.2538, 0.2421, 0.2123],\n",
            "        [0.3098, 0.2409, 0.2363, 0.2129]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2649, 0.2597, 0.2537, 0.2217],\n",
            "        [0.2664, 0.2623, 0.2518, 0.2195],\n",
            "        [0.2829, 0.2556, 0.2459, 0.2156],\n",
            "        [0.2919, 0.2538, 0.2421, 0.2123],\n",
            "        [0.3099, 0.2409, 0.2363, 0.2129]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2649, 0.2597, 0.2537, 0.2217],\n",
            "        [0.2664, 0.2623, 0.2518, 0.2195],\n",
            "        [0.2829, 0.2556, 0.2460, 0.2156],\n",
            "        [0.2919, 0.2537, 0.2421, 0.2123],\n",
            "        [0.3099, 0.2409, 0.2363, 0.2129]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)], 'cell_netG_B': [tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2493, 0.2507, 0.2504, 0.2496],\n",
            "        [0.2499, 0.2501, 0.2501, 0.2499],\n",
            "        [0.2496, 0.2504, 0.2504, 0.2496],\n",
            "        [0.2497, 0.2503, 0.2502, 0.2497],\n",
            "        [0.2499, 0.2502, 0.2502, 0.2497]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2489, 0.2510, 0.2506, 0.2495],\n",
            "        [0.2498, 0.2503, 0.2502, 0.2497],\n",
            "        [0.2494, 0.2508, 0.2506, 0.2493],\n",
            "        [0.2496, 0.2505, 0.2503, 0.2495],\n",
            "        [0.2499, 0.2503, 0.2502, 0.2496]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2489, 0.2511, 0.2507, 0.2493],\n",
            "        [0.2494, 0.2506, 0.2504, 0.2495],\n",
            "        [0.2491, 0.2510, 0.2508, 0.2491],\n",
            "        [0.2493, 0.2508, 0.2505, 0.2494],\n",
            "        [0.2496, 0.2506, 0.2504, 0.2494]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2489, 0.2511, 0.2506, 0.2494],\n",
            "        [0.2490, 0.2509, 0.2507, 0.2494],\n",
            "        [0.2490, 0.2512, 0.2509, 0.2489],\n",
            "        [0.2491, 0.2510, 0.2507, 0.2492],\n",
            "        [0.2496, 0.2507, 0.2505, 0.2492]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2486, 0.2514, 0.2508, 0.2493],\n",
            "        [0.2485, 0.2512, 0.2510, 0.2493],\n",
            "        [0.2485, 0.2516, 0.2513, 0.2486],\n",
            "        [0.2486, 0.2515, 0.2510, 0.2488],\n",
            "        [0.2498, 0.2507, 0.2505, 0.2490]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2488, 0.2514, 0.2507, 0.2491],\n",
            "        [0.2489, 0.2511, 0.2508, 0.2491],\n",
            "        [0.2487, 0.2516, 0.2512, 0.2485],\n",
            "        [0.2487, 0.2517, 0.2510, 0.2486],\n",
            "        [0.2499, 0.2508, 0.2506, 0.2487]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2478, 0.2521, 0.2513, 0.2488],\n",
            "        [0.2485, 0.2513, 0.2510, 0.2492],\n",
            "        [0.2479, 0.2520, 0.2516, 0.2484],\n",
            "        [0.2480, 0.2521, 0.2513, 0.2486],\n",
            "        [0.2495, 0.2510, 0.2507, 0.2488]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2477, 0.2522, 0.2514, 0.2487],\n",
            "        [0.2484, 0.2514, 0.2510, 0.2492],\n",
            "        [0.2475, 0.2523, 0.2518, 0.2484],\n",
            "        [0.2473, 0.2526, 0.2517, 0.2484],\n",
            "        [0.2494, 0.2512, 0.2509, 0.2485]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2477, 0.2523, 0.2514, 0.2486],\n",
            "        [0.2480, 0.2517, 0.2513, 0.2489],\n",
            "        [0.2475, 0.2525, 0.2519, 0.2480],\n",
            "        [0.2476, 0.2525, 0.2516, 0.2483],\n",
            "        [0.2492, 0.2514, 0.2510, 0.2484]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2474, 0.2526, 0.2516, 0.2485],\n",
            "        [0.2474, 0.2522, 0.2517, 0.2487],\n",
            "        [0.2472, 0.2529, 0.2522, 0.2478],\n",
            "        [0.2473, 0.2528, 0.2518, 0.2482],\n",
            "        [0.2489, 0.2517, 0.2512, 0.2482]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2468, 0.2529, 0.2519, 0.2485],\n",
            "        [0.2470, 0.2523, 0.2518, 0.2489],\n",
            "        [0.2464, 0.2534, 0.2527, 0.2475],\n",
            "        [0.2471, 0.2530, 0.2519, 0.2481],\n",
            "        [0.2491, 0.2516, 0.2512, 0.2481]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2465, 0.2531, 0.2520, 0.2484],\n",
            "        [0.2466, 0.2526, 0.2520, 0.2488],\n",
            "        [0.2463, 0.2536, 0.2528, 0.2473],\n",
            "        [0.2471, 0.2531, 0.2519, 0.2479],\n",
            "        [0.2491, 0.2517, 0.2512, 0.2480]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2465, 0.2533, 0.2521, 0.2481],\n",
            "        [0.2469, 0.2526, 0.2519, 0.2485],\n",
            "        [0.2465, 0.2537, 0.2528, 0.2471],\n",
            "        [0.2470, 0.2534, 0.2521, 0.2474],\n",
            "        [0.2493, 0.2518, 0.2512, 0.2477]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2465, 0.2533, 0.2521, 0.2482],\n",
            "        [0.2461, 0.2530, 0.2523, 0.2485],\n",
            "        [0.2461, 0.2539, 0.2530, 0.2470],\n",
            "        [0.2469, 0.2535, 0.2521, 0.2475],\n",
            "        [0.2492, 0.2519, 0.2513, 0.2476]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2463, 0.2537, 0.2523, 0.2477],\n",
            "        [0.2467, 0.2529, 0.2521, 0.2483],\n",
            "        [0.2471, 0.2535, 0.2525, 0.2469],\n",
            "        [0.2470, 0.2536, 0.2521, 0.2473],\n",
            "        [0.2493, 0.2519, 0.2512, 0.2475]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2461, 0.2538, 0.2523, 0.2478],\n",
            "        [0.2461, 0.2533, 0.2524, 0.2482],\n",
            "        [0.2466, 0.2539, 0.2528, 0.2468],\n",
            "        [0.2463, 0.2541, 0.2524, 0.2472],\n",
            "        [0.2491, 0.2520, 0.2513, 0.2475]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2457, 0.2540, 0.2525, 0.2478],\n",
            "        [0.2455, 0.2535, 0.2527, 0.2483],\n",
            "        [0.2460, 0.2543, 0.2532, 0.2466],\n",
            "        [0.2459, 0.2543, 0.2526, 0.2472],\n",
            "        [0.2487, 0.2523, 0.2516, 0.2474]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2455, 0.2543, 0.2527, 0.2475],\n",
            "        [0.2455, 0.2537, 0.2528, 0.2480],\n",
            "        [0.2460, 0.2544, 0.2533, 0.2463],\n",
            "        [0.2462, 0.2544, 0.2526, 0.2467],\n",
            "        [0.2489, 0.2524, 0.2516, 0.2471]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2454, 0.2546, 0.2529, 0.2470],\n",
            "        [0.2459, 0.2536, 0.2527, 0.2478],\n",
            "        [0.2459, 0.2547, 0.2536, 0.2458],\n",
            "        [0.2462, 0.2547, 0.2528, 0.2464],\n",
            "        [0.2489, 0.2526, 0.2518, 0.2467]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2453, 0.2547, 0.2529, 0.2470],\n",
            "        [0.2453, 0.2541, 0.2531, 0.2475],\n",
            "        [0.2461, 0.2547, 0.2535, 0.2458],\n",
            "        [0.2462, 0.2547, 0.2528, 0.2463],\n",
            "        [0.2490, 0.2528, 0.2519, 0.2464]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2454, 0.2548, 0.2529, 0.2470],\n",
            "        [0.2447, 0.2546, 0.2534, 0.2473],\n",
            "        [0.2456, 0.2551, 0.2538, 0.2456],\n",
            "        [0.2457, 0.2552, 0.2530, 0.2462],\n",
            "        [0.2485, 0.2532, 0.2522, 0.2461]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2451, 0.2549, 0.2530, 0.2470],\n",
            "        [0.2443, 0.2549, 0.2536, 0.2472],\n",
            "        [0.2455, 0.2552, 0.2538, 0.2455],\n",
            "        [0.2453, 0.2554, 0.2532, 0.2461],\n",
            "        [0.2486, 0.2532, 0.2522, 0.2460]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2452, 0.2550, 0.2530, 0.2468],\n",
            "        [0.2443, 0.2550, 0.2537, 0.2469],\n",
            "        [0.2459, 0.2552, 0.2538, 0.2451],\n",
            "        [0.2458, 0.2555, 0.2532, 0.2456],\n",
            "        [0.2491, 0.2531, 0.2520, 0.2458]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2451, 0.2553, 0.2532, 0.2464],\n",
            "        [0.2445, 0.2551, 0.2537, 0.2468],\n",
            "        [0.2459, 0.2554, 0.2538, 0.2448],\n",
            "        [0.2458, 0.2557, 0.2533, 0.2452],\n",
            "        [0.2491, 0.2532, 0.2521, 0.2456]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2449, 0.2555, 0.2533, 0.2464],\n",
            "        [0.2443, 0.2552, 0.2538, 0.2467],\n",
            "        [0.2456, 0.2557, 0.2541, 0.2446],\n",
            "        [0.2456, 0.2560, 0.2534, 0.2449],\n",
            "        [0.2492, 0.2533, 0.2521, 0.2455]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2452, 0.2555, 0.2532, 0.2460],\n",
            "        [0.2448, 0.2551, 0.2536, 0.2465],\n",
            "        [0.2459, 0.2557, 0.2540, 0.2443],\n",
            "        [0.2458, 0.2561, 0.2535, 0.2446],\n",
            "        [0.2495, 0.2533, 0.2520, 0.2453]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2451, 0.2557, 0.2533, 0.2458],\n",
            "        [0.2446, 0.2553, 0.2537, 0.2464],\n",
            "        [0.2459, 0.2560, 0.2542, 0.2440],\n",
            "        [0.2459, 0.2562, 0.2534, 0.2444],\n",
            "        [0.2495, 0.2535, 0.2522, 0.2449]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2449, 0.2560, 0.2535, 0.2456],\n",
            "        [0.2443, 0.2555, 0.2538, 0.2463],\n",
            "        [0.2457, 0.2562, 0.2543, 0.2438],\n",
            "        [0.2459, 0.2563, 0.2535, 0.2443],\n",
            "        [0.2492, 0.2538, 0.2524, 0.2447]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2449, 0.2562, 0.2536, 0.2453],\n",
            "        [0.2446, 0.2555, 0.2538, 0.2462],\n",
            "        [0.2460, 0.2561, 0.2542, 0.2437],\n",
            "        [0.2461, 0.2563, 0.2534, 0.2441],\n",
            "        [0.2494, 0.2538, 0.2524, 0.2444]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2452, 0.2562, 0.2536, 0.2450],\n",
            "        [0.2445, 0.2559, 0.2540, 0.2457],\n",
            "        [0.2462, 0.2562, 0.2542, 0.2434],\n",
            "        [0.2461, 0.2567, 0.2537, 0.2435],\n",
            "        [0.2497, 0.2538, 0.2523, 0.2441]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2448, 0.2565, 0.2538, 0.2449],\n",
            "        [0.2444, 0.2559, 0.2540, 0.2457],\n",
            "        [0.2458, 0.2567, 0.2546, 0.2430],\n",
            "        [0.2467, 0.2565, 0.2534, 0.2434],\n",
            "        [0.2497, 0.2539, 0.2524, 0.2440]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2453, 0.2564, 0.2535, 0.2448],\n",
            "        [0.2443, 0.2562, 0.2542, 0.2453],\n",
            "        [0.2463, 0.2566, 0.2544, 0.2427],\n",
            "        [0.2472, 0.2564, 0.2533, 0.2431],\n",
            "        [0.2498, 0.2541, 0.2525, 0.2436]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2450, 0.2567, 0.2537, 0.2446],\n",
            "        [0.2439, 0.2566, 0.2544, 0.2451],\n",
            "        [0.2462, 0.2569, 0.2545, 0.2424],\n",
            "        [0.2475, 0.2565, 0.2532, 0.2428],\n",
            "        [0.2499, 0.2542, 0.2525, 0.2434]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2451, 0.2568, 0.2538, 0.2443],\n",
            "        [0.2440, 0.2567, 0.2544, 0.2449],\n",
            "        [0.2462, 0.2571, 0.2547, 0.2420],\n",
            "        [0.2475, 0.2567, 0.2534, 0.2424],\n",
            "        [0.2502, 0.2543, 0.2526, 0.2430]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2450, 0.2569, 0.2538, 0.2442],\n",
            "        [0.2437, 0.2571, 0.2547, 0.2445],\n",
            "        [0.2464, 0.2571, 0.2547, 0.2418],\n",
            "        [0.2477, 0.2568, 0.2534, 0.2421],\n",
            "        [0.2503, 0.2543, 0.2525, 0.2429]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2454, 0.2569, 0.2537, 0.2439],\n",
            "        [0.2442, 0.2569, 0.2545, 0.2443],\n",
            "        [0.2470, 0.2570, 0.2544, 0.2416],\n",
            "        [0.2483, 0.2567, 0.2532, 0.2418],\n",
            "        [0.2506, 0.2544, 0.2526, 0.2424]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2449, 0.2574, 0.2541, 0.2436],\n",
            "        [0.2443, 0.2570, 0.2545, 0.2443],\n",
            "        [0.2467, 0.2573, 0.2546, 0.2414],\n",
            "        [0.2481, 0.2569, 0.2533, 0.2417],\n",
            "        [0.2504, 0.2546, 0.2527, 0.2423]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2454, 0.2574, 0.2539, 0.2433],\n",
            "        [0.2441, 0.2573, 0.2547, 0.2439],\n",
            "        [0.2470, 0.2575, 0.2547, 0.2407],\n",
            "        [0.2488, 0.2569, 0.2531, 0.2412],\n",
            "        [0.2507, 0.2548, 0.2528, 0.2418]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2451, 0.2577, 0.2541, 0.2431],\n",
            "        [0.2444, 0.2573, 0.2545, 0.2438],\n",
            "        [0.2474, 0.2574, 0.2546, 0.2406],\n",
            "        [0.2494, 0.2568, 0.2529, 0.2409],\n",
            "        [0.2510, 0.2547, 0.2528, 0.2415]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2451, 0.2578, 0.2541, 0.2431],\n",
            "        [0.2440, 0.2576, 0.2547, 0.2437],\n",
            "        [0.2471, 0.2577, 0.2547, 0.2404],\n",
            "        [0.2491, 0.2572, 0.2531, 0.2406],\n",
            "        [0.2511, 0.2548, 0.2528, 0.2413]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2451, 0.2580, 0.2542, 0.2428],\n",
            "        [0.2440, 0.2578, 0.2548, 0.2434],\n",
            "        [0.2476, 0.2577, 0.2546, 0.2401],\n",
            "        [0.2497, 0.2571, 0.2530, 0.2402],\n",
            "        [0.2515, 0.2548, 0.2527, 0.2410]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2449, 0.2583, 0.2544, 0.2424],\n",
            "        [0.2437, 0.2582, 0.2551, 0.2430],\n",
            "        [0.2477, 0.2578, 0.2547, 0.2398],\n",
            "        [0.2496, 0.2574, 0.2532, 0.2399],\n",
            "        [0.2517, 0.2549, 0.2527, 0.2407]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2450, 0.2585, 0.2545, 0.2420],\n",
            "        [0.2440, 0.2582, 0.2551, 0.2427],\n",
            "        [0.2483, 0.2577, 0.2545, 0.2396],\n",
            "        [0.2500, 0.2573, 0.2531, 0.2396],\n",
            "        [0.2520, 0.2549, 0.2527, 0.2405]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2455, 0.2584, 0.2543, 0.2418],\n",
            "        [0.2443, 0.2582, 0.2550, 0.2425],\n",
            "        [0.2481, 0.2580, 0.2547, 0.2392],\n",
            "        [0.2502, 0.2575, 0.2531, 0.2391],\n",
            "        [0.2523, 0.2550, 0.2527, 0.2400]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2457, 0.2584, 0.2542, 0.2416],\n",
            "        [0.2441, 0.2584, 0.2552, 0.2423],\n",
            "        [0.2482, 0.2580, 0.2547, 0.2391],\n",
            "        [0.2503, 0.2575, 0.2531, 0.2390],\n",
            "        [0.2522, 0.2552, 0.2529, 0.2397]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2457, 0.2587, 0.2544, 0.2412],\n",
            "        [0.2446, 0.2584, 0.2550, 0.2419],\n",
            "        [0.2491, 0.2579, 0.2544, 0.2387],\n",
            "        [0.2512, 0.2575, 0.2529, 0.2384],\n",
            "        [0.2529, 0.2551, 0.2526, 0.2394]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2457, 0.2590, 0.2545, 0.2408],\n",
            "        [0.2451, 0.2584, 0.2549, 0.2417],\n",
            "        [0.2491, 0.2581, 0.2545, 0.2382],\n",
            "        [0.2515, 0.2575, 0.2529, 0.2381],\n",
            "        [0.2532, 0.2550, 0.2525, 0.2392]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2456, 0.2593, 0.2546, 0.2405],\n",
            "        [0.2452, 0.2585, 0.2549, 0.2414],\n",
            "        [0.2491, 0.2582, 0.2546, 0.2381],\n",
            "        [0.2517, 0.2576, 0.2528, 0.2379],\n",
            "        [0.2534, 0.2552, 0.2526, 0.2389]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2458, 0.2594, 0.2546, 0.2402],\n",
            "        [0.2449, 0.2589, 0.2551, 0.2411],\n",
            "        [0.2491, 0.2585, 0.2547, 0.2378],\n",
            "        [0.2519, 0.2577, 0.2529, 0.2375],\n",
            "        [0.2536, 0.2554, 0.2528, 0.2383]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2455, 0.2596, 0.2548, 0.2400],\n",
            "        [0.2450, 0.2591, 0.2552, 0.2407],\n",
            "        [0.2495, 0.2585, 0.2547, 0.2373],\n",
            "        [0.2526, 0.2575, 0.2527, 0.2372],\n",
            "        [0.2539, 0.2554, 0.2527, 0.2380]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2451, 0.2600, 0.2551, 0.2398],\n",
            "        [0.2448, 0.2592, 0.2553, 0.2407],\n",
            "        [0.2490, 0.2589, 0.2550, 0.2371],\n",
            "        [0.2524, 0.2578, 0.2528, 0.2369],\n",
            "        [0.2539, 0.2555, 0.2528, 0.2377]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2450, 0.2602, 0.2552, 0.2396],\n",
            "        [0.2447, 0.2594, 0.2554, 0.2405],\n",
            "        [0.2491, 0.2589, 0.2550, 0.2370],\n",
            "        [0.2525, 0.2579, 0.2529, 0.2367],\n",
            "        [0.2543, 0.2554, 0.2527, 0.2377]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2457, 0.2600, 0.2549, 0.2394],\n",
            "        [0.2454, 0.2591, 0.2551, 0.2403],\n",
            "        [0.2497, 0.2588, 0.2548, 0.2366],\n",
            "        [0.2533, 0.2579, 0.2528, 0.2360],\n",
            "        [0.2552, 0.2553, 0.2524, 0.2370]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2459, 0.2601, 0.2549, 0.2391],\n",
            "        [0.2455, 0.2593, 0.2552, 0.2399],\n",
            "        [0.2500, 0.2590, 0.2548, 0.2362],\n",
            "        [0.2542, 0.2576, 0.2524, 0.2358],\n",
            "        [0.2552, 0.2555, 0.2526, 0.2367]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2464, 0.2600, 0.2548, 0.2387],\n",
            "        [0.2460, 0.2593, 0.2551, 0.2395],\n",
            "        [0.2506, 0.2588, 0.2546, 0.2360],\n",
            "        [0.2546, 0.2577, 0.2524, 0.2353],\n",
            "        [0.2556, 0.2556, 0.2526, 0.2362]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2467, 0.2600, 0.2547, 0.2386],\n",
            "        [0.2458, 0.2595, 0.2553, 0.2395],\n",
            "        [0.2510, 0.2587, 0.2544, 0.2359],\n",
            "        [0.2546, 0.2580, 0.2527, 0.2347],\n",
            "        [0.2563, 0.2555, 0.2524, 0.2358]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2464, 0.2603, 0.2549, 0.2383],\n",
            "        [0.2457, 0.2596, 0.2553, 0.2395],\n",
            "        [0.2508, 0.2590, 0.2546, 0.2356],\n",
            "        [0.2547, 0.2583, 0.2527, 0.2344],\n",
            "        [0.2564, 0.2556, 0.2525, 0.2356]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2471, 0.2602, 0.2547, 0.2380],\n",
            "        [0.2463, 0.2596, 0.2552, 0.2389],\n",
            "        [0.2514, 0.2590, 0.2546, 0.2351],\n",
            "        [0.2551, 0.2584, 0.2527, 0.2338],\n",
            "        [0.2571, 0.2555, 0.2523, 0.2352]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2469, 0.2605, 0.2549, 0.2378],\n",
            "        [0.2465, 0.2596, 0.2551, 0.2387],\n",
            "        [0.2514, 0.2592, 0.2546, 0.2348],\n",
            "        [0.2557, 0.2583, 0.2525, 0.2335],\n",
            "        [0.2573, 0.2555, 0.2523, 0.2349]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2477, 0.2604, 0.2546, 0.2374],\n",
            "        [0.2470, 0.2597, 0.2551, 0.2381],\n",
            "        [0.2524, 0.2590, 0.2543, 0.2343],\n",
            "        [0.2568, 0.2581, 0.2523, 0.2328],\n",
            "        [0.2581, 0.2554, 0.2521, 0.2344]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2483, 0.2602, 0.2544, 0.2371],\n",
            "        [0.2475, 0.2596, 0.2550, 0.2379],\n",
            "        [0.2529, 0.2589, 0.2542, 0.2339],\n",
            "        [0.2579, 0.2577, 0.2520, 0.2325],\n",
            "        [0.2588, 0.2553, 0.2520, 0.2339]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2482, 0.2604, 0.2545, 0.2368],\n",
            "        [0.2474, 0.2599, 0.2552, 0.2375],\n",
            "        [0.2533, 0.2590, 0.2542, 0.2336],\n",
            "        [0.2583, 0.2578, 0.2520, 0.2319],\n",
            "        [0.2591, 0.2554, 0.2520, 0.2336]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2488, 0.2603, 0.2543, 0.2366],\n",
            "        [0.2477, 0.2600, 0.2552, 0.2371],\n",
            "        [0.2538, 0.2590, 0.2541, 0.2331],\n",
            "        [0.2595, 0.2574, 0.2515, 0.2316],\n",
            "        [0.2597, 0.2552, 0.2518, 0.2333]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2483, 0.2605, 0.2545, 0.2367],\n",
            "        [0.2475, 0.2600, 0.2552, 0.2373],\n",
            "        [0.2533, 0.2593, 0.2544, 0.2331],\n",
            "        [0.2595, 0.2574, 0.2515, 0.2316],\n",
            "        [0.2598, 0.2553, 0.2518, 0.2330]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2487, 0.2606, 0.2544, 0.2363],\n",
            "        [0.2481, 0.2600, 0.2551, 0.2369],\n",
            "        [0.2540, 0.2593, 0.2542, 0.2325],\n",
            "        [0.2604, 0.2572, 0.2513, 0.2311],\n",
            "        [0.2604, 0.2553, 0.2517, 0.2327]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2487, 0.2607, 0.2545, 0.2362],\n",
            "        [0.2481, 0.2601, 0.2551, 0.2367],\n",
            "        [0.2545, 0.2591, 0.2540, 0.2324],\n",
            "        [0.2608, 0.2573, 0.2512, 0.2307],\n",
            "        [0.2608, 0.2552, 0.2516, 0.2323]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2493, 0.2607, 0.2543, 0.2357],\n",
            "        [0.2488, 0.2600, 0.2549, 0.2362],\n",
            "        [0.2555, 0.2590, 0.2537, 0.2318],\n",
            "        [0.2619, 0.2571, 0.2509, 0.2302],\n",
            "        [0.2618, 0.2551, 0.2513, 0.2319]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2494, 0.2607, 0.2543, 0.2355],\n",
            "        [0.2493, 0.2599, 0.2548, 0.2361],\n",
            "        [0.2557, 0.2591, 0.2538, 0.2315],\n",
            "        [0.2624, 0.2570, 0.2508, 0.2298],\n",
            "        [0.2623, 0.2549, 0.2512, 0.2316]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2501, 0.2607, 0.2541, 0.2350],\n",
            "        [0.2500, 0.2598, 0.2546, 0.2356],\n",
            "        [0.2566, 0.2589, 0.2534, 0.2311],\n",
            "        [0.2636, 0.2566, 0.2504, 0.2294],\n",
            "        [0.2632, 0.2548, 0.2509, 0.2310]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2502, 0.2607, 0.2542, 0.2349],\n",
            "        [0.2500, 0.2598, 0.2546, 0.2355],\n",
            "        [0.2569, 0.2588, 0.2533, 0.2310],\n",
            "        [0.2637, 0.2567, 0.2504, 0.2292],\n",
            "        [0.2633, 0.2548, 0.2510, 0.2309]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2508, 0.2605, 0.2539, 0.2347],\n",
            "        [0.2504, 0.2599, 0.2546, 0.2351],\n",
            "        [0.2573, 0.2589, 0.2533, 0.2305],\n",
            "        [0.2647, 0.2566, 0.2501, 0.2286],\n",
            "        [0.2639, 0.2548, 0.2509, 0.2304]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2509, 0.2608, 0.2540, 0.2343],\n",
            "        [0.2509, 0.2599, 0.2545, 0.2347],\n",
            "        [0.2577, 0.2589, 0.2533, 0.2301],\n",
            "        [0.2651, 0.2566, 0.2500, 0.2283],\n",
            "        [0.2645, 0.2549, 0.2508, 0.2298]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2513, 0.2608, 0.2540, 0.2339],\n",
            "        [0.2511, 0.2601, 0.2545, 0.2343],\n",
            "        [0.2581, 0.2590, 0.2533, 0.2296],\n",
            "        [0.2658, 0.2563, 0.2498, 0.2280],\n",
            "        [0.2649, 0.2548, 0.2507, 0.2295]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2516, 0.2608, 0.2539, 0.2336],\n",
            "        [0.2512, 0.2602, 0.2546, 0.2341],\n",
            "        [0.2584, 0.2590, 0.2532, 0.2293],\n",
            "        [0.2663, 0.2563, 0.2497, 0.2276],\n",
            "        [0.2653, 0.2549, 0.2507, 0.2292]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2526, 0.2606, 0.2536, 0.2332],\n",
            "        [0.2523, 0.2598, 0.2541, 0.2338],\n",
            "        [0.2592, 0.2588, 0.2529, 0.2292],\n",
            "        [0.2667, 0.2565, 0.2498, 0.2270],\n",
            "        [0.2663, 0.2547, 0.2504, 0.2286]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2521, 0.2608, 0.2538, 0.2332],\n",
            "        [0.2518, 0.2600, 0.2544, 0.2338],\n",
            "        [0.2590, 0.2589, 0.2531, 0.2290],\n",
            "        [0.2669, 0.2565, 0.2498, 0.2268],\n",
            "        [0.2665, 0.2547, 0.2504, 0.2285]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2525, 0.2608, 0.2537, 0.2331],\n",
            "        [0.2522, 0.2600, 0.2543, 0.2336],\n",
            "        [0.2591, 0.2591, 0.2531, 0.2287],\n",
            "        [0.2677, 0.2563, 0.2496, 0.2264],\n",
            "        [0.2675, 0.2544, 0.2501, 0.2280]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2528, 0.2607, 0.2536, 0.2329],\n",
            "        [0.2524, 0.2600, 0.2543, 0.2332],\n",
            "        [0.2595, 0.2591, 0.2531, 0.2283],\n",
            "        [0.2683, 0.2562, 0.2494, 0.2261],\n",
            "        [0.2679, 0.2544, 0.2500, 0.2277]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2533, 0.2606, 0.2534, 0.2327],\n",
            "        [0.2530, 0.2599, 0.2542, 0.2329],\n",
            "        [0.2600, 0.2591, 0.2530, 0.2279],\n",
            "        [0.2690, 0.2560, 0.2492, 0.2258],\n",
            "        [0.2685, 0.2543, 0.2499, 0.2273]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2533, 0.2607, 0.2535, 0.2325],\n",
            "        [0.2531, 0.2600, 0.2542, 0.2326],\n",
            "        [0.2602, 0.2592, 0.2531, 0.2276],\n",
            "        [0.2694, 0.2561, 0.2492, 0.2253],\n",
            "        [0.2690, 0.2543, 0.2498, 0.2269]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2532, 0.2608, 0.2535, 0.2325],\n",
            "        [0.2530, 0.2601, 0.2543, 0.2326],\n",
            "        [0.2600, 0.2593, 0.2532, 0.2275],\n",
            "        [0.2695, 0.2561, 0.2492, 0.2252],\n",
            "        [0.2689, 0.2544, 0.2499, 0.2268]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2532, 0.2609, 0.2536, 0.2324],\n",
            "        [0.2529, 0.2603, 0.2544, 0.2324],\n",
            "        [0.2603, 0.2593, 0.2531, 0.2272],\n",
            "        [0.2698, 0.2562, 0.2492, 0.2248],\n",
            "        [0.2696, 0.2543, 0.2497, 0.2264]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2535, 0.2608, 0.2535, 0.2321],\n",
            "        [0.2532, 0.2604, 0.2544, 0.2320],\n",
            "        [0.2611, 0.2591, 0.2529, 0.2269],\n",
            "        [0.2705, 0.2561, 0.2490, 0.2245],\n",
            "        [0.2701, 0.2542, 0.2496, 0.2261]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2537, 0.2610, 0.2536, 0.2317],\n",
            "        [0.2540, 0.2601, 0.2543, 0.2316],\n",
            "        [0.2615, 0.2591, 0.2529, 0.2265],\n",
            "        [0.2713, 0.2558, 0.2488, 0.2241],\n",
            "        [0.2709, 0.2541, 0.2494, 0.2256]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2539, 0.2611, 0.2536, 0.2314],\n",
            "        [0.2543, 0.2602, 0.2542, 0.2314],\n",
            "        [0.2620, 0.2591, 0.2527, 0.2262],\n",
            "        [0.2721, 0.2556, 0.2485, 0.2238],\n",
            "        [0.2714, 0.2540, 0.2493, 0.2253]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2540, 0.2611, 0.2536, 0.2313],\n",
            "        [0.2545, 0.2602, 0.2542, 0.2312],\n",
            "        [0.2624, 0.2590, 0.2527, 0.2259],\n",
            "        [0.2725, 0.2556, 0.2484, 0.2235],\n",
            "        [0.2719, 0.2540, 0.2492, 0.2250]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2540, 0.2612, 0.2537, 0.2311],\n",
            "        [0.2546, 0.2601, 0.2541, 0.2312],\n",
            "        [0.2622, 0.2592, 0.2528, 0.2258],\n",
            "        [0.2727, 0.2556, 0.2484, 0.2233],\n",
            "        [0.2725, 0.2538, 0.2490, 0.2247]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2540, 0.2613, 0.2537, 0.2310],\n",
            "        [0.2547, 0.2602, 0.2541, 0.2309],\n",
            "        [0.2626, 0.2591, 0.2526, 0.2256],\n",
            "        [0.2729, 0.2556, 0.2484, 0.2230],\n",
            "        [0.2728, 0.2538, 0.2489, 0.2245]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2543, 0.2612, 0.2536, 0.2309],\n",
            "        [0.2550, 0.2601, 0.2541, 0.2308],\n",
            "        [0.2630, 0.2591, 0.2525, 0.2254],\n",
            "        [0.2736, 0.2555, 0.2482, 0.2227],\n",
            "        [0.2737, 0.2536, 0.2487, 0.2241]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2547, 0.2611, 0.2535, 0.2307],\n",
            "        [0.2551, 0.2602, 0.2541, 0.2305],\n",
            "        [0.2632, 0.2591, 0.2525, 0.2252],\n",
            "        [0.2739, 0.2555, 0.2482, 0.2224],\n",
            "        [0.2741, 0.2536, 0.2486, 0.2238]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2548, 0.2612, 0.2535, 0.2306],\n",
            "        [0.2554, 0.2602, 0.2541, 0.2303],\n",
            "        [0.2637, 0.2590, 0.2524, 0.2249],\n",
            "        [0.2746, 0.2553, 0.2481, 0.2220],\n",
            "        [0.2747, 0.2535, 0.2484, 0.2234]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2551, 0.2611, 0.2534, 0.2304],\n",
            "        [0.2557, 0.2602, 0.2540, 0.2301],\n",
            "        [0.2640, 0.2590, 0.2523, 0.2247],\n",
            "        [0.2748, 0.2554, 0.2481, 0.2217],\n",
            "        [0.2751, 0.2534, 0.2482, 0.2233]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2553, 0.2611, 0.2534, 0.2302],\n",
            "        [0.2560, 0.2602, 0.2540, 0.2299],\n",
            "        [0.2642, 0.2590, 0.2523, 0.2245],\n",
            "        [0.2753, 0.2553, 0.2479, 0.2215],\n",
            "        [0.2757, 0.2533, 0.2481, 0.2229]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2558, 0.2610, 0.2532, 0.2300],\n",
            "        [0.2564, 0.2601, 0.2539, 0.2296],\n",
            "        [0.2646, 0.2589, 0.2522, 0.2243],\n",
            "        [0.2760, 0.2551, 0.2478, 0.2211],\n",
            "        [0.2764, 0.2531, 0.2479, 0.2226]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2557, 0.2613, 0.2534, 0.2296],\n",
            "        [0.2569, 0.2599, 0.2536, 0.2295],\n",
            "        [0.2647, 0.2591, 0.2523, 0.2240],\n",
            "        [0.2763, 0.2553, 0.2478, 0.2207],\n",
            "        [0.2771, 0.2530, 0.2477, 0.2222]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2558, 0.2613, 0.2534, 0.2295],\n",
            "        [0.2570, 0.2600, 0.2537, 0.2293],\n",
            "        [0.2651, 0.2590, 0.2522, 0.2238],\n",
            "        [0.2765, 0.2552, 0.2477, 0.2206],\n",
            "        [0.2771, 0.2530, 0.2477, 0.2222]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2562, 0.2612, 0.2533, 0.2293],\n",
            "        [0.2573, 0.2600, 0.2536, 0.2290],\n",
            "        [0.2657, 0.2588, 0.2520, 0.2235],\n",
            "        [0.2772, 0.2550, 0.2475, 0.2203],\n",
            "        [0.2778, 0.2529, 0.2475, 0.2218]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2565, 0.2611, 0.2532, 0.2292],\n",
            "        [0.2575, 0.2600, 0.2536, 0.2289],\n",
            "        [0.2659, 0.2588, 0.2519, 0.2234],\n",
            "        [0.2776, 0.2549, 0.2474, 0.2201],\n",
            "        [0.2786, 0.2526, 0.2472, 0.2215]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2565, 0.2614, 0.2533, 0.2289],\n",
            "        [0.2578, 0.2600, 0.2536, 0.2286],\n",
            "        [0.2660, 0.2590, 0.2520, 0.2230],\n",
            "        [0.2782, 0.2548, 0.2472, 0.2198],\n",
            "        [0.2788, 0.2527, 0.2472, 0.2212]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2570, 0.2612, 0.2531, 0.2287],\n",
            "        [0.2583, 0.2598, 0.2534, 0.2285],\n",
            "        [0.2664, 0.2588, 0.2519, 0.2229],\n",
            "        [0.2786, 0.2547, 0.2471, 0.2196],\n",
            "        [0.2793, 0.2527, 0.2472, 0.2208]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2571, 0.2613, 0.2531, 0.2286],\n",
            "        [0.2584, 0.2598, 0.2534, 0.2284],\n",
            "        [0.2668, 0.2587, 0.2517, 0.2228],\n",
            "        [0.2789, 0.2547, 0.2471, 0.2194],\n",
            "        [0.2797, 0.2526, 0.2470, 0.2207]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2577, 0.2611, 0.2529, 0.2282],\n",
            "        [0.2592, 0.2596, 0.2531, 0.2282],\n",
            "        [0.2672, 0.2587, 0.2517, 0.2224],\n",
            "        [0.2795, 0.2546, 0.2469, 0.2190],\n",
            "        [0.2805, 0.2524, 0.2468, 0.2203]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2573, 0.2614, 0.2531, 0.2282],\n",
            "        [0.2588, 0.2598, 0.2533, 0.2281],\n",
            "        [0.2672, 0.2587, 0.2517, 0.2224],\n",
            "        [0.2795, 0.2545, 0.2469, 0.2191],\n",
            "        [0.2805, 0.2525, 0.2468, 0.2203]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2579, 0.2612, 0.2529, 0.2280],\n",
            "        [0.2595, 0.2595, 0.2530, 0.2280],\n",
            "        [0.2678, 0.2585, 0.2514, 0.2222],\n",
            "        [0.2801, 0.2544, 0.2468, 0.2187],\n",
            "        [0.2814, 0.2522, 0.2465, 0.2199]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2576, 0.2614, 0.2531, 0.2279],\n",
            "        [0.2594, 0.2596, 0.2531, 0.2279],\n",
            "        [0.2674, 0.2588, 0.2517, 0.2221],\n",
            "        [0.2801, 0.2544, 0.2468, 0.2186],\n",
            "        [0.2817, 0.2521, 0.2464, 0.2197]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2583, 0.2612, 0.2529, 0.2277],\n",
            "        [0.2599, 0.2594, 0.2529, 0.2277],\n",
            "        [0.2681, 0.2586, 0.2514, 0.2219],\n",
            "        [0.2809, 0.2541, 0.2465, 0.2185],\n",
            "        [0.2821, 0.2521, 0.2464, 0.2194]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2585, 0.2611, 0.2528, 0.2276],\n",
            "        [0.2602, 0.2594, 0.2529, 0.2275],\n",
            "        [0.2685, 0.2585, 0.2514, 0.2217],\n",
            "        [0.2812, 0.2541, 0.2465, 0.2182],\n",
            "        [0.2826, 0.2520, 0.2462, 0.2192]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2588, 0.2611, 0.2527, 0.2274],\n",
            "        [0.2605, 0.2593, 0.2528, 0.2273],\n",
            "        [0.2691, 0.2583, 0.2511, 0.2215],\n",
            "        [0.2816, 0.2541, 0.2464, 0.2179],\n",
            "        [0.2831, 0.2519, 0.2461, 0.2190]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2587, 0.2612, 0.2528, 0.2273],\n",
            "        [0.2605, 0.2595, 0.2529, 0.2272],\n",
            "        [0.2690, 0.2584, 0.2512, 0.2214],\n",
            "        [0.2815, 0.2543, 0.2466, 0.2176],\n",
            "        [0.2835, 0.2518, 0.2459, 0.2187]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2591, 0.2611, 0.2526, 0.2271],\n",
            "        [0.2608, 0.2594, 0.2528, 0.2270],\n",
            "        [0.2695, 0.2583, 0.2510, 0.2211],\n",
            "        [0.2822, 0.2541, 0.2463, 0.2173],\n",
            "        [0.2841, 0.2518, 0.2458, 0.2183]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2592, 0.2611, 0.2526, 0.2271],\n",
            "        [0.2607, 0.2595, 0.2529, 0.2269],\n",
            "        [0.2697, 0.2583, 0.2511, 0.2209],\n",
            "        [0.2826, 0.2540, 0.2462, 0.2172],\n",
            "        [0.2845, 0.2516, 0.2457, 0.2182]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2593, 0.2612, 0.2526, 0.2269],\n",
            "        [0.2610, 0.2595, 0.2528, 0.2267],\n",
            "        [0.2700, 0.2584, 0.2510, 0.2207],\n",
            "        [0.2833, 0.2538, 0.2460, 0.2170],\n",
            "        [0.2850, 0.2515, 0.2455, 0.2180]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2596, 0.2611, 0.2526, 0.2268],\n",
            "        [0.2614, 0.2593, 0.2527, 0.2266],\n",
            "        [0.2701, 0.2583, 0.2510, 0.2206],\n",
            "        [0.2836, 0.2537, 0.2459, 0.2168],\n",
            "        [0.2857, 0.2513, 0.2453, 0.2177]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2600, 0.2610, 0.2524, 0.2266],\n",
            "        [0.2618, 0.2592, 0.2526, 0.2264],\n",
            "        [0.2707, 0.2581, 0.2508, 0.2204],\n",
            "        [0.2841, 0.2536, 0.2458, 0.2165],\n",
            "        [0.2864, 0.2511, 0.2451, 0.2175]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2600, 0.2610, 0.2524, 0.2265],\n",
            "        [0.2620, 0.2592, 0.2526, 0.2263],\n",
            "        [0.2710, 0.2580, 0.2506, 0.2203],\n",
            "        [0.2841, 0.2536, 0.2458, 0.2165],\n",
            "        [0.2866, 0.2511, 0.2450, 0.2172]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2601, 0.2611, 0.2524, 0.2264],\n",
            "        [0.2621, 0.2592, 0.2525, 0.2262],\n",
            "        [0.2710, 0.2581, 0.2507, 0.2202],\n",
            "        [0.2845, 0.2536, 0.2457, 0.2162],\n",
            "        [0.2871, 0.2510, 0.2449, 0.2170]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2604, 0.2610, 0.2523, 0.2263],\n",
            "        [0.2622, 0.2593, 0.2525, 0.2260],\n",
            "        [0.2714, 0.2580, 0.2506, 0.2200],\n",
            "        [0.2850, 0.2534, 0.2455, 0.2161],\n",
            "        [0.2874, 0.2510, 0.2448, 0.2168]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2609, 0.2609, 0.2522, 0.2261],\n",
            "        [0.2627, 0.2591, 0.2524, 0.2258],\n",
            "        [0.2719, 0.2579, 0.2504, 0.2198],\n",
            "        [0.2856, 0.2532, 0.2453, 0.2159],\n",
            "        [0.2879, 0.2508, 0.2446, 0.2166]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2610, 0.2609, 0.2521, 0.2260],\n",
            "        [0.2628, 0.2592, 0.2524, 0.2256],\n",
            "        [0.2720, 0.2579, 0.2504, 0.2196],\n",
            "        [0.2858, 0.2532, 0.2453, 0.2157],\n",
            "        [0.2883, 0.2508, 0.2445, 0.2164]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2610, 0.2608, 0.2521, 0.2260],\n",
            "        [0.2628, 0.2592, 0.2524, 0.2256],\n",
            "        [0.2720, 0.2580, 0.2505, 0.2196],\n",
            "        [0.2861, 0.2531, 0.2452, 0.2156],\n",
            "        [0.2886, 0.2506, 0.2444, 0.2164]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2612, 0.2608, 0.2521, 0.2259],\n",
            "        [0.2629, 0.2592, 0.2524, 0.2254],\n",
            "        [0.2722, 0.2579, 0.2504, 0.2195],\n",
            "        [0.2863, 0.2531, 0.2452, 0.2155],\n",
            "        [0.2891, 0.2505, 0.2443, 0.2161]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2613, 0.2608, 0.2521, 0.2258],\n",
            "        [0.2632, 0.2592, 0.2524, 0.2253],\n",
            "        [0.2726, 0.2578, 0.2503, 0.2193],\n",
            "        [0.2869, 0.2528, 0.2450, 0.2153],\n",
            "        [0.2897, 0.2503, 0.2441, 0.2159]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2614, 0.2608, 0.2520, 0.2258],\n",
            "        [0.2634, 0.2591, 0.2523, 0.2253],\n",
            "        [0.2727, 0.2577, 0.2502, 0.2193],\n",
            "        [0.2868, 0.2529, 0.2451, 0.2152],\n",
            "        [0.2899, 0.2503, 0.2440, 0.2157]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2616, 0.2607, 0.2520, 0.2257],\n",
            "        [0.2635, 0.2590, 0.2523, 0.2251],\n",
            "        [0.2729, 0.2577, 0.2502, 0.2191],\n",
            "        [0.2872, 0.2528, 0.2449, 0.2151],\n",
            "        [0.2902, 0.2503, 0.2439, 0.2156]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2619, 0.2606, 0.2519, 0.2256],\n",
            "        [0.2637, 0.2590, 0.2523, 0.2250],\n",
            "        [0.2733, 0.2576, 0.2501, 0.2190],\n",
            "        [0.2878, 0.2526, 0.2447, 0.2150],\n",
            "        [0.2907, 0.2501, 0.2438, 0.2154]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2621, 0.2606, 0.2518, 0.2255],\n",
            "        [0.2640, 0.2589, 0.2522, 0.2249],\n",
            "        [0.2733, 0.2577, 0.2501, 0.2189],\n",
            "        [0.2879, 0.2526, 0.2447, 0.2148],\n",
            "        [0.2909, 0.2501, 0.2437, 0.2152]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2624, 0.2605, 0.2517, 0.2253],\n",
            "        [0.2642, 0.2589, 0.2521, 0.2248],\n",
            "        [0.2736, 0.2576, 0.2501, 0.2187],\n",
            "        [0.2885, 0.2523, 0.2445, 0.2147],\n",
            "        [0.2913, 0.2500, 0.2436, 0.2150]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2624, 0.2605, 0.2518, 0.2253],\n",
            "        [0.2642, 0.2590, 0.2522, 0.2247],\n",
            "        [0.2738, 0.2576, 0.2500, 0.2187],\n",
            "        [0.2885, 0.2524, 0.2445, 0.2146],\n",
            "        [0.2917, 0.2499, 0.2435, 0.2149]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2625, 0.2606, 0.2517, 0.2252],\n",
            "        [0.2643, 0.2589, 0.2521, 0.2246],\n",
            "        [0.2740, 0.2575, 0.2499, 0.2186],\n",
            "        [0.2888, 0.2523, 0.2444, 0.2144],\n",
            "        [0.2919, 0.2499, 0.2434, 0.2148]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2628, 0.2605, 0.2516, 0.2251],\n",
            "        [0.2647, 0.2588, 0.2520, 0.2245],\n",
            "        [0.2742, 0.2575, 0.2499, 0.2185],\n",
            "        [0.2890, 0.2523, 0.2444, 0.2143],\n",
            "        [0.2922, 0.2498, 0.2433, 0.2146]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2630, 0.2604, 0.2516, 0.2251],\n",
            "        [0.2647, 0.2588, 0.2520, 0.2245],\n",
            "        [0.2743, 0.2575, 0.2498, 0.2184],\n",
            "        [0.2892, 0.2523, 0.2444, 0.2142],\n",
            "        [0.2926, 0.2498, 0.2432, 0.2144]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2632, 0.2603, 0.2515, 0.2250],\n",
            "        [0.2650, 0.2587, 0.2519, 0.2244],\n",
            "        [0.2745, 0.2574, 0.2498, 0.2183],\n",
            "        [0.2894, 0.2522, 0.2443, 0.2141],\n",
            "        [0.2930, 0.2496, 0.2430, 0.2144]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2633, 0.2603, 0.2515, 0.2249],\n",
            "        [0.2651, 0.2587, 0.2519, 0.2243],\n",
            "        [0.2746, 0.2574, 0.2498, 0.2182],\n",
            "        [0.2896, 0.2522, 0.2443, 0.2140],\n",
            "        [0.2931, 0.2496, 0.2430, 0.2143]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2633, 0.2603, 0.2515, 0.2249],\n",
            "        [0.2653, 0.2586, 0.2518, 0.2242],\n",
            "        [0.2748, 0.2574, 0.2497, 0.2181],\n",
            "        [0.2899, 0.2520, 0.2441, 0.2139],\n",
            "        [0.2935, 0.2494, 0.2429, 0.2142]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2636, 0.2602, 0.2514, 0.2248],\n",
            "        [0.2655, 0.2586, 0.2518, 0.2241],\n",
            "        [0.2751, 0.2573, 0.2496, 0.2180],\n",
            "        [0.2902, 0.2519, 0.2440, 0.2138],\n",
            "        [0.2938, 0.2493, 0.2428, 0.2141]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2636, 0.2602, 0.2514, 0.2247],\n",
            "        [0.2656, 0.2586, 0.2518, 0.2241],\n",
            "        [0.2749, 0.2574, 0.2497, 0.2179],\n",
            "        [0.2902, 0.2520, 0.2441, 0.2137],\n",
            "        [0.2940, 0.2493, 0.2427, 0.2139]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2637, 0.2602, 0.2514, 0.2247],\n",
            "        [0.2657, 0.2585, 0.2517, 0.2240],\n",
            "        [0.2751, 0.2573, 0.2496, 0.2179],\n",
            "        [0.2904, 0.2519, 0.2440, 0.2137],\n",
            "        [0.2942, 0.2493, 0.2427, 0.2139]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2637, 0.2602, 0.2514, 0.2246],\n",
            "        [0.2658, 0.2585, 0.2517, 0.2240],\n",
            "        [0.2753, 0.2573, 0.2496, 0.2178],\n",
            "        [0.2906, 0.2519, 0.2439, 0.2136],\n",
            "        [0.2946, 0.2492, 0.2425, 0.2137]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2639, 0.2602, 0.2514, 0.2245],\n",
            "        [0.2660, 0.2585, 0.2517, 0.2239],\n",
            "        [0.2755, 0.2572, 0.2495, 0.2178],\n",
            "        [0.2908, 0.2518, 0.2439, 0.2135],\n",
            "        [0.2948, 0.2491, 0.2425, 0.2136]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2640, 0.2602, 0.2513, 0.2245],\n",
            "        [0.2661, 0.2584, 0.2516, 0.2239],\n",
            "        [0.2756, 0.2572, 0.2495, 0.2177],\n",
            "        [0.2909, 0.2519, 0.2439, 0.2134],\n",
            "        [0.2949, 0.2491, 0.2425, 0.2135]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2640, 0.2602, 0.2513, 0.2245],\n",
            "        [0.2661, 0.2584, 0.2516, 0.2238],\n",
            "        [0.2756, 0.2572, 0.2495, 0.2177],\n",
            "        [0.2910, 0.2518, 0.2438, 0.2134],\n",
            "        [0.2951, 0.2490, 0.2424, 0.2135]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2640, 0.2602, 0.2513, 0.2244],\n",
            "        [0.2661, 0.2584, 0.2516, 0.2238],\n",
            "        [0.2756, 0.2572, 0.2495, 0.2177],\n",
            "        [0.2911, 0.2518, 0.2438, 0.2133],\n",
            "        [0.2952, 0.2490, 0.2423, 0.2135]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2641, 0.2602, 0.2513, 0.2244],\n",
            "        [0.2663, 0.2584, 0.2516, 0.2238],\n",
            "        [0.2757, 0.2572, 0.2495, 0.2176],\n",
            "        [0.2913, 0.2517, 0.2438, 0.2132],\n",
            "        [0.2954, 0.2490, 0.2423, 0.2134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2642, 0.2602, 0.2513, 0.2244],\n",
            "        [0.2663, 0.2584, 0.2516, 0.2237],\n",
            "        [0.2758, 0.2572, 0.2495, 0.2176],\n",
            "        [0.2914, 0.2517, 0.2437, 0.2132],\n",
            "        [0.2955, 0.2489, 0.2423, 0.2133]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2643, 0.2601, 0.2513, 0.2243],\n",
            "        [0.2664, 0.2584, 0.2516, 0.2237],\n",
            "        [0.2759, 0.2572, 0.2494, 0.2175],\n",
            "        [0.2915, 0.2517, 0.2437, 0.2132],\n",
            "        [0.2956, 0.2489, 0.2422, 0.2133]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2643, 0.2601, 0.2513, 0.2243],\n",
            "        [0.2664, 0.2584, 0.2515, 0.2237],\n",
            "        [0.2759, 0.2571, 0.2494, 0.2175],\n",
            "        [0.2915, 0.2517, 0.2437, 0.2131],\n",
            "        [0.2957, 0.2489, 0.2422, 0.2132]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2642, 0.2602, 0.2513, 0.2243],\n",
            "        [0.2664, 0.2584, 0.2515, 0.2237],\n",
            "        [0.2759, 0.2572, 0.2494, 0.2175],\n",
            "        [0.2915, 0.2517, 0.2437, 0.2131],\n",
            "        [0.2958, 0.2488, 0.2421, 0.2132]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2642, 0.2602, 0.2513, 0.2243],\n",
            "        [0.2664, 0.2584, 0.2515, 0.2237],\n",
            "        [0.2759, 0.2572, 0.2494, 0.2175],\n",
            "        [0.2916, 0.2517, 0.2437, 0.2131],\n",
            "        [0.2959, 0.2488, 0.2421, 0.2132]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2643, 0.2602, 0.2513, 0.2243],\n",
            "        [0.2665, 0.2584, 0.2515, 0.2236],\n",
            "        [0.2759, 0.2572, 0.2494, 0.2175],\n",
            "        [0.2916, 0.2516, 0.2437, 0.2131],\n",
            "        [0.2959, 0.2488, 0.2421, 0.2132]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2643, 0.2602, 0.2513, 0.2243],\n",
            "        [0.2665, 0.2583, 0.2515, 0.2236],\n",
            "        [0.2759, 0.2572, 0.2494, 0.2175],\n",
            "        [0.2916, 0.2516, 0.2437, 0.2131],\n",
            "        [0.2960, 0.2488, 0.2421, 0.2132]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN_ReLU --train_name truck_nas_project_layer_types_cycleGAN_ReLU --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 50 --n_epochs 100 --n_epochs_decay 100 --layer_types CycleGan+ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_Y0kMmr5ieY",
        "outputId": "38f77981-475c-4fae-9e24-e3984f444d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 50                            \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: PixelDa+ReLU                  \t[default: CycleGan]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_pixelDa_ReLU\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_pixelDa_ReLU\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 9.615 M\n",
            "[Network G_B] Total number of parameters : 9.615 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_pixelDa_ReLU/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.282, data: 0.216) D_A: 0.259 G_A: 0.472 cycle_A: 1.273 idt_A: 1.531 D_B: 0.857 G_B: 0.994 cycle_B: 3.388 idt_B: 0.442 \n",
            "End of epoch 1 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.283, data: 0.308) D_A: 0.258 G_A: 0.466 cycle_A: 0.926 idt_A: 1.088 D_B: 0.296 G_B: 0.367 cycle_B: 2.286 idt_B: 0.278 \n",
            "End of epoch 2 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.278, data: 0.327) D_A: 0.220 G_A: 0.289 cycle_A: 1.080 idt_A: 0.703 D_B: 0.227 G_B: 0.657 cycle_B: 1.972 idt_B: 0.388 \n",
            "End of epoch 3 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.534, data: 0.304) D_A: 0.185 G_A: 0.407 cycle_A: 1.031 idt_A: 1.268 D_B: 0.157 G_B: 0.582 cycle_B: 2.881 idt_B: 0.404 \n",
            "End of epoch 4 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.289, data: 0.292) D_A: 0.277 G_A: 0.304 cycle_A: 1.177 idt_A: 0.907 D_B: 0.100 G_B: 0.622 cycle_B: 2.284 idt_B: 0.344 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.284, data: 0.280) D_A: 0.177 G_A: 0.315 cycle_A: 0.832 idt_A: 1.317 D_B: 0.288 G_B: 0.443 cycle_B: 2.990 idt_B: 0.368 \n",
            "End of epoch 6 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.287, data: 0.299) D_A: 0.440 G_A: 0.628 cycle_A: 0.417 idt_A: 1.216 D_B: 0.307 G_B: 0.135 cycle_B: 3.047 idt_B: 0.162 \n",
            "End of epoch 7 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.557, data: 0.287) D_A: 0.307 G_A: 0.359 cycle_A: 0.587 idt_A: 1.470 D_B: 0.454 G_B: 0.061 cycle_B: 3.103 idt_B: 0.253 \n",
            "End of epoch 8 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.292, data: 0.290) D_A: 0.137 G_A: 0.431 cycle_A: 0.809 idt_A: 1.222 D_B: 0.242 G_B: 0.431 cycle_B: 3.277 idt_B: 0.230 \n",
            "End of epoch 9 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.297, data: 0.305) D_A: 0.276 G_A: 0.373 cycle_A: 0.428 idt_A: 0.730 D_B: 0.163 G_B: 0.838 cycle_B: 1.674 idt_B: 0.204 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.284, data: 0.314) D_A: 0.197 G_A: 0.606 cycle_A: 0.378 idt_A: 0.834 D_B: 0.097 G_B: 0.734 cycle_B: 2.535 idt_B: 0.167 \n",
            "End of epoch 11 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.545, data: 0.280) D_A: 0.163 G_A: 0.231 cycle_A: 0.538 idt_A: 0.769 D_B: 0.212 G_B: 0.326 cycle_B: 1.669 idt_B: 0.223 \n",
            "End of epoch 12 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.281, data: 0.294) D_A: 0.111 G_A: 0.250 cycle_A: 0.299 idt_A: 1.093 D_B: 0.054 G_B: 0.240 cycle_B: 2.731 idt_B: 0.151 \n",
            "End of epoch 13 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.284, data: 0.288) D_A: 0.165 G_A: 0.816 cycle_A: 0.644 idt_A: 0.586 D_B: 0.298 G_B: 0.125 cycle_B: 1.682 idt_B: 0.273 \n",
            "End of epoch 14 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.282, data: 0.306) D_A: 0.184 G_A: 0.677 cycle_A: 0.652 idt_A: 0.640 D_B: 0.135 G_B: 0.918 cycle_B: 1.716 idt_B: 0.249 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.587, data: 0.307) D_A: 0.272 G_A: 0.318 cycle_A: 1.049 idt_A: 0.695 D_B: 0.184 G_B: 1.476 cycle_B: 1.515 idt_B: 0.367 \n",
            "End of epoch 16 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.281, data: 0.309) D_A: 0.158 G_A: 0.154 cycle_A: 0.612 idt_A: 1.984 D_B: 0.219 G_B: 0.459 cycle_B: 4.205 idt_B: 0.204 \n",
            "End of epoch 17 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.282, data: 0.299) D_A: 0.169 G_A: 0.668 cycle_A: 0.831 idt_A: 0.999 D_B: 0.242 G_B: 0.299 cycle_B: 2.447 idt_B: 0.254 \n",
            "End of epoch 18 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.289, data: 0.270) D_A: 0.134 G_A: 0.334 cycle_A: 0.741 idt_A: 0.759 D_B: 0.343 G_B: 0.189 cycle_B: 1.472 idt_B: 0.283 \n",
            "End of epoch 19 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.609, data: 0.302) D_A: 0.171 G_A: 0.776 cycle_A: 0.868 idt_A: 0.755 D_B: 0.135 G_B: 0.124 cycle_B: 1.789 idt_B: 0.289 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.283, data: 0.306) D_A: 0.373 G_A: 0.940 cycle_A: 0.615 idt_A: 0.821 D_B: 0.313 G_B: 0.312 cycle_B: 1.870 idt_B: 0.100 \n",
            "End of epoch 21 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.284, data: 0.325) D_A: 0.191 G_A: 0.235 cycle_A: 0.427 idt_A: 0.794 D_B: 0.251 G_B: 0.316 cycle_B: 1.816 idt_B: 0.156 \n",
            "End of epoch 22 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.288, data: 0.280) D_A: 0.043 G_A: 0.606 cycle_A: 0.321 idt_A: 0.726 D_B: 0.177 G_B: 0.268 cycle_B: 1.644 idt_B: 0.099 \n",
            "End of epoch 23 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.616, data: 0.280) D_A: 0.228 G_A: 0.999 cycle_A: 0.427 idt_A: 1.154 D_B: 0.187 G_B: 0.626 cycle_B: 2.919 idt_B: 0.183 \n",
            "End of epoch 24 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.287, data: 0.293) D_A: 0.055 G_A: 0.369 cycle_A: 0.471 idt_A: 1.166 D_B: 0.179 G_B: 0.214 cycle_B: 2.533 idt_B: 0.195 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.283, data: 0.289) D_A: 0.232 G_A: 1.209 cycle_A: 0.370 idt_A: 0.561 D_B: 0.112 G_B: 0.482 cycle_B: 1.527 idt_B: 0.125 \n",
            "End of epoch 26 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.279, data: 0.318) D_A: 0.047 G_A: 0.919 cycle_A: 0.847 idt_A: 1.119 D_B: 0.099 G_B: 0.132 cycle_B: 2.716 idt_B: 0.189 \n",
            "End of epoch 27 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.647, data: 0.282) D_A: 0.068 G_A: 0.681 cycle_A: 0.500 idt_A: 0.729 D_B: 0.214 G_B: 0.822 cycle_B: 1.834 idt_B: 0.189 \n",
            "End of epoch 28 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.287, data: 0.281) D_A: 0.100 G_A: 0.248 cycle_A: 0.652 idt_A: 1.106 D_B: 0.070 G_B: 0.668 cycle_B: 3.297 idt_B: 0.244 \n",
            "End of epoch 29 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.279, data: 0.267) D_A: 0.101 G_A: 0.601 cycle_A: 0.575 idt_A: 1.023 D_B: 0.097 G_B: 0.555 cycle_B: 2.341 idt_B: 0.211 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.284, data: 0.281) D_A: 0.169 G_A: 0.278 cycle_A: 0.438 idt_A: 0.655 D_B: 0.158 G_B: 0.418 cycle_B: 1.806 idt_B: 0.158 \n",
            "End of epoch 31 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.698, data: 0.295) D_A: 0.242 G_A: 0.387 cycle_A: 0.396 idt_A: 0.761 D_B: 0.147 G_B: 0.521 cycle_B: 1.841 idt_B: 0.116 \n",
            "End of epoch 32 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.283, data: 0.298) D_A: 0.211 G_A: 0.772 cycle_A: 0.478 idt_A: 0.570 D_B: 0.111 G_B: 0.481 cycle_B: 1.493 idt_B: 0.328 \n",
            "End of epoch 33 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.290, data: 0.285) D_A: 0.053 G_A: 0.615 cycle_A: 0.382 idt_A: 0.909 D_B: 0.137 G_B: 0.702 cycle_B: 2.137 idt_B: 0.120 \n",
            "End of epoch 34 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.278, data: 0.292) D_A: 0.128 G_A: 0.499 cycle_A: 0.630 idt_A: 1.114 D_B: 0.350 G_B: 0.740 cycle_B: 3.222 idt_B: 0.207 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.698, data: 0.283) D_A: 0.038 G_A: 0.328 cycle_A: 0.720 idt_A: 0.996 D_B: 0.079 G_B: 0.619 cycle_B: 2.674 idt_B: 0.208 \n",
            "End of epoch 36 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.281, data: 0.310) D_A: 0.135 G_A: 0.631 cycle_A: 0.281 idt_A: 0.635 D_B: 0.361 G_B: 1.189 cycle_B: 1.506 idt_B: 0.115 \n",
            "End of epoch 37 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.281, data: 0.309) D_A: 0.038 G_A: 0.295 cycle_A: 0.497 idt_A: 0.481 D_B: 0.062 G_B: 0.725 cycle_B: 1.466 idt_B: 0.291 \n",
            "End of epoch 38 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.278, data: 0.286) D_A: 0.208 G_A: 1.061 cycle_A: 0.517 idt_A: 0.482 D_B: 0.074 G_B: 0.524 cycle_B: 1.236 idt_B: 0.194 \n",
            "End of epoch 39 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.701, data: 0.289) D_A: 0.313 G_A: 0.774 cycle_A: 0.380 idt_A: 0.836 D_B: 0.054 G_B: 0.872 cycle_B: 2.314 idt_B: 0.144 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.283, data: 0.290) D_A: 0.117 G_A: 0.746 cycle_A: 0.537 idt_A: 0.741 D_B: 0.299 G_B: 0.081 cycle_B: 1.742 idt_B: 0.169 \n",
            "End of epoch 41 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.285, data: 0.292) D_A: 0.092 G_A: 0.909 cycle_A: 0.578 idt_A: 0.846 D_B: 0.154 G_B: 0.658 cycle_B: 2.012 idt_B: 0.167 \n",
            "End of epoch 42 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.282, data: 0.307) D_A: 0.139 G_A: 0.524 cycle_A: 0.570 idt_A: 0.831 D_B: 0.063 G_B: 0.274 cycle_B: 2.020 idt_B: 0.217 \n",
            "End of epoch 43 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.724, data: 0.309) D_A: 0.058 G_A: 0.429 cycle_A: 1.186 idt_A: 0.567 D_B: 0.254 G_B: 0.143 cycle_B: 1.971 idt_B: 0.328 \n",
            "End of epoch 44 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.281, data: 0.286) D_A: 0.360 G_A: 0.056 cycle_A: 0.427 idt_A: 0.604 D_B: 0.076 G_B: 0.985 cycle_B: 1.884 idt_B: 0.136 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.280, data: 0.304) D_A: 0.075 G_A: 0.394 cycle_A: 0.491 idt_A: 0.806 D_B: 0.146 G_B: 0.461 cycle_B: 1.913 idt_B: 0.144 \n",
            "End of epoch 46 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.282, data: 0.286) D_A: 0.056 G_A: 0.269 cycle_A: 0.478 idt_A: 0.691 D_B: 0.057 G_B: 0.595 cycle_B: 2.812 idt_B: 0.190 \n",
            "End of epoch 47 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 0.992, data: 0.310) D_A: 0.115 G_A: 0.511 cycle_A: 0.457 idt_A: 0.861 D_B: 0.108 G_B: 0.378 cycle_B: 2.041 idt_B: 0.144 \n",
            "End of epoch 48 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.279, data: 0.299) D_A: 0.302 G_A: 0.662 cycle_A: 0.362 idt_A: 0.525 D_B: 0.044 G_B: 0.118 cycle_B: 1.594 idt_B: 0.123 \n",
            "End of epoch 49 / 200 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.278, data: 0.314) D_A: 0.120 G_A: 0.409 cycle_A: 0.410 idt_A: 0.510 D_B: 0.124 G_B: 0.837 cycle_B: 1.706 idt_B: 0.175 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.300, data: 0.317) D_A: 0.122 G_A: 0.381 cycle_A: 0.767 idt_A: 0.661 D_B: 0.234 G_B: 0.558 cycle_B: 1.407 idt_B: 0.300 \n",
            "End of epoch 51 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 0.858, data: 0.354) D_A: 0.197 G_A: 0.534 cycle_A: 0.631 idt_A: 0.787 D_B: 0.454 G_B: 1.031 cycle_B: 3.282 idt_B: 0.119 \n",
            "End of epoch 52 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.290, data: 0.358) D_A: 0.129 G_A: 0.995 cycle_A: 0.516 idt_A: 0.540 D_B: 0.280 G_B: 0.136 cycle_B: 1.441 idt_B: 0.119 \n",
            "End of epoch 53 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.288, data: 0.329) D_A: 0.170 G_A: 0.529 cycle_A: 0.283 idt_A: 0.578 D_B: 0.076 G_B: 0.823 cycle_B: 1.757 idt_B: 0.114 \n",
            "End of epoch 54 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.284, data: 0.355) D_A: 0.064 G_A: 0.306 cycle_A: 0.750 idt_A: 0.500 D_B: 0.159 G_B: 0.106 cycle_B: 1.584 idt_B: 0.213 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 100, time: 0.984, data: 0.335) D_A: 0.248 G_A: 0.978 cycle_A: 0.413 idt_A: 0.768 D_B: 0.181 G_B: 0.253 cycle_B: 2.479 idt_B: 0.177 \n",
            "End of epoch 56 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.272, data: 0.322) D_A: 0.221 G_A: 0.175 cycle_A: 0.475 idt_A: 0.552 D_B: 0.137 G_B: 0.372 cycle_B: 1.276 idt_B: 0.165 \n",
            "End of epoch 57 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.275, data: 0.342) D_A: 0.074 G_A: 0.596 cycle_A: 0.352 idt_A: 0.618 D_B: 0.114 G_B: 0.597 cycle_B: 1.827 idt_B: 0.099 \n",
            "End of epoch 58 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.273, data: 0.317) D_A: 0.030 G_A: 0.305 cycle_A: 0.317 idt_A: 0.446 D_B: 0.619 G_B: 1.228 cycle_B: 1.945 idt_B: 0.141 \n",
            "End of epoch 59 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.858, data: 0.321) D_A: 0.048 G_A: 0.763 cycle_A: 0.406 idt_A: 0.535 D_B: 0.240 G_B: 0.124 cycle_B: 1.226 idt_B: 0.167 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.280, data: 0.312) D_A: 0.119 G_A: 0.436 cycle_A: 0.410 idt_A: 0.600 D_B: 0.200 G_B: 0.360 cycle_B: 1.751 idt_B: 0.154 \n",
            "End of epoch 61 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.275, data: 0.323) D_A: 0.156 G_A: 0.140 cycle_A: 0.290 idt_A: 1.134 D_B: 0.238 G_B: 0.735 cycle_B: 2.843 idt_B: 0.110 \n",
            "End of epoch 62 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.272, data: 0.318) D_A: 0.219 G_A: 0.745 cycle_A: 0.450 idt_A: 0.373 D_B: 0.399 G_B: 1.158 cycle_B: 1.154 idt_B: 0.166 \n",
            "End of epoch 63 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 100, time: 1.091, data: 0.323) D_A: 0.073 G_A: 0.282 cycle_A: 0.476 idt_A: 0.710 D_B: 0.069 G_B: 0.431 cycle_B: 1.589 idt_B: 0.251 \n",
            "End of epoch 64 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.281, data: 0.324) D_A: 0.203 G_A: 0.289 cycle_A: 0.579 idt_A: 0.711 D_B: 0.064 G_B: 0.906 cycle_B: 2.635 idt_B: 0.225 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.296, data: 0.322) D_A: 0.199 G_A: 0.218 cycle_A: 0.921 idt_A: 0.669 D_B: 0.112 G_B: 0.423 cycle_B: 2.198 idt_B: 0.425 \n",
            "End of epoch 66 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.289, data: 0.367) D_A: 0.107 G_A: 0.292 cycle_A: 0.756 idt_A: 1.114 D_B: 0.089 G_B: 0.578 cycle_B: 3.004 idt_B: 0.150 \n",
            "End of epoch 67 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 100, time: 0.952, data: 0.344) D_A: 0.284 G_A: 0.488 cycle_A: 0.391 idt_A: 0.632 D_B: 0.156 G_B: 0.540 cycle_B: 1.789 idt_B: 0.137 \n",
            "End of epoch 68 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.286, data: 0.330) D_A: 0.165 G_A: 0.435 cycle_A: 0.472 idt_A: 0.568 D_B: 0.228 G_B: 0.596 cycle_B: 1.733 idt_B: 0.233 \n",
            "End of epoch 69 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.302, data: 0.336) D_A: 0.263 G_A: 0.134 cycle_A: 0.689 idt_A: 0.685 D_B: 0.491 G_B: 0.030 cycle_B: 2.346 idt_B: 0.286 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.295, data: 0.322) D_A: 0.090 G_A: 0.182 cycle_A: 0.464 idt_A: 0.481 D_B: 0.138 G_B: 0.206 cycle_B: 1.305 idt_B: 0.146 \n",
            "End of epoch 71 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 100, time: 1.151, data: 0.322) D_A: 0.111 G_A: 0.075 cycle_A: 0.247 idt_A: 0.714 D_B: 0.124 G_B: 0.399 cycle_B: 2.097 idt_B: 0.092 \n",
            "End of epoch 72 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.279, data: 0.339) D_A: 0.195 G_A: 0.508 cycle_A: 0.701 idt_A: 0.705 D_B: 0.112 G_B: 0.617 cycle_B: 1.901 idt_B: 0.161 \n",
            "End of epoch 73 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.272, data: 0.336) D_A: 0.054 G_A: 0.280 cycle_A: 0.517 idt_A: 0.747 D_B: 0.167 G_B: 1.504 cycle_B: 1.990 idt_B: 0.217 \n",
            "End of epoch 74 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.290, data: 0.357) D_A: 0.151 G_A: 0.605 cycle_A: 0.308 idt_A: 0.713 D_B: 0.122 G_B: 0.387 cycle_B: 1.809 idt_B: 0.096 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 100, time: 0.967, data: 0.336) D_A: 0.194 G_A: 0.160 cycle_A: 0.661 idt_A: 0.621 D_B: 0.158 G_B: 1.100 cycle_B: 1.021 idt_B: 0.228 \n",
            "End of epoch 76 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.292, data: 0.319) D_A: 0.092 G_A: 0.448 cycle_A: 0.669 idt_A: 0.689 D_B: 0.046 G_B: 1.213 cycle_B: 2.285 idt_B: 0.276 \n",
            "End of epoch 77 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.281, data: 0.333) D_A: 0.091 G_A: 0.337 cycle_A: 0.479 idt_A: 0.948 D_B: 0.215 G_B: 0.412 cycle_B: 2.416 idt_B: 0.205 \n",
            "End of epoch 78 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.281, data: 0.332) D_A: 0.102 G_A: 0.324 cycle_A: 0.268 idt_A: 0.672 D_B: 0.137 G_B: 0.832 cycle_B: 1.735 idt_B: 0.093 \n",
            "End of epoch 79 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 100, time: 0.970, data: 0.326) D_A: 0.167 G_A: 0.744 cycle_A: 0.344 idt_A: 0.739 D_B: 0.054 G_B: 0.555 cycle_B: 2.232 idt_B: 0.141 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 200 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.287, data: 0.330) D_A: 0.281 G_A: 1.189 cycle_A: 0.501 idt_A: 0.745 D_B: 0.114 G_B: 0.472 cycle_B: 1.763 idt_B: 0.180 \n",
            "End of epoch 81 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.276, data: 0.333) D_A: 0.141 G_A: 0.290 cycle_A: 0.346 idt_A: 0.456 D_B: 0.062 G_B: 0.671 cycle_B: 1.422 idt_B: 0.160 \n",
            "End of epoch 82 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.284, data: 0.323) D_A: 0.067 G_A: 0.204 cycle_A: 0.274 idt_A: 0.867 D_B: 0.117 G_B: 0.314 cycle_B: 1.928 idt_B: 0.122 \n",
            "End of epoch 83 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 100, time: 1.013, data: 0.320) D_A: 0.079 G_A: 0.581 cycle_A: 0.296 idt_A: 0.762 D_B: 0.248 G_B: 0.198 cycle_B: 1.589 idt_B: 0.123 \n",
            "End of epoch 84 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.273, data: 0.337) D_A: 0.329 G_A: 0.114 cycle_A: 0.423 idt_A: 0.702 D_B: 0.034 G_B: 0.807 cycle_B: 1.557 idt_B: 0.116 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.274, data: 0.312) D_A: 0.168 G_A: 0.270 cycle_A: 0.626 idt_A: 0.583 D_B: 0.095 G_B: 1.059 cycle_B: 2.234 idt_B: 0.316 \n",
            "End of epoch 86 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.272, data: 0.323) D_A: 0.254 G_A: 0.167 cycle_A: 0.454 idt_A: 0.822 D_B: 0.061 G_B: 0.932 cycle_B: 2.385 idt_B: 0.128 \n",
            "End of epoch 87 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 100, time: 0.989, data: 0.336) D_A: 0.156 G_A: 0.661 cycle_A: 0.353 idt_A: 0.769 D_B: 0.028 G_B: 0.272 cycle_B: 2.014 idt_B: 0.124 \n",
            "End of epoch 88 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.274, data: 0.322) D_A: 0.118 G_A: 0.399 cycle_A: 0.344 idt_A: 0.395 D_B: 0.167 G_B: 0.975 cycle_B: 1.172 idt_B: 0.145 \n",
            "End of epoch 89 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.270, data: 0.309) D_A: 0.220 G_A: 0.315 cycle_A: 0.304 idt_A: 0.653 D_B: 0.192 G_B: 0.880 cycle_B: 1.951 idt_B: 0.095 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.272, data: 0.307) D_A: 0.105 G_A: 0.401 cycle_A: 0.249 idt_A: 0.860 D_B: 0.142 G_B: 0.313 cycle_B: 2.209 idt_B: 0.077 \n",
            "End of epoch 91 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 100, time: 1.212, data: 0.310) D_A: 0.097 G_A: 0.532 cycle_A: 0.624 idt_A: 0.736 D_B: 0.117 G_B: 0.772 cycle_B: 2.136 idt_B: 0.281 \n",
            "End of epoch 92 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.273, data: 0.321) D_A: 0.069 G_A: 0.581 cycle_A: 0.425 idt_A: 0.541 D_B: 0.076 G_B: 0.797 cycle_B: 2.222 idt_B: 0.096 \n",
            "End of epoch 93 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.287, data: 0.316) D_A: 0.318 G_A: 0.090 cycle_A: 0.731 idt_A: 1.321 D_B: 0.182 G_B: 0.915 cycle_B: 2.350 idt_B: 0.201 \n",
            "End of epoch 94 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.275, data: 0.334) D_A: 0.197 G_A: 1.354 cycle_A: 0.405 idt_A: 0.591 D_B: 0.027 G_B: 0.411 cycle_B: 1.715 idt_B: 0.212 \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 100, time: 1.129, data: 0.338) D_A: 0.284 G_A: 0.894 cycle_A: 0.720 idt_A: 0.674 D_B: 0.147 G_B: 0.517 cycle_B: 1.826 idt_B: 0.240 \n",
            "End of epoch 96 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.273, data: 0.334) D_A: 0.097 G_A: 0.605 cycle_A: 0.438 idt_A: 0.538 D_B: 0.145 G_B: 0.671 cycle_B: 1.431 idt_B: 0.169 \n",
            "End of epoch 97 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.275, data: 0.339) D_A: 0.127 G_A: 0.511 cycle_A: 0.830 idt_A: 0.623 D_B: 0.149 G_B: 1.034 cycle_B: 1.632 idt_B: 0.234 \n",
            "End of epoch 98 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.284, data: 0.310) D_A: 0.218 G_A: 0.268 cycle_A: 0.214 idt_A: 0.670 D_B: 0.157 G_B: 1.512 cycle_B: 1.448 idt_B: 0.077 \n",
            "End of epoch 99 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 100, time: 1.087, data: 0.325) D_A: 0.307 G_A: 0.112 cycle_A: 0.386 idt_A: 1.141 D_B: 0.100 G_B: 0.838 cycle_B: 2.743 idt_B: 0.129 \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.271, data: 0.312) D_A: 0.032 G_A: 0.463 cycle_A: 0.466 idt_A: 0.476 D_B: 0.175 G_B: 0.271 cycle_B: 1.476 idt_B: 0.200 \n",
            "End of epoch 101 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 100, time: 0.277, data: 0.313) D_A: 0.225 G_A: 0.216 cycle_A: 0.614 idt_A: 0.690 D_B: 0.094 G_B: 0.681 cycle_B: 2.285 idt_B: 0.192 \n",
            "End of epoch 102 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 100, time: 0.273, data: 0.310) D_A: 0.151 G_A: 0.524 cycle_A: 0.278 idt_A: 0.532 D_B: 0.090 G_B: 0.896 cycle_B: 1.811 idt_B: 0.090 \n",
            "End of epoch 103 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 100, time: 1.316, data: 0.319) D_A: 0.113 G_A: 0.584 cycle_A: 0.366 idt_A: 0.545 D_B: 0.058 G_B: 0.612 cycle_B: 1.256 idt_B: 0.185 \n",
            "End of epoch 104 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 100, time: 0.280, data: 0.297) D_A: 0.185 G_A: 0.613 cycle_A: 0.448 idt_A: 0.418 D_B: 0.256 G_B: 0.507 cycle_B: 1.135 idt_B: 0.152 \n",
            "saving the model at the end of epoch 105, iters 10500\n",
            "End of epoch 105 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 100, time: 0.274, data: 0.320) D_A: 0.176 G_A: 0.754 cycle_A: 0.456 idt_A: 0.608 D_B: 0.069 G_B: 0.694 cycle_B: 1.495 idt_B: 0.236 \n",
            "End of epoch 106 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 100, time: 0.272, data: 0.316) D_A: 0.339 G_A: 0.076 cycle_A: 0.591 idt_A: 0.468 D_B: 0.132 G_B: 0.371 cycle_B: 1.375 idt_B: 0.247 \n",
            "End of epoch 107 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 100, time: 1.135, data: 0.305) D_A: 0.063 G_A: 0.609 cycle_A: 0.895 idt_A: 1.172 D_B: 0.127 G_B: 0.667 cycle_B: 3.232 idt_B: 0.142 \n",
            "End of epoch 108 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 100, time: 0.276, data: 0.309) D_A: 0.215 G_A: 0.272 cycle_A: 0.621 idt_A: 0.557 D_B: 0.097 G_B: 0.980 cycle_B: 2.559 idt_B: 0.197 \n",
            "End of epoch 109 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.271, data: 0.314) D_A: 0.115 G_A: 0.764 cycle_A: 0.419 idt_A: 0.907 D_B: 0.111 G_B: 0.646 cycle_B: 2.213 idt_B: 0.263 \n",
            "saving the model at the end of epoch 110, iters 11000\n",
            "End of epoch 110 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 100, time: 0.274, data: 0.304) D_A: 0.147 G_A: 0.652 cycle_A: 0.374 idt_A: 0.607 D_B: 0.199 G_B: 0.871 cycle_B: 1.955 idt_B: 0.111 \n",
            "End of epoch 111 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 100, time: 1.166, data: 0.305) D_A: 0.145 G_A: 0.283 cycle_A: 0.468 idt_A: 0.569 D_B: 0.114 G_B: 1.486 cycle_B: 1.889 idt_B: 0.079 \n",
            "End of epoch 112 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 100, time: 0.275, data: 0.307) D_A: 0.087 G_A: 0.595 cycle_A: 0.302 idt_A: 0.523 D_B: 0.336 G_B: 1.194 cycle_B: 1.522 idt_B: 0.116 \n",
            "End of epoch 113 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 100, time: 0.267, data: 0.316) D_A: 0.123 G_A: 0.442 cycle_A: 0.363 idt_A: 0.726 D_B: 0.145 G_B: 1.711 cycle_B: 1.782 idt_B: 0.088 \n",
            "End of epoch 114 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 100, time: 0.282, data: 0.315) D_A: 0.160 G_A: 0.388 cycle_A: 0.201 idt_A: 0.440 D_B: 0.062 G_B: 0.616 cycle_B: 1.564 idt_B: 0.083 \n",
            "saving the model at the end of epoch 115, iters 11500\n",
            "End of epoch 115 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 100, time: 1.377, data: 0.310) D_A: 0.086 G_A: 0.400 cycle_A: 0.492 idt_A: 0.475 D_B: 0.087 G_B: 0.678 cycle_B: 1.550 idt_B: 0.163 \n",
            "End of epoch 116 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 100, time: 0.280, data: 0.311) D_A: 0.105 G_A: 0.436 cycle_A: 0.398 idt_A: 0.630 D_B: 0.045 G_B: 0.217 cycle_B: 1.711 idt_B: 0.117 \n",
            "End of epoch 117 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 100, time: 0.281, data: 0.339) D_A: 0.281 G_A: 0.160 cycle_A: 0.418 idt_A: 0.450 D_B: 0.234 G_B: 0.381 cycle_B: 1.416 idt_B: 0.108 \n",
            "End of epoch 118 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 100, time: 0.283, data: 0.309) D_A: 0.097 G_A: 0.455 cycle_A: 0.414 idt_A: 0.547 D_B: 0.064 G_B: 0.358 cycle_B: 1.561 idt_B: 0.128 \n",
            "End of epoch 119 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 100, time: 1.248, data: 0.309) D_A: 0.276 G_A: 0.136 cycle_A: 0.379 idt_A: 0.608 D_B: 0.022 G_B: 0.924 cycle_B: 1.461 idt_B: 0.189 \n",
            "saving the model at the end of epoch 120, iters 12000\n",
            "End of epoch 120 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 100, time: 0.274, data: 0.335) D_A: 0.287 G_A: 0.159 cycle_A: 0.330 idt_A: 0.417 D_B: 0.130 G_B: 0.136 cycle_B: 1.058 idt_B: 0.109 \n",
            "End of epoch 121 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 100, time: 0.275, data: 0.312) D_A: 0.124 G_A: 0.455 cycle_A: 0.367 idt_A: 0.537 D_B: 0.138 G_B: 1.140 cycle_B: 1.857 idt_B: 0.130 \n",
            "End of epoch 122 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 100, time: 0.285, data: 0.332) D_A: 0.229 G_A: 0.524 cycle_A: 0.529 idt_A: 0.348 D_B: 0.114 G_B: 0.392 cycle_B: 1.029 idt_B: 0.199 \n",
            "End of epoch 123 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 100, time: 1.210, data: 0.315) D_A: 0.197 G_A: 0.277 cycle_A: 0.318 idt_A: 0.625 D_B: 0.091 G_B: 0.730 cycle_B: 1.513 idt_B: 0.074 \n",
            "End of epoch 124 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 100, time: 0.273, data: 0.328) D_A: 0.118 G_A: 0.583 cycle_A: 0.390 idt_A: 0.537 D_B: 0.064 G_B: 0.483 cycle_B: 1.709 idt_B: 0.116 \n",
            "saving the model at the end of epoch 125, iters 12500\n",
            "End of epoch 125 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 100, time: 0.276, data: 0.315) D_A: 0.097 G_A: 0.270 cycle_A: 0.437 idt_A: 0.377 D_B: 0.100 G_B: 0.386 cycle_B: 1.152 idt_B: 0.151 \n",
            "End of epoch 126 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 100, time: 0.277, data: 0.334) D_A: 0.375 G_A: 0.483 cycle_A: 0.457 idt_A: 0.654 D_B: 0.149 G_B: 0.232 cycle_B: 1.541 idt_B: 0.160 \n",
            "End of epoch 127 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 100, time: 1.504, data: 0.336) D_A: 0.121 G_A: 0.284 cycle_A: 0.323 idt_A: 0.549 D_B: 0.119 G_B: 0.522 cycle_B: 1.592 idt_B: 0.108 \n",
            "End of epoch 128 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 100, time: 0.271, data: 0.336) D_A: 0.113 G_A: 0.452 cycle_A: 0.487 idt_A: 0.402 D_B: 0.193 G_B: 1.334 cycle_B: 1.261 idt_B: 0.182 \n",
            "End of epoch 129 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 100, time: 0.278, data: 0.308) D_A: 0.250 G_A: 0.480 cycle_A: 0.415 idt_A: 0.708 D_B: 0.048 G_B: 0.775 cycle_B: 1.721 idt_B: 0.171 \n",
            "saving the model at the end of epoch 130, iters 13000\n",
            "End of epoch 130 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 100, time: 0.273, data: 0.320) D_A: 0.232 G_A: 0.187 cycle_A: 0.383 idt_A: 0.725 D_B: 0.094 G_B: 0.937 cycle_B: 1.535 idt_B: 0.082 \n",
            "End of epoch 131 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 100, time: 1.306, data: 0.327) D_A: 0.070 G_A: 0.822 cycle_A: 0.303 idt_A: 0.482 D_B: 0.227 G_B: 1.008 cycle_B: 1.728 idt_B: 0.165 \n",
            "End of epoch 132 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 100, time: 0.280, data: 0.307) D_A: 0.084 G_A: 0.838 cycle_A: 0.336 idt_A: 0.764 D_B: 0.119 G_B: 0.279 cycle_B: 2.110 idt_B: 0.099 \n",
            "End of epoch 133 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 100, time: 0.275, data: 0.305) D_A: 0.192 G_A: 0.205 cycle_A: 0.454 idt_A: 0.557 D_B: 0.089 G_B: 0.670 cycle_B: 1.353 idt_B: 0.198 \n",
            "End of epoch 134 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 100, time: 0.281, data: 0.319) D_A: 0.244 G_A: 0.572 cycle_A: 0.323 idt_A: 0.479 D_B: 0.273 G_B: 0.133 cycle_B: 1.399 idt_B: 0.110 \n",
            "saving the model at the end of epoch 135, iters 13500\n",
            "End of epoch 135 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 100, time: 1.364, data: 0.317) D_A: 0.323 G_A: 0.765 cycle_A: 0.524 idt_A: 0.396 D_B: 0.207 G_B: 0.085 cycle_B: 1.117 idt_B: 0.139 \n",
            "End of epoch 136 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 100, time: 0.281, data: 0.323) D_A: 0.120 G_A: 0.222 cycle_A: 0.348 idt_A: 0.530 D_B: 0.220 G_B: 1.185 cycle_B: 1.289 idt_B: 0.131 \n",
            "End of epoch 137 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 100, time: 0.276, data: 0.321) D_A: 0.102 G_A: 0.487 cycle_A: 0.499 idt_A: 0.389 D_B: 0.083 G_B: 0.787 cycle_B: 1.004 idt_B: 0.143 \n",
            "End of epoch 138 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 100, time: 0.279, data: 0.322) D_A: 0.048 G_A: 0.406 cycle_A: 0.277 idt_A: 0.537 D_B: 0.255 G_B: 0.170 cycle_B: 1.459 idt_B: 0.090 \n",
            "End of epoch 139 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 100, time: 1.312, data: 0.316) D_A: 0.031 G_A: 0.467 cycle_A: 0.324 idt_A: 0.505 D_B: 0.054 G_B: 0.893 cycle_B: 1.364 idt_B: 0.097 \n",
            "saving the model at the end of epoch 140, iters 14000\n",
            "End of epoch 140 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 0.275, data: 0.333) D_A: 0.126 G_A: 0.895 cycle_A: 0.441 idt_A: 0.616 D_B: 0.052 G_B: 0.322 cycle_B: 1.717 idt_B: 0.132 \n",
            "End of epoch 141 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 100, time: 0.278, data: 0.317) D_A: 0.093 G_A: 0.803 cycle_A: 0.257 idt_A: 0.300 D_B: 0.159 G_B: 0.482 cycle_B: 0.825 idt_B: 0.149 \n",
            "End of epoch 142 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 100, time: 0.275, data: 0.316) D_A: 0.075 G_A: 0.689 cycle_A: 0.272 idt_A: 0.559 D_B: 0.050 G_B: 0.585 cycle_B: 1.453 idt_B: 0.091 \n",
            "End of epoch 143 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 100, time: 1.494, data: 0.298) D_A: 0.117 G_A: 0.490 cycle_A: 0.508 idt_A: 0.435 D_B: 0.148 G_B: 0.327 cycle_B: 1.527 idt_B: 0.154 \n",
            "End of epoch 144 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 100, time: 0.276, data: 0.318) D_A: 0.153 G_A: 0.846 cycle_A: 0.417 idt_A: 0.506 D_B: 0.086 G_B: 0.420 cycle_B: 1.357 idt_B: 0.189 \n",
            "saving the model at the end of epoch 145, iters 14500\n",
            "End of epoch 145 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 100, time: 0.271, data: 0.305) D_A: 0.203 G_A: 0.339 cycle_A: 0.435 idt_A: 0.469 D_B: 0.196 G_B: 0.253 cycle_B: 1.271 idt_B: 0.147 \n",
            "End of epoch 146 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 100, time: 0.271, data: 0.304) D_A: 0.114 G_A: 0.548 cycle_A: 0.321 idt_A: 0.487 D_B: 0.100 G_B: 0.538 cycle_B: 1.412 idt_B: 0.124 \n",
            "End of epoch 147 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 100, time: 1.529, data: 0.304) D_A: 0.082 G_A: 0.598 cycle_A: 0.343 idt_A: 0.440 D_B: 0.098 G_B: 0.270 cycle_B: 1.385 idt_B: 0.085 \n",
            "End of epoch 148 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 100, time: 0.272, data: 0.316) D_A: 0.094 G_A: 0.729 cycle_A: 0.261 idt_A: 0.528 D_B: 0.064 G_B: 0.806 cycle_B: 1.508 idt_B: 0.091 \n",
            "End of epoch 149 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 100, time: 0.282, data: 0.312) D_A: 0.222 G_A: 0.408 cycle_A: 0.436 idt_A: 0.714 D_B: 0.103 G_B: 0.649 cycle_B: 1.873 idt_B: 0.128 \n",
            "saving the latest model (epoch 150, total_iters 15000)\n",
            "saving the model at the end of epoch 150, iters 15000\n",
            "End of epoch 150 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 100, time: 0.279, data: 0.315) D_A: 0.135 G_A: 0.758 cycle_A: 0.531 idt_A: 0.393 D_B: 0.059 G_B: 0.651 cycle_B: 1.026 idt_B: 0.195 \n",
            "End of epoch 151 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 100, time: 1.384, data: 0.320) D_A: 0.055 G_A: 0.570 cycle_A: 0.273 idt_A: 0.438 D_B: 0.045 G_B: 0.471 cycle_B: 1.297 idt_B: 0.097 \n",
            "End of epoch 152 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 100, time: 0.273, data: 0.332) D_A: 0.124 G_A: 0.525 cycle_A: 0.406 idt_A: 0.833 D_B: 0.056 G_B: 0.210 cycle_B: 1.239 idt_B: 0.148 \n",
            "End of epoch 153 / 200 \t Time Taken: 25 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 100, time: 0.274, data: 0.303) D_A: 0.218 G_A: 0.247 cycle_A: 0.440 idt_A: 0.795 D_B: 0.195 G_B: 0.318 cycle_B: 1.597 idt_B: 0.142 \n",
            "End of epoch 154 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 100, time: 0.274, data: 0.325) D_A: 0.140 G_A: 0.148 cycle_A: 0.531 idt_A: 0.431 D_B: 0.065 G_B: 0.597 cycle_B: 1.303 idt_B: 0.157 \n",
            "saving the model at the end of epoch 155, iters 15500\n",
            "End of epoch 155 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 100, time: 1.427, data: 0.306) D_A: 0.188 G_A: 0.273 cycle_A: 0.385 idt_A: 0.425 D_B: 0.123 G_B: 0.484 cycle_B: 1.195 idt_B: 0.111 \n",
            "End of epoch 156 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 100, time: 0.271, data: 0.317) D_A: 0.150 G_A: 0.448 cycle_A: 0.414 idt_A: 0.649 D_B: 0.086 G_B: 0.829 cycle_B: 1.623 idt_B: 0.124 \n",
            "End of epoch 157 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 100, time: 0.282, data: 0.310) D_A: 0.065 G_A: 0.326 cycle_A: 0.531 idt_A: 0.476 D_B: 0.202 G_B: 0.296 cycle_B: 1.160 idt_B: 0.155 \n",
            "End of epoch 158 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 100, time: 0.273, data: 0.317) D_A: 0.111 G_A: 0.278 cycle_A: 0.285 idt_A: 0.516 D_B: 0.098 G_B: 0.233 cycle_B: 1.396 idt_B: 0.081 \n",
            "End of epoch 159 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 1.683, data: 0.340) D_A: 0.270 G_A: 0.270 cycle_A: 0.340 idt_A: 0.394 D_B: 0.188 G_B: 0.654 cycle_B: 1.006 idt_B: 0.126 \n",
            "saving the model at the end of epoch 160, iters 16000\n",
            "End of epoch 160 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 100, time: 0.275, data: 0.318) D_A: 0.077 G_A: 0.373 cycle_A: 0.384 idt_A: 0.614 D_B: 0.066 G_B: 0.607 cycle_B: 1.439 idt_B: 0.113 \n",
            "End of epoch 161 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 100, time: 0.285, data: 0.327) D_A: 0.110 G_A: 0.580 cycle_A: 0.292 idt_A: 0.357 D_B: 0.109 G_B: 0.554 cycle_B: 1.141 idt_B: 0.072 \n",
            "End of epoch 162 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 100, time: 0.267, data: 0.321) D_A: 0.043 G_A: 0.674 cycle_A: 0.254 idt_A: 0.422 D_B: 0.193 G_B: 1.076 cycle_B: 1.054 idt_B: 0.086 \n",
            "End of epoch 163 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 100, time: 1.605, data: 0.309) D_A: 0.026 G_A: 0.262 cycle_A: 0.432 idt_A: 0.526 D_B: 0.049 G_B: 0.593 cycle_B: 1.424 idt_B: 0.139 \n",
            "End of epoch 164 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 100, time: 0.280, data: 0.302) D_A: 0.064 G_A: 0.308 cycle_A: 0.373 idt_A: 0.391 D_B: 0.155 G_B: 0.254 cycle_B: 1.154 idt_B: 0.138 \n",
            "saving the model at the end of epoch 165, iters 16500\n",
            "End of epoch 165 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 0.280, data: 0.315) D_A: 0.042 G_A: 0.537 cycle_A: 0.214 idt_A: 0.516 D_B: 0.104 G_B: 0.351 cycle_B: 1.414 idt_B: 0.070 \n",
            "End of epoch 166 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 100, time: 0.275, data: 0.307) D_A: 0.071 G_A: 0.681 cycle_A: 0.281 idt_A: 0.643 D_B: 0.064 G_B: 0.781 cycle_B: 1.767 idt_B: 0.083 \n",
            "End of epoch 167 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 100, time: 1.495, data: 0.324) D_A: 0.077 G_A: 0.486 cycle_A: 0.357 idt_A: 0.563 D_B: 0.082 G_B: 0.629 cycle_B: 1.753 idt_B: 0.126 \n",
            "End of epoch 168 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 100, time: 0.279, data: 0.325) D_A: 0.088 G_A: 0.447 cycle_A: 0.351 idt_A: 0.249 D_B: 0.131 G_B: 0.412 cycle_B: 0.815 idt_B: 0.115 \n",
            "End of epoch 169 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 100, time: 0.280, data: 0.311) D_A: 0.018 G_A: 0.404 cycle_A: 0.509 idt_A: 0.331 D_B: 0.104 G_B: 0.725 cycle_B: 0.932 idt_B: 0.144 \n",
            "saving the model at the end of epoch 170, iters 17000\n",
            "End of epoch 170 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 100, time: 0.272, data: 0.338) D_A: 0.046 G_A: 0.436 cycle_A: 0.281 idt_A: 0.491 D_B: 0.063 G_B: 0.434 cycle_B: 1.296 idt_B: 0.092 \n",
            "End of epoch 171 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 100, time: 1.565, data: 0.318) D_A: 0.039 G_A: 0.344 cycle_A: 0.334 idt_A: 0.261 D_B: 0.179 G_B: 0.224 cycle_B: 0.791 idt_B: 0.092 \n",
            "End of epoch 172 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 100, time: 0.280, data: 0.322) D_A: 0.082 G_A: 0.586 cycle_A: 0.259 idt_A: 0.231 D_B: 0.050 G_B: 0.667 cycle_B: 0.892 idt_B: 0.087 \n",
            "End of epoch 173 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 100, time: 0.277, data: 0.321) D_A: 0.061 G_A: 0.713 cycle_A: 0.486 idt_A: 0.226 D_B: 0.196 G_B: 0.709 cycle_B: 0.691 idt_B: 0.116 \n",
            "End of epoch 174 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 100, time: 0.277, data: 0.321) D_A: 0.089 G_A: 0.453 cycle_A: 0.276 idt_A: 0.608 D_B: 0.099 G_B: 0.614 cycle_B: 1.473 idt_B: 0.073 \n",
            "saving the model at the end of epoch 175, iters 17500\n",
            "End of epoch 175 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 100, time: 1.559, data: 0.328) D_A: 0.110 G_A: 0.390 cycle_A: 0.329 idt_A: 0.515 D_B: 0.189 G_B: 0.579 cycle_B: 1.400 idt_B: 0.086 \n",
            "End of epoch 176 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 100, time: 0.273, data: 0.310) D_A: 0.156 G_A: 0.418 cycle_A: 0.306 idt_A: 0.498 D_B: 0.113 G_B: 0.274 cycle_B: 1.327 idt_B: 0.076 \n",
            "End of epoch 177 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 100, time: 0.279, data: 0.316) D_A: 0.027 G_A: 0.555 cycle_A: 0.349 idt_A: 0.379 D_B: 0.187 G_B: 1.190 cycle_B: 1.187 idt_B: 0.096 \n",
            "End of epoch 178 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 100, time: 0.282, data: 0.318) D_A: 0.234 G_A: 0.253 cycle_A: 0.293 idt_A: 0.392 D_B: 0.074 G_B: 0.706 cycle_B: 1.155 idt_B: 0.087 \n",
            "End of epoch 179 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 100, time: 1.604, data: 0.319) D_A: 0.150 G_A: 0.337 cycle_A: 0.352 idt_A: 0.298 D_B: 0.125 G_B: 0.534 cycle_B: 1.130 idt_B: 0.086 \n",
            "saving the model at the end of epoch 180, iters 18000\n",
            "End of epoch 180 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 100, time: 0.267, data: 0.322) D_A: 0.143 G_A: 0.444 cycle_A: 0.394 idt_A: 0.448 D_B: 0.100 G_B: 0.852 cycle_B: 1.225 idt_B: 0.104 \n",
            "End of epoch 181 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 100, time: 0.290, data: 0.311) D_A: 0.152 G_A: 0.286 cycle_A: 0.235 idt_A: 0.572 D_B: 0.073 G_B: 1.095 cycle_B: 1.535 idt_B: 0.084 \n",
            "End of epoch 182 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 100, time: 0.290, data: 0.331) D_A: 0.290 G_A: 0.894 cycle_A: 0.439 idt_A: 0.267 D_B: 0.120 G_B: 0.755 cycle_B: 0.826 idt_B: 0.123 \n",
            "End of epoch 183 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 100, time: 1.633, data: 0.342) D_A: 0.259 G_A: 0.142 cycle_A: 0.290 idt_A: 0.400 D_B: 0.070 G_B: 0.691 cycle_B: 1.162 idt_B: 0.079 \n",
            "End of epoch 184 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 100, time: 0.274, data: 0.324) D_A: 0.089 G_A: 0.596 cycle_A: 0.435 idt_A: 0.393 D_B: 0.055 G_B: 0.319 cycle_B: 1.073 idt_B: 0.150 \n",
            "saving the model at the end of epoch 185, iters 18500\n",
            "End of epoch 185 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 100, time: 0.270, data: 0.339) D_A: 0.137 G_A: 0.513 cycle_A: 0.323 idt_A: 0.418 D_B: 0.108 G_B: 0.458 cycle_B: 1.140 idt_B: 0.116 \n",
            "End of epoch 186 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 100, time: 0.274, data: 0.334) D_A: 0.108 G_A: 0.482 cycle_A: 0.388 idt_A: 0.391 D_B: 0.060 G_B: 0.884 cycle_B: 1.050 idt_B: 0.134 \n",
            "End of epoch 187 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 100, time: 1.817, data: 0.327) D_A: 0.024 G_A: 0.588 cycle_A: 0.319 idt_A: 0.651 D_B: 0.097 G_B: 0.517 cycle_B: 1.641 idt_B: 0.086 \n",
            "End of epoch 188 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 100, time: 0.272, data: 0.314) D_A: 0.098 G_A: 0.496 cycle_A: 0.463 idt_A: 0.529 D_B: 0.123 G_B: 0.619 cycle_B: 1.298 idt_B: 0.144 \n",
            "End of epoch 189 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 100, time: 0.266, data: 0.320) D_A: 0.037 G_A: 0.457 cycle_A: 0.325 idt_A: 0.261 D_B: 0.078 G_B: 0.533 cycle_B: 0.767 idt_B: 0.081 \n",
            "saving the model at the end of epoch 190, iters 19000\n",
            "End of epoch 190 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 0.274, data: 0.318) D_A: 0.039 G_A: 0.883 cycle_A: 0.391 idt_A: 0.387 D_B: 0.027 G_B: 0.852 cycle_B: 1.205 idt_B: 0.151 \n",
            "End of epoch 191 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 100, time: 1.788, data: 0.322) D_A: 0.160 G_A: 0.644 cycle_A: 0.324 idt_A: 0.449 D_B: 0.112 G_B: 0.449 cycle_B: 1.295 idt_B: 0.084 \n",
            "End of epoch 192 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 100, time: 0.275, data: 0.300) D_A: 0.215 G_A: 0.531 cycle_A: 0.263 idt_A: 0.423 D_B: 0.032 G_B: 0.872 cycle_B: 1.186 idt_B: 0.068 \n",
            "End of epoch 193 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 100, time: 0.287, data: 0.323) D_A: 0.023 G_A: 0.509 cycle_A: 0.314 idt_A: 0.288 D_B: 0.066 G_B: 0.653 cycle_B: 1.011 idt_B: 0.094 \n",
            "End of epoch 194 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 100, time: 0.270, data: 0.316) D_A: 0.098 G_A: 0.441 cycle_A: 0.413 idt_A: 0.470 D_B: 0.072 G_B: 0.697 cycle_B: 1.238 idt_B: 0.151 \n",
            "saving the model at the end of epoch 195, iters 19500\n",
            "End of epoch 195 / 200 \t Time Taken: 27 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 100, time: 1.922, data: 0.327) D_A: 0.068 G_A: 0.698 cycle_A: 0.251 idt_A: 0.319 D_B: 0.044 G_B: 0.698 cycle_B: 0.999 idt_B: 0.076 \n",
            "End of epoch 196 / 200 \t Time Taken: 28 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 100, time: 0.283, data: 0.339) D_A: 0.071 G_A: 0.518 cycle_A: 0.204 idt_A: 0.522 D_B: 0.117 G_B: 0.330 cycle_B: 1.321 idt_B: 0.054 \n",
            "End of epoch 197 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 100, time: 0.280, data: 0.334) D_A: 0.129 G_A: 0.363 cycle_A: 0.311 idt_A: 0.305 D_B: 0.050 G_B: 0.617 cycle_B: 0.956 idt_B: 0.076 \n",
            "End of epoch 198 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 100, time: 0.277, data: 0.335) D_A: 0.113 G_A: 0.437 cycle_A: 0.347 idt_A: 0.253 D_B: 0.065 G_B: 0.601 cycle_B: 0.718 idt_B: 0.086 \n",
            "End of epoch 199 / 200 \t Time Taken: 26 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 100, time: 1.950, data: 0.321) D_A: 0.095 G_A: 0.691 cycle_A: 0.457 idt_A: 0.675 D_B: 0.114 G_B: 0.934 cycle_B: 1.632 idt_B: 0.130 \n",
            "saving the latest model (epoch 200, total_iters 20000)\n",
            "saving the model at the end of epoch 200, iters 20000\n",
            "End of epoch 200 / 200 \t Time Taken: 29 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4988, 0.5012],\n",
            "        [0.4991, 0.5009],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.4990, 0.5010],\n",
            "        [0.5002, 0.4998]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4982, 0.5018],\n",
            "        [0.4991, 0.5009],\n",
            "        [0.4999, 0.5001],\n",
            "        [0.4983, 0.5017],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4976, 0.5024],\n",
            "        [0.4996, 0.5004],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.4985, 0.5015],\n",
            "        [0.5004, 0.4996]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4969, 0.5031],\n",
            "        [0.4992, 0.5008],\n",
            "        [0.5002, 0.4998],\n",
            "        [0.4976, 0.5024],\n",
            "        [0.5005, 0.4995]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4975, 0.5025],\n",
            "        [0.4997, 0.5003],\n",
            "        [0.5006, 0.4994],\n",
            "        [0.4972, 0.5028],\n",
            "        [0.5004, 0.4996]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4976, 0.5024],\n",
            "        [0.4998, 0.5002],\n",
            "        [0.5003, 0.4997],\n",
            "        [0.4968, 0.5032],\n",
            "        [0.5002, 0.4998]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4974, 0.5026],\n",
            "        [0.4990, 0.5010],\n",
            "        [0.5003, 0.4997],\n",
            "        [0.4960, 0.5040],\n",
            "        [0.4994, 0.5006]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4971, 0.5029],\n",
            "        [0.4994, 0.5006],\n",
            "        [0.5005, 0.4995],\n",
            "        [0.4958, 0.5042],\n",
            "        [0.5003, 0.4997]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4972, 0.5028],\n",
            "        [0.4999, 0.5001],\n",
            "        [0.5012, 0.4988],\n",
            "        [0.4957, 0.5043],\n",
            "        [0.5009, 0.4991]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4966, 0.5034],\n",
            "        [0.5003, 0.4997],\n",
            "        [0.5012, 0.4988],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.5009, 0.4991]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4962, 0.5038],\n",
            "        [0.5014, 0.4986],\n",
            "        [0.5011, 0.4989],\n",
            "        [0.4962, 0.5038],\n",
            "        [0.5006, 0.4994]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4956, 0.5044],\n",
            "        [0.5006, 0.4994],\n",
            "        [0.5019, 0.4981],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.5006, 0.4994]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4950, 0.5050],\n",
            "        [0.5001, 0.4999],\n",
            "        [0.5019, 0.4981],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.5009, 0.4991]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4937, 0.5063],\n",
            "        [0.4993, 0.5007],\n",
            "        [0.5014, 0.4986],\n",
            "        [0.4926, 0.5074],\n",
            "        [0.5003, 0.4997]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4935, 0.5065],\n",
            "        [0.4990, 0.5010],\n",
            "        [0.5013, 0.4987],\n",
            "        [0.4925, 0.5075],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4937, 0.5063],\n",
            "        [0.4991, 0.5009],\n",
            "        [0.5014, 0.4986],\n",
            "        [0.4924, 0.5076],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4930, 0.5070],\n",
            "        [0.4994, 0.5006],\n",
            "        [0.5016, 0.4984],\n",
            "        [0.4921, 0.5079],\n",
            "        [0.5007, 0.4993]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4918, 0.5082],\n",
            "        [0.4993, 0.5007],\n",
            "        [0.5013, 0.4987],\n",
            "        [0.4910, 0.5090],\n",
            "        [0.5005, 0.4995]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4916, 0.5084],\n",
            "        [0.4985, 0.5015],\n",
            "        [0.5012, 0.4988],\n",
            "        [0.4905, 0.5095],\n",
            "        [0.5007, 0.4993]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4908, 0.5092],\n",
            "        [0.4986, 0.5014],\n",
            "        [0.5012, 0.4988],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.5001, 0.4999]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4907, 0.5093],\n",
            "        [0.4985, 0.5015],\n",
            "        [0.5009, 0.4991],\n",
            "        [0.4894, 0.5106],\n",
            "        [0.5002, 0.4998]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4901, 0.5099],\n",
            "        [0.4980, 0.5020],\n",
            "        [0.5010, 0.4990],\n",
            "        [0.4889, 0.5111],\n",
            "        [0.5004, 0.4996]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4900, 0.5100],\n",
            "        [0.4983, 0.5017],\n",
            "        [0.5007, 0.4993],\n",
            "        [0.4893, 0.5107],\n",
            "        [0.5004, 0.4996]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4897, 0.5103],\n",
            "        [0.4983, 0.5017],\n",
            "        [0.5006, 0.4994],\n",
            "        [0.4891, 0.5109],\n",
            "        [0.5005, 0.4995]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4894, 0.5106],\n",
            "        [0.4981, 0.5019],\n",
            "        [0.5006, 0.4994],\n",
            "        [0.4881, 0.5119],\n",
            "        [0.5006, 0.4994]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4891, 0.5109],\n",
            "        [0.4977, 0.5023],\n",
            "        [0.5010, 0.4990],\n",
            "        [0.4866, 0.5134],\n",
            "        [0.5007, 0.4993]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4889, 0.5111],\n",
            "        [0.4976, 0.5024],\n",
            "        [0.5009, 0.4991],\n",
            "        [0.4864, 0.5136],\n",
            "        [0.5012, 0.4988]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4884, 0.5116],\n",
            "        [0.4983, 0.5017],\n",
            "        [0.5007, 0.4993],\n",
            "        [0.4861, 0.5139],\n",
            "        [0.5010, 0.4990]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4873, 0.5127],\n",
            "        [0.4986, 0.5014],\n",
            "        [0.5001, 0.4999],\n",
            "        [0.4861, 0.5139],\n",
            "        [0.5008, 0.4992]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4875, 0.5125],\n",
            "        [0.4970, 0.5030],\n",
            "        [0.4993, 0.5007],\n",
            "        [0.4855, 0.5145],\n",
            "        [0.4997, 0.5003]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4879, 0.5121],\n",
            "        [0.4964, 0.5036],\n",
            "        [0.4989, 0.5011],\n",
            "        [0.4844, 0.5156],\n",
            "        [0.5002, 0.4998]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4873, 0.5127],\n",
            "        [0.4963, 0.5037],\n",
            "        [0.4981, 0.5019],\n",
            "        [0.4838, 0.5162],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4863, 0.5137],\n",
            "        [0.4967, 0.5033],\n",
            "        [0.4977, 0.5023],\n",
            "        [0.4834, 0.5166],\n",
            "        [0.4998, 0.5002]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4859, 0.5141],\n",
            "        [0.4968, 0.5032],\n",
            "        [0.4981, 0.5019],\n",
            "        [0.4844, 0.5156],\n",
            "        [0.5002, 0.4998]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4860, 0.5140],\n",
            "        [0.4965, 0.5035],\n",
            "        [0.4985, 0.5015],\n",
            "        [0.4835, 0.5165],\n",
            "        [0.5002, 0.4998]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4855, 0.5145],\n",
            "        [0.4959, 0.5041],\n",
            "        [0.4979, 0.5021],\n",
            "        [0.4821, 0.5179],\n",
            "        [0.5011, 0.4989]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4853, 0.5147],\n",
            "        [0.4951, 0.5049],\n",
            "        [0.4980, 0.5020],\n",
            "        [0.4821, 0.5179],\n",
            "        [0.5008, 0.4992]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4854, 0.5146],\n",
            "        [0.4954, 0.5046],\n",
            "        [0.4979, 0.5021],\n",
            "        [0.4822, 0.5178],\n",
            "        [0.5009, 0.4991]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4838, 0.5162],\n",
            "        [0.4955, 0.5045],\n",
            "        [0.4975, 0.5025],\n",
            "        [0.4812, 0.5188],\n",
            "        [0.5007, 0.4993]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4833, 0.5167],\n",
            "        [0.4958, 0.5042],\n",
            "        [0.4976, 0.5024],\n",
            "        [0.4814, 0.5186],\n",
            "        [0.5004, 0.4996]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4835, 0.5165],\n",
            "        [0.4957, 0.5043],\n",
            "        [0.4974, 0.5026],\n",
            "        [0.4797, 0.5203],\n",
            "        [0.5013, 0.4987]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4836, 0.5164],\n",
            "        [0.4956, 0.5044],\n",
            "        [0.4973, 0.5027],\n",
            "        [0.4801, 0.5199],\n",
            "        [0.5010, 0.4990]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4838, 0.5162],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4980, 0.5020],\n",
            "        [0.4792, 0.5208],\n",
            "        [0.5011, 0.4989]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4832, 0.5168],\n",
            "        [0.4947, 0.5053],\n",
            "        [0.4978, 0.5022],\n",
            "        [0.4776, 0.5224],\n",
            "        [0.5012, 0.4988]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4820, 0.5180],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4965, 0.5035],\n",
            "        [0.4776, 0.5224],\n",
            "        [0.5012, 0.4988]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4822, 0.5178],\n",
            "        [0.4944, 0.5056],\n",
            "        [0.4968, 0.5032],\n",
            "        [0.4778, 0.5222],\n",
            "        [0.5010, 0.4990]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4810, 0.5190],\n",
            "        [0.4942, 0.5058],\n",
            "        [0.4971, 0.5029],\n",
            "        [0.4784, 0.5216],\n",
            "        [0.5007, 0.4993]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4813, 0.5187],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4962, 0.5038],\n",
            "        [0.4787, 0.5213],\n",
            "        [0.5012, 0.4988]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4802, 0.5198],\n",
            "        [0.4935, 0.5065],\n",
            "        [0.4960, 0.5040],\n",
            "        [0.4764, 0.5236],\n",
            "        [0.5002, 0.4998]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4797, 0.5203],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4968, 0.5032],\n",
            "        [0.4768, 0.5232],\n",
            "        [0.5004, 0.4996]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4796, 0.5204],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4965, 0.5035],\n",
            "        [0.4776, 0.5224],\n",
            "        [0.5011, 0.4989]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4792, 0.5208],\n",
            "        [0.4942, 0.5058],\n",
            "        [0.4958, 0.5042],\n",
            "        [0.4779, 0.5221],\n",
            "        [0.5004, 0.4996]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4779, 0.5221],\n",
            "        [0.4947, 0.5053],\n",
            "        [0.4960, 0.5040],\n",
            "        [0.4778, 0.5222],\n",
            "        [0.5003, 0.4997]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4783, 0.5217],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4961, 0.5039],\n",
            "        [0.4770, 0.5230],\n",
            "        [0.5007, 0.4993]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4775, 0.5225],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4959, 0.5041],\n",
            "        [0.4765, 0.5235],\n",
            "        [0.5005, 0.4995]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4781, 0.5219],\n",
            "        [0.4945, 0.5055],\n",
            "        [0.4963, 0.5037],\n",
            "        [0.4761, 0.5239],\n",
            "        [0.5007, 0.4993]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4770, 0.5230],\n",
            "        [0.4953, 0.5047],\n",
            "        [0.4960, 0.5040],\n",
            "        [0.4765, 0.5235],\n",
            "        [0.5014, 0.4986]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4767, 0.5233],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4952, 0.5048],\n",
            "        [0.4759, 0.5241],\n",
            "        [0.5012, 0.4988]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4769, 0.5231],\n",
            "        [0.4934, 0.5066],\n",
            "        [0.4951, 0.5049],\n",
            "        [0.4759, 0.5241],\n",
            "        [0.5014, 0.4986]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4769, 0.5231],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4952, 0.5048],\n",
            "        [0.4765, 0.5235],\n",
            "        [0.5015, 0.4985]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4765, 0.5235],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4956, 0.5044],\n",
            "        [0.4762, 0.5238],\n",
            "        [0.5013, 0.4987]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4760, 0.5240],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4955, 0.5045],\n",
            "        [0.4768, 0.5232],\n",
            "        [0.5009, 0.4991]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4760, 0.5240],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4951, 0.5049],\n",
            "        [0.4759, 0.5241],\n",
            "        [0.5011, 0.4989]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4756, 0.5244],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.4761, 0.5239],\n",
            "        [0.5012, 0.4988]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4751, 0.5249],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4759, 0.5241],\n",
            "        [0.5018, 0.4982]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4747, 0.5253],\n",
            "        [0.4943, 0.5057],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4751, 0.5249],\n",
            "        [0.5017, 0.4983]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4746, 0.5254],\n",
            "        [0.4943, 0.5057],\n",
            "        [0.4944, 0.5056],\n",
            "        [0.4745, 0.5255],\n",
            "        [0.5022, 0.4978]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4754, 0.5246],\n",
            "        [0.4939, 0.5061],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4752, 0.5248],\n",
            "        [0.5026, 0.4974]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4748, 0.5252],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.4759, 0.5241],\n",
            "        [0.5026, 0.4974]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4747, 0.5253],\n",
            "        [0.4937, 0.5063],\n",
            "        [0.4945, 0.5055],\n",
            "        [0.4755, 0.5245],\n",
            "        [0.5027, 0.4973]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4746, 0.5254],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4756, 0.5244],\n",
            "        [0.5031, 0.4969]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4739, 0.5261],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4945, 0.5055],\n",
            "        [0.4758, 0.5242],\n",
            "        [0.5032, 0.4968]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4740, 0.5260],\n",
            "        [0.4944, 0.5056],\n",
            "        [0.4944, 0.5056],\n",
            "        [0.4758, 0.5242],\n",
            "        [0.5035, 0.4965]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4735, 0.5265],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4757, 0.5243],\n",
            "        [0.5039, 0.4961]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4741, 0.5259],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.4765, 0.5235],\n",
            "        [0.5040, 0.4960]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4736, 0.5264],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4947, 0.5053],\n",
            "        [0.4764, 0.5236],\n",
            "        [0.5045, 0.4955]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4741, 0.5259],\n",
            "        [0.4944, 0.5056],\n",
            "        [0.4953, 0.5047],\n",
            "        [0.4766, 0.5234],\n",
            "        [0.5052, 0.4948]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4734, 0.5266],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4764, 0.5236],\n",
            "        [0.5053, 0.4947]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4730, 0.5270],\n",
            "        [0.4951, 0.5049],\n",
            "        [0.4955, 0.5045],\n",
            "        [0.4757, 0.5243],\n",
            "        [0.5052, 0.4948]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4726, 0.5274],\n",
            "        [0.4951, 0.5049],\n",
            "        [0.4955, 0.5045],\n",
            "        [0.4757, 0.5243],\n",
            "        [0.5059, 0.4941]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4729, 0.5271],\n",
            "        [0.4956, 0.5044],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.4757, 0.5243],\n",
            "        [0.5057, 0.4943]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4728, 0.5272],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4956, 0.5044],\n",
            "        [0.4749, 0.5251],\n",
            "        [0.5063, 0.4937]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4723, 0.5277],\n",
            "        [0.4954, 0.5046],\n",
            "        [0.4960, 0.5040],\n",
            "        [0.4749, 0.5251],\n",
            "        [0.5061, 0.4939]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4724, 0.5276],\n",
            "        [0.4955, 0.5045],\n",
            "        [0.4953, 0.5047],\n",
            "        [0.4754, 0.5246],\n",
            "        [0.5063, 0.4937]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4721, 0.5279],\n",
            "        [0.4952, 0.5048],\n",
            "        [0.4953, 0.5047],\n",
            "        [0.4756, 0.5244],\n",
            "        [0.5065, 0.4935]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4722, 0.5278],\n",
            "        [0.4952, 0.5048],\n",
            "        [0.4960, 0.5040],\n",
            "        [0.4756, 0.5244],\n",
            "        [0.5068, 0.4932]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4725, 0.5275],\n",
            "        [0.4947, 0.5053],\n",
            "        [0.4956, 0.5044],\n",
            "        [0.4757, 0.5243],\n",
            "        [0.5070, 0.4930]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4722, 0.5278],\n",
            "        [0.4947, 0.5053],\n",
            "        [0.4957, 0.5043],\n",
            "        [0.4759, 0.5241],\n",
            "        [0.5077, 0.4923]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4719, 0.5281],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4956, 0.5044],\n",
            "        [0.4766, 0.5234],\n",
            "        [0.5077, 0.4923]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4717, 0.5283],\n",
            "        [0.4945, 0.5055],\n",
            "        [0.4958, 0.5042],\n",
            "        [0.4759, 0.5241],\n",
            "        [0.5079, 0.4921]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4718, 0.5282],\n",
            "        [0.4939, 0.5061],\n",
            "        [0.4952, 0.5048],\n",
            "        [0.4753, 0.5247],\n",
            "        [0.5081, 0.4919]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4721, 0.5279],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4944, 0.5056],\n",
            "        [0.4758, 0.5242],\n",
            "        [0.5090, 0.4910]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4721, 0.5279],\n",
            "        [0.4942, 0.5058],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4756, 0.5244],\n",
            "        [0.5087, 0.4913]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4723, 0.5277],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4945, 0.5055],\n",
            "        [0.4748, 0.5252],\n",
            "        [0.5090, 0.4910]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4724, 0.5276],\n",
            "        [0.4934, 0.5066],\n",
            "        [0.4942, 0.5058],\n",
            "        [0.4746, 0.5254],\n",
            "        [0.5088, 0.4912]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4725, 0.5275],\n",
            "        [0.4932, 0.5068],\n",
            "        [0.4944, 0.5056],\n",
            "        [0.4749, 0.5251],\n",
            "        [0.5094, 0.4906]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4722, 0.5278],\n",
            "        [0.4934, 0.5066],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4743, 0.5257],\n",
            "        [0.5097, 0.4903]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4725, 0.5275],\n",
            "        [0.4933, 0.5067],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4748, 0.5252],\n",
            "        [0.5099, 0.4901]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4718, 0.5282],\n",
            "        [0.4936, 0.5064],\n",
            "        [0.4952, 0.5048],\n",
            "        [0.4755, 0.5245],\n",
            "        [0.5105, 0.4895]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4720, 0.5280],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4957, 0.5043],\n",
            "        [0.4762, 0.5238],\n",
            "        [0.5106, 0.4894]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4714, 0.5286],\n",
            "        [0.4936, 0.5064],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.4758, 0.5242],\n",
            "        [0.5104, 0.4896]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4715, 0.5285],\n",
            "        [0.4935, 0.5065],\n",
            "        [0.4945, 0.5055],\n",
            "        [0.4763, 0.5237],\n",
            "        [0.5108, 0.4892]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4720, 0.5280],\n",
            "        [0.4936, 0.5064],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4760, 0.5240],\n",
            "        [0.5108, 0.4892]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4718, 0.5282],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4953, 0.5047],\n",
            "        [0.4753, 0.5247],\n",
            "        [0.5116, 0.4884]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4722, 0.5278],\n",
            "        [0.4935, 0.5065],\n",
            "        [0.4955, 0.5045],\n",
            "        [0.4756, 0.5244],\n",
            "        [0.5115, 0.4885]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4724, 0.5276],\n",
            "        [0.4943, 0.5057],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.4760, 0.5240],\n",
            "        [0.5126, 0.4874]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4726, 0.5274],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4952, 0.5048],\n",
            "        [0.4758, 0.5242],\n",
            "        [0.5131, 0.4869]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4724, 0.5276],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4763, 0.5237],\n",
            "        [0.5128, 0.4872]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4724, 0.5276],\n",
            "        [0.4935, 0.5065],\n",
            "        [0.4951, 0.5049],\n",
            "        [0.4760, 0.5240],\n",
            "        [0.5131, 0.4869]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4726, 0.5274],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4769, 0.5231],\n",
            "        [0.5132, 0.4868]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4727, 0.5273],\n",
            "        [0.4936, 0.5064],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4767, 0.5233],\n",
            "        [0.5136, 0.4864]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4727, 0.5273],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4770, 0.5230],\n",
            "        [0.5138, 0.4862]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4727, 0.5273],\n",
            "        [0.4930, 0.5070],\n",
            "        [0.4947, 0.5053],\n",
            "        [0.4767, 0.5233],\n",
            "        [0.5136, 0.4864]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4731, 0.5269],\n",
            "        [0.4932, 0.5068],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4774, 0.5226],\n",
            "        [0.5142, 0.4858]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4728, 0.5272],\n",
            "        [0.4933, 0.5067],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.4775, 0.5225],\n",
            "        [0.5140, 0.4860]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4729, 0.5271],\n",
            "        [0.4931, 0.5069],\n",
            "        [0.4953, 0.5047],\n",
            "        [0.4770, 0.5230],\n",
            "        [0.5143, 0.4857]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4726, 0.5274],\n",
            "        [0.4936, 0.5064],\n",
            "        [0.4953, 0.5047],\n",
            "        [0.4772, 0.5228],\n",
            "        [0.5146, 0.4854]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4733, 0.5267],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4953, 0.5047],\n",
            "        [0.4772, 0.5228],\n",
            "        [0.5154, 0.4846]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4733, 0.5267],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4955, 0.5045],\n",
            "        [0.4781, 0.5219],\n",
            "        [0.5153, 0.4847]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4734, 0.5266],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4958, 0.5042],\n",
            "        [0.4779, 0.5221],\n",
            "        [0.5156, 0.4844]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4737, 0.5263],\n",
            "        [0.4937, 0.5063],\n",
            "        [0.4959, 0.5041],\n",
            "        [0.4777, 0.5223],\n",
            "        [0.5162, 0.4838]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4739, 0.5261],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4959, 0.5041],\n",
            "        [0.4778, 0.5222],\n",
            "        [0.5160, 0.4840]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4734, 0.5266],\n",
            "        [0.4935, 0.5065],\n",
            "        [0.4961, 0.5039],\n",
            "        [0.4782, 0.5218],\n",
            "        [0.5162, 0.4838]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4733, 0.5267],\n",
            "        [0.4939, 0.5061],\n",
            "        [0.4960, 0.5040],\n",
            "        [0.4783, 0.5217],\n",
            "        [0.5162, 0.4838]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4736, 0.5264],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4960, 0.5040],\n",
            "        [0.4783, 0.5217],\n",
            "        [0.5167, 0.4833]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4737, 0.5263],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4963, 0.5037],\n",
            "        [0.4784, 0.5216],\n",
            "        [0.5169, 0.4831]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4737, 0.5263],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4963, 0.5037],\n",
            "        [0.4782, 0.5218],\n",
            "        [0.5174, 0.4826]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4732, 0.5268],\n",
            "        [0.4943, 0.5057],\n",
            "        [0.4962, 0.5038],\n",
            "        [0.4785, 0.5215],\n",
            "        [0.5175, 0.4825]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4736, 0.5264],\n",
            "        [0.4940, 0.5060],\n",
            "        [0.4963, 0.5037],\n",
            "        [0.4784, 0.5216],\n",
            "        [0.5181, 0.4819]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4738, 0.5262],\n",
            "        [0.4943, 0.5057],\n",
            "        [0.4964, 0.5036],\n",
            "        [0.4785, 0.5215],\n",
            "        [0.5184, 0.4816]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4739, 0.5261],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4966, 0.5034],\n",
            "        [0.4781, 0.5219],\n",
            "        [0.5186, 0.4814]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4739, 0.5261],\n",
            "        [0.4942, 0.5058],\n",
            "        [0.4967, 0.5033],\n",
            "        [0.4784, 0.5216],\n",
            "        [0.5188, 0.4812]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4738, 0.5262],\n",
            "        [0.4943, 0.5057],\n",
            "        [0.4967, 0.5033],\n",
            "        [0.4788, 0.5212],\n",
            "        [0.5188, 0.4812]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4739, 0.5261],\n",
            "        [0.4944, 0.5056],\n",
            "        [0.4968, 0.5032],\n",
            "        [0.4790, 0.5210],\n",
            "        [0.5191, 0.4809]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4737, 0.5263],\n",
            "        [0.4945, 0.5055],\n",
            "        [0.4965, 0.5035],\n",
            "        [0.4791, 0.5209],\n",
            "        [0.5191, 0.4809]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4739, 0.5261],\n",
            "        [0.4944, 0.5056],\n",
            "        [0.4967, 0.5033],\n",
            "        [0.4789, 0.5211],\n",
            "        [0.5193, 0.4807]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4741, 0.5259],\n",
            "        [0.4943, 0.5057],\n",
            "        [0.4971, 0.5029],\n",
            "        [0.4790, 0.5210],\n",
            "        [0.5195, 0.4805]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4740, 0.5260],\n",
            "        [0.4946, 0.5054],\n",
            "        [0.4971, 0.5029],\n",
            "        [0.4793, 0.5207],\n",
            "        [0.5196, 0.4804]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4745, 0.5255],\n",
            "        [0.4945, 0.5055],\n",
            "        [0.4973, 0.5027],\n",
            "        [0.4790, 0.5210],\n",
            "        [0.5197, 0.4803]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4744, 0.5256],\n",
            "        [0.4945, 0.5055],\n",
            "        [0.4973, 0.5027],\n",
            "        [0.4791, 0.5209],\n",
            "        [0.5200, 0.4800]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4744, 0.5256],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4972, 0.5028],\n",
            "        [0.4794, 0.5206],\n",
            "        [0.5202, 0.4798]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4744, 0.5256],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4973, 0.5027],\n",
            "        [0.4793, 0.5207],\n",
            "        [0.5204, 0.4796]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4746, 0.5254],\n",
            "        [0.4947, 0.5053],\n",
            "        [0.4975, 0.5025],\n",
            "        [0.4793, 0.5207],\n",
            "        [0.5205, 0.4795]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4746, 0.5254],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4974, 0.5026],\n",
            "        [0.4793, 0.5207],\n",
            "        [0.5206, 0.4794]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4746, 0.5254],\n",
            "        [0.4947, 0.5053],\n",
            "        [0.4974, 0.5026],\n",
            "        [0.4794, 0.5206],\n",
            "        [0.5207, 0.4793]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4747, 0.5253],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4975, 0.5025],\n",
            "        [0.4796, 0.5204],\n",
            "        [0.5208, 0.4792]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4747, 0.5253],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4976, 0.5024],\n",
            "        [0.4796, 0.5204],\n",
            "        [0.5209, 0.4791]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4748, 0.5252],\n",
            "        [0.4950, 0.5050],\n",
            "        [0.4976, 0.5024],\n",
            "        [0.4797, 0.5203],\n",
            "        [0.5210, 0.4790]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4748, 0.5252],\n",
            "        [0.4951, 0.5049],\n",
            "        [0.4975, 0.5025],\n",
            "        [0.4797, 0.5203],\n",
            "        [0.5210, 0.4790]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4748, 0.5252],\n",
            "        [0.4951, 0.5049],\n",
            "        [0.4975, 0.5025],\n",
            "        [0.4797, 0.5203],\n",
            "        [0.5210, 0.4790]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>)], 'cell_netG_B': [tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64), tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4994, 0.5006],\n",
            "        [0.4996, 0.5004],\n",
            "        [0.4998, 0.5002],\n",
            "        [0.4989, 0.5011],\n",
            "        [0.4993, 0.5007]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4986, 0.5014],\n",
            "        [0.4990, 0.5010],\n",
            "        [0.4993, 0.5007],\n",
            "        [0.4994, 0.5006],\n",
            "        [0.4990, 0.5010]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4983, 0.5017],\n",
            "        [0.4984, 0.5016],\n",
            "        [0.4991, 0.5009],\n",
            "        [0.4991, 0.5009],\n",
            "        [0.4991, 0.5009]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4969, 0.5031],\n",
            "        [0.4970, 0.5030],\n",
            "        [0.4979, 0.5021],\n",
            "        [0.4988, 0.5012],\n",
            "        [0.4974, 0.5026]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4968, 0.5032],\n",
            "        [0.4976, 0.5024],\n",
            "        [0.4977, 0.5023],\n",
            "        [0.4983, 0.5017],\n",
            "        [0.4972, 0.5028]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4975, 0.5025],\n",
            "        [0.4984, 0.5016],\n",
            "        [0.4981, 0.5019],\n",
            "        [0.4978, 0.5022],\n",
            "        [0.4983, 0.5017]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4971, 0.5029],\n",
            "        [0.4980, 0.5020],\n",
            "        [0.4976, 0.5024],\n",
            "        [0.4976, 0.5024],\n",
            "        [0.4978, 0.5022]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4965, 0.5035],\n",
            "        [0.4990, 0.5010],\n",
            "        [0.4978, 0.5022],\n",
            "        [0.4985, 0.5015],\n",
            "        [0.4985, 0.5015]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4957, 0.5043],\n",
            "        [0.4980, 0.5020],\n",
            "        [0.4975, 0.5025],\n",
            "        [0.4977, 0.5023],\n",
            "        [0.4970, 0.5030]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4957, 0.5043],\n",
            "        [0.4975, 0.5025],\n",
            "        [0.4970, 0.5030],\n",
            "        [0.4983, 0.5017],\n",
            "        [0.4966, 0.5034]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4956, 0.5044],\n",
            "        [0.4974, 0.5026],\n",
            "        [0.4966, 0.5034],\n",
            "        [0.4975, 0.5025],\n",
            "        [0.4970, 0.5030]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4955, 0.5045],\n",
            "        [0.4974, 0.5026],\n",
            "        [0.4963, 0.5037],\n",
            "        [0.4978, 0.5022],\n",
            "        [0.4970, 0.5030]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4953, 0.5047],\n",
            "        [0.4977, 0.5023],\n",
            "        [0.4960, 0.5040],\n",
            "        [0.4978, 0.5022],\n",
            "        [0.4970, 0.5030]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4944, 0.5056],\n",
            "        [0.4971, 0.5029],\n",
            "        [0.4959, 0.5041],\n",
            "        [0.4961, 0.5039],\n",
            "        [0.4961, 0.5039]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4946, 0.5054],\n",
            "        [0.4969, 0.5031],\n",
            "        [0.4959, 0.5041],\n",
            "        [0.4965, 0.5035],\n",
            "        [0.4955, 0.5045]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4942, 0.5058],\n",
            "        [0.4970, 0.5030],\n",
            "        [0.4947, 0.5053],\n",
            "        [0.4967, 0.5033],\n",
            "        [0.4944, 0.5056]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4932, 0.5068],\n",
            "        [0.4959, 0.5041],\n",
            "        [0.4949, 0.5051],\n",
            "        [0.4948, 0.5052],\n",
            "        [0.4925, 0.5075]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4903, 0.5097],\n",
            "        [0.4930, 0.5070],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4923, 0.5077],\n",
            "        [0.4884, 0.5116]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4900, 0.5100],\n",
            "        [0.4931, 0.5069],\n",
            "        [0.4939, 0.5061],\n",
            "        [0.4922, 0.5078],\n",
            "        [0.4891, 0.5109]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4902, 0.5098],\n",
            "        [0.4937, 0.5063],\n",
            "        [0.4941, 0.5059],\n",
            "        [0.4926, 0.5074],\n",
            "        [0.4895, 0.5105]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4901, 0.5099],\n",
            "        [0.4939, 0.5061],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4923, 0.5077],\n",
            "        [0.4900, 0.5100]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4905, 0.5095],\n",
            "        [0.4943, 0.5057],\n",
            "        [0.4937, 0.5063],\n",
            "        [0.4929, 0.5071],\n",
            "        [0.4900, 0.5100]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4896, 0.5104],\n",
            "        [0.4938, 0.5062],\n",
            "        [0.4932, 0.5068],\n",
            "        [0.4925, 0.5075],\n",
            "        [0.4894, 0.5106]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4891, 0.5109],\n",
            "        [0.4939, 0.5061],\n",
            "        [0.4929, 0.5071],\n",
            "        [0.4922, 0.5078],\n",
            "        [0.4894, 0.5106]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4885, 0.5115],\n",
            "        [0.4929, 0.5071],\n",
            "        [0.4918, 0.5082],\n",
            "        [0.4927, 0.5073],\n",
            "        [0.4881, 0.5119]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4880, 0.5120],\n",
            "        [0.4930, 0.5070],\n",
            "        [0.4910, 0.5090],\n",
            "        [0.4919, 0.5081],\n",
            "        [0.4874, 0.5126]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4881, 0.5119],\n",
            "        [0.4931, 0.5069],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.4918, 0.5082],\n",
            "        [0.4880, 0.5120]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4879, 0.5121],\n",
            "        [0.4931, 0.5069],\n",
            "        [0.4911, 0.5089],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.4880, 0.5120]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4878, 0.5122],\n",
            "        [0.4932, 0.5068],\n",
            "        [0.4907, 0.5093],\n",
            "        [0.4917, 0.5083],\n",
            "        [0.4886, 0.5114]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4872, 0.5128],\n",
            "        [0.4924, 0.5076],\n",
            "        [0.4900, 0.5100],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.4883, 0.5117]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4875, 0.5125],\n",
            "        [0.4930, 0.5070],\n",
            "        [0.4900, 0.5100],\n",
            "        [0.4919, 0.5081],\n",
            "        [0.4880, 0.5120]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4877, 0.5123],\n",
            "        [0.4926, 0.5074],\n",
            "        [0.4896, 0.5104],\n",
            "        [0.4920, 0.5080],\n",
            "        [0.4884, 0.5116]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4876, 0.5124],\n",
            "        [0.4921, 0.5079],\n",
            "        [0.4901, 0.5099],\n",
            "        [0.4917, 0.5083],\n",
            "        [0.4888, 0.5112]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4871, 0.5129],\n",
            "        [0.4920, 0.5080],\n",
            "        [0.4899, 0.5101],\n",
            "        [0.4925, 0.5075],\n",
            "        [0.4886, 0.5114]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4869, 0.5131],\n",
            "        [0.4921, 0.5079],\n",
            "        [0.4892, 0.5108],\n",
            "        [0.4918, 0.5082],\n",
            "        [0.4885, 0.5115]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4871, 0.5129],\n",
            "        [0.4924, 0.5076],\n",
            "        [0.4892, 0.5108],\n",
            "        [0.4919, 0.5081],\n",
            "        [0.4888, 0.5112]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4875, 0.5125],\n",
            "        [0.4923, 0.5077],\n",
            "        [0.4883, 0.5117],\n",
            "        [0.4925, 0.5075],\n",
            "        [0.4898, 0.5102]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4867, 0.5133],\n",
            "        [0.4924, 0.5076],\n",
            "        [0.4885, 0.5115],\n",
            "        [0.4906, 0.5094],\n",
            "        [0.4884, 0.5116]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4856, 0.5144],\n",
            "        [0.4916, 0.5084],\n",
            "        [0.4875, 0.5125],\n",
            "        [0.4910, 0.5090],\n",
            "        [0.4874, 0.5126]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4854, 0.5146],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.4878, 0.5122],\n",
            "        [0.4906, 0.5094],\n",
            "        [0.4875, 0.5125]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4844, 0.5156],\n",
            "        [0.4911, 0.5089],\n",
            "        [0.4868, 0.5132],\n",
            "        [0.4904, 0.5096],\n",
            "        [0.4862, 0.5138]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4841, 0.5159],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.4861, 0.5139],\n",
            "        [0.4901, 0.5099],\n",
            "        [0.4863, 0.5137]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4848, 0.5152],\n",
            "        [0.4920, 0.5080],\n",
            "        [0.4861, 0.5139],\n",
            "        [0.4906, 0.5094],\n",
            "        [0.4866, 0.5134]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4836, 0.5164],\n",
            "        [0.4905, 0.5095],\n",
            "        [0.4854, 0.5146],\n",
            "        [0.4898, 0.5102],\n",
            "        [0.4856, 0.5144]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4837, 0.5163],\n",
            "        [0.4913, 0.5087],\n",
            "        [0.4852, 0.5148],\n",
            "        [0.4897, 0.5103],\n",
            "        [0.4854, 0.5146]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4832, 0.5168],\n",
            "        [0.4910, 0.5090],\n",
            "        [0.4847, 0.5153],\n",
            "        [0.4895, 0.5105],\n",
            "        [0.4856, 0.5144]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4832, 0.5168],\n",
            "        [0.4913, 0.5087],\n",
            "        [0.4847, 0.5153],\n",
            "        [0.4897, 0.5103],\n",
            "        [0.4844, 0.5156]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4823, 0.5177],\n",
            "        [0.4908, 0.5092],\n",
            "        [0.4840, 0.5160],\n",
            "        [0.4889, 0.5111],\n",
            "        [0.4849, 0.5151]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4819, 0.5181],\n",
            "        [0.4902, 0.5098],\n",
            "        [0.4834, 0.5166],\n",
            "        [0.4885, 0.5115],\n",
            "        [0.4859, 0.5141]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4818, 0.5182],\n",
            "        [0.4905, 0.5095],\n",
            "        [0.4836, 0.5164],\n",
            "        [0.4883, 0.5117],\n",
            "        [0.4854, 0.5146]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4820, 0.5180],\n",
            "        [0.4906, 0.5094],\n",
            "        [0.4840, 0.5160],\n",
            "        [0.4888, 0.5112],\n",
            "        [0.4855, 0.5145]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4818, 0.5182],\n",
            "        [0.4902, 0.5098],\n",
            "        [0.4840, 0.5160],\n",
            "        [0.4889, 0.5111],\n",
            "        [0.4864, 0.5136]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4814, 0.5186],\n",
            "        [0.4894, 0.5106],\n",
            "        [0.4836, 0.5164],\n",
            "        [0.4882, 0.5118],\n",
            "        [0.4863, 0.5137]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4798, 0.5202],\n",
            "        [0.4877, 0.5123],\n",
            "        [0.4825, 0.5175],\n",
            "        [0.4869, 0.5131],\n",
            "        [0.4856, 0.5144]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4806, 0.5194],\n",
            "        [0.4883, 0.5117],\n",
            "        [0.4830, 0.5170],\n",
            "        [0.4874, 0.5126],\n",
            "        [0.4864, 0.5136]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4805, 0.5195],\n",
            "        [0.4889, 0.5111],\n",
            "        [0.4825, 0.5175],\n",
            "        [0.4868, 0.5132],\n",
            "        [0.4868, 0.5132]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4802, 0.5198],\n",
            "        [0.4885, 0.5115],\n",
            "        [0.4822, 0.5178],\n",
            "        [0.4871, 0.5129],\n",
            "        [0.4860, 0.5140]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4777, 0.5223],\n",
            "        [0.4860, 0.5140],\n",
            "        [0.4794, 0.5206],\n",
            "        [0.4846, 0.5154],\n",
            "        [0.4838, 0.5162]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4779, 0.5221],\n",
            "        [0.4862, 0.5138],\n",
            "        [0.4796, 0.5204],\n",
            "        [0.4850, 0.5150],\n",
            "        [0.4838, 0.5162]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4778, 0.5222],\n",
            "        [0.4861, 0.5139],\n",
            "        [0.4792, 0.5208],\n",
            "        [0.4847, 0.5153],\n",
            "        [0.4842, 0.5158]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4779, 0.5221],\n",
            "        [0.4862, 0.5138],\n",
            "        [0.4795, 0.5205],\n",
            "        [0.4848, 0.5152],\n",
            "        [0.4839, 0.5161]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4779, 0.5221],\n",
            "        [0.4860, 0.5140],\n",
            "        [0.4794, 0.5206],\n",
            "        [0.4847, 0.5153],\n",
            "        [0.4842, 0.5158]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4780, 0.5220],\n",
            "        [0.4862, 0.5138],\n",
            "        [0.4795, 0.5205],\n",
            "        [0.4846, 0.5154],\n",
            "        [0.4843, 0.5157]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4781, 0.5219],\n",
            "        [0.4864, 0.5136],\n",
            "        [0.4797, 0.5203],\n",
            "        [0.4846, 0.5154],\n",
            "        [0.4846, 0.5154]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4780, 0.5220],\n",
            "        [0.4863, 0.5137],\n",
            "        [0.4796, 0.5204],\n",
            "        [0.4846, 0.5154],\n",
            "        [0.4849, 0.5151]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4781, 0.5219],\n",
            "        [0.4863, 0.5137],\n",
            "        [0.4794, 0.5206],\n",
            "        [0.4847, 0.5153],\n",
            "        [0.4847, 0.5153]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4777, 0.5223],\n",
            "        [0.4861, 0.5139],\n",
            "        [0.4795, 0.5205],\n",
            "        [0.4845, 0.5155],\n",
            "        [0.4850, 0.5150]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4781, 0.5219],\n",
            "        [0.4862, 0.5138],\n",
            "        [0.4795, 0.5205],\n",
            "        [0.4845, 0.5155],\n",
            "        [0.4851, 0.5149]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4780, 0.5220],\n",
            "        [0.4863, 0.5137],\n",
            "        [0.4796, 0.5204],\n",
            "        [0.4846, 0.5154],\n",
            "        [0.4857, 0.5143]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4782, 0.5218],\n",
            "        [0.4863, 0.5137],\n",
            "        [0.4796, 0.5204],\n",
            "        [0.4848, 0.5152],\n",
            "        [0.4859, 0.5141]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4782, 0.5218],\n",
            "        [0.4863, 0.5137],\n",
            "        [0.4797, 0.5203],\n",
            "        [0.4850, 0.5150],\n",
            "        [0.4860, 0.5140]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4781, 0.5219],\n",
            "        [0.4864, 0.5136],\n",
            "        [0.4796, 0.5204],\n",
            "        [0.4848, 0.5152],\n",
            "        [0.4859, 0.5141]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4784, 0.5216],\n",
            "        [0.4865, 0.5135],\n",
            "        [0.4795, 0.5205],\n",
            "        [0.4848, 0.5152],\n",
            "        [0.4861, 0.5139]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4783, 0.5217],\n",
            "        [0.4868, 0.5132],\n",
            "        [0.4795, 0.5205],\n",
            "        [0.4852, 0.5148],\n",
            "        [0.4864, 0.5136]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4785, 0.5215],\n",
            "        [0.4865, 0.5135],\n",
            "        [0.4791, 0.5209],\n",
            "        [0.4844, 0.5156],\n",
            "        [0.4856, 0.5144]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4784, 0.5216],\n",
            "        [0.4864, 0.5136],\n",
            "        [0.4794, 0.5206],\n",
            "        [0.4844, 0.5156],\n",
            "        [0.4860, 0.5140]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4783, 0.5217],\n",
            "        [0.4865, 0.5135],\n",
            "        [0.4791, 0.5209],\n",
            "        [0.4844, 0.5156],\n",
            "        [0.4864, 0.5136]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4782, 0.5218],\n",
            "        [0.4864, 0.5136],\n",
            "        [0.4793, 0.5207],\n",
            "        [0.4844, 0.5156],\n",
            "        [0.4866, 0.5134]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4782, 0.5218],\n",
            "        [0.4865, 0.5135],\n",
            "        [0.4794, 0.5206],\n",
            "        [0.4843, 0.5157],\n",
            "        [0.4866, 0.5134]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4779, 0.5221],\n",
            "        [0.4864, 0.5136],\n",
            "        [0.4791, 0.5209],\n",
            "        [0.4842, 0.5158],\n",
            "        [0.4867, 0.5133]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4779, 0.5221],\n",
            "        [0.4863, 0.5137],\n",
            "        [0.4790, 0.5210],\n",
            "        [0.4839, 0.5161],\n",
            "        [0.4866, 0.5134]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4779, 0.5221],\n",
            "        [0.4864, 0.5136],\n",
            "        [0.4790, 0.5210],\n",
            "        [0.4841, 0.5159],\n",
            "        [0.4867, 0.5133]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4780, 0.5220],\n",
            "        [0.4864, 0.5136],\n",
            "        [0.4790, 0.5210],\n",
            "        [0.4838, 0.5162],\n",
            "        [0.4872, 0.5128]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4781, 0.5219],\n",
            "        [0.4865, 0.5135],\n",
            "        [0.4792, 0.5208],\n",
            "        [0.4836, 0.5164],\n",
            "        [0.4876, 0.5124]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4782, 0.5218],\n",
            "        [0.4867, 0.5133],\n",
            "        [0.4794, 0.5206],\n",
            "        [0.4840, 0.5160],\n",
            "        [0.4880, 0.5120]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4783, 0.5217],\n",
            "        [0.4869, 0.5131],\n",
            "        [0.4799, 0.5201],\n",
            "        [0.4846, 0.5154],\n",
            "        [0.4887, 0.5113]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4783, 0.5217],\n",
            "        [0.4869, 0.5131],\n",
            "        [0.4794, 0.5206],\n",
            "        [0.4846, 0.5154],\n",
            "        [0.4886, 0.5114]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4783, 0.5217],\n",
            "        [0.4869, 0.5131],\n",
            "        [0.4796, 0.5204],\n",
            "        [0.4850, 0.5150],\n",
            "        [0.4891, 0.5109]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4784, 0.5216],\n",
            "        [0.4871, 0.5129],\n",
            "        [0.4798, 0.5202],\n",
            "        [0.4852, 0.5148],\n",
            "        [0.4897, 0.5103]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4787, 0.5213],\n",
            "        [0.4873, 0.5127],\n",
            "        [0.4803, 0.5197],\n",
            "        [0.4849, 0.5151],\n",
            "        [0.4900, 0.5100]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4782, 0.5218],\n",
            "        [0.4871, 0.5129],\n",
            "        [0.4803, 0.5197],\n",
            "        [0.4852, 0.5148],\n",
            "        [0.4901, 0.5099]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4782, 0.5218],\n",
            "        [0.4870, 0.5130],\n",
            "        [0.4801, 0.5199],\n",
            "        [0.4853, 0.5147],\n",
            "        [0.4904, 0.5096]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4784, 0.5216],\n",
            "        [0.4869, 0.5131],\n",
            "        [0.4807, 0.5193],\n",
            "        [0.4848, 0.5152],\n",
            "        [0.4904, 0.5096]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4785, 0.5215],\n",
            "        [0.4876, 0.5124],\n",
            "        [0.4807, 0.5193],\n",
            "        [0.4840, 0.5160],\n",
            "        [0.4901, 0.5099]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4787, 0.5213],\n",
            "        [0.4878, 0.5122],\n",
            "        [0.4803, 0.5197],\n",
            "        [0.4847, 0.5153],\n",
            "        [0.4906, 0.5094]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4787, 0.5213],\n",
            "        [0.4877, 0.5123],\n",
            "        [0.4802, 0.5198],\n",
            "        [0.4847, 0.5153],\n",
            "        [0.4909, 0.5091]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4789, 0.5211],\n",
            "        [0.4877, 0.5123],\n",
            "        [0.4802, 0.5198],\n",
            "        [0.4846, 0.5154],\n",
            "        [0.4913, 0.5087]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4791, 0.5209],\n",
            "        [0.4877, 0.5123],\n",
            "        [0.4805, 0.5195],\n",
            "        [0.4849, 0.5151],\n",
            "        [0.4918, 0.5082]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4790, 0.5210],\n",
            "        [0.4880, 0.5120],\n",
            "        [0.4802, 0.5198],\n",
            "        [0.4850, 0.5150],\n",
            "        [0.4920, 0.5080]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4783, 0.5217],\n",
            "        [0.4876, 0.5124],\n",
            "        [0.4799, 0.5201],\n",
            "        [0.4851, 0.5149],\n",
            "        [0.4924, 0.5076]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4786, 0.5214],\n",
            "        [0.4879, 0.5121],\n",
            "        [0.4802, 0.5198],\n",
            "        [0.4852, 0.5148],\n",
            "        [0.4929, 0.5071]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4783, 0.5217],\n",
            "        [0.4879, 0.5121],\n",
            "        [0.4807, 0.5193],\n",
            "        [0.4853, 0.5147],\n",
            "        [0.4933, 0.5067]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4782, 0.5218],\n",
            "        [0.4879, 0.5121],\n",
            "        [0.4806, 0.5194],\n",
            "        [0.4854, 0.5146],\n",
            "        [0.4935, 0.5065]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4783, 0.5217],\n",
            "        [0.4879, 0.5121],\n",
            "        [0.4809, 0.5191],\n",
            "        [0.4852, 0.5148],\n",
            "        [0.4933, 0.5067]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4786, 0.5214],\n",
            "        [0.4881, 0.5119],\n",
            "        [0.4809, 0.5191],\n",
            "        [0.4852, 0.5148],\n",
            "        [0.4939, 0.5061]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4784, 0.5216],\n",
            "        [0.4881, 0.5119],\n",
            "        [0.4809, 0.5191],\n",
            "        [0.4855, 0.5145],\n",
            "        [0.4939, 0.5061]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4788, 0.5212],\n",
            "        [0.4890, 0.5110],\n",
            "        [0.4821, 0.5179],\n",
            "        [0.4866, 0.5134],\n",
            "        [0.4944, 0.5056]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4789, 0.5211],\n",
            "        [0.4888, 0.5112],\n",
            "        [0.4819, 0.5181],\n",
            "        [0.4865, 0.5135],\n",
            "        [0.4946, 0.5054]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4785, 0.5215],\n",
            "        [0.4885, 0.5115],\n",
            "        [0.4818, 0.5182],\n",
            "        [0.4865, 0.5135],\n",
            "        [0.4950, 0.5050]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4784, 0.5216],\n",
            "        [0.4887, 0.5113],\n",
            "        [0.4821, 0.5179],\n",
            "        [0.4868, 0.5132],\n",
            "        [0.4958, 0.5042]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4781, 0.5219],\n",
            "        [0.4886, 0.5114],\n",
            "        [0.4817, 0.5183],\n",
            "        [0.4867, 0.5133],\n",
            "        [0.4956, 0.5044]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4787, 0.5213],\n",
            "        [0.4892, 0.5108],\n",
            "        [0.4818, 0.5182],\n",
            "        [0.4871, 0.5129],\n",
            "        [0.4966, 0.5034]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4786, 0.5214],\n",
            "        [0.4890, 0.5110],\n",
            "        [0.4818, 0.5182],\n",
            "        [0.4872, 0.5128],\n",
            "        [0.4963, 0.5037]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4788, 0.5212],\n",
            "        [0.4892, 0.5108],\n",
            "        [0.4820, 0.5180],\n",
            "        [0.4874, 0.5126],\n",
            "        [0.4967, 0.5033]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4788, 0.5212],\n",
            "        [0.4895, 0.5105],\n",
            "        [0.4822, 0.5178],\n",
            "        [0.4874, 0.5126],\n",
            "        [0.4972, 0.5028]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4794, 0.5206],\n",
            "        [0.4897, 0.5103],\n",
            "        [0.4827, 0.5173],\n",
            "        [0.4876, 0.5124],\n",
            "        [0.4976, 0.5024]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4789, 0.5211],\n",
            "        [0.4896, 0.5104],\n",
            "        [0.4827, 0.5173],\n",
            "        [0.4878, 0.5122],\n",
            "        [0.4980, 0.5020]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4791, 0.5209],\n",
            "        [0.4897, 0.5103],\n",
            "        [0.4832, 0.5168],\n",
            "        [0.4878, 0.5122],\n",
            "        [0.4982, 0.5018]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4787, 0.5213],\n",
            "        [0.4892, 0.5108],\n",
            "        [0.4830, 0.5170],\n",
            "        [0.4891, 0.5109],\n",
            "        [0.4975, 0.5025]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4787, 0.5213],\n",
            "        [0.4892, 0.5108],\n",
            "        [0.4833, 0.5167],\n",
            "        [0.4888, 0.5112],\n",
            "        [0.4977, 0.5023]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4790, 0.5210],\n",
            "        [0.4894, 0.5106],\n",
            "        [0.4836, 0.5164],\n",
            "        [0.4891, 0.5109],\n",
            "        [0.4980, 0.5020]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4790, 0.5210],\n",
            "        [0.4894, 0.5106],\n",
            "        [0.4833, 0.5167],\n",
            "        [0.4890, 0.5110],\n",
            "        [0.4982, 0.5018]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4791, 0.5209],\n",
            "        [0.4895, 0.5105],\n",
            "        [0.4834, 0.5166],\n",
            "        [0.4890, 0.5110],\n",
            "        [0.4984, 0.5016]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4792, 0.5208],\n",
            "        [0.4897, 0.5103],\n",
            "        [0.4838, 0.5162],\n",
            "        [0.4894, 0.5106],\n",
            "        [0.4988, 0.5012]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4791, 0.5209],\n",
            "        [0.4899, 0.5101],\n",
            "        [0.4834, 0.5166],\n",
            "        [0.4894, 0.5106],\n",
            "        [0.4991, 0.5009]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4793, 0.5207],\n",
            "        [0.4900, 0.5100],\n",
            "        [0.4835, 0.5165],\n",
            "        [0.4896, 0.5104],\n",
            "        [0.4995, 0.5005]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4794, 0.5206],\n",
            "        [0.4899, 0.5101],\n",
            "        [0.4837, 0.5163],\n",
            "        [0.4896, 0.5104],\n",
            "        [0.4997, 0.5003]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4793, 0.5207],\n",
            "        [0.4901, 0.5099],\n",
            "        [0.4839, 0.5161],\n",
            "        [0.4898, 0.5102],\n",
            "        [0.4998, 0.5002]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4794, 0.5206],\n",
            "        [0.4902, 0.5098],\n",
            "        [0.4843, 0.5157],\n",
            "        [0.4900, 0.5100],\n",
            "        [0.5002, 0.4998]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4795, 0.5205],\n",
            "        [0.4903, 0.5097],\n",
            "        [0.4844, 0.5156],\n",
            "        [0.4901, 0.5099],\n",
            "        [0.5007, 0.4993]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4794, 0.5206],\n",
            "        [0.4905, 0.5095],\n",
            "        [0.4848, 0.5152],\n",
            "        [0.4903, 0.5097],\n",
            "        [0.5009, 0.4991]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4794, 0.5206],\n",
            "        [0.4903, 0.5097],\n",
            "        [0.4848, 0.5152],\n",
            "        [0.4903, 0.5097],\n",
            "        [0.5010, 0.4990]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4795, 0.5205],\n",
            "        [0.4904, 0.5096],\n",
            "        [0.4848, 0.5152],\n",
            "        [0.4904, 0.5096],\n",
            "        [0.5013, 0.4987]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4797, 0.5203],\n",
            "        [0.4905, 0.5095],\n",
            "        [0.4851, 0.5149],\n",
            "        [0.4904, 0.5096],\n",
            "        [0.5017, 0.4983]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4797, 0.5203],\n",
            "        [0.4908, 0.5092],\n",
            "        [0.4853, 0.5147],\n",
            "        [0.4905, 0.5095],\n",
            "        [0.5019, 0.4981]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4799, 0.5201],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.4853, 0.5147],\n",
            "        [0.4906, 0.5094],\n",
            "        [0.5021, 0.4979]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4799, 0.5201],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.4853, 0.5147],\n",
            "        [0.4908, 0.5092],\n",
            "        [0.5025, 0.4975]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4800, 0.5200],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.4855, 0.5145],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.5026, 0.4974]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4798, 0.5202],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.4855, 0.5145],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.5027, 0.4973]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4799, 0.5201],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.4854, 0.5146],\n",
            "        [0.4908, 0.5092],\n",
            "        [0.5028, 0.4972]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4800, 0.5200],\n",
            "        [0.4910, 0.5090],\n",
            "        [0.4855, 0.5145],\n",
            "        [0.4909, 0.5091],\n",
            "        [0.5030, 0.4970]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4801, 0.5199],\n",
            "        [0.4911, 0.5089],\n",
            "        [0.4857, 0.5143],\n",
            "        [0.4910, 0.5090],\n",
            "        [0.5032, 0.4968]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4802, 0.5198],\n",
            "        [0.4913, 0.5087],\n",
            "        [0.4857, 0.5143],\n",
            "        [0.4911, 0.5089],\n",
            "        [0.5035, 0.4965]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4802, 0.5198],\n",
            "        [0.4913, 0.5087],\n",
            "        [0.4858, 0.5142],\n",
            "        [0.4911, 0.5089],\n",
            "        [0.5036, 0.4964]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4803, 0.5197],\n",
            "        [0.4913, 0.5087],\n",
            "        [0.4859, 0.5141],\n",
            "        [0.4912, 0.5088],\n",
            "        [0.5038, 0.4962]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4803, 0.5197],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.4860, 0.5140],\n",
            "        [0.4913, 0.5087],\n",
            "        [0.5038, 0.4962]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4803, 0.5197],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.4860, 0.5140],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.5039, 0.4961]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4803, 0.5197],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.4860, 0.5140],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.5040, 0.4960]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4803, 0.5197],\n",
            "        [0.4915, 0.5085],\n",
            "        [0.4860, 0.5140],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.5041, 0.4959]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>), tensor([[0.4803, 0.5197],\n",
            "        [0.4915, 0.5085],\n",
            "        [0.4860, 0.5140],\n",
            "        [0.4914, 0.5086],\n",
            "        [0.5041, 0.4959]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<SoftmaxBackward0>)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_pixelDa_ReLU --train_name truck_nas_project_layer_types_pixelDa_ReLU --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 50 --n_epochs 100 --n_epochs_decay 100 --layer_types PixelDa+ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdC9C8FC5jC-",
        "outputId": "b34823b3-ddfe-4d9b-c729-2a917620db56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 50                            \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: all_layers                    \t[default: CycleGan]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_epochs: 50                            \t[default: 100]\n",
            "           n_epochs_decay: 50                            \t[default: 100]\n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_all_layers\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_all_layers\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 36.161 M\n",
            "[Network G_B] Total number of parameters : 36.161 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_all_layers/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 1.373, data: 0.239) D_A: 0.304 G_A: 0.365 cycle_A: 1.004 idt_A: 1.492 D_B: 0.184 G_B: 0.630 cycle_B: 2.917 idt_B: 0.381 \n",
            "End of epoch 1 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 1.369, data: 0.256) D_A: 0.216 G_A: 0.367 cycle_A: 1.302 idt_A: 1.156 D_B: 0.149 G_B: 0.548 cycle_B: 3.035 idt_B: 0.562 \n",
            "End of epoch 2 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 1.366, data: 0.330) D_A: 0.218 G_A: 0.480 cycle_A: 1.290 idt_A: 1.328 D_B: 0.355 G_B: 0.312 cycle_B: 3.272 idt_B: 0.604 \n",
            "End of epoch 3 / 100 \t Time Taken: 125 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 1.588, data: 0.409) D_A: 0.208 G_A: 0.272 cycle_A: 1.034 idt_A: 3.117 D_B: 0.158 G_B: 0.282 cycle_B: 6.282 idt_B: 0.453 \n",
            "End of epoch 4 / 100 \t Time Taken: 125 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 1.374, data: 0.230) D_A: 0.440 G_A: 0.518 cycle_A: 0.819 idt_A: 1.173 D_B: 0.516 G_B: 0.353 cycle_B: 2.657 idt_B: 0.361 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 1.367, data: 0.240) D_A: 0.214 G_A: 0.240 cycle_A: 0.806 idt_A: 0.860 D_B: 0.076 G_B: 0.494 cycle_B: 2.337 idt_B: 0.414 \n",
            "End of epoch 6 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 1.377, data: 0.207) D_A: 0.390 G_A: 0.501 cycle_A: 0.607 idt_A: 1.129 D_B: 0.144 G_B: 0.652 cycle_B: 2.418 idt_B: 0.265 \n",
            "End of epoch 7 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 1.618, data: 0.383) D_A: 0.281 G_A: 0.412 cycle_A: 0.956 idt_A: 0.965 D_B: 0.255 G_B: 0.186 cycle_B: 2.405 idt_B: 0.411 \n",
            "End of epoch 8 / 100 \t Time Taken: 125 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 1.370, data: 0.315) D_A: 0.297 G_A: 0.202 cycle_A: 0.690 idt_A: 1.116 D_B: 0.189 G_B: 0.607 cycle_B: 2.393 idt_B: 0.323 \n",
            "End of epoch 9 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 1.356, data: 0.230) D_A: 0.423 G_A: 0.748 cycle_A: 0.791 idt_A: 0.622 D_B: 0.206 G_B: 0.922 cycle_B: 1.847 idt_B: 0.369 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 100 \t Time Taken: 134 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 1.364, data: 0.626) D_A: 0.241 G_A: 0.297 cycle_A: 0.573 idt_A: 0.828 D_B: 0.189 G_B: 0.024 cycle_B: 1.636 idt_B: 0.255 \n",
            "End of epoch 11 / 100 \t Time Taken: 125 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 1.630, data: 0.246) D_A: 0.249 G_A: 0.292 cycle_A: 0.877 idt_A: 0.997 D_B: 0.295 G_B: 0.928 cycle_B: 2.160 idt_B: 0.333 \n",
            "End of epoch 12 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 1.366, data: 0.243) D_A: 0.268 G_A: 0.703 cycle_A: 0.581 idt_A: 0.869 D_B: 0.080 G_B: 0.561 cycle_B: 1.973 idt_B: 0.274 \n",
            "End of epoch 13 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 1.367, data: 0.322) D_A: 0.230 G_A: 0.334 cycle_A: 1.582 idt_A: 1.211 D_B: 0.135 G_B: 0.403 cycle_B: 2.749 idt_B: 0.699 \n",
            "End of epoch 14 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 1.364, data: 0.398) D_A: 0.398 G_A: 0.625 cycle_A: 0.760 idt_A: 1.078 D_B: 0.069 G_B: 0.853 cycle_B: 3.019 idt_B: 0.392 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 100 \t Time Taken: 135 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 1.704, data: 0.338) D_A: 0.176 G_A: 0.350 cycle_A: 1.274 idt_A: 1.671 D_B: 0.100 G_B: 0.506 cycle_B: 3.381 idt_B: 0.539 \n",
            "End of epoch 16 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 1.363, data: 0.387) D_A: 0.186 G_A: 0.622 cycle_A: 1.660 idt_A: 0.723 D_B: 0.170 G_B: 0.428 cycle_B: 3.024 idt_B: 0.768 \n",
            "End of epoch 17 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 1.365, data: 0.239) D_A: 0.124 G_A: 0.584 cycle_A: 0.666 idt_A: 0.977 D_B: 0.052 G_B: 0.682 cycle_B: 2.029 idt_B: 0.219 \n",
            "End of epoch 18 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 1.368, data: 0.210) D_A: 0.331 G_A: 0.598 cycle_A: 0.648 idt_A: 0.838 D_B: 0.050 G_B: 0.373 cycle_B: 2.166 idt_B: 0.218 \n",
            "End of epoch 19 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 1.702, data: 0.336) D_A: 0.166 G_A: 0.225 cycle_A: 0.721 idt_A: 0.755 D_B: 0.047 G_B: 0.961 cycle_B: 1.863 idt_B: 0.326 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 100 \t Time Taken: 133 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 1.367, data: 0.584) D_A: 0.136 G_A: 0.567 cycle_A: 1.453 idt_A: 0.850 D_B: 0.128 G_B: 0.635 cycle_B: 2.429 idt_B: 0.342 \n",
            "End of epoch 21 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 1.362, data: 0.236) D_A: 0.193 G_A: 0.209 cycle_A: 0.911 idt_A: 0.795 D_B: 0.513 G_B: 0.610 cycle_B: 1.785 idt_B: 0.370 \n",
            "End of epoch 22 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 1.360, data: 0.401) D_A: 0.303 G_A: 1.034 cycle_A: 0.814 idt_A: 1.165 D_B: 0.193 G_B: 0.360 cycle_B: 2.631 idt_B: 0.256 \n",
            "End of epoch 23 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 1.693, data: 0.261) D_A: 0.270 G_A: 0.330 cycle_A: 0.717 idt_A: 1.064 D_B: 0.331 G_B: 0.081 cycle_B: 2.575 idt_B: 0.278 \n",
            "End of epoch 24 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 1.366, data: 0.332) D_A: 0.111 G_A: 0.433 cycle_A: 0.942 idt_A: 0.778 D_B: 0.128 G_B: 0.731 cycle_B: 2.332 idt_B: 0.262 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 100 \t Time Taken: 131 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 1.365, data: 0.331) D_A: 0.073 G_A: 0.286 cycle_A: 1.222 idt_A: 1.189 D_B: 0.222 G_B: 0.849 cycle_B: 2.786 idt_B: 0.482 \n",
            "End of epoch 26 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 1.361, data: 0.397) D_A: 0.119 G_A: 0.715 cycle_A: 0.513 idt_A: 0.838 D_B: 0.067 G_B: 0.154 cycle_B: 1.997 idt_B: 0.161 \n",
            "End of epoch 27 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 1.697, data: 0.230) D_A: 0.321 G_A: 0.129 cycle_A: 1.000 idt_A: 1.468 D_B: 0.104 G_B: 0.625 cycle_B: 3.222 idt_B: 0.372 \n",
            "End of epoch 28 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 1.364, data: 0.354) D_A: 0.084 G_A: 0.607 cycle_A: 0.818 idt_A: 1.089 D_B: 0.141 G_B: 0.433 cycle_B: 2.231 idt_B: 0.382 \n",
            "End of epoch 29 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 1.360, data: 0.237) D_A: 0.153 G_A: 0.353 cycle_A: 0.812 idt_A: 1.173 D_B: 0.098 G_B: 1.044 cycle_B: 2.855 idt_B: 0.275 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 100 \t Time Taken: 133 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 1.365, data: 0.331) D_A: 0.333 G_A: 0.600 cycle_A: 0.772 idt_A: 1.205 D_B: 0.240 G_B: 0.285 cycle_B: 2.233 idt_B: 0.275 \n",
            "End of epoch 31 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 1.814, data: 0.242) D_A: 0.066 G_A: 0.681 cycle_A: 0.789 idt_A: 0.741 D_B: 0.258 G_B: 0.697 cycle_B: 1.619 idt_B: 0.534 \n",
            "End of epoch 32 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 1.363, data: 0.340) D_A: 0.128 G_A: 0.610 cycle_A: 0.845 idt_A: 0.859 D_B: 0.207 G_B: 0.865 cycle_B: 2.269 idt_B: 0.313 \n",
            "End of epoch 33 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 1.362, data: 0.234) D_A: 0.129 G_A: 0.570 cycle_A: 0.641 idt_A: 1.589 D_B: 0.166 G_B: 0.438 cycle_B: 3.229 idt_B: 0.273 \n",
            "End of epoch 34 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 1.360, data: 0.383) D_A: 0.318 G_A: 0.407 cycle_A: 0.480 idt_A: 0.882 D_B: 0.117 G_B: 0.779 cycle_B: 1.701 idt_B: 0.173 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 100 \t Time Taken: 131 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 1.798, data: 0.338) D_A: 0.108 G_A: 0.703 cycle_A: 0.893 idt_A: 0.784 D_B: 0.083 G_B: 0.269 cycle_B: 2.002 idt_B: 0.279 \n",
            "End of epoch 36 / 100 \t Time Taken: 125 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 1.359, data: 0.258) D_A: 0.074 G_A: 0.910 cycle_A: 0.636 idt_A: 1.095 D_B: 0.129 G_B: 0.459 cycle_B: 2.481 idt_B: 0.199 \n",
            "End of epoch 37 / 100 \t Time Taken: 123 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 1.371, data: 0.280) D_A: 0.172 G_A: 1.010 cycle_A: 0.585 idt_A: 1.053 D_B: 0.161 G_B: 0.345 cycle_B: 2.516 idt_B: 0.201 \n",
            "End of epoch 38 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 1.379, data: 0.394) D_A: 0.170 G_A: 0.540 cycle_A: 1.375 idt_A: 1.092 D_B: 0.149 G_B: 0.265 cycle_B: 2.456 idt_B: 0.602 \n",
            "End of epoch 39 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 1.777, data: 0.349) D_A: 0.090 G_A: 0.485 cycle_A: 0.737 idt_A: 1.074 D_B: 0.124 G_B: 0.321 cycle_B: 2.382 idt_B: 0.316 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 100 \t Time Taken: 131 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 1.363, data: 0.218) D_A: 0.059 G_A: 0.228 cycle_A: 0.738 idt_A: 0.939 D_B: 0.122 G_B: 0.312 cycle_B: 3.337 idt_B: 0.239 \n",
            "End of epoch 41 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 1.355, data: 0.377) D_A: 0.149 G_A: 0.438 cycle_A: 1.140 idt_A: 0.753 D_B: 0.116 G_B: 0.891 cycle_B: 1.992 idt_B: 0.436 \n",
            "End of epoch 42 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 1.362, data: 0.279) D_A: 0.422 G_A: 0.090 cycle_A: 0.717 idt_A: 1.063 D_B: 0.195 G_B: 0.185 cycle_B: 3.550 idt_B: 0.233 \n",
            "End of epoch 43 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 1.930, data: 0.277) D_A: 0.205 G_A: 0.278 cycle_A: 0.786 idt_A: 0.958 D_B: 0.118 G_B: 0.444 cycle_B: 1.627 idt_B: 0.286 \n",
            "End of epoch 44 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 1.366, data: 0.462) D_A: 0.118 G_A: 0.501 cycle_A: 0.727 idt_A: 1.127 D_B: 0.110 G_B: 0.418 cycle_B: 2.567 idt_B: 0.449 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 100 \t Time Taken: 133 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 1.363, data: 0.326) D_A: 0.223 G_A: 0.333 cycle_A: 0.776 idt_A: 1.001 D_B: 0.125 G_B: 0.148 cycle_B: 2.357 idt_B: 0.265 \n",
            "End of epoch 46 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 1.359, data: 0.365) D_A: 0.206 G_A: 0.206 cycle_A: 0.461 idt_A: 0.774 D_B: 0.202 G_B: 0.538 cycle_B: 2.243 idt_B: 0.184 \n",
            "End of epoch 47 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 1.823, data: 0.627) D_A: 0.094 G_A: 0.277 cycle_A: 1.179 idt_A: 0.830 D_B: 0.195 G_B: 0.338 cycle_B: 1.761 idt_B: 0.315 \n",
            "End of epoch 48 / 100 \t Time Taken: 125 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 1.357, data: 0.261) D_A: 0.241 G_A: 0.661 cycle_A: 0.407 idt_A: 0.737 D_B: 0.241 G_B: 0.175 cycle_B: 1.825 idt_B: 0.177 \n",
            "End of epoch 49 / 100 \t Time Taken: 124 sec\n",
            "learning rate 0.0002000 -> 0.0001961\n",
            "(epoch: 50, iters: 100, time: 1.387, data: 0.268) D_A: 0.064 G_A: 0.518 cycle_A: 0.692 idt_A: 1.210 D_B: 0.172 G_B: 0.358 cycle_B: 1.887 idt_B: 0.349 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 100 \t Time Taken: 139 sec\n",
            "learning rate 0.0001961 -> 0.0001922\n",
            "(epoch: 51, iters: 100, time: 1.381, data: 0.304) D_A: 0.103 G_A: 0.450 cycle_A: 0.488 idt_A: 0.772 D_B: 0.122 G_B: 0.568 cycle_B: 1.633 idt_B: 0.184 \n",
            "End of epoch 51 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0001922 -> 0.0001882\n",
            "(epoch: 52, iters: 100, time: 1.862, data: 0.452) D_A: 0.123 G_A: 0.564 cycle_A: 0.535 idt_A: 0.670 D_B: 0.125 G_B: 0.421 cycle_B: 2.022 idt_B: 0.235 \n",
            "End of epoch 52 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0001882 -> 0.0001843\n",
            "(epoch: 53, iters: 100, time: 1.371, data: 0.291) D_A: 0.063 G_A: 0.639 cycle_A: 0.620 idt_A: 0.820 D_B: 0.057 G_B: 0.779 cycle_B: 3.672 idt_B: 0.237 \n",
            "End of epoch 53 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001843 -> 0.0001804\n",
            "(epoch: 54, iters: 100, time: 1.380, data: 0.242) D_A: 0.159 G_A: 0.299 cycle_A: 1.216 idt_A: 1.044 D_B: 0.169 G_B: 1.024 cycle_B: 3.421 idt_B: 0.460 \n",
            "End of epoch 54 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001804 -> 0.0001765\n",
            "(epoch: 55, iters: 100, time: 1.384, data: 0.237) D_A: 0.291 G_A: 0.226 cycle_A: 0.368 idt_A: 1.236 D_B: 0.075 G_B: 0.732 cycle_B: 2.768 idt_B: 0.183 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 100 \t Time Taken: 135 sec\n",
            "learning rate 0.0001765 -> 0.0001725\n",
            "(epoch: 56, iters: 100, time: 2.062, data: 0.361) D_A: 0.099 G_A: 0.295 cycle_A: 0.668 idt_A: 0.936 D_B: 0.331 G_B: 0.408 cycle_B: 2.291 idt_B: 0.221 \n",
            "End of epoch 56 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0001725 -> 0.0001686\n",
            "(epoch: 57, iters: 100, time: 1.367, data: 0.288) D_A: 0.111 G_A: 0.583 cycle_A: 0.428 idt_A: 0.886 D_B: 0.157 G_B: 0.400 cycle_B: 2.134 idt_B: 0.210 \n",
            "End of epoch 57 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001686 -> 0.0001647\n",
            "(epoch: 58, iters: 100, time: 1.378, data: 0.419) D_A: 0.169 G_A: 0.458 cycle_A: 0.961 idt_A: 0.987 D_B: 0.067 G_B: 0.560 cycle_B: 2.812 idt_B: 0.445 \n",
            "End of epoch 58 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001647 -> 0.0001608\n",
            "(epoch: 59, iters: 100, time: 1.370, data: 0.277) D_A: 0.063 G_A: 0.098 cycle_A: 0.745 idt_A: 0.905 D_B: 0.101 G_B: 0.171 cycle_B: 1.984 idt_B: 0.190 \n",
            "End of epoch 59 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001608 -> 0.0001569\n",
            "(epoch: 60, iters: 100, time: 1.914, data: 0.272) D_A: 0.142 G_A: 0.364 cycle_A: 0.669 idt_A: 0.581 D_B: 0.109 G_B: 0.586 cycle_B: 1.688 idt_B: 0.176 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 100 \t Time Taken: 136 sec\n",
            "learning rate 0.0001569 -> 0.0001529\n",
            "(epoch: 61, iters: 100, time: 1.374, data: 0.280) D_A: 0.166 G_A: 0.395 cycle_A: 0.498 idt_A: 0.779 D_B: 0.354 G_B: 0.398 cycle_B: 2.402 idt_B: 0.164 \n",
            "End of epoch 61 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001529 -> 0.0001490\n",
            "(epoch: 62, iters: 100, time: 1.369, data: 0.288) D_A: 0.047 G_A: 0.459 cycle_A: 0.581 idt_A: 0.847 D_B: 0.080 G_B: 1.069 cycle_B: 2.690 idt_B: 0.276 \n",
            "End of epoch 62 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001490 -> 0.0001451\n",
            "(epoch: 63, iters: 100, time: 1.371, data: 0.280) D_A: 0.236 G_A: 0.493 cycle_A: 0.527 idt_A: 0.699 D_B: 0.108 G_B: 0.368 cycle_B: 1.915 idt_B: 0.151 \n",
            "End of epoch 63 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001451 -> 0.0001412\n",
            "(epoch: 64, iters: 100, time: 1.975, data: 0.376) D_A: 0.134 G_A: 0.368 cycle_A: 0.619 idt_A: 0.601 D_B: 0.204 G_B: 0.282 cycle_B: 1.136 idt_B: 0.265 \n",
            "End of epoch 64 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0001412 -> 0.0001373\n",
            "(epoch: 65, iters: 100, time: 1.375, data: 0.227) D_A: 0.159 G_A: 0.333 cycle_A: 0.887 idt_A: 1.012 D_B: 0.156 G_B: 0.376 cycle_B: 2.062 idt_B: 0.364 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 100 \t Time Taken: 136 sec\n",
            "learning rate 0.0001373 -> 0.0001333\n",
            "(epoch: 66, iters: 100, time: 1.374, data: 0.560) D_A: 0.153 G_A: 0.434 cycle_A: 0.655 idt_A: 0.867 D_B: 0.188 G_B: 0.900 cycle_B: 2.559 idt_B: 0.219 \n",
            "End of epoch 66 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0001333 -> 0.0001294\n",
            "(epoch: 67, iters: 100, time: 1.366, data: 0.276) D_A: 0.340 G_A: 0.222 cycle_A: 0.448 idt_A: 0.732 D_B: 0.141 G_B: 0.473 cycle_B: 1.413 idt_B: 0.169 \n",
            "End of epoch 67 / 100 \t Time Taken: 128 sec\n",
            "learning rate 0.0001294 -> 0.0001255\n",
            "(epoch: 68, iters: 100, time: 1.977, data: 0.285) D_A: 0.414 G_A: 0.569 cycle_A: 0.592 idt_A: 0.646 D_B: 0.432 G_B: 0.037 cycle_B: 1.262 idt_B: 0.185 \n",
            "End of epoch 68 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001255 -> 0.0001216\n",
            "(epoch: 69, iters: 100, time: 1.382, data: 0.242) D_A: 0.296 G_A: 0.848 cycle_A: 0.418 idt_A: 0.898 D_B: 0.056 G_B: 0.674 cycle_B: 2.642 idt_B: 0.137 \n",
            "End of epoch 69 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001216 -> 0.0001176\n",
            "(epoch: 70, iters: 100, time: 1.371, data: 0.401) D_A: 0.092 G_A: 0.690 cycle_A: 0.601 idt_A: 0.687 D_B: 0.110 G_B: 0.546 cycle_B: 1.750 idt_B: 0.301 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 100 \t Time Taken: 136 sec\n",
            "learning rate 0.0001176 -> 0.0001137\n",
            "(epoch: 71, iters: 100, time: 1.378, data: 0.366) D_A: 0.089 G_A: 0.147 cycle_A: 0.612 idt_A: 0.453 D_B: 0.123 G_B: 0.871 cycle_B: 1.354 idt_B: 0.200 \n",
            "End of epoch 71 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001137 -> 0.0001098\n",
            "(epoch: 72, iters: 100, time: 1.977, data: 0.384) D_A: 0.074 G_A: 0.573 cycle_A: 0.334 idt_A: 0.920 D_B: 0.077 G_B: 0.686 cycle_B: 2.667 idt_B: 0.129 \n",
            "End of epoch 72 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0001098 -> 0.0001059\n",
            "(epoch: 73, iters: 100, time: 1.380, data: 0.379) D_A: 0.074 G_A: 0.421 cycle_A: 0.498 idt_A: 0.576 D_B: 0.084 G_B: 0.454 cycle_B: 1.406 idt_B: 0.173 \n",
            "End of epoch 73 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001059 -> 0.0001020\n",
            "(epoch: 74, iters: 100, time: 1.376, data: 0.243) D_A: 0.071 G_A: 0.594 cycle_A: 0.470 idt_A: 0.565 D_B: 0.122 G_B: 0.452 cycle_B: 1.610 idt_B: 0.181 \n",
            "End of epoch 74 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0001020 -> 0.0000980\n",
            "(epoch: 75, iters: 100, time: 1.376, data: 0.220) D_A: 0.155 G_A: 0.412 cycle_A: 0.398 idt_A: 0.594 D_B: 0.188 G_B: 1.354 cycle_B: 1.579 idt_B: 0.213 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 100 \t Time Taken: 135 sec\n",
            "learning rate 0.0000980 -> 0.0000941\n",
            "(epoch: 76, iters: 100, time: 2.014, data: 0.433) D_A: 0.424 G_A: 0.054 cycle_A: 0.766 idt_A: 1.000 D_B: 0.071 G_B: 0.565 cycle_B: 1.878 idt_B: 0.380 \n",
            "End of epoch 76 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0000941 -> 0.0000902\n",
            "(epoch: 77, iters: 100, time: 1.374, data: 0.254) D_A: 0.091 G_A: 0.734 cycle_A: 0.503 idt_A: 0.722 D_B: 0.092 G_B: 0.841 cycle_B: 2.086 idt_B: 0.238 \n",
            "End of epoch 77 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0000902 -> 0.0000863\n",
            "(epoch: 78, iters: 100, time: 1.371, data: 0.402) D_A: 0.088 G_A: 0.276 cycle_A: 0.466 idt_A: 0.737 D_B: 0.114 G_B: 0.439 cycle_B: 1.441 idt_B: 0.182 \n",
            "End of epoch 78 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0000863 -> 0.0000824\n",
            "(epoch: 79, iters: 100, time: 1.374, data: 0.245) D_A: 0.051 G_A: 0.337 cycle_A: 0.579 idt_A: 0.751 D_B: 0.057 G_B: 0.592 cycle_B: 1.826 idt_B: 0.270 \n",
            "End of epoch 79 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0000824 -> 0.0000784\n",
            "(epoch: 80, iters: 100, time: 2.022, data: 0.296) D_A: 0.089 G_A: 0.631 cycle_A: 0.533 idt_A: 0.559 D_B: 0.058 G_B: 1.163 cycle_B: 1.620 idt_B: 0.154 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 100 \t Time Taken: 136 sec\n",
            "learning rate 0.0000784 -> 0.0000745\n",
            "(epoch: 81, iters: 100, time: 1.374, data: 0.309) D_A: 0.249 G_A: 0.149 cycle_A: 0.478 idt_A: 0.523 D_B: 0.068 G_B: 1.162 cycle_B: 1.279 idt_B: 0.156 \n",
            "End of epoch 81 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0000745 -> 0.0000706\n",
            "(epoch: 82, iters: 100, time: 1.364, data: 0.253) D_A: 0.107 G_A: 0.721 cycle_A: 0.368 idt_A: 0.584 D_B: 0.097 G_B: 1.196 cycle_B: 1.905 idt_B: 0.139 \n",
            "End of epoch 82 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0000706 -> 0.0000667\n",
            "(epoch: 83, iters: 100, time: 1.373, data: 0.306) D_A: 0.153 G_A: 0.276 cycle_A: 0.298 idt_A: 0.828 D_B: 0.038 G_B: 0.794 cycle_B: 2.325 idt_B: 0.140 \n",
            "End of epoch 83 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0000667 -> 0.0000627\n",
            "(epoch: 84, iters: 100, time: 2.061, data: 0.378) D_A: 0.125 G_A: 0.456 cycle_A: 0.492 idt_A: 0.668 D_B: 0.119 G_B: 0.501 cycle_B: 1.906 idt_B: 0.191 \n",
            "End of epoch 84 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0000627 -> 0.0000588\n",
            "(epoch: 85, iters: 100, time: 1.383, data: 0.248) D_A: 0.215 G_A: 0.363 cycle_A: 0.453 idt_A: 0.702 D_B: 0.173 G_B: 0.269 cycle_B: 1.932 idt_B: 0.192 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 100 \t Time Taken: 131 sec\n",
            "learning rate 0.0000588 -> 0.0000549\n",
            "(epoch: 86, iters: 100, time: 1.377, data: 0.303) D_A: 0.158 G_A: 0.261 cycle_A: 0.587 idt_A: 0.602 D_B: 0.249 G_B: 0.074 cycle_B: 1.462 idt_B: 0.221 \n",
            "End of epoch 86 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0000549 -> 0.0000510\n",
            "(epoch: 87, iters: 100, time: 1.368, data: 0.290) D_A: 0.058 G_A: 0.639 cycle_A: 0.419 idt_A: 0.396 D_B: 0.101 G_B: 0.366 cycle_B: 1.231 idt_B: 0.163 \n",
            "End of epoch 87 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0000510 -> 0.0000471\n",
            "(epoch: 88, iters: 100, time: 2.073, data: 0.404) D_A: 0.046 G_A: 0.458 cycle_A: 0.497 idt_A: 0.925 D_B: 0.147 G_B: 0.291 cycle_B: 2.231 idt_B: 0.168 \n",
            "End of epoch 88 / 100 \t Time Taken: 130 sec\n",
            "learning rate 0.0000471 -> 0.0000431\n",
            "(epoch: 89, iters: 100, time: 1.372, data: 0.433) D_A: 0.197 G_A: 0.319 cycle_A: 0.380 idt_A: 0.468 D_B: 0.246 G_B: 0.575 cycle_B: 1.434 idt_B: 0.142 \n",
            "End of epoch 89 / 100 \t Time Taken: 129 sec\n",
            "learning rate 0.0000431 -> 0.0000392\n",
            "(epoch: 90, iters: 100, time: 1.365, data: 0.263) D_A: 0.116 G_A: 0.530 cycle_A: 0.327 idt_A: 0.754 D_B: 0.084 G_B: 0.743 cycle_B: 2.269 idt_B: 0.118 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 100 \t Time Taken: 135 sec\n",
            "learning rate 0.0000392 -> 0.0000353\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/repos/pytorch-UniCycleGAN-project/train.py\", line 59, in <module>\n",
            "    for i, data in enumerate(dataset):  # inner loop within one epoch\n",
            "  File \"/content/drive/MyDrive/repos/pytorch-UniCycleGAN-project/data/__init__.py\", line 90, in __iter__\n",
            "    for i, data in enumerate(self.dataloader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1345, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 694, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/drive/MyDrive/repos/pytorch-UniCycleGAN-project/data/unaligned_dataset.py\", line 57, in __getitem__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3227, in open\n",
            "    fp = builtins.open(filename, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split/trainA/Copy of Copy of src_3_2857__129_10_165.png'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_all_layers --train_name truck_nas_project_layer_types_all_layers --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 50 --n_epochs 50 --n_epochs_decay 50 --layer_types all_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPBVRicuyx2r",
        "outputId": "17cd54e1-98c6-4f8d-e3ff-1bf8cdd368fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 50                            \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split_500\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: CycleGan+ReLU                 \t[default: CycleGan]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_cycleGAN_ReLU_500\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_ReLU_500\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 500\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 9.611 M\n",
            "[Network G_B] Total number of parameters : 9.611 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_ReLU_500/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.367, data: 1.080) D_A: 0.277 G_A: 0.416 cycle_A: 1.320 idt_A: 1.752 D_B: 0.361 G_B: 0.329 cycle_B: 3.819 idt_B: 0.573 \n",
            "(epoch: 1, iters: 200, time: 0.372, data: 0.006) D_A: 0.296 G_A: 0.673 cycle_A: 0.696 idt_A: 0.801 D_B: 0.230 G_B: 0.615 cycle_B: 1.761 idt_B: 0.296 \n",
            "(epoch: 1, iters: 300, time: 0.392, data: 0.002) D_A: 0.236 G_A: 0.399 cycle_A: 0.897 idt_A: 0.715 D_B: 0.086 G_B: 0.280 cycle_B: 1.868 idt_B: 0.368 \n",
            "(epoch: 1, iters: 400, time: 0.673, data: 0.004) D_A: 0.136 G_A: 0.309 cycle_A: 0.652 idt_A: 1.037 D_B: 0.061 G_B: 1.211 cycle_B: 2.277 idt_B: 0.316 \n",
            "(epoch: 1, iters: 500, time: 0.383, data: 0.007) D_A: 0.161 G_A: 0.520 cycle_A: 0.668 idt_A: 0.711 D_B: 0.169 G_B: 0.571 cycle_B: 1.964 idt_B: 0.390 \n",
            "End of epoch 1 / 200 \t Time Taken: 188 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.367, data: 0.311) D_A: 0.186 G_A: 0.501 cycle_A: 0.814 idt_A: 1.446 D_B: 0.101 G_B: 1.585 cycle_B: 2.947 idt_B: 0.364 \n",
            "(epoch: 2, iters: 200, time: 0.366, data: 0.002) D_A: 0.157 G_A: 0.406 cycle_A: 0.685 idt_A: 0.638 D_B: 0.088 G_B: 0.873 cycle_B: 1.675 idt_B: 0.322 \n",
            "(epoch: 2, iters: 300, time: 0.636, data: 0.003) D_A: 0.297 G_A: 0.170 cycle_A: 0.472 idt_A: 0.684 D_B: 0.069 G_B: 0.938 cycle_B: 1.369 idt_B: 0.211 \n",
            "(epoch: 2, iters: 400, time: 0.381, data: 0.003) D_A: 0.132 G_A: 0.728 cycle_A: 0.758 idt_A: 1.242 D_B: 0.188 G_B: 1.675 cycle_B: 3.283 idt_B: 0.337 \n",
            "(epoch: 2, iters: 500, time: 0.378, data: 0.004) D_A: 0.137 G_A: 0.408 cycle_A: 0.577 idt_A: 1.289 D_B: 0.084 G_B: 0.946 cycle_B: 1.913 idt_B: 0.349 \n",
            "End of epoch 2 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.381, data: 0.380) D_A: 0.112 G_A: 0.427 cycle_A: 0.482 idt_A: 0.616 D_B: 0.178 G_B: 0.236 cycle_B: 5.235 idt_B: 0.215 \n",
            "(epoch: 3, iters: 200, time: 0.604, data: 0.005) D_A: 0.194 G_A: 0.320 cycle_A: 0.610 idt_A: 0.860 D_B: 0.097 G_B: 0.500 cycle_B: 1.776 idt_B: 0.196 \n",
            "(epoch: 3, iters: 300, time: 0.367, data: 0.003) D_A: 0.085 G_A: 0.500 cycle_A: 0.538 idt_A: 0.765 D_B: 0.051 G_B: 0.665 cycle_B: 1.873 idt_B: 0.280 \n",
            "(epoch: 3, iters: 400, time: 0.367, data: 0.005) D_A: 0.216 G_A: 0.196 cycle_A: 0.436 idt_A: 1.503 D_B: 0.223 G_B: 1.424 cycle_B: 3.511 idt_B: 0.405 \n",
            "(epoch: 3, iters: 500, time: 0.364, data: 0.004) D_A: 0.501 G_A: 0.086 cycle_A: 0.938 idt_A: 1.066 D_B: 0.319 G_B: 1.008 cycle_B: 2.524 idt_B: 0.430 \n",
            "End of epoch 3 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.677, data: 0.203) D_A: 0.171 G_A: 0.480 cycle_A: 0.833 idt_A: 1.179 D_B: 0.384 G_B: 1.073 cycle_B: 3.010 idt_B: 0.306 \n",
            "(epoch: 4, iters: 200, time: 0.370, data: 0.013) D_A: 0.104 G_A: 0.322 cycle_A: 0.580 idt_A: 1.097 D_B: 0.125 G_B: 0.375 cycle_B: 2.567 idt_B: 0.237 \n",
            "(epoch: 4, iters: 300, time: 0.394, data: 0.004) D_A: 0.221 G_A: 0.519 cycle_A: 0.543 idt_A: 0.774 D_B: 0.039 G_B: 0.647 cycle_B: 2.166 idt_B: 0.241 \n",
            "(epoch: 4, iters: 400, time: 0.385, data: 0.011) D_A: 0.208 G_A: 0.470 cycle_A: 0.562 idt_A: 0.858 D_B: 0.087 G_B: 1.004 cycle_B: 2.086 idt_B: 0.250 \n",
            "(epoch: 4, iters: 500, time: 0.621, data: 0.003) D_A: 0.220 G_A: 0.685 cycle_A: 0.570 idt_A: 0.783 D_B: 0.082 G_B: 0.401 cycle_B: 1.882 idt_B: 0.183 \n",
            "End of epoch 4 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.364, data: 0.229) D_A: 0.166 G_A: 0.659 cycle_A: 0.649 idt_A: 1.163 D_B: 0.091 G_B: 0.480 cycle_B: 3.082 idt_B: 0.247 \n",
            "(epoch: 5, iters: 200, time: 0.364, data: 0.004) D_A: 0.098 G_A: 0.619 cycle_A: 0.463 idt_A: 0.939 D_B: 0.158 G_B: 0.393 cycle_B: 2.059 idt_B: 0.184 \n",
            "(epoch: 5, iters: 300, time: 0.367, data: 0.003) D_A: 0.271 G_A: 0.317 cycle_A: 0.497 idt_A: 0.534 D_B: 0.045 G_B: 0.511 cycle_B: 1.285 idt_B: 0.212 \n",
            "(epoch: 5, iters: 400, time: 0.709, data: 0.003) D_A: 0.272 G_A: 0.469 cycle_A: 0.625 idt_A: 0.851 D_B: 0.134 G_B: 1.215 cycle_B: 2.405 idt_B: 0.271 \n",
            "(epoch: 5, iters: 500, time: 0.375, data: 0.012) D_A: 0.261 G_A: 0.914 cycle_A: 0.552 idt_A: 0.790 D_B: 0.116 G_B: 0.330 cycle_B: 1.710 idt_B: 0.265 \n",
            "saving the model at the end of epoch 5, iters 2500\n",
            "End of epoch 5 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.360, data: 0.257) D_A: 0.097 G_A: 0.376 cycle_A: 0.751 idt_A: 1.485 D_B: 0.299 G_B: 1.220 cycle_B: 3.873 idt_B: 0.244 \n",
            "(epoch: 6, iters: 200, time: 0.369, data: 0.003) D_A: 0.257 G_A: 0.170 cycle_A: 0.580 idt_A: 0.868 D_B: 0.246 G_B: 1.565 cycle_B: 1.925 idt_B: 0.206 \n",
            "(epoch: 6, iters: 300, time: 0.646, data: 0.003) D_A: 0.132 G_A: 0.539 cycle_A: 0.957 idt_A: 1.943 D_B: 0.216 G_B: 0.190 cycle_B: 4.469 idt_B: 0.310 \n",
            "(epoch: 6, iters: 400, time: 0.407, data: 0.003) D_A: 0.147 G_A: 0.366 cycle_A: 0.418 idt_A: 1.166 D_B: 0.110 G_B: 0.462 cycle_B: 2.344 idt_B: 0.183 \n",
            "(epoch: 6, iters: 500, time: 0.377, data: 0.016) D_A: 0.329 G_A: 1.069 cycle_A: 0.436 idt_A: 0.854 D_B: 0.088 G_B: 0.887 cycle_B: 1.891 idt_B: 0.173 \n",
            "End of epoch 6 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.382, data: 0.380) D_A: 0.168 G_A: 0.225 cycle_A: 0.741 idt_A: 0.406 D_B: 0.092 G_B: 1.149 cycle_B: 1.338 idt_B: 0.277 \n",
            "(epoch: 7, iters: 200, time: 0.667, data: 0.012) D_A: 0.176 G_A: 0.692 cycle_A: 0.624 idt_A: 0.752 D_B: 0.278 G_B: 0.187 cycle_B: 1.781 idt_B: 0.276 \n",
            "(epoch: 7, iters: 300, time: 0.368, data: 0.003) D_A: 0.158 G_A: 0.153 cycle_A: 0.889 idt_A: 0.571 D_B: 0.314 G_B: 0.062 cycle_B: 1.736 idt_B: 0.359 \n",
            "(epoch: 7, iters: 400, time: 0.365, data: 0.003) D_A: 0.209 G_A: 0.240 cycle_A: 0.776 idt_A: 0.860 D_B: 0.167 G_B: 0.373 cycle_B: 2.392 idt_B: 0.162 \n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split_500 --name truck_nas_project_layer_types_cycleGAN_ReLU_500 --train_name truck_nas_project_layer_types_cycleGAN_ReLU_500 --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 50 --n_epochs 100 --n_epochs_decay 100 --layer_types CycleGan+ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avvY16DBlI3T"
      },
      "source": [
        "## NAS: CycleGAN+ReLU+Conv\n",
        "100 epochs\n",
        "truck_nas_project_layer_types_cycleGAN_ReLU_Conv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-nk3SUMk1su",
        "outputId": "62fe5d9f-7e1c-42a6-9812-ae7d9c449bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 50                            \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 10                            \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: CycleGan+ReLU+Conv            \t[default: ReflectionPad2d_Conv2d+ReLU]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_blocks: 3                             \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_cycleGAN_ReLU_Conv_200_ep\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_ReLU_Conv_200_ep\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_ReLU_Conv_200_ep/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.482, data: 1.289) D_A: 0.282 G_A: 0.556 cycle_A: 1.080 idt_A: 1.292 D_B: 0.196 G_B: 0.357 cycle_B: 2.990 idt_B: 0.459 \n",
            "End of epoch 1 / 200 \t Time Taken: 61 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.449, data: 0.218) D_A: 0.240 G_A: 0.367 cycle_A: 1.186 idt_A: 1.122 D_B: 0.136 G_B: 0.685 cycle_B: 2.410 idt_B: 0.695 \n",
            "End of epoch 2 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.555, data: 0.234) D_A: 0.263 G_A: 0.453 cycle_A: 0.650 idt_A: 1.030 D_B: 0.143 G_B: 0.536 cycle_B: 2.602 idt_B: 0.320 \n",
            "End of epoch 3 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.744, data: 0.228) D_A: 0.275 G_A: 0.338 cycle_A: 0.786 idt_A: 0.669 D_B: 0.077 G_B: 0.718 cycle_B: 1.585 idt_B: 0.346 \n",
            "End of epoch 4 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.563, data: 0.210) D_A: 0.164 G_A: 0.311 cycle_A: 1.137 idt_A: 1.444 D_B: 0.307 G_B: 0.680 cycle_B: 3.006 idt_B: 0.365 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 200 \t Time Taken: 55 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.496, data: 0.226) D_A: 0.243 G_A: 0.336 cycle_A: 0.546 idt_A: 0.991 D_B: 0.105 G_B: 0.536 cycle_B: 2.415 idt_B: 0.250 \n",
            "End of epoch 6 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.530, data: 0.210) D_A: 0.432 G_A: 0.128 cycle_A: 0.977 idt_A: 1.858 D_B: 0.329 G_B: 0.100 cycle_B: 3.860 idt_B: 0.329 \n",
            "End of epoch 7 / 200 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.798, data: 0.326) D_A: 0.163 G_A: 0.363 cycle_A: 0.992 idt_A: 1.433 D_B: 0.091 G_B: 0.650 cycle_B: 3.199 idt_B: 0.446 \n",
            "End of epoch 8 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.472, data: 0.177) D_A: 0.224 G_A: 0.589 cycle_A: 0.607 idt_A: 0.762 D_B: 0.039 G_B: 0.978 cycle_B: 1.833 idt_B: 0.208 \n",
            "End of epoch 9 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.473, data: 0.225) D_A: 0.126 G_A: 0.608 cycle_A: 0.834 idt_A: 0.634 D_B: 0.248 G_B: 0.295 cycle_B: 1.887 idt_B: 0.372 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.557, data: 0.306) D_A: 0.283 G_A: 0.483 cycle_A: 0.462 idt_A: 2.720 D_B: 0.181 G_B: 0.984 cycle_B: 5.432 idt_B: 0.190 \n",
            "End of epoch 11 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.744, data: 0.223) D_A: 0.381 G_A: 0.704 cycle_A: 0.918 idt_A: 0.913 D_B: 0.131 G_B: 0.272 cycle_B: 2.384 idt_B: 0.380 \n",
            "End of epoch 12 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.508, data: 0.182) D_A: 0.193 G_A: 0.777 cycle_A: 1.195 idt_A: 1.030 D_B: 0.120 G_B: 0.725 cycle_B: 2.589 idt_B: 0.667 \n",
            "End of epoch 13 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.555, data: 0.165) D_A: 0.232 G_A: 0.498 cycle_A: 0.855 idt_A: 1.089 D_B: 0.136 G_B: 0.419 cycle_B: 3.880 idt_B: 0.434 \n",
            "End of epoch 14 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.497, data: 0.324) D_A: 0.095 G_A: 0.659 cycle_A: 1.072 idt_A: 0.963 D_B: 0.167 G_B: 0.322 cycle_B: 2.352 idt_B: 0.605 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.822, data: 0.200) D_A: 0.124 G_A: 0.818 cycle_A: 0.799 idt_A: 1.086 D_B: 0.247 G_B: 0.098 cycle_B: 2.393 idt_B: 0.339 \n",
            "End of epoch 16 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.466, data: 0.187) D_A: 0.216 G_A: 0.698 cycle_A: 0.869 idt_A: 1.075 D_B: 0.107 G_B: 0.241 cycle_B: 2.609 idt_B: 0.405 \n",
            "End of epoch 17 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.414, data: 0.343) D_A: 0.069 G_A: 0.854 cycle_A: 0.730 idt_A: 0.779 D_B: 0.176 G_B: 0.361 cycle_B: 2.106 idt_B: 0.285 \n",
            "End of epoch 18 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.427, data: 0.217) D_A: 0.062 G_A: 0.532 cycle_A: 0.498 idt_A: 1.387 D_B: 0.238 G_B: 0.151 cycle_B: 3.418 idt_B: 0.220 \n",
            "End of epoch 19 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.733, data: 0.235) D_A: 0.143 G_A: 0.421 cycle_A: 0.599 idt_A: 1.299 D_B: 0.097 G_B: 0.882 cycle_B: 3.000 idt_B: 0.234 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.463, data: 0.229) D_A: 0.179 G_A: 0.338 cycle_A: 0.930 idt_A: 0.873 D_B: 0.229 G_B: 0.243 cycle_B: 3.376 idt_B: 0.334 \n",
            "End of epoch 21 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.399, data: 0.290) D_A: 0.163 G_A: 0.438 cycle_A: 0.577 idt_A: 0.745 D_B: 0.041 G_B: 0.605 cycle_B: 1.945 idt_B: 0.264 \n",
            "End of epoch 22 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.409, data: 0.217) D_A: 0.155 G_A: 0.726 cycle_A: 0.520 idt_A: 0.835 D_B: 0.627 G_B: 0.052 cycle_B: 2.143 idt_B: 0.190 \n",
            "End of epoch 23 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.957, data: 0.238) D_A: 0.165 G_A: 0.571 cycle_A: 0.725 idt_A: 0.912 D_B: 0.173 G_B: 0.601 cycle_B: 1.930 idt_B: 0.452 \n",
            "End of epoch 24 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.428, data: 0.330) D_A: 0.173 G_A: 0.929 cycle_A: 0.598 idt_A: 0.873 D_B: 0.210 G_B: 0.393 cycle_B: 2.252 idt_B: 0.252 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.424, data: 0.275) D_A: 0.268 G_A: 0.994 cycle_A: 0.507 idt_A: 0.853 D_B: 0.093 G_B: 0.469 cycle_B: 2.049 idt_B: 0.189 \n",
            "End of epoch 26 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.422, data: 0.237) D_A: 0.239 G_A: 0.505 cycle_A: 0.510 idt_A: 1.049 D_B: 0.114 G_B: 0.426 cycle_B: 2.268 idt_B: 0.207 \n",
            "End of epoch 27 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.946, data: 0.274) D_A: 0.092 G_A: 0.425 cycle_A: 0.488 idt_A: 1.262 D_B: 0.151 G_B: 0.494 cycle_B: 2.765 idt_B: 0.139 \n",
            "End of epoch 28 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.399, data: 0.358) D_A: 0.125 G_A: 0.927 cycle_A: 0.518 idt_A: 0.840 D_B: 0.098 G_B: 0.518 cycle_B: 2.741 idt_B: 0.159 \n",
            "End of epoch 29 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.406, data: 0.310) D_A: 0.225 G_A: 0.236 cycle_A: 0.561 idt_A: 0.829 D_B: 0.078 G_B: 0.558 cycle_B: 1.695 idt_B: 0.187 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.477, data: 0.298) D_A: 0.574 G_A: 0.103 cycle_A: 1.085 idt_A: 0.798 D_B: 0.156 G_B: 0.212 cycle_B: 2.810 idt_B: 0.345 \n",
            "End of epoch 31 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.797, data: 0.224) D_A: 0.204 G_A: 0.612 cycle_A: 0.646 idt_A: 1.170 D_B: 0.138 G_B: 0.313 cycle_B: 2.863 idt_B: 0.253 \n",
            "End of epoch 32 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.417, data: 0.207) D_A: 0.189 G_A: 0.748 cycle_A: 0.556 idt_A: 0.939 D_B: 0.131 G_B: 0.426 cycle_B: 2.153 idt_B: 0.243 \n",
            "End of epoch 33 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.396, data: 0.319) D_A: 0.038 G_A: 0.800 cycle_A: 0.805 idt_A: 0.980 D_B: 0.154 G_B: 0.372 cycle_B: 2.226 idt_B: 0.287 \n",
            "End of epoch 34 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.440, data: 0.213) D_A: 0.153 G_A: 0.534 cycle_A: 0.534 idt_A: 1.033 D_B: 0.146 G_B: 1.336 cycle_B: 2.322 idt_B: 0.233 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.928, data: 0.259) D_A: 0.149 G_A: 0.820 cycle_A: 0.694 idt_A: 0.662 D_B: 0.230 G_B: 0.637 cycle_B: 2.036 idt_B: 0.277 \n",
            "End of epoch 36 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.406, data: 0.230) D_A: 0.144 G_A: 0.424 cycle_A: 0.600 idt_A: 1.036 D_B: 0.103 G_B: 0.573 cycle_B: 2.116 idt_B: 0.223 \n",
            "End of epoch 37 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.407, data: 0.227) D_A: 0.070 G_A: 0.386 cycle_A: 0.628 idt_A: 1.070 D_B: 0.086 G_B: 0.825 cycle_B: 2.426 idt_B: 0.317 \n",
            "End of epoch 38 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.436, data: 0.233) D_A: 0.069 G_A: 0.857 cycle_A: 0.429 idt_A: 0.783 D_B: 1.055 G_B: 1.414 cycle_B: 2.114 idt_B: 0.175 \n",
            "End of epoch 39 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.843, data: 0.343) D_A: 0.197 G_A: 0.195 cycle_A: 0.726 idt_A: 0.899 D_B: 0.256 G_B: 0.206 cycle_B: 2.200 idt_B: 0.292 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.399, data: 0.362) D_A: 0.209 G_A: 0.777 cycle_A: 0.360 idt_A: 0.890 D_B: 0.107 G_B: 0.565 cycle_B: 1.916 idt_B: 0.161 \n",
            "End of epoch 41 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.392, data: 0.243) D_A: 0.064 G_A: 0.150 cycle_A: 0.848 idt_A: 0.708 D_B: 0.119 G_B: 1.283 cycle_B: 1.708 idt_B: 0.310 \n",
            "End of epoch 42 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.455, data: 0.172) D_A: 0.131 G_A: 0.421 cycle_A: 0.618 idt_A: 0.762 D_B: 0.154 G_B: 0.381 cycle_B: 1.768 idt_B: 0.296 \n",
            "End of epoch 43 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.885, data: 0.356) D_A: 0.115 G_A: 0.713 cycle_A: 0.516 idt_A: 0.765 D_B: 0.149 G_B: 1.076 cycle_B: 2.439 idt_B: 0.188 \n",
            "End of epoch 44 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.401, data: 0.242) D_A: 0.158 G_A: 0.286 cycle_A: 0.402 idt_A: 1.084 D_B: 0.231 G_B: 0.802 cycle_B: 1.983 idt_B: 0.168 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.420, data: 0.239) D_A: 0.081 G_A: 0.757 cycle_A: 0.633 idt_A: 0.861 D_B: 0.060 G_B: 0.513 cycle_B: 2.304 idt_B: 0.211 \n",
            "End of epoch 46 / 200 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.395, data: 0.366) D_A: 0.176 G_A: 0.230 cycle_A: 1.453 idt_A: 0.650 D_B: 0.311 G_B: 0.193 cycle_B: 1.088 idt_B: 0.561 \n",
            "End of epoch 47 / 200 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 1.043, data: 0.194) D_A: 0.106 G_A: 0.412 cycle_A: 0.574 idt_A: 0.917 D_B: 0.089 G_B: 0.440 cycle_B: 4.984 idt_B: 0.209 \n",
            "End of epoch 48 / 200 \t Time Taken: 39 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.397, data: 0.215) D_A: 0.157 G_A: 0.392 cycle_A: 0.439 idt_A: 1.064 D_B: 0.166 G_B: 0.335 cycle_B: 2.589 idt_B: 0.160 \n",
            "End of epoch 49 / 200 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.602, data: 0.248) D_A: 0.211 G_A: 0.359 cycle_A: 0.711 idt_A: 0.564 D_B: 0.396 G_B: 0.030 cycle_B: 1.489 idt_B: 0.292 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.469, data: 0.356) D_A: 0.186 G_A: 0.117 cycle_A: 0.484 idt_A: 0.783 D_B: 0.319 G_B: 0.126 cycle_B: 1.991 idt_B: 0.171 \n",
            "End of epoch 51 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 0.957, data: 0.227) D_A: 0.103 G_A: 0.122 cycle_A: 0.639 idt_A: 1.140 D_B: 0.251 G_B: 0.712 cycle_B: 2.777 idt_B: 0.206 \n",
            "End of epoch 52 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.407, data: 0.235) D_A: 0.193 G_A: 0.749 cycle_A: 0.654 idt_A: 0.593 D_B: 0.177 G_B: 0.211 cycle_B: 1.429 idt_B: 0.286 \n",
            "End of epoch 53 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.425, data: 0.259) D_A: 0.061 G_A: 0.292 cycle_A: 0.465 idt_A: 0.812 D_B: 0.160 G_B: 0.459 cycle_B: 2.094 idt_B: 0.149 \n",
            "End of epoch 54 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.452, data: 0.184) D_A: 0.111 G_A: 0.426 cycle_A: 1.315 idt_A: 0.848 D_B: 0.070 G_B: 0.538 cycle_B: 2.080 idt_B: 0.214 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 100, time: 0.949, data: 0.330) D_A: 0.196 G_A: 0.660 cycle_A: 0.547 idt_A: 1.023 D_B: 0.118 G_B: 0.320 cycle_B: 1.895 idt_B: 0.197 \n",
            "End of epoch 56 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.397, data: 0.348) D_A: 0.217 G_A: 0.401 cycle_A: 0.725 idt_A: 1.168 D_B: 0.286 G_B: 0.265 cycle_B: 2.684 idt_B: 0.162 \n",
            "End of epoch 57 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.404, data: 0.295) D_A: 0.085 G_A: 0.457 cycle_A: 0.610 idt_A: 1.100 D_B: 0.118 G_B: 0.259 cycle_B: 2.271 idt_B: 0.260 \n",
            "End of epoch 58 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.411, data: 0.207) D_A: 0.139 G_A: 0.132 cycle_A: 0.456 idt_A: 0.815 D_B: 0.172 G_B: 0.245 cycle_B: 1.840 idt_B: 0.215 \n",
            "End of epoch 59 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 1.082, data: 0.273) D_A: 0.177 G_A: 1.257 cycle_A: 0.685 idt_A: 0.837 D_B: 0.101 G_B: 0.456 cycle_B: 2.200 idt_B: 0.208 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.406, data: 0.203) D_A: 0.105 G_A: 0.292 cycle_A: 0.798 idt_A: 1.382 D_B: 0.069 G_B: 0.646 cycle_B: 2.459 idt_B: 0.280 \n",
            "End of epoch 61 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.445, data: 0.189) D_A: 0.049 G_A: 0.075 cycle_A: 0.415 idt_A: 0.697 D_B: 0.144 G_B: 0.550 cycle_B: 1.622 idt_B: 0.150 \n",
            "End of epoch 62 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.424, data: 0.318) D_A: 0.314 G_A: 0.134 cycle_A: 1.161 idt_A: 0.696 D_B: 0.148 G_B: 0.369 cycle_B: 1.839 idt_B: 0.460 \n",
            "End of epoch 63 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 100, time: 1.012, data: 0.335) D_A: 0.360 G_A: 0.060 cycle_A: 0.585 idt_A: 0.593 D_B: 0.108 G_B: 0.702 cycle_B: 1.520 idt_B: 0.154 \n",
            "End of epoch 64 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.400, data: 0.195) D_A: 0.212 G_A: 0.491 cycle_A: 0.657 idt_A: 0.662 D_B: 0.152 G_B: 0.556 cycle_B: 1.817 idt_B: 0.274 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.413, data: 0.301) D_A: 0.185 G_A: 0.408 cycle_A: 0.785 idt_A: 0.765 D_B: 0.080 G_B: 0.510 cycle_B: 2.019 idt_B: 0.353 \n",
            "End of epoch 66 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.393, data: 0.182) D_A: 0.147 G_A: 0.397 cycle_A: 0.550 idt_A: 0.764 D_B: 0.112 G_B: 1.233 cycle_B: 2.325 idt_B: 0.221 \n",
            "End of epoch 67 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 100, time: 1.043, data: 0.203) D_A: 0.159 G_A: 0.386 cycle_A: 0.393 idt_A: 1.059 D_B: 0.050 G_B: 0.545 cycle_B: 2.670 idt_B: 0.175 \n",
            "End of epoch 68 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.397, data: 0.225) D_A: 0.101 G_A: 0.327 cycle_A: 0.829 idt_A: 0.782 D_B: 0.241 G_B: 0.993 cycle_B: 2.203 idt_B: 0.333 \n",
            "End of epoch 69 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.491, data: 0.219) D_A: 0.146 G_A: 0.068 cycle_A: 0.550 idt_A: 0.520 D_B: 0.102 G_B: 0.180 cycle_B: 1.604 idt_B: 0.187 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.443, data: 0.237) D_A: 0.102 G_A: 0.549 cycle_A: 0.463 idt_A: 0.759 D_B: 0.116 G_B: 0.890 cycle_B: 1.932 idt_B: 0.160 \n",
            "End of epoch 71 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 100, time: 1.304, data: 0.357) D_A: 0.117 G_A: 0.711 cycle_A: 0.622 idt_A: 0.643 D_B: 0.092 G_B: 0.613 cycle_B: 1.965 idt_B: 0.305 \n",
            "End of epoch 72 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.484, data: 0.332) D_A: 0.341 G_A: 0.071 cycle_A: 0.651 idt_A: 0.697 D_B: 0.155 G_B: 0.261 cycle_B: 1.942 idt_B: 0.252 \n",
            "End of epoch 73 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.392, data: 0.395) D_A: 0.090 G_A: 0.537 cycle_A: 0.796 idt_A: 0.766 D_B: 0.229 G_B: 0.300 cycle_B: 1.779 idt_B: 0.302 \n",
            "End of epoch 74 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.388, data: 0.250) D_A: 0.292 G_A: 0.231 cycle_A: 0.714 idt_A: 0.635 D_B: 0.237 G_B: 1.228 cycle_B: 2.116 idt_B: 0.307 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 100, time: 1.057, data: 0.251) D_A: 0.113 G_A: 0.475 cycle_A: 0.740 idt_A: 0.545 D_B: 0.193 G_B: 1.252 cycle_B: 1.677 idt_B: 0.260 \n",
            "End of epoch 76 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.407, data: 0.264) D_A: 0.179 G_A: 0.601 cycle_A: 0.546 idt_A: 0.702 D_B: 0.071 G_B: 0.692 cycle_B: 2.881 idt_B: 0.189 \n",
            "End of epoch 77 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.396, data: 0.252) D_A: 0.331 G_A: 0.115 cycle_A: 0.731 idt_A: 0.449 D_B: 0.154 G_B: 0.310 cycle_B: 1.420 idt_B: 0.275 \n",
            "End of epoch 78 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.430, data: 0.208) D_A: 0.300 G_A: 0.122 cycle_A: 0.500 idt_A: 0.661 D_B: 0.223 G_B: 1.273 cycle_B: 2.076 idt_B: 0.161 \n",
            "End of epoch 79 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 100, time: 1.304, data: 0.427) D_A: 0.175 G_A: 0.536 cycle_A: 0.479 idt_A: 1.057 D_B: 0.035 G_B: 0.563 cycle_B: 2.872 idt_B: 0.156 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.452, data: 0.257) D_A: 0.096 G_A: 0.564 cycle_A: 0.298 idt_A: 0.626 D_B: 0.028 G_B: 0.916 cycle_B: 1.929 idt_B: 0.126 \n",
            "End of epoch 81 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.506, data: 0.295) D_A: 0.061 G_A: 0.150 cycle_A: 0.598 idt_A: 0.456 D_B: 0.138 G_B: 0.566 cycle_B: 1.423 idt_B: 0.239 \n",
            "End of epoch 82 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.401, data: 0.391) D_A: 0.177 G_A: 0.306 cycle_A: 0.504 idt_A: 0.553 D_B: 0.127 G_B: 0.520 cycle_B: 1.966 idt_B: 0.180 \n",
            "End of epoch 83 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 100, time: 1.103, data: 0.359) D_A: 0.052 G_A: 0.728 cycle_A: 0.714 idt_A: 0.790 D_B: 0.060 G_B: 0.778 cycle_B: 2.045 idt_B: 0.282 \n",
            "End of epoch 84 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.416, data: 0.181) D_A: 0.163 G_A: 0.561 cycle_A: 0.792 idt_A: 0.740 D_B: 0.119 G_B: 0.492 cycle_B: 1.969 idt_B: 0.383 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.388, data: 0.252) D_A: 0.099 G_A: 0.992 cycle_A: 0.422 idt_A: 0.816 D_B: 0.074 G_B: 0.792 cycle_B: 2.723 idt_B: 0.177 \n",
            "End of epoch 86 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.393, data: 0.207) D_A: 0.099 G_A: 0.402 cycle_A: 0.505 idt_A: 0.931 D_B: 0.224 G_B: 0.298 cycle_B: 2.626 idt_B: 0.174 \n",
            "End of epoch 87 / 200 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 100, time: 1.334, data: 0.229) D_A: 0.202 G_A: 0.593 cycle_A: 0.850 idt_A: 0.763 D_B: 0.161 G_B: 0.354 cycle_B: 2.420 idt_B: 0.171 \n",
            "End of epoch 88 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.428, data: 0.413) D_A: 0.163 G_A: 0.338 cycle_A: 0.374 idt_A: 0.611 D_B: 0.156 G_B: 0.245 cycle_B: 1.539 idt_B: 0.119 \n",
            "End of epoch 89 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.402, data: 0.333) D_A: 0.205 G_A: 0.713 cycle_A: 0.247 idt_A: 0.763 D_B: 0.069 G_B: 0.978 cycle_B: 2.113 idt_B: 0.113 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.382, data: 0.410) D_A: 0.175 G_A: 0.083 cycle_A: 0.402 idt_A: 0.678 D_B: 0.061 G_B: 0.812 cycle_B: 2.011 idt_B: 0.141 \n",
            "End of epoch 91 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 100, time: 1.409, data: 0.230) D_A: 0.223 G_A: 0.214 cycle_A: 0.955 idt_A: 0.510 D_B: 0.294 G_B: 0.296 cycle_B: 1.311 idt_B: 0.469 \n",
            "End of epoch 92 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.396, data: 0.208) D_A: 0.051 G_A: 0.726 cycle_A: 0.563 idt_A: 0.531 D_B: 0.086 G_B: 0.795 cycle_B: 1.320 idt_B: 0.217 \n",
            "End of epoch 93 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.392, data: 0.245) D_A: 0.070 G_A: 0.611 cycle_A: 0.499 idt_A: 0.697 D_B: 0.143 G_B: 0.587 cycle_B: 1.757 idt_B: 0.160 \n",
            "End of epoch 94 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.438, data: 0.224) D_A: 0.091 G_A: 0.703 cycle_A: 0.495 idt_A: 1.085 D_B: 0.138 G_B: 0.273 cycle_B: 2.607 idt_B: 0.192 \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 100, time: 1.359, data: 0.232) D_A: 0.053 G_A: 0.253 cycle_A: 0.474 idt_A: 0.601 D_B: 0.273 G_B: 0.528 cycle_B: 1.833 idt_B: 0.171 \n",
            "End of epoch 96 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.415, data: 0.202) D_A: 0.309 G_A: 1.222 cycle_A: 0.529 idt_A: 0.709 D_B: 0.071 G_B: 0.785 cycle_B: 2.166 idt_B: 0.161 \n",
            "End of epoch 97 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.400, data: 0.312) D_A: 0.273 G_A: 0.124 cycle_A: 0.397 idt_A: 0.326 D_B: 0.064 G_B: 1.276 cycle_B: 0.979 idt_B: 0.227 \n",
            "End of epoch 98 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.398, data: 0.369) D_A: 0.111 G_A: 0.402 cycle_A: 0.694 idt_A: 0.494 D_B: 0.181 G_B: 0.654 cycle_B: 2.048 idt_B: 0.237 \n",
            "End of epoch 99 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 100, time: 1.264, data: 0.194) D_A: 0.151 G_A: 0.120 cycle_A: 0.564 idt_A: 0.564 D_B: 0.258 G_B: 1.350 cycle_B: 1.407 idt_B: 0.215 \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 200 \t Time Taken: 48 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.422, data: 0.391) D_A: 0.262 G_A: 0.145 cycle_A: 0.186 idt_A: 0.599 D_B: 0.151 G_B: 0.311 cycle_B: 1.952 idt_B: 0.057 \n",
            "End of epoch 101 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 100, time: 0.402, data: 0.362) D_A: 0.282 G_A: 0.424 cycle_A: 0.559 idt_A: 0.620 D_B: 0.056 G_B: 0.366 cycle_B: 2.235 idt_B: 0.189 \n",
            "End of epoch 102 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 100, time: 0.400, data: 0.207) D_A: 0.058 G_A: 0.260 cycle_A: 0.395 idt_A: 0.868 D_B: 0.063 G_B: 0.979 cycle_B: 2.080 idt_B: 0.130 \n",
            "End of epoch 103 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 100, time: 1.246, data: 0.243) D_A: 0.039 G_A: 0.478 cycle_A: 0.791 idt_A: 0.625 D_B: 0.111 G_B: 1.040 cycle_B: 1.591 idt_B: 0.220 \n",
            "End of epoch 104 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 100, time: 0.393, data: 0.219) D_A: 0.183 G_A: 0.495 cycle_A: 0.358 idt_A: 0.694 D_B: 0.124 G_B: 0.659 cycle_B: 1.829 idt_B: 0.108 \n",
            "saving the model at the end of epoch 105, iters 10500\n",
            "End of epoch 105 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 100, time: 0.402, data: 0.229) D_A: 0.146 G_A: 0.756 cycle_A: 0.591 idt_A: 0.490 D_B: 0.239 G_B: 0.240 cycle_B: 1.360 idt_B: 0.308 \n",
            "End of epoch 106 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 100, time: 0.397, data: 0.300) D_A: 0.083 G_A: 0.671 cycle_A: 0.387 idt_A: 0.737 D_B: 0.117 G_B: 0.432 cycle_B: 2.238 idt_B: 0.128 \n",
            "End of epoch 107 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 100, time: 1.251, data: 0.221) D_A: 0.215 G_A: 0.193 cycle_A: 0.367 idt_A: 0.633 D_B: 0.108 G_B: 0.363 cycle_B: 1.260 idt_B: 0.126 \n",
            "End of epoch 108 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 100, time: 0.439, data: 0.189) D_A: 0.097 G_A: 0.085 cycle_A: 0.345 idt_A: 0.591 D_B: 0.092 G_B: 0.697 cycle_B: 1.874 idt_B: 0.139 \n",
            "End of epoch 109 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.415, data: 0.420) D_A: 0.146 G_A: 0.291 cycle_A: 0.341 idt_A: 0.830 D_B: 0.317 G_B: 0.388 cycle_B: 2.024 idt_B: 0.120 \n",
            "saving the model at the end of epoch 110, iters 11000\n",
            "End of epoch 110 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 100, time: 0.433, data: 0.293) D_A: 0.068 G_A: 1.024 cycle_A: 0.538 idt_A: 0.707 D_B: 0.072 G_B: 0.545 cycle_B: 1.916 idt_B: 0.226 \n",
            "End of epoch 111 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 100, time: 1.487, data: 0.200) D_A: 0.147 G_A: 0.311 cycle_A: 0.350 idt_A: 0.378 D_B: 0.155 G_B: 0.325 cycle_B: 1.528 idt_B: 0.132 \n",
            "End of epoch 112 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 100, time: 0.456, data: 0.232) D_A: 0.041 G_A: 0.079 cycle_A: 0.561 idt_A: 0.515 D_B: 0.266 G_B: 0.035 cycle_B: 1.475 idt_B: 0.237 \n",
            "End of epoch 113 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 100, time: 0.476, data: 0.345) D_A: 0.126 G_A: 0.412 cycle_A: 0.508 idt_A: 0.782 D_B: 0.170 G_B: 0.842 cycle_B: 2.538 idt_B: 0.215 \n",
            "End of epoch 114 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 100, time: 0.473, data: 0.336) D_A: 0.080 G_A: 0.231 cycle_A: 0.413 idt_A: 0.570 D_B: 0.038 G_B: 0.898 cycle_B: 1.301 idt_B: 0.105 \n",
            "saving the model at the end of epoch 115, iters 11500\n",
            "End of epoch 115 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 100, time: 1.362, data: 0.245) D_A: 0.113 G_A: 1.083 cycle_A: 0.582 idt_A: 1.075 D_B: 0.044 G_B: 0.820 cycle_B: 2.907 idt_B: 0.215 \n",
            "End of epoch 116 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 100, time: 0.389, data: 0.248) D_A: 0.201 G_A: 0.896 cycle_A: 0.351 idt_A: 0.897 D_B: 0.188 G_B: 0.228 cycle_B: 2.358 idt_B: 0.141 \n",
            "End of epoch 117 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 100, time: 0.429, data: 0.206) D_A: 0.082 G_A: 0.184 cycle_A: 0.481 idt_A: 0.451 D_B: 0.149 G_B: 0.385 cycle_B: 1.250 idt_B: 0.162 \n",
            "End of epoch 118 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 100, time: 0.538, data: 0.297) D_A: 0.289 G_A: 0.322 cycle_A: 0.564 idt_A: 0.651 D_B: 0.076 G_B: 0.656 cycle_B: 1.615 idt_B: 0.197 \n",
            "End of epoch 119 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 100, time: 1.667, data: 0.313) D_A: 0.036 G_A: 0.316 cycle_A: 0.425 idt_A: 0.773 D_B: 0.156 G_B: 0.326 cycle_B: 1.284 idt_B: 0.134 \n",
            "saving the model at the end of epoch 120, iters 12000\n",
            "End of epoch 120 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 100, time: 0.436, data: 0.345) D_A: 0.055 G_A: 0.474 cycle_A: 0.379 idt_A: 0.755 D_B: 0.142 G_B: 0.300 cycle_B: 1.948 idt_B: 0.107 \n",
            "End of epoch 121 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 100, time: 0.510, data: 0.390) D_A: 0.213 G_A: 0.178 cycle_A: 0.487 idt_A: 0.631 D_B: 0.149 G_B: 0.325 cycle_B: 1.665 idt_B: 0.187 \n",
            "End of epoch 122 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 100, time: 0.405, data: 0.360) D_A: 0.074 G_A: 0.914 cycle_A: 0.305 idt_A: 0.705 D_B: 0.042 G_B: 0.761 cycle_B: 1.759 idt_B: 0.131 \n",
            "End of epoch 123 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 100, time: 1.346, data: 0.239) D_A: 0.357 G_A: 0.203 cycle_A: 0.611 idt_A: 0.886 D_B: 0.153 G_B: 0.269 cycle_B: 2.329 idt_B: 0.247 \n",
            "End of epoch 124 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 100, time: 0.394, data: 0.169) D_A: 0.070 G_A: 0.859 cycle_A: 0.456 idt_A: 0.870 D_B: 0.051 G_B: 0.662 cycle_B: 1.834 idt_B: 0.111 \n",
            "saving the model at the end of epoch 125, iters 12500\n",
            "End of epoch 125 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 100, time: 0.396, data: 0.256) D_A: 0.309 G_A: 0.161 cycle_A: 0.497 idt_A: 0.444 D_B: 0.200 G_B: 0.338 cycle_B: 1.067 idt_B: 0.187 \n",
            "End of epoch 126 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 100, time: 0.411, data: 0.247) D_A: 0.028 G_A: 0.158 cycle_A: 0.318 idt_A: 0.392 D_B: 0.162 G_B: 0.372 cycle_B: 1.204 idt_B: 0.119 \n",
            "End of epoch 127 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 100, time: 1.381, data: 0.266) D_A: 0.317 G_A: 0.699 cycle_A: 0.370 idt_A: 0.642 D_B: 0.125 G_B: 0.175 cycle_B: 1.600 idt_B: 0.114 \n",
            "End of epoch 128 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 100, time: 0.391, data: 0.297) D_A: 0.181 G_A: 0.072 cycle_A: 0.432 idt_A: 0.357 D_B: 0.139 G_B: 0.716 cycle_B: 1.258 idt_B: 0.123 \n",
            "End of epoch 129 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 100, time: 0.408, data: 0.201) D_A: 0.063 G_A: 0.379 cycle_A: 0.412 idt_A: 0.491 D_B: 0.248 G_B: 1.148 cycle_B: 1.404 idt_B: 0.147 \n",
            "saving the model at the end of epoch 130, iters 13000\n",
            "End of epoch 130 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 100, time: 0.395, data: 0.280) D_A: 0.094 G_A: 0.781 cycle_A: 0.508 idt_A: 0.508 D_B: 0.129 G_B: 0.258 cycle_B: 1.469 idt_B: 0.148 \n",
            "End of epoch 131 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 100, time: 1.397, data: 0.216) D_A: 0.298 G_A: 1.121 cycle_A: 0.329 idt_A: 0.510 D_B: 0.056 G_B: 0.642 cycle_B: 1.596 idt_B: 0.122 \n",
            "End of epoch 132 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 100, time: 0.396, data: 0.258) D_A: 0.092 G_A: 0.784 cycle_A: 0.600 idt_A: 0.561 D_B: 0.141 G_B: 0.329 cycle_B: 1.485 idt_B: 0.240 \n",
            "End of epoch 133 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 100, time: 0.510, data: 0.198) D_A: 0.070 G_A: 0.520 cycle_A: 0.453 idt_A: 0.465 D_B: 0.117 G_B: 0.866 cycle_B: 1.326 idt_B: 0.169 \n",
            "End of epoch 134 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 100, time: 0.432, data: 0.306) D_A: 0.066 G_A: 0.656 cycle_A: 0.500 idt_A: 0.661 D_B: 0.144 G_B: 0.739 cycle_B: 1.322 idt_B: 0.159 \n",
            "saving the model at the end of epoch 135, iters 13500\n",
            "End of epoch 135 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 100, time: 1.616, data: 0.251) D_A: 0.331 G_A: 0.433 cycle_A: 0.301 idt_A: 0.585 D_B: 0.138 G_B: 0.268 cycle_B: 1.594 idt_B: 0.105 \n",
            "End of epoch 136 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 100, time: 0.449, data: 0.251) D_A: 0.082 G_A: 0.057 cycle_A: 0.367 idt_A: 0.361 D_B: 0.140 G_B: 0.531 cycle_B: 0.950 idt_B: 0.103 \n",
            "End of epoch 137 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 100, time: 0.465, data: 0.329) D_A: 0.238 G_A: 0.813 cycle_A: 0.507 idt_A: 0.451 D_B: 0.110 G_B: 0.351 cycle_B: 2.178 idt_B: 0.228 \n",
            "End of epoch 138 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 100, time: 0.397, data: 0.330) D_A: 0.119 G_A: 0.456 cycle_A: 0.353 idt_A: 0.613 D_B: 0.203 G_B: 0.237 cycle_B: 1.737 idt_B: 0.102 \n",
            "End of epoch 139 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 100, time: 1.406, data: 0.204) D_A: 0.100 G_A: 0.699 cycle_A: 0.405 idt_A: 0.402 D_B: 0.095 G_B: 0.399 cycle_B: 1.009 idt_B: 0.154 \n",
            "saving the model at the end of epoch 140, iters 14000\n",
            "End of epoch 140 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 0.389, data: 0.340) D_A: 0.265 G_A: 0.364 cycle_A: 0.340 idt_A: 0.419 D_B: 0.272 G_B: 0.182 cycle_B: 1.352 idt_B: 0.133 \n",
            "End of epoch 141 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 100, time: 0.408, data: 0.306) D_A: 0.129 G_A: 0.422 cycle_A: 0.580 idt_A: 0.783 D_B: 0.167 G_B: 0.259 cycle_B: 2.057 idt_B: 0.212 \n",
            "End of epoch 142 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 100, time: 0.409, data: 0.230) D_A: 0.213 G_A: 0.132 cycle_A: 0.345 idt_A: 0.770 D_B: 0.187 G_B: 0.496 cycle_B: 2.590 idt_B: 0.151 \n",
            "End of epoch 143 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 100, time: 1.459, data: 0.226) D_A: 0.024 G_A: 0.151 cycle_A: 0.367 idt_A: 0.693 D_B: 0.036 G_B: 0.852 cycle_B: 1.990 idt_B: 0.152 \n",
            "End of epoch 144 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 100, time: 0.403, data: 0.246) D_A: 0.220 G_A: 0.305 cycle_A: 0.376 idt_A: 0.572 D_B: 0.091 G_B: 1.391 cycle_B: 1.677 idt_B: 0.138 \n",
            "saving the model at the end of epoch 145, iters 14500\n",
            "End of epoch 145 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 100, time: 0.415, data: 0.284) D_A: 0.294 G_A: 0.201 cycle_A: 0.435 idt_A: 0.559 D_B: 0.060 G_B: 0.400 cycle_B: 1.696 idt_B: 0.175 \n",
            "End of epoch 146 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 100, time: 0.395, data: 0.225) D_A: 0.040 G_A: 0.174 cycle_A: 0.332 idt_A: 0.737 D_B: 0.041 G_B: 0.256 cycle_B: 2.011 idt_B: 0.116 \n",
            "End of epoch 147 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 100, time: 1.481, data: 0.191) D_A: 0.022 G_A: 0.578 cycle_A: 0.384 idt_A: 0.491 D_B: 0.083 G_B: 0.323 cycle_B: 1.030 idt_B: 0.121 \n",
            "End of epoch 148 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 100, time: 0.398, data: 0.198) D_A: 0.147 G_A: 0.559 cycle_A: 0.354 idt_A: 0.492 D_B: 0.157 G_B: 0.239 cycle_B: 1.268 idt_B: 0.122 \n",
            "End of epoch 149 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 100, time: 0.405, data: 0.233) D_A: 0.254 G_A: 0.206 cycle_A: 0.275 idt_A: 0.314 D_B: 0.116 G_B: 0.586 cycle_B: 1.114 idt_B: 0.094 \n",
            "saving the latest model (epoch 150, total_iters 15000)\n",
            "saving the model at the end of epoch 150, iters 15000\n",
            "End of epoch 150 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 100, time: 0.416, data: 0.229) D_A: 0.236 G_A: 0.198 cycle_A: 0.342 idt_A: 0.523 D_B: 0.159 G_B: 0.274 cycle_B: 1.474 idt_B: 0.122 \n",
            "End of epoch 151 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 100, time: 2.102, data: 0.196) D_A: 0.192 G_A: 0.374 cycle_A: 0.149 idt_A: 0.553 D_B: 0.053 G_B: 0.833 cycle_B: 1.953 idt_B: 0.049 \n",
            "End of epoch 152 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 100, time: 0.496, data: 0.245) D_A: 0.044 G_A: 0.393 cycle_A: 0.381 idt_A: 0.269 D_B: 0.137 G_B: 0.437 cycle_B: 1.202 idt_B: 0.189 \n",
            "End of epoch 153 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 100, time: 0.423, data: 0.339) D_A: 0.135 G_A: 0.297 cycle_A: 0.392 idt_A: 0.453 D_B: 0.102 G_B: 0.937 cycle_B: 1.291 idt_B: 0.144 \n",
            "End of epoch 154 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 100, time: 0.422, data: 0.380) D_A: 0.149 G_A: 0.379 cycle_A: 0.313 idt_A: 0.762 D_B: 0.048 G_B: 0.634 cycle_B: 2.129 idt_B: 0.108 \n",
            "saving the model at the end of epoch 155, iters 15500\n",
            "End of epoch 155 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 100, time: 1.694, data: 0.274) D_A: 0.061 G_A: 0.932 cycle_A: 0.489 idt_A: 0.556 D_B: 0.080 G_B: 0.868 cycle_B: 1.688 idt_B: 0.169 \n",
            "End of epoch 156 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 100, time: 0.474, data: 0.290) D_A: 0.096 G_A: 0.956 cycle_A: 0.514 idt_A: 0.519 D_B: 0.059 G_B: 0.200 cycle_B: 1.569 idt_B: 0.201 \n",
            "End of epoch 157 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 100, time: 0.523, data: 0.241) D_A: 0.053 G_A: 0.269 cycle_A: 0.480 idt_A: 0.623 D_B: 0.125 G_B: 0.711 cycle_B: 2.002 idt_B: 0.167 \n",
            "End of epoch 158 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 100, time: 0.425, data: 0.377) D_A: 0.090 G_A: 0.497 cycle_A: 0.342 idt_A: 0.558 D_B: 0.102 G_B: 0.729 cycle_B: 1.432 idt_B: 0.105 \n",
            "End of epoch 159 / 200 \t Time Taken: 41 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 1.663, data: 0.392) D_A: 0.111 G_A: 0.388 cycle_A: 0.527 idt_A: 0.463 D_B: 0.291 G_B: 0.395 cycle_B: 1.652 idt_B: 0.168 \n",
            "saving the model at the end of epoch 160, iters 16000\n",
            "End of epoch 160 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 100, time: 0.425, data: 0.411) D_A: 0.126 G_A: 0.777 cycle_A: 0.238 idt_A: 0.267 D_B: 0.162 G_B: 0.393 cycle_B: 0.895 idt_B: 0.102 \n",
            "End of epoch 161 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 100, time: 0.454, data: 0.488) D_A: 0.216 G_A: 0.387 cycle_A: 0.343 idt_A: 0.534 D_B: 0.097 G_B: 0.516 cycle_B: 1.528 idt_B: 0.101 \n",
            "End of epoch 162 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 100, time: 0.395, data: 0.356) D_A: 0.037 G_A: 0.166 cycle_A: 0.287 idt_A: 0.553 D_B: 0.066 G_B: 0.593 cycle_B: 1.356 idt_B: 0.103 \n",
            "End of epoch 163 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 100, time: 1.565, data: 0.272) D_A: 0.065 G_A: 0.119 cycle_A: 0.358 idt_A: 0.583 D_B: 0.068 G_B: 0.633 cycle_B: 1.249 idt_B: 0.113 \n",
            "End of epoch 164 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 100, time: 0.429, data: 0.200) D_A: 0.068 G_A: 1.014 cycle_A: 0.249 idt_A: 0.479 D_B: 0.030 G_B: 0.418 cycle_B: 1.383 idt_B: 0.098 \n",
            "saving the model at the end of epoch 165, iters 16500\n",
            "End of epoch 165 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 0.415, data: 0.217) D_A: 0.074 G_A: 0.628 cycle_A: 0.565 idt_A: 0.346 D_B: 0.142 G_B: 0.553 cycle_B: 0.983 idt_B: 0.196 \n",
            "End of epoch 166 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 100, time: 0.399, data: 0.277) D_A: 0.123 G_A: 0.339 cycle_A: 0.551 idt_A: 0.539 D_B: 0.027 G_B: 0.848 cycle_B: 0.873 idt_B: 0.217 \n",
            "End of epoch 167 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 100, time: 1.806, data: 0.234) D_A: 0.169 G_A: 0.638 cycle_A: 0.453 idt_A: 0.522 D_B: 0.059 G_B: 0.727 cycle_B: 1.538 idt_B: 0.166 \n",
            "End of epoch 168 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 100, time: 0.403, data: 0.241) D_A: 0.125 G_A: 0.382 cycle_A: 0.393 idt_A: 0.351 D_B: 0.233 G_B: 0.260 cycle_B: 1.313 idt_B: 0.142 \n",
            "End of epoch 169 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 100, time: 0.420, data: 0.194) D_A: 0.067 G_A: 0.232 cycle_A: 0.469 idt_A: 0.754 D_B: 0.254 G_B: 0.547 cycle_B: 2.382 idt_B: 0.164 \n",
            "saving the model at the end of epoch 170, iters 17000\n",
            "End of epoch 170 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 100, time: 0.402, data: 0.237) D_A: 0.178 G_A: 0.211 cycle_A: 0.379 idt_A: 0.405 D_B: 0.080 G_B: 0.480 cycle_B: 1.063 idt_B: 0.128 \n",
            "End of epoch 171 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 100, time: 1.827, data: 0.221) D_A: 0.071 G_A: 0.492 cycle_A: 0.350 idt_A: 0.633 D_B: 0.101 G_B: 0.256 cycle_B: 1.585 idt_B: 0.123 \n",
            "End of epoch 172 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 100, time: 0.464, data: 0.178) D_A: 0.070 G_A: 0.569 cycle_A: 0.361 idt_A: 0.581 D_B: 0.095 G_B: 1.177 cycle_B: 1.606 idt_B: 0.135 \n",
            "End of epoch 173 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 100, time: 0.411, data: 0.360) D_A: 0.121 G_A: 0.363 cycle_A: 0.317 idt_A: 0.402 D_B: 0.135 G_B: 0.686 cycle_B: 1.141 idt_B: 0.125 \n",
            "End of epoch 174 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 100, time: 0.410, data: 0.211) D_A: 0.161 G_A: 0.629 cycle_A: 0.232 idt_A: 0.719 D_B: 0.097 G_B: 0.809 cycle_B: 2.162 idt_B: 0.086 \n",
            "saving the model at the end of epoch 175, iters 17500\n",
            "End of epoch 175 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 100, time: 1.636, data: 0.207) D_A: 0.071 G_A: 0.557 cycle_A: 0.367 idt_A: 0.374 D_B: 0.081 G_B: 0.610 cycle_B: 0.969 idt_B: 0.121 \n",
            "End of epoch 176 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 100, time: 0.390, data: 0.181) D_A: 0.063 G_A: 0.228 cycle_A: 0.314 idt_A: 0.661 D_B: 0.079 G_B: 1.287 cycle_B: 1.733 idt_B: 0.099 \n",
            "End of epoch 177 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 100, time: 0.402, data: 0.228) D_A: 0.103 G_A: 0.379 cycle_A: 0.275 idt_A: 0.399 D_B: 0.083 G_B: 0.370 cycle_B: 1.517 idt_B: 0.089 \n",
            "End of epoch 178 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 100, time: 0.415, data: 0.202) D_A: 0.201 G_A: 0.188 cycle_A: 0.478 idt_A: 0.438 D_B: 0.090 G_B: 0.612 cycle_B: 1.293 idt_B: 0.199 \n",
            "End of epoch 179 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 100, time: 1.818, data: 0.263) D_A: 0.111 G_A: 0.340 cycle_A: 0.341 idt_A: 0.334 D_B: 0.040 G_B: 0.980 cycle_B: 1.107 idt_B: 0.100 \n",
            "saving the model at the end of epoch 180, iters 18000\n",
            "End of epoch 180 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 100, time: 0.386, data: 0.288) D_A: 0.068 G_A: 0.714 cycle_A: 0.300 idt_A: 0.572 D_B: 0.072 G_B: 0.484 cycle_B: 1.845 idt_B: 0.098 \n",
            "End of epoch 181 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 100, time: 0.404, data: 0.195) D_A: 0.062 G_A: 0.235 cycle_A: 0.267 idt_A: 0.493 D_B: 0.077 G_B: 0.550 cycle_B: 0.773 idt_B: 0.091 \n",
            "End of epoch 182 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 100, time: 0.400, data: 0.233) D_A: 0.184 G_A: 0.289 cycle_A: 0.275 idt_A: 0.441 D_B: 0.110 G_B: 0.416 cycle_B: 1.016 idt_B: 0.094 \n",
            "End of epoch 183 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 100, time: 1.754, data: 0.220) D_A: 0.161 G_A: 0.491 cycle_A: 0.245 idt_A: 0.492 D_B: 0.068 G_B: 0.539 cycle_B: 1.409 idt_B: 0.092 \n",
            "End of epoch 184 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 100, time: 0.483, data: 0.188) D_A: 0.116 G_A: 0.429 cycle_A: 0.303 idt_A: 0.394 D_B: 0.125 G_B: 0.351 cycle_B: 1.478 idt_B: 0.083 \n",
            "saving the model at the end of epoch 185, iters 18500\n",
            "End of epoch 185 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 100, time: 0.403, data: 0.264) D_A: 0.090 G_A: 0.476 cycle_A: 0.277 idt_A: 0.665 D_B: 0.041 G_B: 0.601 cycle_B: 1.733 idt_B: 0.081 \n",
            "End of epoch 186 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 100, time: 0.512, data: 0.261) D_A: 0.093 G_A: 0.492 cycle_A: 0.232 idt_A: 0.579 D_B: 0.049 G_B: 0.568 cycle_B: 1.399 idt_B: 0.085 \n",
            "End of epoch 187 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 100, time: 2.382, data: 0.262) D_A: 0.025 G_A: 0.610 cycle_A: 0.288 idt_A: 0.465 D_B: 0.036 G_B: 0.771 cycle_B: 1.351 idt_B: 0.107 \n",
            "End of epoch 188 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 100, time: 0.471, data: 0.331) D_A: 0.043 G_A: 0.725 cycle_A: 0.233 idt_A: 0.509 D_B: 0.050 G_B: 0.582 cycle_B: 1.506 idt_B: 0.070 \n",
            "End of epoch 189 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 100, time: 0.444, data: 0.311) D_A: 0.119 G_A: 0.244 cycle_A: 0.376 idt_A: 0.464 D_B: 0.042 G_B: 0.571 cycle_B: 1.293 idt_B: 0.102 \n",
            "saving the model at the end of epoch 190, iters 19000\n",
            "End of epoch 190 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 0.509, data: 0.200) D_A: 0.043 G_A: 0.763 cycle_A: 0.397 idt_A: 0.421 D_B: 0.132 G_B: 0.582 cycle_B: 1.503 idt_B: 0.147 \n",
            "End of epoch 191 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 100, time: 2.249, data: 0.352) D_A: 0.070 G_A: 0.617 cycle_A: 0.390 idt_A: 0.679 D_B: 0.049 G_B: 0.524 cycle_B: 1.958 idt_B: 0.134 \n",
            "End of epoch 192 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 100, time: 0.513, data: 0.222) D_A: 0.161 G_A: 0.490 cycle_A: 0.306 idt_A: 0.415 D_B: 0.063 G_B: 0.732 cycle_B: 1.180 idt_B: 0.089 \n",
            "End of epoch 193 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 100, time: 0.487, data: 0.331) D_A: 0.083 G_A: 0.490 cycle_A: 0.231 idt_A: 0.538 D_B: 0.022 G_B: 0.435 cycle_B: 1.749 idt_B: 0.077 \n",
            "End of epoch 194 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 100, time: 0.429, data: 0.318) D_A: 0.124 G_A: 0.333 cycle_A: 0.268 idt_A: 0.453 D_B: 0.088 G_B: 0.484 cycle_B: 1.212 idt_B: 0.086 \n",
            "saving the model at the end of epoch 195, iters 19500\n",
            "End of epoch 195 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 100, time: 2.211, data: 0.297) D_A: 0.087 G_A: 0.456 cycle_A: 0.266 idt_A: 0.474 D_B: 0.105 G_B: 0.681 cycle_B: 1.501 idt_B: 0.088 \n",
            "End of epoch 196 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 100, time: 0.486, data: 0.278) D_A: 0.185 G_A: 0.220 cycle_A: 0.549 idt_A: 0.324 D_B: 0.084 G_B: 0.424 cycle_B: 0.796 idt_B: 0.177 \n",
            "End of epoch 197 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 100, time: 0.519, data: 0.291) D_A: 0.114 G_A: 0.558 cycle_A: 0.266 idt_A: 0.504 D_B: 0.080 G_B: 0.481 cycle_B: 1.297 idt_B: 0.091 \n",
            "End of epoch 198 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 100, time: 0.447, data: 0.365) D_A: 0.072 G_A: 0.513 cycle_A: 0.637 idt_A: 0.443 D_B: 0.129 G_B: 0.616 cycle_B: 1.277 idt_B: 0.258 \n",
            "End of epoch 199 / 200 \t Time Taken: 42 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 100, time: 2.030, data: 0.328) D_A: 0.116 G_A: 0.480 cycle_A: 0.337 idt_A: 0.472 D_B: 0.050 G_B: 0.605 cycle_B: 1.333 idt_B: 0.117 \n",
            "saving the latest model (epoch 200, total_iters 20000)\n",
            "saving the model at the end of epoch 200, iters 20000\n",
            "End of epoch 200 / 200 \t Time Taken: 48 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2000, 0.1973, 0.2009, 0.2009, 0.2008],\n",
            "        [0.2004, 0.1980, 0.2005, 0.2004, 0.2007],\n",
            "        [0.2003, 0.1979, 0.2005, 0.2004, 0.2009],\n",
            "        [0.2002, 0.1979, 0.2005, 0.2004, 0.2010],\n",
            "        [0.2000, 0.1980, 0.2006, 0.2005, 0.2009]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2003, 0.1957, 0.2013, 0.2013, 0.2014],\n",
            "        [0.2007, 0.1963, 0.2010, 0.2007, 0.2012],\n",
            "        [0.2006, 0.1964, 0.2009, 0.2007, 0.2014],\n",
            "        [0.2004, 0.1963, 0.2009, 0.2008, 0.2016],\n",
            "        [0.2004, 0.1965, 0.2008, 0.2007, 0.2015]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2005, 0.1934, 0.2019, 0.2020, 0.2022],\n",
            "        [0.2009, 0.1944, 0.2016, 0.2012, 0.2019],\n",
            "        [0.2009, 0.1944, 0.2014, 0.2011, 0.2022],\n",
            "        [0.2008, 0.1945, 0.2012, 0.2011, 0.2024],\n",
            "        [0.2009, 0.1947, 0.2014, 0.2012, 0.2019]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2007, 0.1916, 0.2025, 0.2026, 0.2026],\n",
            "        [0.2013, 0.1927, 0.2021, 0.2015, 0.2024],\n",
            "        [0.2013, 0.1926, 0.2019, 0.2014, 0.2028],\n",
            "        [0.2012, 0.1927, 0.2017, 0.2014, 0.2029],\n",
            "        [0.2013, 0.1931, 0.2016, 0.2014, 0.2025]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2008, 0.1898, 0.2030, 0.2030, 0.2034],\n",
            "        [0.2016, 0.1911, 0.2026, 0.2018, 0.2030],\n",
            "        [0.2014, 0.1909, 0.2024, 0.2018, 0.2035],\n",
            "        [0.2014, 0.1910, 0.2021, 0.2017, 0.2038],\n",
            "        [0.2015, 0.1917, 0.2021, 0.2018, 0.2030]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2013, 0.1878, 0.2035, 0.2036, 0.2038],\n",
            "        [0.2022, 0.1891, 0.2031, 0.2022, 0.2034],\n",
            "        [0.2020, 0.1893, 0.2026, 0.2020, 0.2040],\n",
            "        [0.2021, 0.1893, 0.2024, 0.2020, 0.2042],\n",
            "        [0.2024, 0.1899, 0.2022, 0.2019, 0.2036]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2013, 0.1861, 0.2042, 0.2042, 0.2043],\n",
            "        [0.2024, 0.1873, 0.2038, 0.2027, 0.2039],\n",
            "        [0.2024, 0.1875, 0.2031, 0.2023, 0.2047],\n",
            "        [0.2024, 0.1876, 0.2029, 0.2024, 0.2048],\n",
            "        [0.2028, 0.1883, 0.2025, 0.2022, 0.2042]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2014, 0.1846, 0.2047, 0.2047, 0.2046],\n",
            "        [0.2028, 0.1861, 0.2040, 0.2028, 0.2042],\n",
            "        [0.2027, 0.1863, 0.2034, 0.2025, 0.2050],\n",
            "        [0.2028, 0.1863, 0.2031, 0.2025, 0.2053],\n",
            "        [0.2032, 0.1871, 0.2028, 0.2024, 0.2046]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2017, 0.1831, 0.2052, 0.2051, 0.2049],\n",
            "        [0.2032, 0.1847, 0.2044, 0.2031, 0.2046],\n",
            "        [0.2031, 0.1849, 0.2037, 0.2028, 0.2055],\n",
            "        [0.2032, 0.1849, 0.2034, 0.2027, 0.2058],\n",
            "        [0.2038, 0.1858, 0.2031, 0.2026, 0.2048]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2018, 0.1811, 0.2057, 0.2056, 0.2058],\n",
            "        [0.2033, 0.1827, 0.2051, 0.2036, 0.2053],\n",
            "        [0.2033, 0.1830, 0.2042, 0.2032, 0.2062],\n",
            "        [0.2035, 0.1828, 0.2039, 0.2032, 0.2065],\n",
            "        [0.2041, 0.1837, 0.2035, 0.2030, 0.2056]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2022, 0.1796, 0.2062, 0.2061, 0.2059],\n",
            "        [0.2039, 0.1813, 0.2054, 0.2038, 0.2055],\n",
            "        [0.2039, 0.1818, 0.2044, 0.2032, 0.2067],\n",
            "        [0.2041, 0.1813, 0.2043, 0.2035, 0.2068],\n",
            "        [0.2048, 0.1823, 0.2038, 0.2032, 0.2059]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2025, 0.1776, 0.2069, 0.2068, 0.2063],\n",
            "        [0.2045, 0.1797, 0.2058, 0.2041, 0.2060],\n",
            "        [0.2044, 0.1801, 0.2047, 0.2035, 0.2073],\n",
            "        [0.2044, 0.1794, 0.2047, 0.2039, 0.2076],\n",
            "        [0.2050, 0.1806, 0.2043, 0.2037, 0.2065]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2026, 0.1759, 0.2075, 0.2074, 0.2065],\n",
            "        [0.2048, 0.1782, 0.2062, 0.2044, 0.2064],\n",
            "        [0.2050, 0.1786, 0.2050, 0.2036, 0.2078],\n",
            "        [0.2050, 0.1780, 0.2049, 0.2040, 0.2080],\n",
            "        [0.2058, 0.1792, 0.2044, 0.2037, 0.2069]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2029, 0.1745, 0.2079, 0.2077, 0.2069],\n",
            "        [0.2050, 0.1766, 0.2068, 0.2048, 0.2068],\n",
            "        [0.2052, 0.1771, 0.2054, 0.2039, 0.2084],\n",
            "        [0.2052, 0.1764, 0.2054, 0.2044, 0.2085],\n",
            "        [0.2061, 0.1777, 0.2048, 0.2041, 0.2073]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2033, 0.1733, 0.2085, 0.2082, 0.2067],\n",
            "        [0.2057, 0.1758, 0.2068, 0.2047, 0.2070],\n",
            "        [0.2055, 0.1761, 0.2056, 0.2041, 0.2087],\n",
            "        [0.2056, 0.1753, 0.2057, 0.2046, 0.2087],\n",
            "        [0.2067, 0.1767, 0.2050, 0.2043, 0.2073]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2033, 0.1718, 0.2090, 0.2087, 0.2072],\n",
            "        [0.2059, 0.1745, 0.2073, 0.2050, 0.2073],\n",
            "        [0.2056, 0.1749, 0.2059, 0.2042, 0.2094],\n",
            "        [0.2058, 0.1741, 0.2059, 0.2048, 0.2094],\n",
            "        [0.2068, 0.1756, 0.2053, 0.2045, 0.2078]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2036, 0.1700, 0.2096, 0.2092, 0.2076],\n",
            "        [0.2064, 0.1727, 0.2078, 0.2053, 0.2078],\n",
            "        [0.2062, 0.1731, 0.2061, 0.2044, 0.2102],\n",
            "        [0.2062, 0.1721, 0.2065, 0.2052, 0.2100],\n",
            "        [0.2075, 0.1737, 0.2056, 0.2048, 0.2084]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2036, 0.1685, 0.2102, 0.2097, 0.2080],\n",
            "        [0.2066, 0.1714, 0.2082, 0.2056, 0.2082],\n",
            "        [0.2065, 0.1718, 0.2064, 0.2046, 0.2107],\n",
            "        [0.2065, 0.1705, 0.2068, 0.2055, 0.2107],\n",
            "        [0.2079, 0.1720, 0.2060, 0.2051, 0.2091]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2037, 0.1673, 0.2106, 0.2100, 0.2083],\n",
            "        [0.2071, 0.1705, 0.2083, 0.2056, 0.2084],\n",
            "        [0.2069, 0.1707, 0.2067, 0.2048, 0.2109],\n",
            "        [0.2069, 0.1694, 0.2070, 0.2056, 0.2110],\n",
            "        [0.2082, 0.1712, 0.2061, 0.2053, 0.2093]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2042, 0.1661, 0.2109, 0.2103, 0.2085],\n",
            "        [0.2076, 0.1694, 0.2085, 0.2058, 0.2087],\n",
            "        [0.2073, 0.1694, 0.2069, 0.2049, 0.2115],\n",
            "        [0.2072, 0.1682, 0.2073, 0.2058, 0.2115],\n",
            "        [0.2086, 0.1699, 0.2064, 0.2055, 0.2096]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2043, 0.1646, 0.2115, 0.2107, 0.2089],\n",
            "        [0.2081, 0.1678, 0.2089, 0.2060, 0.2092],\n",
            "        [0.2078, 0.1679, 0.2072, 0.2051, 0.2121],\n",
            "        [0.2076, 0.1665, 0.2077, 0.2061, 0.2120],\n",
            "        [0.2091, 0.1683, 0.2067, 0.2057, 0.2101]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2045, 0.1634, 0.2119, 0.2111, 0.2091],\n",
            "        [0.2083, 0.1668, 0.2092, 0.2062, 0.2094],\n",
            "        [0.2080, 0.1669, 0.2074, 0.2054, 0.2123],\n",
            "        [0.2080, 0.1656, 0.2079, 0.2062, 0.2122],\n",
            "        [0.2097, 0.1677, 0.2066, 0.2057, 0.2103]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2049, 0.1621, 0.2122, 0.2114, 0.2094],\n",
            "        [0.2087, 0.1655, 0.2095, 0.2065, 0.2098],\n",
            "        [0.2084, 0.1655, 0.2078, 0.2056, 0.2128],\n",
            "        [0.2085, 0.1641, 0.2081, 0.2064, 0.2128],\n",
            "        [0.2102, 0.1663, 0.2071, 0.2060, 0.2105]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2051, 0.1607, 0.2129, 0.2119, 0.2094],\n",
            "        [0.2093, 0.1646, 0.2097, 0.2065, 0.2099],\n",
            "        [0.2089, 0.1645, 0.2078, 0.2056, 0.2132],\n",
            "        [0.2089, 0.1631, 0.2084, 0.2066, 0.2131],\n",
            "        [0.2106, 0.1653, 0.2073, 0.2061, 0.2107]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2051, 0.1582, 0.2138, 0.2127, 0.2103],\n",
            "        [0.2096, 0.1622, 0.2105, 0.2071, 0.2105],\n",
            "        [0.2092, 0.1623, 0.2084, 0.2060, 0.2142],\n",
            "        [0.2092, 0.1610, 0.2087, 0.2068, 0.2143],\n",
            "        [0.2109, 0.1632, 0.2078, 0.2066, 0.2114]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2054, 0.1574, 0.2141, 0.2128, 0.2103],\n",
            "        [0.2102, 0.1613, 0.2107, 0.2072, 0.2107],\n",
            "        [0.2097, 0.1615, 0.2085, 0.2060, 0.2143],\n",
            "        [0.2097, 0.1599, 0.2090, 0.2070, 0.2144],\n",
            "        [0.2116, 0.1625, 0.2078, 0.2066, 0.2115]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2059, 0.1560, 0.2146, 0.2132, 0.2103],\n",
            "        [0.2109, 0.1599, 0.2109, 0.2073, 0.2110],\n",
            "        [0.2103, 0.1600, 0.2086, 0.2061, 0.2149],\n",
            "        [0.2102, 0.1585, 0.2093, 0.2072, 0.2148],\n",
            "        [0.2125, 0.1611, 0.2080, 0.2067, 0.2118]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2061, 0.1539, 0.2156, 0.2141, 0.2104],\n",
            "        [0.2116, 0.1585, 0.2112, 0.2074, 0.2112],\n",
            "        [0.2109, 0.1585, 0.2090, 0.2063, 0.2153],\n",
            "        [0.2107, 0.1568, 0.2096, 0.2075, 0.2154],\n",
            "        [0.2130, 0.1598, 0.2082, 0.2069, 0.2122]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2067, 0.1531, 0.2158, 0.2142, 0.2102],\n",
            "        [0.2124, 0.1574, 0.2114, 0.2075, 0.2113],\n",
            "        [0.2117, 0.1575, 0.2091, 0.2064, 0.2153],\n",
            "        [0.2115, 0.1558, 0.2097, 0.2075, 0.2154],\n",
            "        [0.2140, 0.1589, 0.2082, 0.2068, 0.2121]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2071, 0.1518, 0.2164, 0.2146, 0.2102],\n",
            "        [0.2131, 0.1563, 0.2118, 0.2077, 0.2111],\n",
            "        [0.2126, 0.1564, 0.2091, 0.2064, 0.2155],\n",
            "        [0.2123, 0.1547, 0.2100, 0.2077, 0.2154],\n",
            "        [0.2149, 0.1579, 0.2082, 0.2068, 0.2122]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2071, 0.1506, 0.2168, 0.2150, 0.2105],\n",
            "        [0.2132, 0.1552, 0.2122, 0.2081, 0.2113],\n",
            "        [0.2131, 0.1553, 0.2093, 0.2065, 0.2158],\n",
            "        [0.2126, 0.1535, 0.2101, 0.2078, 0.2160],\n",
            "        [0.2150, 0.1565, 0.2087, 0.2073, 0.2126]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2074, 0.1498, 0.2172, 0.2152, 0.2104],\n",
            "        [0.2137, 0.1547, 0.2123, 0.2080, 0.2113],\n",
            "        [0.2138, 0.1548, 0.2092, 0.2064, 0.2158],\n",
            "        [0.2131, 0.1526, 0.2103, 0.2079, 0.2162],\n",
            "        [0.2154, 0.1555, 0.2089, 0.2075, 0.2127]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2081, 0.1484, 0.2176, 0.2155, 0.2104],\n",
            "        [0.2145, 0.1532, 0.2126, 0.2082, 0.2114],\n",
            "        [0.2147, 0.1533, 0.2094, 0.2065, 0.2160],\n",
            "        [0.2138, 0.1513, 0.2105, 0.2080, 0.2163],\n",
            "        [0.2167, 0.1542, 0.2089, 0.2074, 0.2128]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2083, 0.1468, 0.2184, 0.2161, 0.2105],\n",
            "        [0.2152, 0.1519, 0.2129, 0.2084, 0.2116],\n",
            "        [0.2151, 0.1519, 0.2097, 0.2067, 0.2166],\n",
            "        [0.2143, 0.1499, 0.2108, 0.2082, 0.2167],\n",
            "        [0.2173, 0.1529, 0.2091, 0.2076, 0.2131]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2083, 0.1450, 0.2193, 0.2168, 0.2106],\n",
            "        [0.2156, 0.1503, 0.2136, 0.2088, 0.2117],\n",
            "        [0.2157, 0.1507, 0.2098, 0.2068, 0.2169],\n",
            "        [0.2148, 0.1488, 0.2110, 0.2083, 0.2171],\n",
            "        [0.2178, 0.1515, 0.2094, 0.2078, 0.2134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2085, 0.1441, 0.2198, 0.2172, 0.2104],\n",
            "        [0.2161, 0.1497, 0.2137, 0.2088, 0.2117],\n",
            "        [0.2163, 0.1502, 0.2098, 0.2067, 0.2170],\n",
            "        [0.2153, 0.1480, 0.2111, 0.2084, 0.2172],\n",
            "        [0.2183, 0.1506, 0.2096, 0.2080, 0.2135]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2087, 0.1434, 0.2202, 0.2175, 0.2103],\n",
            "        [0.2166, 0.1490, 0.2138, 0.2089, 0.2117],\n",
            "        [0.2167, 0.1495, 0.2100, 0.2068, 0.2170],\n",
            "        [0.2157, 0.1473, 0.2114, 0.2086, 0.2170],\n",
            "        [0.2189, 0.1500, 0.2096, 0.2080, 0.2134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2090, 0.1425, 0.2204, 0.2176, 0.2106],\n",
            "        [0.2169, 0.1479, 0.2143, 0.2091, 0.2118],\n",
            "        [0.2169, 0.1486, 0.2102, 0.2069, 0.2174],\n",
            "        [0.2160, 0.1462, 0.2117, 0.2088, 0.2173],\n",
            "        [0.2195, 0.1491, 0.2098, 0.2081, 0.2135]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2095, 0.1417, 0.2204, 0.2176, 0.2109],\n",
            "        [0.2177, 0.1465, 0.2145, 0.2093, 0.2119],\n",
            "        [0.2173, 0.1471, 0.2105, 0.2072, 0.2179],\n",
            "        [0.2164, 0.1445, 0.2122, 0.2093, 0.2178],\n",
            "        [0.2200, 0.1476, 0.2102, 0.2085, 0.2137]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2099, 0.1408, 0.2208, 0.2179, 0.2107],\n",
            "        [0.2185, 0.1459, 0.2145, 0.2091, 0.2120],\n",
            "        [0.2182, 0.1465, 0.2104, 0.2070, 0.2179],\n",
            "        [0.2171, 0.1438, 0.2122, 0.2092, 0.2178],\n",
            "        [0.2208, 0.1469, 0.2103, 0.2086, 0.2134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2101, 0.1400, 0.2211, 0.2181, 0.2108],\n",
            "        [0.2192, 0.1452, 0.2146, 0.2091, 0.2118],\n",
            "        [0.2186, 0.1458, 0.2104, 0.2070, 0.2182],\n",
            "        [0.2176, 0.1429, 0.2124, 0.2093, 0.2178],\n",
            "        [0.2214, 0.1460, 0.2105, 0.2087, 0.2134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2103, 0.1393, 0.2215, 0.2183, 0.2107],\n",
            "        [0.2194, 0.1444, 0.2150, 0.2094, 0.2118],\n",
            "        [0.2190, 0.1450, 0.2107, 0.2072, 0.2181],\n",
            "        [0.2182, 0.1422, 0.2125, 0.2094, 0.2178],\n",
            "        [0.2217, 0.1455, 0.2107, 0.2088, 0.2133]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2107, 0.1385, 0.2217, 0.2184, 0.2106],\n",
            "        [0.2203, 0.1438, 0.2149, 0.2093, 0.2117],\n",
            "        [0.2199, 0.1444, 0.2106, 0.2070, 0.2182],\n",
            "        [0.2191, 0.1413, 0.2124, 0.2092, 0.2179],\n",
            "        [0.2228, 0.1448, 0.2105, 0.2086, 0.2132]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2108, 0.1380, 0.2220, 0.2186, 0.2106],\n",
            "        [0.2207, 0.1430, 0.2151, 0.2093, 0.2119],\n",
            "        [0.2203, 0.1435, 0.2107, 0.2071, 0.2184],\n",
            "        [0.2195, 0.1407, 0.2125, 0.2093, 0.2180],\n",
            "        [0.2234, 0.1441, 0.2105, 0.2086, 0.2134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2113, 0.1369, 0.2223, 0.2189, 0.2107],\n",
            "        [0.2211, 0.1422, 0.2153, 0.2094, 0.2120],\n",
            "        [0.2209, 0.1424, 0.2109, 0.2071, 0.2188],\n",
            "        [0.2199, 0.1395, 0.2128, 0.2095, 0.2182],\n",
            "        [0.2244, 0.1431, 0.2105, 0.2086, 0.2134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2114, 0.1362, 0.2227, 0.2191, 0.2107],\n",
            "        [0.2217, 0.1408, 0.2157, 0.2096, 0.2122],\n",
            "        [0.2214, 0.1412, 0.2109, 0.2071, 0.2193],\n",
            "        [0.2199, 0.1384, 0.2133, 0.2099, 0.2185],\n",
            "        [0.2244, 0.1419, 0.2110, 0.2090, 0.2137]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2117, 0.1353, 0.2229, 0.2193, 0.2108],\n",
            "        [0.2223, 0.1399, 0.2159, 0.2097, 0.2122],\n",
            "        [0.2218, 0.1405, 0.2111, 0.2072, 0.2194],\n",
            "        [0.2207, 0.1375, 0.2134, 0.2099, 0.2185],\n",
            "        [0.2253, 0.1411, 0.2110, 0.2090, 0.2137]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2117, 0.1346, 0.2232, 0.2195, 0.2110],\n",
            "        [0.2222, 0.1390, 0.2163, 0.2100, 0.2125],\n",
            "        [0.2217, 0.1395, 0.2115, 0.2075, 0.2199],\n",
            "        [0.2208, 0.1362, 0.2138, 0.2102, 0.2188],\n",
            "        [0.2257, 0.1402, 0.2112, 0.2091, 0.2139]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2118, 0.1339, 0.2236, 0.2198, 0.2109],\n",
            "        [0.2228, 0.1381, 0.2165, 0.2101, 0.2125],\n",
            "        [0.2222, 0.1387, 0.2116, 0.2075, 0.2200],\n",
            "        [0.2213, 0.1354, 0.2140, 0.2103, 0.2189],\n",
            "        [0.2260, 0.1392, 0.2115, 0.2093, 0.2140]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2116, 0.1331, 0.2240, 0.2202, 0.2111],\n",
            "        [0.2230, 0.1370, 0.2168, 0.2103, 0.2129],\n",
            "        [0.2224, 0.1374, 0.2120, 0.2079, 0.2203],\n",
            "        [0.2220, 0.1342, 0.2142, 0.2104, 0.2192],\n",
            "        [0.2266, 0.1381, 0.2116, 0.2094, 0.2142]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2115, 0.1324, 0.2246, 0.2207, 0.2109],\n",
            "        [0.2235, 0.1363, 0.2170, 0.2103, 0.2129],\n",
            "        [0.2229, 0.1368, 0.2120, 0.2078, 0.2205],\n",
            "        [0.2223, 0.1336, 0.2143, 0.2105, 0.2193],\n",
            "        [0.2268, 0.1375, 0.2119, 0.2097, 0.2142]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2122, 0.1320, 0.2245, 0.2205, 0.2108],\n",
            "        [0.2241, 0.1358, 0.2170, 0.2102, 0.2129],\n",
            "        [0.2233, 0.1360, 0.2122, 0.2080, 0.2205],\n",
            "        [0.2229, 0.1329, 0.2144, 0.2106, 0.2192],\n",
            "        [0.2273, 0.1372, 0.2119, 0.2097, 0.2139]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2124, 0.1315, 0.2248, 0.2207, 0.2105],\n",
            "        [0.2245, 0.1353, 0.2170, 0.2101, 0.2130],\n",
            "        [0.2238, 0.1354, 0.2122, 0.2079, 0.2208],\n",
            "        [0.2231, 0.1325, 0.2146, 0.2107, 0.2192],\n",
            "        [0.2280, 0.1367, 0.2119, 0.2096, 0.2138]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2125, 0.1306, 0.2252, 0.2210, 0.2107],\n",
            "        [0.2248, 0.1343, 0.2173, 0.2103, 0.2132],\n",
            "        [0.2237, 0.1341, 0.2127, 0.2082, 0.2212],\n",
            "        [0.2231, 0.1312, 0.2151, 0.2111, 0.2196],\n",
            "        [0.2284, 0.1356, 0.2121, 0.2098, 0.2140]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2127, 0.1301, 0.2255, 0.2211, 0.2106],\n",
            "        [0.2250, 0.1338, 0.2176, 0.2104, 0.2132],\n",
            "        [0.2240, 0.1337, 0.2129, 0.2084, 0.2211],\n",
            "        [0.2237, 0.1308, 0.2150, 0.2109, 0.2196],\n",
            "        [0.2287, 0.1352, 0.2123, 0.2099, 0.2139]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2132, 0.1295, 0.2255, 0.2211, 0.2107],\n",
            "        [0.2252, 0.1332, 0.2178, 0.2106, 0.2132],\n",
            "        [0.2243, 0.1332, 0.2130, 0.2084, 0.2211],\n",
            "        [0.2242, 0.1302, 0.2151, 0.2109, 0.2195],\n",
            "        [0.2292, 0.1347, 0.2123, 0.2099, 0.2139]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2133, 0.1288, 0.2258, 0.2214, 0.2107],\n",
            "        [0.2255, 0.1324, 0.2180, 0.2107, 0.2133],\n",
            "        [0.2249, 0.1325, 0.2129, 0.2083, 0.2214],\n",
            "        [0.2247, 0.1297, 0.2151, 0.2109, 0.2195],\n",
            "        [0.2293, 0.1338, 0.2127, 0.2102, 0.2140]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2138, 0.1282, 0.2260, 0.2215, 0.2105],\n",
            "        [0.2261, 0.1318, 0.2182, 0.2108, 0.2130],\n",
            "        [0.2258, 0.1321, 0.2128, 0.2081, 0.2212],\n",
            "        [0.2255, 0.1291, 0.2150, 0.2108, 0.2195],\n",
            "        [0.2299, 0.1335, 0.2126, 0.2101, 0.2138]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2138, 0.1276, 0.2263, 0.2218, 0.2105],\n",
            "        [0.2265, 0.1313, 0.2183, 0.2108, 0.2131],\n",
            "        [0.2259, 0.1317, 0.2129, 0.2082, 0.2213],\n",
            "        [0.2256, 0.1286, 0.2153, 0.2111, 0.2194],\n",
            "        [0.2301, 0.1328, 0.2129, 0.2104, 0.2138]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2139, 0.1271, 0.2266, 0.2220, 0.2105],\n",
            "        [0.2267, 0.1308, 0.2184, 0.2109, 0.2131],\n",
            "        [0.2262, 0.1313, 0.2130, 0.2083, 0.2213],\n",
            "        [0.2261, 0.1282, 0.2154, 0.2111, 0.2192],\n",
            "        [0.2308, 0.1325, 0.2127, 0.2102, 0.2138]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2138, 0.1268, 0.2268, 0.2222, 0.2104],\n",
            "        [0.2269, 0.1304, 0.2185, 0.2110, 0.2132],\n",
            "        [0.2261, 0.1309, 0.2133, 0.2085, 0.2213],\n",
            "        [0.2262, 0.1275, 0.2157, 0.2113, 0.2193],\n",
            "        [0.2311, 0.1321, 0.2128, 0.2103, 0.2138]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2137, 0.1264, 0.2270, 0.2223, 0.2106],\n",
            "        [0.2267, 0.1300, 0.2188, 0.2112, 0.2133],\n",
            "        [0.2262, 0.1305, 0.2134, 0.2086, 0.2213],\n",
            "        [0.2263, 0.1271, 0.2159, 0.2115, 0.2192],\n",
            "        [0.2312, 0.1318, 0.2129, 0.2104, 0.2137]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2139, 0.1261, 0.2272, 0.2224, 0.2105],\n",
            "        [0.2270, 0.1296, 0.2189, 0.2113, 0.2131],\n",
            "        [0.2265, 0.1303, 0.2134, 0.2085, 0.2213],\n",
            "        [0.2270, 0.1267, 0.2158, 0.2114, 0.2191],\n",
            "        [0.2319, 0.1312, 0.2129, 0.2103, 0.2137]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2141, 0.1259, 0.2271, 0.2223, 0.2105],\n",
            "        [0.2272, 0.1290, 0.2192, 0.2114, 0.2132],\n",
            "        [0.2266, 0.1298, 0.2136, 0.2086, 0.2214],\n",
            "        [0.2273, 0.1262, 0.2160, 0.2115, 0.2190],\n",
            "        [0.2320, 0.1308, 0.2132, 0.2105, 0.2136]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2139, 0.1253, 0.2275, 0.2226, 0.2107],\n",
            "        [0.2272, 0.1286, 0.2194, 0.2116, 0.2133],\n",
            "        [0.2266, 0.1293, 0.2138, 0.2088, 0.2216],\n",
            "        [0.2272, 0.1257, 0.2162, 0.2117, 0.2192],\n",
            "        [0.2319, 0.1303, 0.2133, 0.2107, 0.2138]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2143, 0.1251, 0.2275, 0.2227, 0.2104],\n",
            "        [0.2277, 0.1285, 0.2193, 0.2115, 0.2130],\n",
            "        [0.2272, 0.1291, 0.2137, 0.2087, 0.2214],\n",
            "        [0.2278, 0.1256, 0.2161, 0.2116, 0.2189],\n",
            "        [0.2325, 0.1302, 0.2133, 0.2107, 0.2134]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2143, 0.1248, 0.2278, 0.2229, 0.2102],\n",
            "        [0.2281, 0.1283, 0.2192, 0.2113, 0.2130],\n",
            "        [0.2274, 0.1288, 0.2138, 0.2088, 0.2212],\n",
            "        [0.2283, 0.1250, 0.2163, 0.2117, 0.2186],\n",
            "        [0.2330, 0.1300, 0.2131, 0.2105, 0.2133]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2143, 0.1243, 0.2282, 0.2232, 0.2100],\n",
            "        [0.2285, 0.1277, 0.2194, 0.2114, 0.2130],\n",
            "        [0.2279, 0.1282, 0.2139, 0.2088, 0.2213],\n",
            "        [0.2289, 0.1245, 0.2164, 0.2117, 0.2185],\n",
            "        [0.2338, 0.1297, 0.2130, 0.2103, 0.2133]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2147, 0.1239, 0.2283, 0.2232, 0.2099],\n",
            "        [0.2288, 0.1274, 0.2195, 0.2114, 0.2129],\n",
            "        [0.2283, 0.1279, 0.2138, 0.2086, 0.2213],\n",
            "        [0.2289, 0.1240, 0.2165, 0.2118, 0.2188],\n",
            "        [0.2338, 0.1292, 0.2133, 0.2106, 0.2131]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2147, 0.1235, 0.2285, 0.2234, 0.2098],\n",
            "        [0.2293, 0.1267, 0.2196, 0.2115, 0.2129],\n",
            "        [0.2288, 0.1274, 0.2138, 0.2087, 0.2213],\n",
            "        [0.2297, 0.1235, 0.2165, 0.2118, 0.2185],\n",
            "        [0.2346, 0.1286, 0.2132, 0.2105, 0.2130]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2154, 0.1232, 0.2284, 0.2232, 0.2097],\n",
            "        [0.2298, 0.1264, 0.2197, 0.2115, 0.2125],\n",
            "        [0.2296, 0.1273, 0.2137, 0.2085, 0.2209],\n",
            "        [0.2303, 0.1234, 0.2164, 0.2116, 0.2183],\n",
            "        [0.2351, 0.1285, 0.2133, 0.2105, 0.2126]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2156, 0.1229, 0.2286, 0.2235, 0.2094],\n",
            "        [0.2302, 0.1262, 0.2197, 0.2115, 0.2124],\n",
            "        [0.2300, 0.1269, 0.2138, 0.2086, 0.2208],\n",
            "        [0.2308, 0.1231, 0.2165, 0.2118, 0.2178],\n",
            "        [0.2357, 0.1283, 0.2131, 0.2104, 0.2124]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2158, 0.1227, 0.2288, 0.2235, 0.2092],\n",
            "        [0.2305, 0.1259, 0.2199, 0.2115, 0.2122],\n",
            "        [0.2308, 0.1266, 0.2137, 0.2084, 0.2206],\n",
            "        [0.2315, 0.1227, 0.2165, 0.2117, 0.2176],\n",
            "        [0.2362, 0.1278, 0.2132, 0.2104, 0.2125]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2157, 0.1220, 0.2292, 0.2239, 0.2091],\n",
            "        [0.2311, 0.1254, 0.2199, 0.2116, 0.2119],\n",
            "        [0.2311, 0.1263, 0.2136, 0.2083, 0.2207],\n",
            "        [0.2321, 0.1223, 0.2164, 0.2117, 0.2175],\n",
            "        [0.2365, 0.1274, 0.2134, 0.2105, 0.2121]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2160, 0.1217, 0.2293, 0.2239, 0.2090],\n",
            "        [0.2314, 0.1250, 0.2201, 0.2117, 0.2118],\n",
            "        [0.2316, 0.1259, 0.2136, 0.2083, 0.2206],\n",
            "        [0.2325, 0.1218, 0.2165, 0.2118, 0.2174],\n",
            "        [0.2369, 0.1272, 0.2134, 0.2106, 0.2120]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2162, 0.1211, 0.2297, 0.2243, 0.2087],\n",
            "        [0.2321, 0.1246, 0.2199, 0.2114, 0.2120],\n",
            "        [0.2318, 0.1253, 0.2139, 0.2085, 0.2205],\n",
            "        [0.2328, 0.1214, 0.2166, 0.2118, 0.2174],\n",
            "        [0.2375, 0.1268, 0.2134, 0.2105, 0.2118]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2162, 0.1208, 0.2298, 0.2244, 0.2088],\n",
            "        [0.2321, 0.1241, 0.2201, 0.2116, 0.2121],\n",
            "        [0.2319, 0.1249, 0.2140, 0.2086, 0.2205],\n",
            "        [0.2330, 0.1209, 0.2168, 0.2119, 0.2174],\n",
            "        [0.2375, 0.1264, 0.2136, 0.2107, 0.2118]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2164, 0.1206, 0.2299, 0.2245, 0.2086],\n",
            "        [0.2325, 0.1238, 0.2201, 0.2116, 0.2120],\n",
            "        [0.2321, 0.1245, 0.2141, 0.2086, 0.2207],\n",
            "        [0.2331, 0.1207, 0.2170, 0.2121, 0.2172],\n",
            "        [0.2379, 0.1262, 0.2136, 0.2106, 0.2117]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2165, 0.1202, 0.2302, 0.2246, 0.2085],\n",
            "        [0.2327, 0.1236, 0.2202, 0.2116, 0.2120],\n",
            "        [0.2324, 0.1244, 0.2142, 0.2086, 0.2204],\n",
            "        [0.2336, 0.1205, 0.2170, 0.2120, 0.2169],\n",
            "        [0.2383, 0.1260, 0.2136, 0.2106, 0.2115]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2164, 0.1198, 0.2304, 0.2248, 0.2085],\n",
            "        [0.2329, 0.1232, 0.2202, 0.2116, 0.2121],\n",
            "        [0.2321, 0.1239, 0.2145, 0.2089, 0.2206],\n",
            "        [0.2336, 0.1199, 0.2173, 0.2123, 0.2169],\n",
            "        [0.2384, 0.1256, 0.2137, 0.2108, 0.2115]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2165, 0.1194, 0.2307, 0.2251, 0.2083],\n",
            "        [0.2332, 0.1229, 0.2202, 0.2116, 0.2121],\n",
            "        [0.2325, 0.1235, 0.2145, 0.2089, 0.2207],\n",
            "        [0.2336, 0.1196, 0.2176, 0.2125, 0.2167],\n",
            "        [0.2388, 0.1254, 0.2137, 0.2107, 0.2113]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2171, 0.1192, 0.2305, 0.2248, 0.2083],\n",
            "        [0.2336, 0.1224, 0.2203, 0.2116, 0.2121],\n",
            "        [0.2329, 0.1230, 0.2146, 0.2089, 0.2205],\n",
            "        [0.2344, 0.1189, 0.2175, 0.2124, 0.2168],\n",
            "        [0.2393, 0.1249, 0.2138, 0.2108, 0.2112]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2170, 0.1191, 0.2307, 0.2250, 0.2083],\n",
            "        [0.2335, 0.1223, 0.2205, 0.2117, 0.2120],\n",
            "        [0.2330, 0.1230, 0.2145, 0.2088, 0.2207],\n",
            "        [0.2345, 0.1187, 0.2177, 0.2126, 0.2166],\n",
            "        [0.2396, 0.1248, 0.2137, 0.2107, 0.2113]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2171, 0.1190, 0.2307, 0.2250, 0.2082],\n",
            "        [0.2340, 0.1221, 0.2204, 0.2116, 0.2120],\n",
            "        [0.2334, 0.1228, 0.2145, 0.2088, 0.2205],\n",
            "        [0.2349, 0.1185, 0.2176, 0.2125, 0.2164],\n",
            "        [0.2400, 0.1246, 0.2136, 0.2106, 0.2112]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2173, 0.1188, 0.2308, 0.2250, 0.2081],\n",
            "        [0.2339, 0.1219, 0.2206, 0.2117, 0.2119],\n",
            "        [0.2337, 0.1225, 0.2145, 0.2088, 0.2205],\n",
            "        [0.2350, 0.1183, 0.2178, 0.2127, 0.2162],\n",
            "        [0.2402, 0.1245, 0.2137, 0.2107, 0.2109]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2171, 0.1182, 0.2312, 0.2254, 0.2081],\n",
            "        [0.2343, 0.1215, 0.2205, 0.2116, 0.2122],\n",
            "        [0.2333, 0.1219, 0.2149, 0.2091, 0.2207],\n",
            "        [0.2350, 0.1175, 0.2181, 0.2129, 0.2165],\n",
            "        [0.2401, 0.1237, 0.2141, 0.2111, 0.2110]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2172, 0.1179, 0.2312, 0.2255, 0.2082],\n",
            "        [0.2345, 0.1211, 0.2207, 0.2118, 0.2120],\n",
            "        [0.2337, 0.1215, 0.2150, 0.2092, 0.2206],\n",
            "        [0.2352, 0.1174, 0.2181, 0.2129, 0.2164],\n",
            "        [0.2402, 0.1236, 0.2141, 0.2111, 0.2109]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2176, 0.1177, 0.2312, 0.2254, 0.2080],\n",
            "        [0.2349, 0.1210, 0.2206, 0.2117, 0.2118],\n",
            "        [0.2341, 0.1215, 0.2149, 0.2091, 0.2204],\n",
            "        [0.2357, 0.1173, 0.2181, 0.2129, 0.2160],\n",
            "        [0.2411, 0.1236, 0.2139, 0.2109, 0.2105]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2176, 0.1176, 0.2314, 0.2255, 0.2079],\n",
            "        [0.2352, 0.1209, 0.2206, 0.2117, 0.2117],\n",
            "        [0.2343, 0.1214, 0.2149, 0.2091, 0.2203],\n",
            "        [0.2359, 0.1171, 0.2182, 0.2130, 0.2158],\n",
            "        [0.2412, 0.1234, 0.2140, 0.2109, 0.2104]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2178, 0.1173, 0.2315, 0.2257, 0.2077],\n",
            "        [0.2355, 0.1207, 0.2207, 0.2118, 0.2114],\n",
            "        [0.2350, 0.1211, 0.2149, 0.2090, 0.2200],\n",
            "        [0.2369, 0.1168, 0.2179, 0.2127, 0.2156],\n",
            "        [0.2420, 0.1234, 0.2138, 0.2108, 0.2100]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2178, 0.1172, 0.2316, 0.2257, 0.2077],\n",
            "        [0.2356, 0.1206, 0.2207, 0.2117, 0.2115],\n",
            "        [0.2349, 0.1210, 0.2150, 0.2091, 0.2200],\n",
            "        [0.2368, 0.1167, 0.2181, 0.2129, 0.2155],\n",
            "        [0.2420, 0.1233, 0.2139, 0.2108, 0.2100]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2179, 0.1170, 0.2317, 0.2259, 0.2075],\n",
            "        [0.2360, 0.1205, 0.2206, 0.2117, 0.2113],\n",
            "        [0.2353, 0.1209, 0.2150, 0.2091, 0.2198],\n",
            "        [0.2371, 0.1167, 0.2180, 0.2128, 0.2153],\n",
            "        [0.2422, 0.1233, 0.2139, 0.2108, 0.2097]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2178, 0.1170, 0.2318, 0.2259, 0.2075],\n",
            "        [0.2359, 0.1205, 0.2207, 0.2117, 0.2112],\n",
            "        [0.2354, 0.1208, 0.2150, 0.2090, 0.2198],\n",
            "        [0.2372, 0.1166, 0.2181, 0.2129, 0.2152],\n",
            "        [0.2423, 0.1233, 0.2139, 0.2109, 0.2096]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2178, 0.1169, 0.2319, 0.2260, 0.2074],\n",
            "        [0.2361, 0.1203, 0.2207, 0.2117, 0.2111],\n",
            "        [0.2353, 0.1206, 0.2152, 0.2092, 0.2197],\n",
            "        [0.2373, 0.1163, 0.2183, 0.2130, 0.2151],\n",
            "        [0.2425, 0.1231, 0.2140, 0.2109, 0.2095]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2181, 0.1167, 0.2320, 0.2260, 0.2072],\n",
            "        [0.2363, 0.1202, 0.2208, 0.2117, 0.2110],\n",
            "        [0.2358, 0.1205, 0.2151, 0.2091, 0.2195],\n",
            "        [0.2378, 0.1163, 0.2182, 0.2129, 0.2148],\n",
            "        [0.2432, 0.1231, 0.2138, 0.2108, 0.2092]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2184, 0.1167, 0.2318, 0.2259, 0.2072],\n",
            "        [0.2364, 0.1201, 0.2209, 0.2118, 0.2109],\n",
            "        [0.2362, 0.1203, 0.2150, 0.2091, 0.2194],\n",
            "        [0.2384, 0.1161, 0.2181, 0.2128, 0.2146],\n",
            "        [0.2435, 0.1230, 0.2138, 0.2107, 0.2091]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2186, 0.1165, 0.2320, 0.2260, 0.2069],\n",
            "        [0.2371, 0.1201, 0.2206, 0.2116, 0.2106],\n",
            "        [0.2370, 0.1202, 0.2148, 0.2089, 0.2190],\n",
            "        [0.2389, 0.1161, 0.2181, 0.2128, 0.2142],\n",
            "        [0.2444, 0.1231, 0.2135, 0.2104, 0.2087]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2187, 0.1165, 0.2320, 0.2260, 0.2069],\n",
            "        [0.2371, 0.1200, 0.2207, 0.2116, 0.2106],\n",
            "        [0.2370, 0.1202, 0.2149, 0.2089, 0.2189],\n",
            "        [0.2392, 0.1159, 0.2180, 0.2127, 0.2141],\n",
            "        [0.2442, 0.1229, 0.2136, 0.2105, 0.2088]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2188, 0.1163, 0.2321, 0.2261, 0.2068],\n",
            "        [0.2373, 0.1198, 0.2207, 0.2116, 0.2106],\n",
            "        [0.2373, 0.1200, 0.2149, 0.2090, 0.2188],\n",
            "        [0.2395, 0.1158, 0.2181, 0.2128, 0.2139],\n",
            "        [0.2447, 0.1228, 0.2134, 0.2103, 0.2088]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2192, 0.1161, 0.2322, 0.2261, 0.2065],\n",
            "        [0.2377, 0.1198, 0.2207, 0.2116, 0.2103],\n",
            "        [0.2379, 0.1199, 0.2148, 0.2088, 0.2186],\n",
            "        [0.2399, 0.1157, 0.2181, 0.2128, 0.2135],\n",
            "        [0.2454, 0.1228, 0.2133, 0.2101, 0.2083]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2193, 0.1161, 0.2322, 0.2261, 0.2063],\n",
            "        [0.2380, 0.1196, 0.2207, 0.2115, 0.2102],\n",
            "        [0.2379, 0.1198, 0.2148, 0.2088, 0.2185],\n",
            "        [0.2402, 0.1157, 0.2181, 0.2127, 0.2134],\n",
            "        [0.2455, 0.1227, 0.2133, 0.2101, 0.2083]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2194, 0.1157, 0.2323, 0.2262, 0.2064],\n",
            "        [0.2382, 0.1192, 0.2208, 0.2115, 0.2102],\n",
            "        [0.2380, 0.1194, 0.2151, 0.2090, 0.2185],\n",
            "        [0.2406, 0.1154, 0.2181, 0.2127, 0.2133],\n",
            "        [0.2460, 0.1225, 0.2132, 0.2100, 0.2082]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2193, 0.1154, 0.2325, 0.2263, 0.2064],\n",
            "        [0.2386, 0.1192, 0.2207, 0.2115, 0.2100],\n",
            "        [0.2383, 0.1195, 0.2150, 0.2089, 0.2183],\n",
            "        [0.2410, 0.1154, 0.2180, 0.2127, 0.2129],\n",
            "        [0.2463, 0.1225, 0.2132, 0.2100, 0.2081]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2196, 0.1155, 0.2324, 0.2263, 0.2063],\n",
            "        [0.2388, 0.1190, 0.2208, 0.2116, 0.2098],\n",
            "        [0.2387, 0.1194, 0.2149, 0.2089, 0.2181],\n",
            "        [0.2414, 0.1152, 0.2179, 0.2126, 0.2129],\n",
            "        [0.2466, 0.1224, 0.2131, 0.2099, 0.2079]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2197, 0.1154, 0.2324, 0.2263, 0.2061],\n",
            "        [0.2389, 0.1189, 0.2209, 0.2116, 0.2097],\n",
            "        [0.2389, 0.1192, 0.2149, 0.2088, 0.2182],\n",
            "        [0.2414, 0.1150, 0.2182, 0.2128, 0.2127],\n",
            "        [0.2469, 0.1223, 0.2132, 0.2100, 0.2077]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2198, 0.1153, 0.2326, 0.2264, 0.2059],\n",
            "        [0.2395, 0.1188, 0.2207, 0.2114, 0.2096],\n",
            "        [0.2392, 0.1192, 0.2149, 0.2088, 0.2179],\n",
            "        [0.2418, 0.1149, 0.2180, 0.2126, 0.2126],\n",
            "        [0.2471, 0.1221, 0.2132, 0.2099, 0.2076]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2198, 0.1152, 0.2327, 0.2265, 0.2058],\n",
            "        [0.2395, 0.1187, 0.2208, 0.2115, 0.2095],\n",
            "        [0.2394, 0.1191, 0.2149, 0.2088, 0.2178],\n",
            "        [0.2420, 0.1148, 0.2181, 0.2127, 0.2124],\n",
            "        [0.2475, 0.1221, 0.2131, 0.2098, 0.2075]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2199, 0.1151, 0.2327, 0.2265, 0.2058],\n",
            "        [0.2396, 0.1185, 0.2209, 0.2116, 0.2094],\n",
            "        [0.2396, 0.1190, 0.2149, 0.2087, 0.2178],\n",
            "        [0.2421, 0.1147, 0.2181, 0.2126, 0.2125],\n",
            "        [0.2475, 0.1220, 0.2132, 0.2099, 0.2074]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2201, 0.1151, 0.2326, 0.2264, 0.2058],\n",
            "        [0.2396, 0.1184, 0.2210, 0.2116, 0.2094],\n",
            "        [0.2396, 0.1189, 0.2149, 0.2088, 0.2178],\n",
            "        [0.2421, 0.1146, 0.2182, 0.2128, 0.2122],\n",
            "        [0.2477, 0.1220, 0.2132, 0.2099, 0.2072]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2200, 0.1149, 0.2328, 0.2266, 0.2057],\n",
            "        [0.2397, 0.1183, 0.2210, 0.2116, 0.2094],\n",
            "        [0.2397, 0.1190, 0.2149, 0.2088, 0.2176],\n",
            "        [0.2425, 0.1148, 0.2182, 0.2127, 0.2118],\n",
            "        [0.2481, 0.1221, 0.2130, 0.2098, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2201, 0.1148, 0.2329, 0.2266, 0.2055],\n",
            "        [0.2401, 0.1184, 0.2208, 0.2115, 0.2092],\n",
            "        [0.2399, 0.1191, 0.2149, 0.2088, 0.2174],\n",
            "        [0.2430, 0.1147, 0.2181, 0.2127, 0.2116],\n",
            "        [0.2484, 0.1220, 0.2130, 0.2097, 0.2068]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2203, 0.1147, 0.2329, 0.2266, 0.2055],\n",
            "        [0.2403, 0.1183, 0.2209, 0.2116, 0.2090],\n",
            "        [0.2403, 0.1189, 0.2148, 0.2086, 0.2174],\n",
            "        [0.2431, 0.1146, 0.2182, 0.2127, 0.2114],\n",
            "        [0.2487, 0.1220, 0.2130, 0.2097, 0.2066]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2203, 0.1147, 0.2330, 0.2267, 0.2053],\n",
            "        [0.2406, 0.1183, 0.2208, 0.2114, 0.2089],\n",
            "        [0.2405, 0.1190, 0.2147, 0.2086, 0.2172],\n",
            "        [0.2434, 0.1145, 0.2181, 0.2126, 0.2114],\n",
            "        [0.2488, 0.1220, 0.2130, 0.2097, 0.2065]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2204, 0.1148, 0.2329, 0.2266, 0.2052],\n",
            "        [0.2405, 0.1182, 0.2209, 0.2115, 0.2088],\n",
            "        [0.2405, 0.1189, 0.2148, 0.2087, 0.2172],\n",
            "        [0.2433, 0.1145, 0.2183, 0.2128, 0.2111],\n",
            "        [0.2491, 0.1220, 0.2128, 0.2096, 0.2065]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2204, 0.1146, 0.2331, 0.2268, 0.2052],\n",
            "        [0.2405, 0.1181, 0.2210, 0.2116, 0.2087],\n",
            "        [0.2405, 0.1189, 0.2149, 0.2087, 0.2170],\n",
            "        [0.2434, 0.1146, 0.2184, 0.2129, 0.2107],\n",
            "        [0.2495, 0.1221, 0.2127, 0.2095, 0.2062]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2204, 0.1144, 0.2332, 0.2268, 0.2052],\n",
            "        [0.2406, 0.1180, 0.2211, 0.2116, 0.2087],\n",
            "        [0.2407, 0.1188, 0.2149, 0.2087, 0.2169],\n",
            "        [0.2436, 0.1144, 0.2183, 0.2128, 0.2110],\n",
            "        [0.2493, 0.1219, 0.2130, 0.2097, 0.2061]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2204, 0.1144, 0.2332, 0.2269, 0.2051],\n",
            "        [0.2407, 0.1180, 0.2210, 0.2116, 0.2086],\n",
            "        [0.2407, 0.1188, 0.2149, 0.2087, 0.2168],\n",
            "        [0.2439, 0.1144, 0.2182, 0.2127, 0.2108],\n",
            "        [0.2494, 0.1220, 0.2130, 0.2096, 0.2060]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2206, 0.1144, 0.2331, 0.2268, 0.2051],\n",
            "        [0.2408, 0.1178, 0.2211, 0.2117, 0.2085],\n",
            "        [0.2407, 0.1188, 0.2150, 0.2088, 0.2167],\n",
            "        [0.2442, 0.1145, 0.2181, 0.2126, 0.2107],\n",
            "        [0.2494, 0.1221, 0.2130, 0.2097, 0.2058]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2206, 0.1144, 0.2332, 0.2269, 0.2050],\n",
            "        [0.2409, 0.1179, 0.2211, 0.2117, 0.2083],\n",
            "        [0.2409, 0.1189, 0.2149, 0.2088, 0.2166],\n",
            "        [0.2444, 0.1145, 0.2181, 0.2127, 0.2103],\n",
            "        [0.2498, 0.1220, 0.2129, 0.2096, 0.2057]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2207, 0.1143, 0.2332, 0.2269, 0.2049],\n",
            "        [0.2411, 0.1179, 0.2210, 0.2116, 0.2083],\n",
            "        [0.2409, 0.1189, 0.2149, 0.2087, 0.2165],\n",
            "        [0.2446, 0.1144, 0.2181, 0.2126, 0.2102],\n",
            "        [0.2499, 0.1221, 0.2129, 0.2095, 0.2056]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2208, 0.1144, 0.2331, 0.2268, 0.2048],\n",
            "        [0.2411, 0.1181, 0.2210, 0.2116, 0.2082],\n",
            "        [0.2410, 0.1190, 0.2150, 0.2088, 0.2163],\n",
            "        [0.2449, 0.1146, 0.2180, 0.2125, 0.2099],\n",
            "        [0.2501, 0.1222, 0.2128, 0.2094, 0.2055]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2209, 0.1144, 0.2332, 0.2268, 0.2047],\n",
            "        [0.2415, 0.1181, 0.2209, 0.2114, 0.2081],\n",
            "        [0.2413, 0.1189, 0.2149, 0.2087, 0.2162],\n",
            "        [0.2454, 0.1146, 0.2179, 0.2124, 0.2097],\n",
            "        [0.2509, 0.1222, 0.2125, 0.2091, 0.2053]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2209, 0.1145, 0.2331, 0.2268, 0.2047],\n",
            "        [0.2413, 0.1181, 0.2210, 0.2115, 0.2080],\n",
            "        [0.2412, 0.1189, 0.2149, 0.2087, 0.2163],\n",
            "        [0.2451, 0.1146, 0.2181, 0.2126, 0.2096],\n",
            "        [0.2507, 0.1221, 0.2127, 0.2093, 0.2052]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2209, 0.1144, 0.2332, 0.2269, 0.2047],\n",
            "        [0.2416, 0.1180, 0.2209, 0.2115, 0.2080],\n",
            "        [0.2414, 0.1188, 0.2149, 0.2087, 0.2162],\n",
            "        [0.2453, 0.1144, 0.2181, 0.2125, 0.2096],\n",
            "        [0.2509, 0.1220, 0.2126, 0.2092, 0.2052]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2209, 0.1143, 0.2333, 0.2270, 0.2046],\n",
            "        [0.2416, 0.1179, 0.2210, 0.2115, 0.2080],\n",
            "        [0.2415, 0.1188, 0.2149, 0.2087, 0.2162],\n",
            "        [0.2453, 0.1143, 0.2182, 0.2127, 0.2095],\n",
            "        [0.2510, 0.1219, 0.2126, 0.2092, 0.2052]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2209, 0.1143, 0.2333, 0.2270, 0.2046],\n",
            "        [0.2417, 0.1179, 0.2209, 0.2115, 0.2079],\n",
            "        [0.2416, 0.1188, 0.2149, 0.2087, 0.2160],\n",
            "        [0.2455, 0.1143, 0.2181, 0.2126, 0.2094],\n",
            "        [0.2511, 0.1221, 0.2125, 0.2091, 0.2051]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2210, 0.1141, 0.2334, 0.2271, 0.2045],\n",
            "        [0.2419, 0.1178, 0.2209, 0.2115, 0.2078],\n",
            "        [0.2419, 0.1187, 0.2148, 0.2086, 0.2160],\n",
            "        [0.2457, 0.1143, 0.2182, 0.2126, 0.2092],\n",
            "        [0.2515, 0.1221, 0.2125, 0.2091, 0.2049]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2212, 0.1142, 0.2333, 0.2270, 0.2044],\n",
            "        [0.2420, 0.1180, 0.2209, 0.2114, 0.2078],\n",
            "        [0.2419, 0.1188, 0.2149, 0.2086, 0.2159],\n",
            "        [0.2458, 0.1144, 0.2181, 0.2126, 0.2091],\n",
            "        [0.2514, 0.1222, 0.2125, 0.2091, 0.2047]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2211, 0.1142, 0.2333, 0.2270, 0.2043],\n",
            "        [0.2421, 0.1179, 0.2209, 0.2115, 0.2076],\n",
            "        [0.2420, 0.1188, 0.2148, 0.2086, 0.2158],\n",
            "        [0.2460, 0.1144, 0.2181, 0.2125, 0.2090],\n",
            "        [0.2517, 0.1221, 0.2124, 0.2090, 0.2047]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2213, 0.1142, 0.2333, 0.2270, 0.2043],\n",
            "        [0.2422, 0.1180, 0.2208, 0.2114, 0.2075],\n",
            "        [0.2422, 0.1188, 0.2148, 0.2086, 0.2157],\n",
            "        [0.2461, 0.1144, 0.2180, 0.2125, 0.2090],\n",
            "        [0.2518, 0.1222, 0.2124, 0.2090, 0.2046]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2214, 0.1143, 0.2332, 0.2269, 0.2041],\n",
            "        [0.2423, 0.1180, 0.2208, 0.2114, 0.2074],\n",
            "        [0.2425, 0.1188, 0.2147, 0.2085, 0.2155],\n",
            "        [0.2464, 0.1145, 0.2180, 0.2124, 0.2088],\n",
            "        [0.2520, 0.1223, 0.2123, 0.2089, 0.2045]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2216, 0.1143, 0.2332, 0.2269, 0.2040],\n",
            "        [0.2425, 0.1181, 0.2208, 0.2114, 0.2073],\n",
            "        [0.2427, 0.1189, 0.2146, 0.2084, 0.2154],\n",
            "        [0.2465, 0.1145, 0.2180, 0.2125, 0.2085],\n",
            "        [0.2523, 0.1223, 0.2123, 0.2088, 0.2043]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2215, 0.1143, 0.2333, 0.2270, 0.2039],\n",
            "        [0.2426, 0.1181, 0.2207, 0.2113, 0.2073],\n",
            "        [0.2427, 0.1189, 0.2146, 0.2084, 0.2154],\n",
            "        [0.2465, 0.1145, 0.2180, 0.2125, 0.2085],\n",
            "        [0.2524, 0.1223, 0.2122, 0.2088, 0.2042]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2215, 0.1143, 0.2333, 0.2270, 0.2039],\n",
            "        [0.2427, 0.1181, 0.2207, 0.2113, 0.2072],\n",
            "        [0.2428, 0.1189, 0.2146, 0.2084, 0.2153],\n",
            "        [0.2467, 0.1146, 0.2179, 0.2124, 0.2084],\n",
            "        [0.2525, 0.1224, 0.2122, 0.2087, 0.2042]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2216, 0.1143, 0.2333, 0.2270, 0.2038],\n",
            "        [0.2429, 0.1181, 0.2206, 0.2112, 0.2071],\n",
            "        [0.2429, 0.1190, 0.2145, 0.2083, 0.2152],\n",
            "        [0.2468, 0.1146, 0.2179, 0.2123, 0.2083],\n",
            "        [0.2527, 0.1224, 0.2121, 0.2086, 0.2041]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2217, 0.1143, 0.2333, 0.2270, 0.2038],\n",
            "        [0.2432, 0.1182, 0.2205, 0.2111, 0.2070],\n",
            "        [0.2430, 0.1190, 0.2145, 0.2083, 0.2151],\n",
            "        [0.2470, 0.1146, 0.2179, 0.2123, 0.2082],\n",
            "        [0.2529, 0.1225, 0.2120, 0.2086, 0.2040]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2217, 0.1143, 0.2333, 0.2270, 0.2038],\n",
            "        [0.2432, 0.1181, 0.2205, 0.2111, 0.2070],\n",
            "        [0.2431, 0.1190, 0.2145, 0.2083, 0.2151],\n",
            "        [0.2470, 0.1146, 0.2179, 0.2124, 0.2081],\n",
            "        [0.2531, 0.1224, 0.2120, 0.2085, 0.2040]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2217, 0.1142, 0.2333, 0.2270, 0.2037],\n",
            "        [0.2433, 0.1181, 0.2205, 0.2111, 0.2069],\n",
            "        [0.2432, 0.1190, 0.2145, 0.2083, 0.2150],\n",
            "        [0.2472, 0.1146, 0.2179, 0.2123, 0.2081],\n",
            "        [0.2531, 0.1224, 0.2120, 0.2085, 0.2040]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2218, 0.1142, 0.2333, 0.2270, 0.2037],\n",
            "        [0.2434, 0.1181, 0.2206, 0.2112, 0.2068],\n",
            "        [0.2434, 0.1191, 0.2144, 0.2082, 0.2149],\n",
            "        [0.2474, 0.1146, 0.2178, 0.2122, 0.2080],\n",
            "        [0.2533, 0.1225, 0.2119, 0.2084, 0.2039]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2219, 0.1142, 0.2333, 0.2270, 0.2037],\n",
            "        [0.2435, 0.1181, 0.2205, 0.2112, 0.2066],\n",
            "        [0.2436, 0.1191, 0.2143, 0.2082, 0.2148],\n",
            "        [0.2476, 0.1146, 0.2177, 0.2122, 0.2079],\n",
            "        [0.2534, 0.1226, 0.2119, 0.2084, 0.2038]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2219, 0.1142, 0.2333, 0.2270, 0.2036],\n",
            "        [0.2437, 0.1181, 0.2205, 0.2111, 0.2066],\n",
            "        [0.2437, 0.1191, 0.2143, 0.2081, 0.2147],\n",
            "        [0.2477, 0.1146, 0.2177, 0.2121, 0.2078],\n",
            "        [0.2537, 0.1226, 0.2118, 0.2083, 0.2037]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2219, 0.1142, 0.2333, 0.2270, 0.2036],\n",
            "        [0.2437, 0.1181, 0.2205, 0.2111, 0.2066],\n",
            "        [0.2438, 0.1192, 0.2143, 0.2082, 0.2146],\n",
            "        [0.2478, 0.1146, 0.2177, 0.2121, 0.2077],\n",
            "        [0.2539, 0.1226, 0.2116, 0.2082, 0.2037]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2220, 0.1142, 0.2333, 0.2270, 0.2035],\n",
            "        [0.2437, 0.1182, 0.2205, 0.2111, 0.2065],\n",
            "        [0.2438, 0.1192, 0.2143, 0.2082, 0.2146],\n",
            "        [0.2478, 0.1147, 0.2177, 0.2121, 0.2076],\n",
            "        [0.2539, 0.1227, 0.2116, 0.2082, 0.2036]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2220, 0.1143, 0.2332, 0.2269, 0.2035],\n",
            "        [0.2437, 0.1182, 0.2205, 0.2111, 0.2064],\n",
            "        [0.2438, 0.1193, 0.2143, 0.2081, 0.2145],\n",
            "        [0.2478, 0.1147, 0.2177, 0.2122, 0.2076],\n",
            "        [0.2540, 0.1227, 0.2116, 0.2081, 0.2035]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2220, 0.1143, 0.2333, 0.2269, 0.2035],\n",
            "        [0.2437, 0.1182, 0.2205, 0.2111, 0.2064],\n",
            "        [0.2438, 0.1192, 0.2143, 0.2082, 0.2145],\n",
            "        [0.2478, 0.1147, 0.2177, 0.2122, 0.2076],\n",
            "        [0.2540, 0.1227, 0.2116, 0.2081, 0.2036]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2220, 0.1143, 0.2332, 0.2269, 0.2036],\n",
            "        [0.2437, 0.1183, 0.2205, 0.2111, 0.2064],\n",
            "        [0.2438, 0.1192, 0.2143, 0.2081, 0.2146],\n",
            "        [0.2478, 0.1147, 0.2177, 0.2122, 0.2075],\n",
            "        [0.2540, 0.1227, 0.2116, 0.2081, 0.2035]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2221, 0.1143, 0.2332, 0.2269, 0.2035],\n",
            "        [0.2437, 0.1183, 0.2205, 0.2111, 0.2064],\n",
            "        [0.2438, 0.1193, 0.2142, 0.2081, 0.2145],\n",
            "        [0.2479, 0.1148, 0.2177, 0.2122, 0.2075],\n",
            "        [0.2541, 0.1227, 0.2116, 0.2081, 0.2035]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2221, 0.1143, 0.2332, 0.2269, 0.2035],\n",
            "        [0.2438, 0.1183, 0.2205, 0.2111, 0.2064],\n",
            "        [0.2439, 0.1193, 0.2142, 0.2081, 0.2145],\n",
            "        [0.2479, 0.1148, 0.2177, 0.2122, 0.2074],\n",
            "        [0.2541, 0.1227, 0.2116, 0.2081, 0.2034]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2221, 0.1143, 0.2332, 0.2269, 0.2035],\n",
            "        [0.2438, 0.1183, 0.2204, 0.2111, 0.2063],\n",
            "        [0.2439, 0.1193, 0.2142, 0.2081, 0.2145],\n",
            "        [0.2480, 0.1148, 0.2177, 0.2122, 0.2074],\n",
            "        [0.2541, 0.1227, 0.2116, 0.2081, 0.2034]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2221, 0.1143, 0.2332, 0.2269, 0.2035],\n",
            "        [0.2438, 0.1183, 0.2204, 0.2111, 0.2063],\n",
            "        [0.2439, 0.1193, 0.2142, 0.2081, 0.2145],\n",
            "        [0.2480, 0.1148, 0.2177, 0.2121, 0.2074],\n",
            "        [0.2541, 0.1227, 0.2116, 0.2081, 0.2034]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)], 'cell_netG_B': [tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2003, 0.1986, 0.2004, 0.2004, 0.2003],\n",
            "        [0.2005, 0.1979, 0.2004, 0.2003, 0.2010],\n",
            "        [0.2005, 0.1981, 0.2005, 0.2004, 0.2005],\n",
            "        [0.2004, 0.1980, 0.2005, 0.2004, 0.2007],\n",
            "        [0.2004, 0.1980, 0.2004, 0.2004, 0.2008]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2006, 0.1974, 0.2008, 0.2007, 0.2005],\n",
            "        [0.2007, 0.1966, 0.2007, 0.2005, 0.2015],\n",
            "        [0.2009, 0.1967, 0.2009, 0.2008, 0.2007],\n",
            "        [0.2006, 0.1964, 0.2009, 0.2008, 0.2012],\n",
            "        [0.2007, 0.1965, 0.2009, 0.2009, 0.2010]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2008, 0.1962, 0.2012, 0.2010, 0.2008],\n",
            "        [0.2010, 0.1947, 0.2013, 0.2010, 0.2020],\n",
            "        [0.2016, 0.1949, 0.2013, 0.2011, 0.2011],\n",
            "        [0.2010, 0.1944, 0.2014, 0.2012, 0.2019],\n",
            "        [0.2011, 0.1947, 0.2014, 0.2013, 0.2014]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2012, 0.1949, 0.2015, 0.2013, 0.2011],\n",
            "        [0.2014, 0.1928, 0.2017, 0.2014, 0.2027],\n",
            "        [0.2024, 0.1931, 0.2016, 0.2014, 0.2014],\n",
            "        [0.2017, 0.1923, 0.2018, 0.2016, 0.2026],\n",
            "        [0.2017, 0.1925, 0.2020, 0.2019, 0.2019]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2017, 0.1927, 0.2020, 0.2018, 0.2018],\n",
            "        [0.2019, 0.1902, 0.2022, 0.2018, 0.2039],\n",
            "        [0.2029, 0.1906, 0.2022, 0.2019, 0.2023],\n",
            "        [0.2013, 0.1897, 0.2028, 0.2024, 0.2038],\n",
            "        [0.2020, 0.1898, 0.2028, 0.2026, 0.2027]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2025, 0.1915, 0.2023, 0.2020, 0.2018],\n",
            "        [0.2026, 0.1885, 0.2027, 0.2021, 0.2041],\n",
            "        [0.2037, 0.1890, 0.2027, 0.2023, 0.2022],\n",
            "        [0.2023, 0.1878, 0.2031, 0.2027, 0.2042],\n",
            "        [0.2030, 0.1881, 0.2032, 0.2029, 0.2028]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2026, 0.1904, 0.2026, 0.2023, 0.2021],\n",
            "        [0.2027, 0.1868, 0.2032, 0.2026, 0.2046],\n",
            "        [0.2043, 0.1876, 0.2030, 0.2026, 0.2025],\n",
            "        [0.2024, 0.1863, 0.2036, 0.2031, 0.2047],\n",
            "        [0.2032, 0.1866, 0.2037, 0.2034, 0.2031]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2030, 0.1896, 0.2028, 0.2025, 0.2022],\n",
            "        [0.2032, 0.1856, 0.2035, 0.2028, 0.2049],\n",
            "        [0.2048, 0.1862, 0.2034, 0.2029, 0.2026],\n",
            "        [0.2028, 0.1847, 0.2040, 0.2034, 0.2051],\n",
            "        [0.2038, 0.1852, 0.2041, 0.2037, 0.2032]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2031, 0.1884, 0.2032, 0.2028, 0.2024],\n",
            "        [0.2037, 0.1842, 0.2038, 0.2031, 0.2052],\n",
            "        [0.2054, 0.1852, 0.2036, 0.2031, 0.2028],\n",
            "        [0.2030, 0.1837, 0.2043, 0.2037, 0.2054],\n",
            "        [0.2042, 0.1841, 0.2043, 0.2040, 0.2035]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2034, 0.1868, 0.2037, 0.2033, 0.2028],\n",
            "        [0.2041, 0.1824, 0.2045, 0.2036, 0.2055],\n",
            "        [0.2065, 0.1834, 0.2039, 0.2033, 0.2028],\n",
            "        [0.2037, 0.1818, 0.2046, 0.2039, 0.2060],\n",
            "        [0.2051, 0.1823, 0.2046, 0.2042, 0.2038]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2036, 0.1859, 0.2040, 0.2035, 0.2029],\n",
            "        [0.2046, 0.1811, 0.2047, 0.2038, 0.2059],\n",
            "        [0.2072, 0.1823, 0.2041, 0.2035, 0.2029],\n",
            "        [0.2042, 0.1805, 0.2048, 0.2041, 0.2063],\n",
            "        [0.2058, 0.1810, 0.2049, 0.2044, 0.2039]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2041, 0.1851, 0.2041, 0.2036, 0.2030],\n",
            "        [0.2052, 0.1800, 0.2048, 0.2038, 0.2062],\n",
            "        [0.2079, 0.1811, 0.2044, 0.2036, 0.2030],\n",
            "        [0.2047, 0.1792, 0.2051, 0.2044, 0.2066],\n",
            "        [0.2066, 0.1800, 0.2049, 0.2044, 0.2040]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2045, 0.1842, 0.2044, 0.2038, 0.2031],\n",
            "        [0.2058, 0.1788, 0.2050, 0.2039, 0.2065],\n",
            "        [0.2085, 0.1799, 0.2047, 0.2039, 0.2031],\n",
            "        [0.2053, 0.1777, 0.2053, 0.2045, 0.2072],\n",
            "        [0.2072, 0.1786, 0.2053, 0.2047, 0.2042]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2047, 0.1833, 0.2047, 0.2041, 0.2032],\n",
            "        [0.2058, 0.1775, 0.2055, 0.2043, 0.2069],\n",
            "        [0.2088, 0.1786, 0.2051, 0.2042, 0.2033],\n",
            "        [0.2053, 0.1762, 0.2059, 0.2050, 0.2077],\n",
            "        [0.2072, 0.1774, 0.2058, 0.2051, 0.2044]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2052, 0.1826, 0.2049, 0.2042, 0.2031],\n",
            "        [0.2065, 0.1766, 0.2055, 0.2043, 0.2070],\n",
            "        [0.2096, 0.1777, 0.2052, 0.2043, 0.2032],\n",
            "        [0.2058, 0.1752, 0.2061, 0.2052, 0.2077],\n",
            "        [0.2082, 0.1766, 0.2058, 0.2050, 0.2044]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2051, 0.1813, 0.2054, 0.2047, 0.2035],\n",
            "        [0.2068, 0.1750, 0.2060, 0.2047, 0.2074],\n",
            "        [0.2102, 0.1762, 0.2056, 0.2046, 0.2035],\n",
            "        [0.2061, 0.1735, 0.2066, 0.2055, 0.2083],\n",
            "        [0.2087, 0.1751, 0.2062, 0.2054, 0.2047]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2056, 0.1800, 0.2057, 0.2049, 0.2038],\n",
            "        [0.2072, 0.1732, 0.2065, 0.2051, 0.2080],\n",
            "        [0.2108, 0.1747, 0.2060, 0.2049, 0.2036],\n",
            "        [0.2066, 0.1719, 0.2069, 0.2058, 0.2088],\n",
            "        [0.2093, 0.1736, 0.2065, 0.2057, 0.2049]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2058, 0.1790, 0.2061, 0.2053, 0.2039],\n",
            "        [0.2077, 0.1719, 0.2067, 0.2053, 0.2084],\n",
            "        [0.2112, 0.1735, 0.2064, 0.2052, 0.2036],\n",
            "        [0.2071, 0.1704, 0.2071, 0.2060, 0.2093],\n",
            "        [0.2096, 0.1724, 0.2069, 0.2060, 0.2051]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2062, 0.1780, 0.2063, 0.2055, 0.2041],\n",
            "        [0.2080, 0.1711, 0.2069, 0.2054, 0.2086],\n",
            "        [0.2118, 0.1726, 0.2066, 0.2054, 0.2037],\n",
            "        [0.2072, 0.1694, 0.2075, 0.2063, 0.2096],\n",
            "        [0.2100, 0.1715, 0.2072, 0.2062, 0.2051]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2070, 0.1775, 0.2062, 0.2054, 0.2039],\n",
            "        [0.2090, 0.1704, 0.2068, 0.2053, 0.2085],\n",
            "        [0.2131, 0.1718, 0.2064, 0.2051, 0.2036],\n",
            "        [0.2079, 0.1685, 0.2076, 0.2063, 0.2096],\n",
            "        [0.2113, 0.1707, 0.2070, 0.2060, 0.2051]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2073, 0.1762, 0.2067, 0.2057, 0.2041],\n",
            "        [0.2094, 0.1687, 0.2073, 0.2056, 0.2090],\n",
            "        [0.2136, 0.1704, 0.2069, 0.2056, 0.2035],\n",
            "        [0.2086, 0.1666, 0.2080, 0.2066, 0.2101],\n",
            "        [0.2114, 0.1692, 0.2075, 0.2065, 0.2054]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2074, 0.1753, 0.2070, 0.2060, 0.2042],\n",
            "        [0.2098, 0.1678, 0.2075, 0.2057, 0.2092],\n",
            "        [0.2143, 0.1694, 0.2071, 0.2057, 0.2035],\n",
            "        [0.2091, 0.1657, 0.2082, 0.2068, 0.2102],\n",
            "        [0.2122, 0.1682, 0.2076, 0.2065, 0.2054]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2078, 0.1745, 0.2072, 0.2062, 0.2043],\n",
            "        [0.2101, 0.1667, 0.2077, 0.2059, 0.2096],\n",
            "        [0.2149, 0.1686, 0.2073, 0.2058, 0.2035],\n",
            "        [0.2096, 0.1646, 0.2084, 0.2069, 0.2105],\n",
            "        [0.2131, 0.1673, 0.2076, 0.2064, 0.2056]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2084, 0.1737, 0.2073, 0.2063, 0.2044],\n",
            "        [0.2112, 0.1657, 0.2076, 0.2058, 0.2097],\n",
            "        [0.2158, 0.1677, 0.2072, 0.2057, 0.2035],\n",
            "        [0.2101, 0.1634, 0.2087, 0.2072, 0.2107],\n",
            "        [0.2138, 0.1663, 0.2078, 0.2066, 0.2055]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2087, 0.1724, 0.2077, 0.2066, 0.2046],\n",
            "        [0.2114, 0.1639, 0.2082, 0.2062, 0.2102],\n",
            "        [0.2163, 0.1658, 0.2080, 0.2063, 0.2036],\n",
            "        [0.2107, 0.1612, 0.2092, 0.2076, 0.2113],\n",
            "        [0.2147, 0.1643, 0.2082, 0.2069, 0.2059]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2087, 0.1717, 0.2080, 0.2068, 0.2047],\n",
            "        [0.2120, 0.1629, 0.2083, 0.2063, 0.2105],\n",
            "        [0.2167, 0.1652, 0.2081, 0.2064, 0.2036],\n",
            "        [0.2111, 0.1602, 0.2094, 0.2077, 0.2116],\n",
            "        [0.2151, 0.1635, 0.2084, 0.2070, 0.2060]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2092, 0.1708, 0.2082, 0.2070, 0.2047],\n",
            "        [0.2128, 0.1619, 0.2083, 0.2062, 0.2108],\n",
            "        [0.2173, 0.1643, 0.2084, 0.2066, 0.2034],\n",
            "        [0.2118, 0.1589, 0.2097, 0.2079, 0.2118],\n",
            "        [0.2160, 0.1627, 0.2084, 0.2070, 0.2059]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2096, 0.1696, 0.2086, 0.2074, 0.2048],\n",
            "        [0.2135, 0.1606, 0.2085, 0.2063, 0.2111],\n",
            "        [0.2180, 0.1630, 0.2088, 0.2069, 0.2033],\n",
            "        [0.2124, 0.1574, 0.2099, 0.2081, 0.2122],\n",
            "        [0.2171, 0.1613, 0.2086, 0.2071, 0.2059]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2097, 0.1689, 0.2090, 0.2076, 0.2048],\n",
            "        [0.2141, 0.1597, 0.2086, 0.2063, 0.2112],\n",
            "        [0.2187, 0.1622, 0.2090, 0.2069, 0.2032],\n",
            "        [0.2131, 0.1563, 0.2100, 0.2081, 0.2125],\n",
            "        [0.2177, 0.1606, 0.2087, 0.2071, 0.2060]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2103, 0.1682, 0.2090, 0.2077, 0.2048],\n",
            "        [0.2148, 0.1589, 0.2087, 0.2064, 0.2111],\n",
            "        [0.2196, 0.1615, 0.2090, 0.2068, 0.2030],\n",
            "        [0.2137, 0.1553, 0.2102, 0.2082, 0.2126],\n",
            "        [0.2187, 0.1599, 0.2086, 0.2069, 0.2059]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2104, 0.1673, 0.2094, 0.2080, 0.2049],\n",
            "        [0.2155, 0.1579, 0.2088, 0.2064, 0.2114],\n",
            "        [0.2199, 0.1606, 0.2094, 0.2071, 0.2030],\n",
            "        [0.2141, 0.1541, 0.2104, 0.2084, 0.2130],\n",
            "        [0.2187, 0.1587, 0.2092, 0.2074, 0.2060]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2105, 0.1666, 0.2097, 0.2082, 0.2050],\n",
            "        [0.2158, 0.1568, 0.2090, 0.2066, 0.2118],\n",
            "        [0.2203, 0.1596, 0.2097, 0.2074, 0.2030],\n",
            "        [0.2146, 0.1529, 0.2106, 0.2086, 0.2133],\n",
            "        [0.2194, 0.1578, 0.2092, 0.2075, 0.2061]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2107, 0.1656, 0.2099, 0.2085, 0.2052],\n",
            "        [0.2161, 0.1557, 0.2093, 0.2068, 0.2122],\n",
            "        [0.2209, 0.1585, 0.2100, 0.2076, 0.2030],\n",
            "        [0.2148, 0.1517, 0.2110, 0.2089, 0.2137],\n",
            "        [0.2200, 0.1566, 0.2095, 0.2077, 0.2062]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2108, 0.1650, 0.2103, 0.2087, 0.2053],\n",
            "        [0.2165, 0.1547, 0.2094, 0.2068, 0.2126],\n",
            "        [0.2210, 0.1579, 0.2103, 0.2078, 0.2030],\n",
            "        [0.2151, 0.1504, 0.2113, 0.2090, 0.2142],\n",
            "        [0.2203, 0.1556, 0.2099, 0.2079, 0.2063]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2110, 0.1636, 0.2107, 0.2091, 0.2056],\n",
            "        [0.2168, 0.1530, 0.2098, 0.2072, 0.2132],\n",
            "        [0.2218, 0.1564, 0.2105, 0.2080, 0.2033],\n",
            "        [0.2155, 0.1487, 0.2116, 0.2093, 0.2149],\n",
            "        [0.2209, 0.1543, 0.2100, 0.2081, 0.2068]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2114, 0.1631, 0.2108, 0.2092, 0.2054],\n",
            "        [0.2175, 0.1524, 0.2098, 0.2071, 0.2131],\n",
            "        [0.2222, 0.1558, 0.2108, 0.2082, 0.2030],\n",
            "        [0.2162, 0.1479, 0.2117, 0.2094, 0.2149],\n",
            "        [0.2215, 0.1538, 0.2100, 0.2080, 0.2066]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2114, 0.1619, 0.2113, 0.2096, 0.2058],\n",
            "        [0.2176, 0.1510, 0.2102, 0.2074, 0.2138],\n",
            "        [0.2229, 0.1545, 0.2111, 0.2084, 0.2032],\n",
            "        [0.2165, 0.1464, 0.2121, 0.2096, 0.2155],\n",
            "        [0.2221, 0.1525, 0.2103, 0.2082, 0.2069]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2120, 0.1608, 0.2116, 0.2098, 0.2058],\n",
            "        [0.2181, 0.1501, 0.2104, 0.2075, 0.2139],\n",
            "        [0.2235, 0.1539, 0.2112, 0.2084, 0.2030],\n",
            "        [0.2173, 0.1453, 0.2122, 0.2097, 0.2155],\n",
            "        [0.2228, 0.1518, 0.2105, 0.2083, 0.2067]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2123, 0.1604, 0.2117, 0.2099, 0.2057],\n",
            "        [0.2189, 0.1495, 0.2103, 0.2074, 0.2139],\n",
            "        [0.2243, 0.1532, 0.2112, 0.2084, 0.2029],\n",
            "        [0.2182, 0.1444, 0.2121, 0.2096, 0.2156],\n",
            "        [0.2237, 0.1510, 0.2104, 0.2082, 0.2067]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2126, 0.1597, 0.2119, 0.2101, 0.2057],\n",
            "        [0.2196, 0.1486, 0.2104, 0.2074, 0.2139],\n",
            "        [0.2251, 0.1525, 0.2113, 0.2084, 0.2028],\n",
            "        [0.2190, 0.1433, 0.2123, 0.2097, 0.2157],\n",
            "        [0.2246, 0.1502, 0.2104, 0.2081, 0.2067]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2126, 0.1590, 0.2122, 0.2103, 0.2059],\n",
            "        [0.2198, 0.1480, 0.2106, 0.2076, 0.2140],\n",
            "        [0.2254, 0.1518, 0.2115, 0.2085, 0.2028],\n",
            "        [0.2190, 0.1425, 0.2127, 0.2100, 0.2158],\n",
            "        [0.2252, 0.1496, 0.2103, 0.2081, 0.2067]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2128, 0.1583, 0.2125, 0.2105, 0.2059],\n",
            "        [0.2208, 0.1470, 0.2105, 0.2074, 0.2142],\n",
            "        [0.2261, 0.1509, 0.2117, 0.2086, 0.2027],\n",
            "        [0.2198, 0.1413, 0.2127, 0.2100, 0.2162],\n",
            "        [0.2257, 0.1487, 0.2105, 0.2082, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2132, 0.1574, 0.2128, 0.2108, 0.2058],\n",
            "        [0.2208, 0.1461, 0.2111, 0.2078, 0.2142],\n",
            "        [0.2267, 0.1501, 0.2119, 0.2087, 0.2026],\n",
            "        [0.2203, 0.1402, 0.2129, 0.2101, 0.2164],\n",
            "        [0.2259, 0.1478, 0.2109, 0.2085, 0.2068]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2135, 0.1563, 0.2132, 0.2111, 0.2059],\n",
            "        [0.2211, 0.1448, 0.2114, 0.2081, 0.2146],\n",
            "        [0.2272, 0.1488, 0.2123, 0.2091, 0.2026],\n",
            "        [0.2207, 0.1389, 0.2133, 0.2103, 0.2168],\n",
            "        [0.2266, 0.1465, 0.2111, 0.2087, 0.2071]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2138, 0.1551, 0.2136, 0.2114, 0.2061],\n",
            "        [0.2215, 0.1434, 0.2118, 0.2083, 0.2150],\n",
            "        [0.2275, 0.1477, 0.2128, 0.2094, 0.2025],\n",
            "        [0.2215, 0.1373, 0.2135, 0.2105, 0.2172],\n",
            "        [0.2273, 0.1454, 0.2114, 0.2088, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2140, 0.1546, 0.2138, 0.2116, 0.2061],\n",
            "        [0.2221, 0.1426, 0.2118, 0.2084, 0.2150],\n",
            "        [0.2282, 0.1471, 0.2128, 0.2094, 0.2025],\n",
            "        [0.2218, 0.1366, 0.2138, 0.2107, 0.2172],\n",
            "        [0.2281, 0.1448, 0.2113, 0.2087, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2144, 0.1540, 0.2139, 0.2116, 0.2060],\n",
            "        [0.2225, 0.1422, 0.2119, 0.2083, 0.2150],\n",
            "        [0.2285, 0.1467, 0.2130, 0.2095, 0.2023],\n",
            "        [0.2224, 0.1360, 0.2137, 0.2106, 0.2173],\n",
            "        [0.2286, 0.1442, 0.2115, 0.2088, 0.2068]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2145, 0.1535, 0.2142, 0.2119, 0.2060],\n",
            "        [0.2233, 0.1414, 0.2118, 0.2082, 0.2153],\n",
            "        [0.2290, 0.1459, 0.2131, 0.2096, 0.2024],\n",
            "        [0.2225, 0.1351, 0.2141, 0.2109, 0.2173],\n",
            "        [0.2293, 0.1435, 0.2115, 0.2087, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2144, 0.1525, 0.2147, 0.2123, 0.2061],\n",
            "        [0.2231, 0.1405, 0.2123, 0.2086, 0.2155],\n",
            "        [0.2292, 0.1452, 0.2135, 0.2098, 0.2024],\n",
            "        [0.2229, 0.1342, 0.2144, 0.2111, 0.2175],\n",
            "        [0.2295, 0.1429, 0.2117, 0.2089, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2150, 0.1514, 0.2150, 0.2125, 0.2061],\n",
            "        [0.2232, 0.1393, 0.2128, 0.2090, 0.2158],\n",
            "        [0.2298, 0.1441, 0.2138, 0.2101, 0.2023],\n",
            "        [0.2233, 0.1326, 0.2149, 0.2114, 0.2178],\n",
            "        [0.2303, 0.1419, 0.2119, 0.2089, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2151, 0.1513, 0.2150, 0.2125, 0.2060],\n",
            "        [0.2242, 0.1389, 0.2125, 0.2087, 0.2158],\n",
            "        [0.2303, 0.1437, 0.2138, 0.2100, 0.2023],\n",
            "        [0.2238, 0.1320, 0.2149, 0.2114, 0.2180],\n",
            "        [0.2310, 0.1414, 0.2117, 0.2088, 0.2071]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2154, 0.1507, 0.2153, 0.2127, 0.2059],\n",
            "        [0.2242, 0.1384, 0.2127, 0.2088, 0.2159],\n",
            "        [0.2306, 0.1432, 0.2140, 0.2101, 0.2021],\n",
            "        [0.2243, 0.1313, 0.2150, 0.2115, 0.2178],\n",
            "        [0.2314, 0.1409, 0.2118, 0.2088, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2153, 0.1504, 0.2154, 0.2129, 0.2061],\n",
            "        [0.2246, 0.1378, 0.2126, 0.2087, 0.2162],\n",
            "        [0.2307, 0.1426, 0.2141, 0.2103, 0.2023],\n",
            "        [0.2243, 0.1308, 0.2152, 0.2117, 0.2180],\n",
            "        [0.2320, 0.1404, 0.2116, 0.2087, 0.2073]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2154, 0.1496, 0.2158, 0.2132, 0.2060],\n",
            "        [0.2251, 0.1369, 0.2129, 0.2090, 0.2162],\n",
            "        [0.2313, 0.1420, 0.2143, 0.2104, 0.2021],\n",
            "        [0.2250, 0.1298, 0.2152, 0.2116, 0.2183],\n",
            "        [0.2322, 0.1398, 0.2120, 0.2089, 0.2072]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2157, 0.1493, 0.2158, 0.2132, 0.2060],\n",
            "        [0.2249, 0.1363, 0.2133, 0.2093, 0.2162],\n",
            "        [0.2315, 0.1414, 0.2146, 0.2106, 0.2020],\n",
            "        [0.2253, 0.1290, 0.2155, 0.2119, 0.2183],\n",
            "        [0.2325, 0.1391, 0.2122, 0.2091, 0.2071]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2159, 0.1491, 0.2159, 0.2132, 0.2059],\n",
            "        [0.2254, 0.1360, 0.2131, 0.2091, 0.2164],\n",
            "        [0.2317, 0.1411, 0.2147, 0.2106, 0.2019],\n",
            "        [0.2256, 0.1286, 0.2156, 0.2119, 0.2182],\n",
            "        [0.2330, 0.1388, 0.2121, 0.2089, 0.2072]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2155, 0.1479, 0.2165, 0.2138, 0.2063],\n",
            "        [0.2253, 0.1346, 0.2136, 0.2095, 0.2171],\n",
            "        [0.2318, 0.1398, 0.2152, 0.2111, 0.2022],\n",
            "        [0.2255, 0.1272, 0.2160, 0.2123, 0.2190],\n",
            "        [0.2331, 0.1374, 0.2123, 0.2092, 0.2079]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2155, 0.1473, 0.2168, 0.2141, 0.2064],\n",
            "        [0.2258, 0.1337, 0.2137, 0.2096, 0.2173],\n",
            "        [0.2322, 0.1391, 0.2153, 0.2112, 0.2022],\n",
            "        [0.2262, 0.1265, 0.2160, 0.2122, 0.2191],\n",
            "        [0.2339, 0.1365, 0.2125, 0.2093, 0.2078]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2160, 0.1470, 0.2168, 0.2140, 0.2062],\n",
            "        [0.2261, 0.1337, 0.2138, 0.2096, 0.2168],\n",
            "        [0.2331, 0.1388, 0.2151, 0.2110, 0.2020],\n",
            "        [0.2265, 0.1261, 0.2163, 0.2124, 0.2187],\n",
            "        [0.2348, 0.1361, 0.2124, 0.2092, 0.2075]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2166, 0.1466, 0.2168, 0.2140, 0.2059],\n",
            "        [0.2268, 0.1335, 0.2137, 0.2094, 0.2166],\n",
            "        [0.2336, 0.1388, 0.2151, 0.2109, 0.2017],\n",
            "        [0.2273, 0.1260, 0.2161, 0.2121, 0.2185],\n",
            "        [0.2356, 0.1360, 0.2124, 0.2090, 0.2071]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2170, 0.1463, 0.2169, 0.2140, 0.2058],\n",
            "        [0.2272, 0.1332, 0.2137, 0.2094, 0.2166],\n",
            "        [0.2340, 0.1385, 0.2151, 0.2108, 0.2016],\n",
            "        [0.2277, 0.1256, 0.2161, 0.2121, 0.2184],\n",
            "        [0.2360, 0.1358, 0.2124, 0.2090, 0.2068]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2169, 0.1463, 0.2170, 0.2141, 0.2057],\n",
            "        [0.2280, 0.1329, 0.2134, 0.2092, 0.2165],\n",
            "        [0.2342, 0.1384, 0.2151, 0.2108, 0.2015],\n",
            "        [0.2281, 0.1253, 0.2162, 0.2121, 0.2183],\n",
            "        [0.2363, 0.1356, 0.2123, 0.2089, 0.2069]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2166, 0.1456, 0.2174, 0.2145, 0.2060],\n",
            "        [0.2277, 0.1322, 0.2138, 0.2095, 0.2167],\n",
            "        [0.2346, 0.1377, 0.2152, 0.2109, 0.2016],\n",
            "        [0.2280, 0.1249, 0.2164, 0.2124, 0.2183],\n",
            "        [0.2369, 0.1349, 0.2122, 0.2088, 0.2071]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2171, 0.1450, 0.2175, 0.2146, 0.2058],\n",
            "        [0.2281, 0.1313, 0.2140, 0.2096, 0.2170],\n",
            "        [0.2346, 0.1370, 0.2157, 0.2113, 0.2015],\n",
            "        [0.2283, 0.1240, 0.2167, 0.2126, 0.2185],\n",
            "        [0.2371, 0.1344, 0.2126, 0.2090, 0.2068]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2170, 0.1445, 0.2178, 0.2148, 0.2059],\n",
            "        [0.2282, 0.1306, 0.2143, 0.2098, 0.2171],\n",
            "        [0.2348, 0.1366, 0.2158, 0.2113, 0.2014],\n",
            "        [0.2286, 0.1234, 0.2168, 0.2126, 0.2185],\n",
            "        [0.2374, 0.1339, 0.2127, 0.2091, 0.2069]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2173, 0.1443, 0.2177, 0.2148, 0.2059],\n",
            "        [0.2287, 0.1304, 0.2142, 0.2098, 0.2169],\n",
            "        [0.2353, 0.1363, 0.2156, 0.2112, 0.2015],\n",
            "        [0.2289, 0.1231, 0.2168, 0.2126, 0.2186],\n",
            "        [0.2378, 0.1335, 0.2126, 0.2091, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2176, 0.1440, 0.2179, 0.2149, 0.2058],\n",
            "        [0.2291, 0.1301, 0.2142, 0.2097, 0.2168],\n",
            "        [0.2357, 0.1359, 0.2157, 0.2112, 0.2015],\n",
            "        [0.2289, 0.1227, 0.2171, 0.2128, 0.2185],\n",
            "        [0.2381, 0.1329, 0.2128, 0.2092, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2174, 0.1436, 0.2181, 0.2151, 0.2058],\n",
            "        [0.2292, 0.1293, 0.2145, 0.2099, 0.2170],\n",
            "        [0.2356, 0.1352, 0.2162, 0.2116, 0.2014],\n",
            "        [0.2293, 0.1219, 0.2172, 0.2129, 0.2186],\n",
            "        [0.2386, 0.1322, 0.2127, 0.2091, 0.2073]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2172, 0.1429, 0.2185, 0.2154, 0.2061],\n",
            "        [0.2293, 0.1287, 0.2147, 0.2101, 0.2172],\n",
            "        [0.2359, 0.1347, 0.2162, 0.2117, 0.2015],\n",
            "        [0.2295, 0.1214, 0.2172, 0.2129, 0.2189],\n",
            "        [0.2391, 0.1317, 0.2127, 0.2091, 0.2074]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2174, 0.1427, 0.2185, 0.2155, 0.2059],\n",
            "        [0.2297, 0.1286, 0.2147, 0.2101, 0.2169],\n",
            "        [0.2365, 0.1345, 0.2161, 0.2116, 0.2013],\n",
            "        [0.2300, 0.1213, 0.2173, 0.2129, 0.2185],\n",
            "        [0.2398, 0.1315, 0.2126, 0.2090, 0.2071]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2181, 0.1423, 0.2185, 0.2154, 0.2057],\n",
            "        [0.2302, 0.1283, 0.2146, 0.2100, 0.2169],\n",
            "        [0.2367, 0.1343, 0.2163, 0.2117, 0.2010],\n",
            "        [0.2308, 0.1208, 0.2172, 0.2127, 0.2185],\n",
            "        [0.2402, 0.1312, 0.2128, 0.2090, 0.2068]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2182, 0.1421, 0.2186, 0.2155, 0.2056],\n",
            "        [0.2305, 0.1278, 0.2147, 0.2101, 0.2170],\n",
            "        [0.2369, 0.1341, 0.2163, 0.2117, 0.2010],\n",
            "        [0.2310, 0.1205, 0.2173, 0.2128, 0.2184],\n",
            "        [0.2406, 0.1307, 0.2128, 0.2091, 0.2068]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2184, 0.1418, 0.2186, 0.2155, 0.2057],\n",
            "        [0.2305, 0.1275, 0.2149, 0.2102, 0.2169],\n",
            "        [0.2372, 0.1336, 0.2164, 0.2117, 0.2011],\n",
            "        [0.2312, 0.1200, 0.2174, 0.2129, 0.2185],\n",
            "        [0.2411, 0.1304, 0.2127, 0.2090, 0.2069]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2182, 0.1416, 0.2188, 0.2157, 0.2057],\n",
            "        [0.2307, 0.1272, 0.2149, 0.2102, 0.2169],\n",
            "        [0.2377, 0.1332, 0.2163, 0.2116, 0.2011],\n",
            "        [0.2314, 0.1197, 0.2175, 0.2129, 0.2185],\n",
            "        [0.2415, 0.1300, 0.2127, 0.2089, 0.2070]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2185, 0.1413, 0.2190, 0.2157, 0.2055],\n",
            "        [0.2314, 0.1269, 0.2148, 0.2100, 0.2169],\n",
            "        [0.2380, 0.1329, 0.2166, 0.2117, 0.2009],\n",
            "        [0.2322, 0.1193, 0.2173, 0.2127, 0.2185],\n",
            "        [0.2417, 0.1298, 0.2129, 0.2090, 0.2067]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2186, 0.1410, 0.2191, 0.2158, 0.2055],\n",
            "        [0.2314, 0.1263, 0.2151, 0.2102, 0.2170],\n",
            "        [0.2380, 0.1325, 0.2167, 0.2119, 0.2009],\n",
            "        [0.2322, 0.1189, 0.2175, 0.2128, 0.2185],\n",
            "        [0.2420, 0.1294, 0.2129, 0.2090, 0.2066]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2187, 0.1406, 0.2191, 0.2159, 0.2057],\n",
            "        [0.2316, 0.1258, 0.2151, 0.2103, 0.2172],\n",
            "        [0.2382, 0.1320, 0.2168, 0.2120, 0.2010],\n",
            "        [0.2322, 0.1184, 0.2177, 0.2129, 0.2187],\n",
            "        [0.2422, 0.1289, 0.2129, 0.2090, 0.2069]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2190, 0.1405, 0.2191, 0.2159, 0.2055],\n",
            "        [0.2321, 0.1256, 0.2150, 0.2101, 0.2171],\n",
            "        [0.2384, 0.1318, 0.2170, 0.2121, 0.2008],\n",
            "        [0.2327, 0.1181, 0.2176, 0.2129, 0.2186],\n",
            "        [0.2426, 0.1287, 0.2131, 0.2091, 0.2065]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2188, 0.1405, 0.2192, 0.2160, 0.2056],\n",
            "        [0.2325, 0.1256, 0.2148, 0.2100, 0.2172],\n",
            "        [0.2388, 0.1315, 0.2168, 0.2119, 0.2009],\n",
            "        [0.2328, 0.1181, 0.2177, 0.2129, 0.2185],\n",
            "        [0.2432, 0.1285, 0.2127, 0.2088, 0.2069]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2193, 0.1403, 0.2192, 0.2159, 0.2053],\n",
            "        [0.2331, 0.1256, 0.2148, 0.2099, 0.2167],\n",
            "        [0.2398, 0.1315, 0.2165, 0.2116, 0.2007],\n",
            "        [0.2334, 0.1178, 0.2176, 0.2128, 0.2183],\n",
            "        [0.2439, 0.1284, 0.2126, 0.2086, 0.2065]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2197, 0.1399, 0.2193, 0.2160, 0.2051],\n",
            "        [0.2332, 0.1253, 0.2149, 0.2099, 0.2167],\n",
            "        [0.2398, 0.1313, 0.2167, 0.2117, 0.2004],\n",
            "        [0.2339, 0.1176, 0.2176, 0.2127, 0.2182],\n",
            "        [0.2441, 0.1283, 0.2128, 0.2087, 0.2061]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2193, 0.1397, 0.2196, 0.2162, 0.2052],\n",
            "        [0.2336, 0.1248, 0.2149, 0.2099, 0.2168],\n",
            "        [0.2402, 0.1309, 0.2166, 0.2117, 0.2006],\n",
            "        [0.2337, 0.1173, 0.2178, 0.2129, 0.2182],\n",
            "        [0.2446, 0.1279, 0.2126, 0.2086, 0.2063]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2195, 0.1395, 0.2196, 0.2162, 0.2051],\n",
            "        [0.2338, 0.1246, 0.2149, 0.2099, 0.2168],\n",
            "        [0.2404, 0.1307, 0.2167, 0.2117, 0.2006],\n",
            "        [0.2340, 0.1170, 0.2179, 0.2129, 0.2182],\n",
            "        [0.2450, 0.1277, 0.2125, 0.2084, 0.2064]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2197, 0.1393, 0.2196, 0.2162, 0.2052],\n",
            "        [0.2340, 0.1244, 0.2149, 0.2099, 0.2168],\n",
            "        [0.2407, 0.1304, 0.2166, 0.2116, 0.2006],\n",
            "        [0.2344, 0.1168, 0.2178, 0.2129, 0.2182],\n",
            "        [0.2456, 0.1274, 0.2123, 0.2083, 0.2064]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2201, 0.1388, 0.2197, 0.2163, 0.2051],\n",
            "        [0.2339, 0.1241, 0.2152, 0.2101, 0.2166],\n",
            "        [0.2408, 0.1302, 0.2168, 0.2118, 0.2004],\n",
            "        [0.2349, 0.1165, 0.2178, 0.2128, 0.2180],\n",
            "        [0.2458, 0.1273, 0.2125, 0.2084, 0.2061]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2192, 0.1387, 0.2202, 0.2167, 0.2053],\n",
            "        [0.2341, 0.1237, 0.2152, 0.2102, 0.2169],\n",
            "        [0.2409, 0.1298, 0.2168, 0.2118, 0.2006],\n",
            "        [0.2346, 0.1162, 0.2181, 0.2131, 0.2181],\n",
            "        [0.2462, 0.1269, 0.2122, 0.2082, 0.2065]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2196, 0.1384, 0.2202, 0.2167, 0.2051],\n",
            "        [0.2341, 0.1235, 0.2154, 0.2102, 0.2168],\n",
            "        [0.2410, 0.1296, 0.2171, 0.2120, 0.2004],\n",
            "        [0.2350, 0.1160, 0.2180, 0.2130, 0.2179],\n",
            "        [0.2464, 0.1268, 0.2124, 0.2083, 0.2062]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2199, 0.1383, 0.2201, 0.2166, 0.2050],\n",
            "        [0.2343, 0.1234, 0.2154, 0.2103, 0.2166],\n",
            "        [0.2412, 0.1296, 0.2171, 0.2120, 0.2002],\n",
            "        [0.2353, 0.1160, 0.2180, 0.2129, 0.2177],\n",
            "        [0.2468, 0.1268, 0.2123, 0.2082, 0.2058]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2203, 0.1383, 0.2201, 0.2165, 0.2048],\n",
            "        [0.2349, 0.1233, 0.2152, 0.2100, 0.2165],\n",
            "        [0.2415, 0.1295, 0.2170, 0.2118, 0.2001],\n",
            "        [0.2358, 0.1160, 0.2180, 0.2128, 0.2175],\n",
            "        [0.2475, 0.1265, 0.2122, 0.2080, 0.2057]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2201, 0.1380, 0.2202, 0.2167, 0.2049],\n",
            "        [0.2349, 0.1229, 0.2154, 0.2102, 0.2167],\n",
            "        [0.2420, 0.1291, 0.2169, 0.2118, 0.2002],\n",
            "        [0.2361, 0.1156, 0.2179, 0.2128, 0.2175],\n",
            "        [0.2479, 0.1263, 0.2120, 0.2079, 0.2059]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2204, 0.1376, 0.2204, 0.2168, 0.2048],\n",
            "        [0.2349, 0.1225, 0.2155, 0.2103, 0.2167],\n",
            "        [0.2420, 0.1288, 0.2171, 0.2119, 0.2001],\n",
            "        [0.2362, 0.1152, 0.2180, 0.2129, 0.2176],\n",
            "        [0.2482, 0.1261, 0.2121, 0.2079, 0.2057]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2205, 0.1376, 0.2204, 0.2168, 0.2047],\n",
            "        [0.2352, 0.1224, 0.2155, 0.2103, 0.2166],\n",
            "        [0.2423, 0.1288, 0.2171, 0.2119, 0.1999],\n",
            "        [0.2368, 0.1151, 0.2179, 0.2128, 0.2174],\n",
            "        [0.2486, 0.1259, 0.2121, 0.2079, 0.2055]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2210, 0.1377, 0.2201, 0.2166, 0.2046],\n",
            "        [0.2356, 0.1226, 0.2154, 0.2101, 0.2163],\n",
            "        [0.2427, 0.1288, 0.2169, 0.2117, 0.1998],\n",
            "        [0.2372, 0.1152, 0.2178, 0.2126, 0.2172],\n",
            "        [0.2491, 0.1259, 0.2119, 0.2077, 0.2054]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2208, 0.1376, 0.2203, 0.2167, 0.2046],\n",
            "        [0.2358, 0.1223, 0.2153, 0.2101, 0.2164],\n",
            "        [0.2429, 0.1286, 0.2169, 0.2117, 0.1999],\n",
            "        [0.2371, 0.1151, 0.2179, 0.2127, 0.2171],\n",
            "        [0.2496, 0.1257, 0.2117, 0.2075, 0.2055]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2207, 0.1372, 0.2206, 0.2170, 0.2046],\n",
            "        [0.2358, 0.1219, 0.2155, 0.2103, 0.2165],\n",
            "        [0.2428, 0.1283, 0.2172, 0.2119, 0.1998],\n",
            "        [0.2372, 0.1148, 0.2181, 0.2128, 0.2172],\n",
            "        [0.2496, 0.1253, 0.2119, 0.2077, 0.2055]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2210, 0.1370, 0.2205, 0.2169, 0.2046],\n",
            "        [0.2359, 0.1217, 0.2156, 0.2104, 0.2165],\n",
            "        [0.2429, 0.1280, 0.2172, 0.2120, 0.1999],\n",
            "        [0.2374, 0.1145, 0.2181, 0.2128, 0.2172],\n",
            "        [0.2500, 0.1251, 0.2118, 0.2075, 0.2056]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2211, 0.1369, 0.2205, 0.2169, 0.2046],\n",
            "        [0.2360, 0.1213, 0.2157, 0.2104, 0.2166],\n",
            "        [0.2432, 0.1278, 0.2172, 0.2119, 0.1999],\n",
            "        [0.2375, 0.1142, 0.2181, 0.2128, 0.2173],\n",
            "        [0.2503, 0.1250, 0.2117, 0.2074, 0.2056]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2210, 0.1367, 0.2207, 0.2170, 0.2045],\n",
            "        [0.2362, 0.1212, 0.2157, 0.2104, 0.2165],\n",
            "        [0.2435, 0.1278, 0.2171, 0.2119, 0.1998],\n",
            "        [0.2378, 0.1141, 0.2181, 0.2128, 0.2171],\n",
            "        [0.2509, 0.1248, 0.2116, 0.2073, 0.2054]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2211, 0.1362, 0.2209, 0.2173, 0.2045],\n",
            "        [0.2363, 0.1209, 0.2159, 0.2105, 0.2165],\n",
            "        [0.2436, 0.1275, 0.2172, 0.2120, 0.1998],\n",
            "        [0.2381, 0.1138, 0.2181, 0.2128, 0.2172],\n",
            "        [0.2510, 0.1245, 0.2117, 0.2074, 0.2054]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2216, 0.1362, 0.2207, 0.2171, 0.2044],\n",
            "        [0.2365, 0.1209, 0.2158, 0.2104, 0.2163],\n",
            "        [0.2439, 0.1275, 0.2172, 0.2119, 0.1995],\n",
            "        [0.2387, 0.1138, 0.2179, 0.2126, 0.2170],\n",
            "        [0.2515, 0.1246, 0.2115, 0.2072, 0.2051]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2217, 0.1362, 0.2207, 0.2170, 0.2043],\n",
            "        [0.2368, 0.1208, 0.2158, 0.2104, 0.2162],\n",
            "        [0.2443, 0.1274, 0.2170, 0.2117, 0.1996],\n",
            "        [0.2387, 0.1138, 0.2180, 0.2126, 0.2169],\n",
            "        [0.2519, 0.1244, 0.2114, 0.2071, 0.2052]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2218, 0.1360, 0.2207, 0.2171, 0.2044],\n",
            "        [0.2368, 0.1208, 0.2158, 0.2105, 0.2161],\n",
            "        [0.2447, 0.1274, 0.2169, 0.2116, 0.1995],\n",
            "        [0.2390, 0.1138, 0.2179, 0.2125, 0.2168],\n",
            "        [0.2522, 0.1245, 0.2112, 0.2069, 0.2051]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2219, 0.1360, 0.2208, 0.2171, 0.2043],\n",
            "        [0.2372, 0.1208, 0.2158, 0.2104, 0.2159],\n",
            "        [0.2449, 0.1273, 0.2169, 0.2116, 0.1995],\n",
            "        [0.2392, 0.1136, 0.2180, 0.2126, 0.2167],\n",
            "        [0.2526, 0.1243, 0.2112, 0.2069, 0.2050]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2223, 0.1360, 0.2207, 0.2170, 0.2040],\n",
            "        [0.2378, 0.1207, 0.2156, 0.2101, 0.2158],\n",
            "        [0.2450, 0.1273, 0.2169, 0.2115, 0.1992],\n",
            "        [0.2399, 0.1137, 0.2177, 0.2123, 0.2165],\n",
            "        [0.2532, 0.1244, 0.2110, 0.2067, 0.2047]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2221, 0.1360, 0.2208, 0.2170, 0.2041],\n",
            "        [0.2377, 0.1204, 0.2157, 0.2103, 0.2159],\n",
            "        [0.2450, 0.1270, 0.2170, 0.2117, 0.1993],\n",
            "        [0.2398, 0.1134, 0.2179, 0.2125, 0.2166],\n",
            "        [0.2534, 0.1241, 0.2110, 0.2066, 0.2049]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2224, 0.1358, 0.2208, 0.2170, 0.2040],\n",
            "        [0.2378, 0.1203, 0.2158, 0.2103, 0.2158],\n",
            "        [0.2452, 0.1270, 0.2170, 0.2116, 0.1992],\n",
            "        [0.2401, 0.1133, 0.2178, 0.2124, 0.2165],\n",
            "        [0.2539, 0.1241, 0.2108, 0.2065, 0.2048]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2224, 0.1356, 0.2209, 0.2171, 0.2040],\n",
            "        [0.2379, 0.1203, 0.2157, 0.2103, 0.2158],\n",
            "        [0.2454, 0.1270, 0.2170, 0.2116, 0.1991],\n",
            "        [0.2405, 0.1133, 0.2176, 0.2122, 0.2163],\n",
            "        [0.2543, 0.1241, 0.2107, 0.2063, 0.2046]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2223, 0.1356, 0.2209, 0.2172, 0.2040],\n",
            "        [0.2380, 0.1203, 0.2157, 0.2103, 0.2157],\n",
            "        [0.2456, 0.1269, 0.2169, 0.2115, 0.1991],\n",
            "        [0.2403, 0.1132, 0.2178, 0.2124, 0.2163],\n",
            "        [0.2546, 0.1238, 0.2107, 0.2063, 0.2045]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2225, 0.1356, 0.2209, 0.2171, 0.2039],\n",
            "        [0.2383, 0.1202, 0.2156, 0.2102, 0.2156],\n",
            "        [0.2459, 0.1268, 0.2168, 0.2114, 0.1990],\n",
            "        [0.2406, 0.1131, 0.2178, 0.2123, 0.2162],\n",
            "        [0.2548, 0.1238, 0.2107, 0.2063, 0.2045]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2224, 0.1357, 0.2209, 0.2171, 0.2039],\n",
            "        [0.2384, 0.1201, 0.2156, 0.2102, 0.2156],\n",
            "        [0.2461, 0.1268, 0.2167, 0.2113, 0.1991],\n",
            "        [0.2405, 0.1131, 0.2178, 0.2124, 0.2161],\n",
            "        [0.2550, 0.1237, 0.2105, 0.2061, 0.2046]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2227, 0.1355, 0.2209, 0.2171, 0.2038],\n",
            "        [0.2387, 0.1202, 0.2156, 0.2101, 0.2154],\n",
            "        [0.2463, 0.1268, 0.2167, 0.2113, 0.1989],\n",
            "        [0.2408, 0.1130, 0.2178, 0.2123, 0.2160],\n",
            "        [0.2552, 0.1237, 0.2106, 0.2061, 0.2043]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2227, 0.1354, 0.2210, 0.2172, 0.2037],\n",
            "        [0.2388, 0.1200, 0.2156, 0.2101, 0.2155],\n",
            "        [0.2463, 0.1267, 0.2168, 0.2114, 0.1988],\n",
            "        [0.2411, 0.1130, 0.2177, 0.2123, 0.2160],\n",
            "        [0.2553, 0.1236, 0.2106, 0.2062, 0.2042]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2226, 0.1355, 0.2209, 0.2172, 0.2038],\n",
            "        [0.2389, 0.1200, 0.2155, 0.2101, 0.2155],\n",
            "        [0.2464, 0.1266, 0.2167, 0.2113, 0.1990],\n",
            "        [0.2411, 0.1130, 0.2177, 0.2123, 0.2159],\n",
            "        [0.2558, 0.1235, 0.2103, 0.2059, 0.2044]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2228, 0.1355, 0.2209, 0.2171, 0.2036],\n",
            "        [0.2393, 0.1199, 0.2155, 0.2100, 0.2153],\n",
            "        [0.2467, 0.1265, 0.2167, 0.2113, 0.1988],\n",
            "        [0.2414, 0.1129, 0.2176, 0.2122, 0.2158],\n",
            "        [0.2561, 0.1235, 0.2103, 0.2058, 0.2043]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2230, 0.1352, 0.2210, 0.2172, 0.2036],\n",
            "        [0.2391, 0.1198, 0.2156, 0.2101, 0.2153],\n",
            "        [0.2468, 0.1264, 0.2167, 0.2113, 0.1987],\n",
            "        [0.2415, 0.1129, 0.2177, 0.2122, 0.2157],\n",
            "        [0.2562, 0.1235, 0.2104, 0.2059, 0.2041]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2232, 0.1352, 0.2209, 0.2171, 0.2036],\n",
            "        [0.2390, 0.1199, 0.2157, 0.2102, 0.2152],\n",
            "        [0.2472, 0.1264, 0.2166, 0.2112, 0.1987],\n",
            "        [0.2416, 0.1128, 0.2177, 0.2122, 0.2157],\n",
            "        [0.2565, 0.1234, 0.2103, 0.2058, 0.2040]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2230, 0.1352, 0.2210, 0.2172, 0.2036],\n",
            "        [0.2393, 0.1197, 0.2156, 0.2101, 0.2152],\n",
            "        [0.2474, 0.1263, 0.2165, 0.2111, 0.1987],\n",
            "        [0.2418, 0.1127, 0.2176, 0.2122, 0.2157],\n",
            "        [0.2568, 0.1233, 0.2101, 0.2057, 0.2041]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2232, 0.1352, 0.2209, 0.2171, 0.2035],\n",
            "        [0.2394, 0.1197, 0.2156, 0.2101, 0.2152],\n",
            "        [0.2476, 0.1263, 0.2165, 0.2110, 0.1986],\n",
            "        [0.2420, 0.1127, 0.2176, 0.2122, 0.2155],\n",
            "        [0.2571, 0.1234, 0.2100, 0.2055, 0.2040]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2233, 0.1351, 0.2209, 0.2171, 0.2035],\n",
            "        [0.2395, 0.1197, 0.2156, 0.2101, 0.2150],\n",
            "        [0.2479, 0.1262, 0.2164, 0.2109, 0.1986],\n",
            "        [0.2421, 0.1127, 0.2176, 0.2121, 0.2155],\n",
            "        [0.2573, 0.1233, 0.2100, 0.2055, 0.2038]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2234, 0.1352, 0.2208, 0.2170, 0.2036],\n",
            "        [0.2397, 0.1198, 0.2155, 0.2101, 0.2149],\n",
            "        [0.2481, 0.1263, 0.2162, 0.2108, 0.1987],\n",
            "        [0.2422, 0.1128, 0.2176, 0.2121, 0.2153],\n",
            "        [0.2579, 0.1234, 0.2096, 0.2052, 0.2039]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2236, 0.1350, 0.2208, 0.2170, 0.2034],\n",
            "        [0.2398, 0.1196, 0.2156, 0.2101, 0.2149],\n",
            "        [0.2481, 0.1262, 0.2163, 0.2108, 0.1985],\n",
            "        [0.2425, 0.1125, 0.2175, 0.2121, 0.2153],\n",
            "        [0.2579, 0.1234, 0.2097, 0.2052, 0.2038]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2239, 0.1349, 0.2209, 0.2170, 0.2033],\n",
            "        [0.2400, 0.1196, 0.2155, 0.2100, 0.2149],\n",
            "        [0.2482, 0.1263, 0.2164, 0.2108, 0.1983],\n",
            "        [0.2428, 0.1125, 0.2174, 0.2120, 0.2153],\n",
            "        [0.2581, 0.1234, 0.2097, 0.2052, 0.2035]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2239, 0.1350, 0.2208, 0.2170, 0.2033],\n",
            "        [0.2402, 0.1196, 0.2155, 0.2100, 0.2148],\n",
            "        [0.2483, 0.1262, 0.2163, 0.2108, 0.1983],\n",
            "        [0.2430, 0.1125, 0.2174, 0.2119, 0.2152],\n",
            "        [0.2583, 0.1234, 0.2097, 0.2052, 0.2035]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2240, 0.1351, 0.2208, 0.2169, 0.2032],\n",
            "        [0.2404, 0.1196, 0.2154, 0.2099, 0.2147],\n",
            "        [0.2486, 0.1263, 0.2162, 0.2107, 0.1982],\n",
            "        [0.2432, 0.1126, 0.2173, 0.2119, 0.2151],\n",
            "        [0.2587, 0.1234, 0.2095, 0.2050, 0.2034]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2239, 0.1350, 0.2207, 0.2169, 0.2033],\n",
            "        [0.2403, 0.1195, 0.2155, 0.2100, 0.2147],\n",
            "        [0.2488, 0.1262, 0.2161, 0.2107, 0.1983],\n",
            "        [0.2432, 0.1126, 0.2172, 0.2118, 0.2151],\n",
            "        [0.2589, 0.1233, 0.2094, 0.2049, 0.2035]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2239, 0.1351, 0.2207, 0.2169, 0.2033],\n",
            "        [0.2403, 0.1195, 0.2155, 0.2100, 0.2147],\n",
            "        [0.2490, 0.1262, 0.2160, 0.2105, 0.1983],\n",
            "        [0.2433, 0.1125, 0.2173, 0.2119, 0.2150],\n",
            "        [0.2591, 0.1233, 0.2093, 0.2048, 0.2035]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2240, 0.1350, 0.2208, 0.2170, 0.2032],\n",
            "        [0.2404, 0.1195, 0.2155, 0.2100, 0.2146],\n",
            "        [0.2490, 0.1261, 0.2161, 0.2106, 0.1982],\n",
            "        [0.2434, 0.1124, 0.2173, 0.2118, 0.2150],\n",
            "        [0.2591, 0.1232, 0.2094, 0.2049, 0.2035]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2241, 0.1349, 0.2208, 0.2170, 0.2032],\n",
            "        [0.2406, 0.1195, 0.2154, 0.2099, 0.2146],\n",
            "        [0.2491, 0.1261, 0.2160, 0.2105, 0.1982],\n",
            "        [0.2436, 0.1125, 0.2172, 0.2118, 0.2150],\n",
            "        [0.2594, 0.1232, 0.2093, 0.2048, 0.2034]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2242, 0.1349, 0.2208, 0.2170, 0.2031],\n",
            "        [0.2407, 0.1195, 0.2154, 0.2099, 0.2145],\n",
            "        [0.2493, 0.1262, 0.2160, 0.2105, 0.1981],\n",
            "        [0.2439, 0.1125, 0.2171, 0.2117, 0.2149],\n",
            "        [0.2595, 0.1233, 0.2092, 0.2047, 0.2033]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2243, 0.1350, 0.2207, 0.2169, 0.2031],\n",
            "        [0.2408, 0.1195, 0.2154, 0.2099, 0.2144],\n",
            "        [0.2496, 0.1262, 0.2159, 0.2104, 0.1980],\n",
            "        [0.2440, 0.1126, 0.2170, 0.2116, 0.2147],\n",
            "        [0.2598, 0.1233, 0.2091, 0.2045, 0.2032]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2244, 0.1349, 0.2208, 0.2169, 0.2031],\n",
            "        [0.2409, 0.1195, 0.2154, 0.2099, 0.2144],\n",
            "        [0.2496, 0.1262, 0.2159, 0.2103, 0.1980],\n",
            "        [0.2442, 0.1126, 0.2169, 0.2115, 0.2147],\n",
            "        [0.2599, 0.1234, 0.2091, 0.2045, 0.2031]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2244, 0.1349, 0.2207, 0.2169, 0.2031],\n",
            "        [0.2408, 0.1195, 0.2154, 0.2099, 0.2143],\n",
            "        [0.2497, 0.1261, 0.2158, 0.2103, 0.1980],\n",
            "        [0.2441, 0.1126, 0.2170, 0.2116, 0.2147],\n",
            "        [0.2601, 0.1234, 0.2090, 0.2045, 0.2031]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2245, 0.1349, 0.2207, 0.2169, 0.2030],\n",
            "        [0.2409, 0.1195, 0.2154, 0.2099, 0.2143],\n",
            "        [0.2499, 0.1262, 0.2158, 0.2102, 0.1979],\n",
            "        [0.2443, 0.1127, 0.2169, 0.2115, 0.2146],\n",
            "        [0.2602, 0.1235, 0.2089, 0.2044, 0.2030]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2246, 0.1349, 0.2207, 0.2169, 0.2030],\n",
            "        [0.2411, 0.1195, 0.2153, 0.2098, 0.2142],\n",
            "        [0.2499, 0.1262, 0.2158, 0.2102, 0.1979],\n",
            "        [0.2444, 0.1127, 0.2169, 0.2115, 0.2146],\n",
            "        [0.2604, 0.1235, 0.2088, 0.2043, 0.2030]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2246, 0.1349, 0.2207, 0.2168, 0.2030],\n",
            "        [0.2410, 0.1195, 0.2154, 0.2099, 0.2142],\n",
            "        [0.2501, 0.1262, 0.2157, 0.2102, 0.1979],\n",
            "        [0.2444, 0.1127, 0.2169, 0.2115, 0.2145],\n",
            "        [0.2606, 0.1235, 0.2088, 0.2042, 0.2030]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2246, 0.1348, 0.2207, 0.2169, 0.2030],\n",
            "        [0.2411, 0.1195, 0.2154, 0.2099, 0.2142],\n",
            "        [0.2501, 0.1262, 0.2157, 0.2102, 0.1979],\n",
            "        [0.2444, 0.1127, 0.2169, 0.2115, 0.2145],\n",
            "        [0.2606, 0.1235, 0.2088, 0.2042, 0.2029]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2247, 0.1348, 0.2207, 0.2169, 0.2029],\n",
            "        [0.2412, 0.1195, 0.2153, 0.2098, 0.2142],\n",
            "        [0.2501, 0.1262, 0.2157, 0.2102, 0.1978],\n",
            "        [0.2446, 0.1127, 0.2168, 0.2115, 0.2145],\n",
            "        [0.2607, 0.1235, 0.2088, 0.2042, 0.2028]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2247, 0.1348, 0.2207, 0.2168, 0.2029],\n",
            "        [0.2412, 0.1195, 0.2153, 0.2098, 0.2142],\n",
            "        [0.2501, 0.1262, 0.2157, 0.2101, 0.1978],\n",
            "        [0.2447, 0.1127, 0.2168, 0.2114, 0.2145],\n",
            "        [0.2609, 0.1235, 0.2087, 0.2041, 0.2028]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2248, 0.1349, 0.2207, 0.2168, 0.2029],\n",
            "        [0.2413, 0.1196, 0.2152, 0.2097, 0.2141],\n",
            "        [0.2502, 0.1263, 0.2157, 0.2101, 0.1978],\n",
            "        [0.2448, 0.1127, 0.2167, 0.2114, 0.2144],\n",
            "        [0.2610, 0.1235, 0.2086, 0.2040, 0.2028]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2249, 0.1349, 0.2206, 0.2168, 0.2029],\n",
            "        [0.2414, 0.1196, 0.2152, 0.2097, 0.2141],\n",
            "        [0.2503, 0.1263, 0.2156, 0.2101, 0.1978],\n",
            "        [0.2448, 0.1128, 0.2167, 0.2114, 0.2143],\n",
            "        [0.2612, 0.1235, 0.2086, 0.2040, 0.2027]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2249, 0.1349, 0.2206, 0.2168, 0.2029],\n",
            "        [0.2414, 0.1196, 0.2152, 0.2097, 0.2141],\n",
            "        [0.2503, 0.1263, 0.2156, 0.2100, 0.1978],\n",
            "        [0.2449, 0.1128, 0.2167, 0.2113, 0.2143],\n",
            "        [0.2613, 0.1236, 0.2085, 0.2039, 0.2027]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2249, 0.1349, 0.2206, 0.2168, 0.2029],\n",
            "        [0.2414, 0.1196, 0.2153, 0.2098, 0.2140],\n",
            "        [0.2504, 0.1263, 0.2156, 0.2100, 0.1978],\n",
            "        [0.2449, 0.1128, 0.2167, 0.2113, 0.2143],\n",
            "        [0.2613, 0.1236, 0.2085, 0.2039, 0.2027]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2249, 0.1349, 0.2206, 0.2168, 0.2029],\n",
            "        [0.2413, 0.1196, 0.2153, 0.2098, 0.2140],\n",
            "        [0.2504, 0.1263, 0.2155, 0.2100, 0.1978],\n",
            "        [0.2449, 0.1128, 0.2167, 0.2113, 0.2143],\n",
            "        [0.2614, 0.1236, 0.2084, 0.2039, 0.2027]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2249, 0.1349, 0.2206, 0.2167, 0.2029],\n",
            "        [0.2414, 0.1196, 0.2152, 0.2097, 0.2140],\n",
            "        [0.2505, 0.1263, 0.2155, 0.2100, 0.1978],\n",
            "        [0.2450, 0.1128, 0.2167, 0.2113, 0.2142],\n",
            "        [0.2615, 0.1236, 0.2084, 0.2038, 0.2027]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.1349, 0.2206, 0.2167, 0.2028],\n",
            "        [0.2415, 0.1196, 0.2152, 0.2097, 0.2140],\n",
            "        [0.2505, 0.1263, 0.2155, 0.2099, 0.1977],\n",
            "        [0.2450, 0.1128, 0.2166, 0.2113, 0.2142],\n",
            "        [0.2615, 0.1236, 0.2084, 0.2038, 0.2026]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.1349, 0.2206, 0.2167, 0.2028],\n",
            "        [0.2415, 0.1196, 0.2152, 0.2097, 0.2139],\n",
            "        [0.2506, 0.1263, 0.2155, 0.2099, 0.1977],\n",
            "        [0.2451, 0.1128, 0.2166, 0.2113, 0.2142],\n",
            "        [0.2616, 0.1236, 0.2084, 0.2038, 0.2026]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.1349, 0.2206, 0.2167, 0.2028],\n",
            "        [0.2416, 0.1196, 0.2152, 0.2097, 0.2139],\n",
            "        [0.2506, 0.1263, 0.2155, 0.2099, 0.1977],\n",
            "        [0.2451, 0.1128, 0.2166, 0.2113, 0.2142],\n",
            "        [0.2617, 0.1236, 0.2084, 0.2038, 0.2026]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.1349, 0.2206, 0.2167, 0.2028],\n",
            "        [0.2416, 0.1196, 0.2152, 0.2097, 0.2139],\n",
            "        [0.2506, 0.1263, 0.2155, 0.2099, 0.1977],\n",
            "        [0.2451, 0.1128, 0.2166, 0.2113, 0.2142],\n",
            "        [0.2617, 0.1237, 0.2083, 0.2037, 0.2026]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.1349, 0.2206, 0.2167, 0.2028],\n",
            "        [0.2416, 0.1196, 0.2152, 0.2097, 0.2139],\n",
            "        [0.2506, 0.1263, 0.2155, 0.2099, 0.1977],\n",
            "        [0.2452, 0.1128, 0.2166, 0.2113, 0.2142],\n",
            "        [0.2617, 0.1237, 0.2083, 0.2037, 0.2025]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2250, 0.1349, 0.2206, 0.2167, 0.2028],\n",
            "        [0.2416, 0.1196, 0.2152, 0.2097, 0.2139],\n",
            "        [0.2507, 0.1263, 0.2155, 0.2099, 0.1977],\n",
            "        [0.2452, 0.1128, 0.2166, 0.2112, 0.2141],\n",
            "        [0.2617, 0.1237, 0.2083, 0.2037, 0.2025]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN_ReLU_Conv_200_ep --train_name truck_nas_project_layer_types_cycleGAN_ReLU_Conv_200_ep --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 50 --n_epochs 100 --n_epochs_decay 100 --layer_types CycleGan+ReLU+Conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8qXRxU991Ey",
        "outputId": "be974415-20a6-4bec-ca7f-6d33ab48595d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 50                            \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: CycleGan+ReLU+Pool            \t[default: CycleGan]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_epochs: 50                            \t[default: 100]\n",
            "           n_epochs_decay: 50                            \t[default: 100]\n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_cycleGAN_ReLU_Pool_100_ep\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_ReLU_Pool_100_ep\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 9.611 M\n",
            "[Network G_B] Total number of parameters : 9.611 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_ReLU_Pool_100_ep/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.387, data: 0.261) D_A: 0.644 G_A: 0.899 cycle_A: 0.987 idt_A: 1.541 D_B: 0.165 G_B: 0.483 cycle_B: 3.602 idt_B: 0.404 \n",
            "End of epoch 1 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.365, data: 0.439) D_A: 0.231 G_A: 0.271 cycle_A: 0.987 idt_A: 1.243 D_B: 0.120 G_B: 0.476 cycle_B: 2.821 idt_B: 0.469 \n",
            "End of epoch 2 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.372, data: 0.244) D_A: 0.329 G_A: 0.437 cycle_A: 1.533 idt_A: 1.315 D_B: 0.126 G_B: 0.715 cycle_B: 3.030 idt_B: 0.717 \n",
            "End of epoch 3 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.598, data: 0.260) D_A: 0.260 G_A: 0.503 cycle_A: 1.241 idt_A: 1.606 D_B: 0.105 G_B: 0.783 cycle_B: 3.518 idt_B: 0.316 \n",
            "End of epoch 4 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.383, data: 0.313) D_A: 0.462 G_A: 0.100 cycle_A: 0.720 idt_A: 1.736 D_B: 0.082 G_B: 0.572 cycle_B: 3.521 idt_B: 0.313 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.365, data: 0.282) D_A: 0.214 G_A: 0.337 cycle_A: 1.016 idt_A: 1.026 D_B: 0.117 G_B: 0.443 cycle_B: 2.724 idt_B: 0.475 \n",
            "End of epoch 6 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.372, data: 0.267) D_A: 0.243 G_A: 0.414 cycle_A: 0.766 idt_A: 1.326 D_B: 0.066 G_B: 0.122 cycle_B: 3.109 idt_B: 0.367 \n",
            "End of epoch 7 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.694, data: 0.329) D_A: 0.180 G_A: 0.381 cycle_A: 0.741 idt_A: 2.058 D_B: 0.199 G_B: 0.270 cycle_B: 4.067 idt_B: 0.381 \n",
            "End of epoch 8 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.365, data: 0.494) D_A: 0.194 G_A: 0.525 cycle_A: 0.691 idt_A: 2.117 D_B: 0.043 G_B: 1.104 cycle_B: 3.819 idt_B: 0.273 \n",
            "End of epoch 9 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.382, data: 0.232) D_A: 0.152 G_A: 0.440 cycle_A: 0.902 idt_A: 1.279 D_B: 0.081 G_B: 0.974 cycle_B: 3.044 idt_B: 0.427 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.369, data: 0.243) D_A: 0.192 G_A: 0.590 cycle_A: 0.449 idt_A: 1.987 D_B: 0.067 G_B: 0.387 cycle_B: 4.332 idt_B: 0.209 \n",
            "End of epoch 11 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.719, data: 0.471) D_A: 0.250 G_A: 0.406 cycle_A: 0.726 idt_A: 0.802 D_B: 0.105 G_B: 0.462 cycle_B: 2.197 idt_B: 0.323 \n",
            "End of epoch 12 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.366, data: 0.586) D_A: 0.134 G_A: 0.832 cycle_A: 1.187 idt_A: 1.079 D_B: 0.119 G_B: 0.725 cycle_B: 2.713 idt_B: 0.652 \n",
            "End of epoch 13 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.366, data: 0.272) D_A: 0.113 G_A: 0.630 cycle_A: 1.440 idt_A: 1.124 D_B: 0.046 G_B: 0.983 cycle_B: 2.852 idt_B: 0.519 \n",
            "End of epoch 14 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.367, data: 0.246) D_A: 0.129 G_A: 0.736 cycle_A: 0.620 idt_A: 1.206 D_B: 0.172 G_B: 1.069 cycle_B: 2.844 idt_B: 0.174 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.755, data: 0.293) D_A: 0.104 G_A: 0.559 cycle_A: 0.572 idt_A: 0.912 D_B: 0.159 G_B: 0.243 cycle_B: 2.537 idt_B: 0.225 \n",
            "End of epoch 16 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.369, data: 0.401) D_A: 0.102 G_A: 0.750 cycle_A: 1.140 idt_A: 0.821 D_B: 0.042 G_B: 0.506 cycle_B: 1.838 idt_B: 0.514 \n",
            "End of epoch 17 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.364, data: 0.276) D_A: 0.105 G_A: 0.603 cycle_A: 0.684 idt_A: 1.061 D_B: 0.224 G_B: 0.135 cycle_B: 2.833 idt_B: 0.245 \n",
            "End of epoch 18 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.365, data: 0.246) D_A: 0.104 G_A: 0.432 cycle_A: 0.527 idt_A: 0.826 D_B: 0.102 G_B: 0.525 cycle_B: 2.214 idt_B: 0.205 \n",
            "End of epoch 19 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.782, data: 0.255) D_A: 0.167 G_A: 1.713 cycle_A: 0.943 idt_A: 1.186 D_B: 0.098 G_B: 0.653 cycle_B: 3.026 idt_B: 0.380 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 100 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.360, data: 0.400) D_A: 0.089 G_A: 0.388 cycle_A: 0.847 idt_A: 0.727 D_B: 0.059 G_B: 0.061 cycle_B: 1.646 idt_B: 0.366 \n",
            "End of epoch 21 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.372, data: 0.287) D_A: 0.070 G_A: 0.651 cycle_A: 0.728 idt_A: 1.235 D_B: 0.062 G_B: 0.566 cycle_B: 2.709 idt_B: 0.256 \n",
            "End of epoch 22 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.364, data: 0.268) D_A: 0.066 G_A: 0.336 cycle_A: 0.731 idt_A: 1.690 D_B: 0.059 G_B: 0.487 cycle_B: 4.821 idt_B: 0.243 \n",
            "End of epoch 23 / 100 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.813, data: 0.289) D_A: 0.251 G_A: 0.999 cycle_A: 0.638 idt_A: 0.988 D_B: 0.129 G_B: 0.385 cycle_B: 4.449 idt_B: 0.264 \n",
            "End of epoch 24 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.376, data: 0.268) D_A: 0.196 G_A: 0.313 cycle_A: 0.828 idt_A: 1.186 D_B: 0.430 G_B: 1.021 cycle_B: 2.788 idt_B: 0.335 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.332, data: 0.242) D_A: 0.186 G_A: 0.693 cycle_A: 0.854 idt_A: 0.829 D_B: 0.203 G_B: 1.002 cycle_B: 2.138 idt_B: 0.355 \n",
            "End of epoch 26 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.334, data: 0.263) D_A: 0.102 G_A: 0.429 cycle_A: 1.182 idt_A: 1.072 D_B: 0.086 G_B: 0.632 cycle_B: 2.353 idt_B: 0.602 \n",
            "End of epoch 27 / 100 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.697, data: 0.267) D_A: 0.132 G_A: 0.391 cycle_A: 0.597 idt_A: 1.470 D_B: 0.038 G_B: 0.396 cycle_B: 3.248 idt_B: 0.212 \n",
            "End of epoch 28 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.343, data: 0.254) D_A: 0.359 G_A: 0.208 cycle_A: 0.599 idt_A: 0.951 D_B: 0.158 G_B: 0.132 cycle_B: 2.079 idt_B: 0.305 \n",
            "End of epoch 29 / 100 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.332, data: 0.214) D_A: 0.057 G_A: 0.502 cycle_A: 2.131 idt_A: 1.251 D_B: 0.154 G_B: 1.166 cycle_B: 2.916 idt_B: 0.278 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.360, data: 0.219) D_A: 0.131 G_A: 0.609 cycle_A: 0.850 idt_A: 1.657 D_B: 0.123 G_B: 0.791 cycle_B: 4.181 idt_B: 0.337 \n",
            "End of epoch 31 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.784, data: 0.415) D_A: 0.052 G_A: 0.864 cycle_A: 1.108 idt_A: 0.808 D_B: 0.199 G_B: 1.587 cycle_B: 2.197 idt_B: 0.442 \n",
            "End of epoch 32 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.394, data: 0.401) D_A: 0.123 G_A: 0.487 cycle_A: 0.626 idt_A: 0.862 D_B: 0.060 G_B: 0.650 cycle_B: 2.518 idt_B: 0.276 \n",
            "End of epoch 33 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.368, data: 0.412) D_A: 0.075 G_A: 0.463 cycle_A: 0.892 idt_A: 1.134 D_B: 0.317 G_B: 0.711 cycle_B: 2.351 idt_B: 0.365 \n",
            "End of epoch 34 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.370, data: 0.425) D_A: 0.081 G_A: 0.630 cycle_A: 0.954 idt_A: 0.625 D_B: 0.080 G_B: 0.570 cycle_B: 1.607 idt_B: 0.425 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.916, data: 0.250) D_A: 0.203 G_A: 0.317 cycle_A: 0.657 idt_A: 0.878 D_B: 0.174 G_B: 0.469 cycle_B: 2.271 idt_B: 0.181 \n",
            "End of epoch 36 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.406, data: 0.379) D_A: 0.038 G_A: 0.476 cycle_A: 0.459 idt_A: 0.636 D_B: 0.043 G_B: 1.198 cycle_B: 1.732 idt_B: 0.190 \n",
            "End of epoch 37 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.362, data: 0.423) D_A: 0.187 G_A: 0.422 cycle_A: 0.775 idt_A: 0.868 D_B: 0.251 G_B: 0.043 cycle_B: 1.832 idt_B: 0.276 \n",
            "End of epoch 38 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.376, data: 0.224) D_A: 0.035 G_A: 0.261 cycle_A: 0.521 idt_A: 0.994 D_B: 0.246 G_B: 0.171 cycle_B: 2.314 idt_B: 0.238 \n",
            "End of epoch 39 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.969, data: 0.227) D_A: 0.077 G_A: 0.279 cycle_A: 0.766 idt_A: 0.842 D_B: 0.255 G_B: 0.751 cycle_B: 2.138 idt_B: 0.401 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 100 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.387, data: 0.435) D_A: 0.069 G_A: 0.479 cycle_A: 0.876 idt_A: 0.582 D_B: 0.119 G_B: 0.796 cycle_B: 1.676 idt_B: 0.360 \n",
            "End of epoch 41 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.345, data: 0.330) D_A: 0.062 G_A: 0.839 cycle_A: 0.723 idt_A: 0.980 D_B: 0.089 G_B: 0.676 cycle_B: 2.262 idt_B: 0.207 \n",
            "End of epoch 42 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.346, data: 0.235) D_A: 0.042 G_A: 0.969 cycle_A: 1.124 idt_A: 0.965 D_B: 0.086 G_B: 0.310 cycle_B: 2.067 idt_B: 0.397 \n",
            "End of epoch 43 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.882, data: 0.255) D_A: 0.052 G_A: 0.617 cycle_A: 0.680 idt_A: 0.908 D_B: 0.059 G_B: 0.981 cycle_B: 2.662 idt_B: 0.253 \n",
            "End of epoch 44 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.351, data: 0.243) D_A: 0.247 G_A: 0.136 cycle_A: 1.132 idt_A: 0.943 D_B: 0.099 G_B: 0.646 cycle_B: 2.385 idt_B: 0.546 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.399, data: 0.263) D_A: 0.220 G_A: 0.927 cycle_A: 0.394 idt_A: 0.686 D_B: 0.086 G_B: 0.319 cycle_B: 1.944 idt_B: 0.165 \n",
            "End of epoch 46 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.391, data: 0.426) D_A: 0.120 G_A: 0.824 cycle_A: 0.397 idt_A: 0.882 D_B: 0.138 G_B: 0.476 cycle_B: 2.208 idt_B: 0.162 \n",
            "End of epoch 47 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 1.043, data: 0.429) D_A: 0.149 G_A: 0.313 cycle_A: 0.494 idt_A: 0.936 D_B: 0.107 G_B: 0.591 cycle_B: 2.592 idt_B: 0.181 \n",
            "End of epoch 48 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.368, data: 0.275) D_A: 0.146 G_A: 0.299 cycle_A: 0.658 idt_A: 0.671 D_B: 0.199 G_B: 0.426 cycle_B: 1.684 idt_B: 0.288 \n",
            "End of epoch 49 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0001961\n",
            "(epoch: 50, iters: 100, time: 0.361, data: 0.267) D_A: 0.072 G_A: 0.604 cycle_A: 0.712 idt_A: 0.882 D_B: 0.079 G_B: 0.748 cycle_B: 1.940 idt_B: 0.330 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0001961 -> 0.0001922\n",
            "(epoch: 51, iters: 100, time: 0.363, data: 0.742) D_A: 0.220 G_A: 0.967 cycle_A: 0.847 idt_A: 0.894 D_B: 0.222 G_B: 0.278 cycle_B: 1.811 idt_B: 0.436 \n",
            "End of epoch 51 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0001922 -> 0.0001882\n",
            "(epoch: 52, iters: 100, time: 1.027, data: 0.236) D_A: 0.029 G_A: 0.383 cycle_A: 0.648 idt_A: 1.318 D_B: 0.124 G_B: 0.724 cycle_B: 2.659 idt_B: 0.220 \n",
            "End of epoch 52 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001882 -> 0.0001843\n",
            "(epoch: 53, iters: 100, time: 0.375, data: 0.435) D_A: 0.141 G_A: 0.990 cycle_A: 0.635 idt_A: 1.179 D_B: 0.269 G_B: 0.180 cycle_B: 2.329 idt_B: 0.230 \n",
            "End of epoch 53 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001843 -> 0.0001804\n",
            "(epoch: 54, iters: 100, time: 0.361, data: 0.237) D_A: 0.200 G_A: 0.777 cycle_A: 0.571 idt_A: 0.626 D_B: 0.087 G_B: 0.566 cycle_B: 1.772 idt_B: 0.267 \n",
            "End of epoch 54 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0001804 -> 0.0001765\n",
            "(epoch: 55, iters: 100, time: 0.369, data: 0.300) D_A: 0.314 G_A: 1.003 cycle_A: 0.532 idt_A: 0.817 D_B: 0.124 G_B: 0.112 cycle_B: 2.470 idt_B: 0.200 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0001765 -> 0.0001725\n",
            "(epoch: 56, iters: 100, time: 0.948, data: 0.291) D_A: 0.161 G_A: 0.514 cycle_A: 0.432 idt_A: 0.519 D_B: 0.062 G_B: 1.172 cycle_B: 1.561 idt_B: 0.156 \n",
            "End of epoch 56 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0001725 -> 0.0001686\n",
            "(epoch: 57, iters: 100, time: 0.373, data: 0.269) D_A: 0.274 G_A: 0.972 cycle_A: 0.530 idt_A: 0.595 D_B: 0.050 G_B: 0.577 cycle_B: 2.024 idt_B: 0.175 \n",
            "End of epoch 57 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0001686 -> 0.0001647\n",
            "(epoch: 58, iters: 100, time: 0.326, data: 0.375) D_A: 0.038 G_A: 0.674 cycle_A: 0.332 idt_A: 0.851 D_B: 0.075 G_B: 0.540 cycle_B: 2.039 idt_B: 0.109 \n",
            "End of epoch 58 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0001647 -> 0.0001608\n",
            "(epoch: 59, iters: 100, time: 0.329, data: 0.259) D_A: 0.058 G_A: 0.635 cycle_A: 0.497 idt_A: 0.699 D_B: 0.106 G_B: 0.232 cycle_B: 1.886 idt_B: 0.164 \n",
            "End of epoch 59 / 100 \t Time Taken: 35 sec\n",
            "learning rate 0.0001608 -> 0.0001569\n",
            "(epoch: 60, iters: 100, time: 0.960, data: 0.251) D_A: 0.186 G_A: 0.255 cycle_A: 0.695 idt_A: 0.557 D_B: 0.383 G_B: 0.112 cycle_B: 1.700 idt_B: 0.248 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0001569 -> 0.0001529\n",
            "(epoch: 61, iters: 100, time: 0.366, data: 0.254) D_A: 0.115 G_A: 0.268 cycle_A: 0.810 idt_A: 0.492 D_B: 0.276 G_B: 1.327 cycle_B: 1.459 idt_B: 0.301 \n",
            "End of epoch 61 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0001529 -> 0.0001490\n",
            "(epoch: 62, iters: 100, time: 0.372, data: 0.249) D_A: 0.337 G_A: 1.224 cycle_A: 0.450 idt_A: 0.606 D_B: 0.159 G_B: 0.431 cycle_B: 1.577 idt_B: 0.142 \n",
            "End of epoch 62 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0001490 -> 0.0001451\n",
            "(epoch: 63, iters: 100, time: 0.424, data: 0.282) D_A: 0.040 G_A: 0.172 cycle_A: 0.967 idt_A: 0.831 D_B: 0.101 G_B: 0.591 cycle_B: 2.239 idt_B: 0.338 \n",
            "End of epoch 63 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001451 -> 0.0001412\n",
            "(epoch: 64, iters: 100, time: 1.005, data: 0.368) D_A: 0.117 G_A: 0.404 cycle_A: 0.481 idt_A: 0.807 D_B: 0.045 G_B: 0.974 cycle_B: 1.720 idt_B: 0.141 \n",
            "End of epoch 64 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001412 -> 0.0001373\n",
            "(epoch: 65, iters: 100, time: 0.420, data: 0.250) D_A: 0.061 G_A: 0.328 cycle_A: 0.313 idt_A: 1.072 D_B: 0.086 G_B: 0.585 cycle_B: 2.662 idt_B: 0.115 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0001373 -> 0.0001333\n",
            "(epoch: 66, iters: 100, time: 0.360, data: 0.413) D_A: 0.150 G_A: 0.429 cycle_A: 0.462 idt_A: 1.051 D_B: 0.083 G_B: 0.628 cycle_B: 2.703 idt_B: 0.141 \n",
            "End of epoch 66 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001333 -> 0.0001294\n",
            "(epoch: 67, iters: 100, time: 0.419, data: 0.374) D_A: 0.167 G_A: 0.722 cycle_A: 0.806 idt_A: 0.855 D_B: 0.070 G_B: 0.174 cycle_B: 1.602 idt_B: 0.259 \n",
            "End of epoch 67 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001294 -> 0.0001255\n",
            "(epoch: 68, iters: 100, time: 1.246, data: 0.375) D_A: 0.214 G_A: 0.689 cycle_A: 0.791 idt_A: 0.751 D_B: 0.144 G_B: 0.299 cycle_B: 2.024 idt_B: 0.307 \n",
            "End of epoch 68 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001255 -> 0.0001216\n",
            "(epoch: 69, iters: 100, time: 0.416, data: 0.242) D_A: 0.103 G_A: 0.385 cycle_A: 1.034 idt_A: 0.762 D_B: 0.087 G_B: 1.002 cycle_B: 1.991 idt_B: 0.414 \n",
            "End of epoch 69 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001216 -> 0.0001176\n",
            "(epoch: 70, iters: 100, time: 0.352, data: 0.395) D_A: 0.217 G_A: 0.270 cycle_A: 0.567 idt_A: 0.554 D_B: 0.181 G_B: 0.386 cycle_B: 1.642 idt_B: 0.220 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0001176 -> 0.0001137\n",
            "(epoch: 71, iters: 100, time: 0.414, data: 0.250) D_A: 0.117 G_A: 0.513 cycle_A: 0.452 idt_A: 0.692 D_B: 0.059 G_B: 0.526 cycle_B: 2.178 idt_B: 0.141 \n",
            "End of epoch 71 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0001137 -> 0.0001098\n",
            "(epoch: 72, iters: 100, time: 1.088, data: 0.542) D_A: 0.025 G_A: 0.949 cycle_A: 0.552 idt_A: 0.422 D_B: 0.257 G_B: 1.563 cycle_B: 1.248 idt_B: 0.243 \n",
            "End of epoch 72 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001098 -> 0.0001059\n",
            "(epoch: 73, iters: 100, time: 0.408, data: 0.305) D_A: 0.289 G_A: 0.114 cycle_A: 0.583 idt_A: 0.658 D_B: 0.124 G_B: 0.335 cycle_B: 1.885 idt_B: 0.275 \n",
            "End of epoch 73 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001059 -> 0.0001020\n",
            "(epoch: 74, iters: 100, time: 0.369, data: 0.343) D_A: 0.049 G_A: 0.344 cycle_A: 0.358 idt_A: 0.676 D_B: 0.033 G_B: 0.481 cycle_B: 1.829 idt_B: 0.133 \n",
            "End of epoch 74 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0001020 -> 0.0000980\n",
            "(epoch: 75, iters: 100, time: 0.391, data: 0.228) D_A: 0.134 G_A: 0.859 cycle_A: 0.663 idt_A: 0.801 D_B: 0.105 G_B: 0.521 cycle_B: 1.894 idt_B: 0.230 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000980 -> 0.0000941\n",
            "(epoch: 76, iters: 100, time: 1.088, data: 0.372) D_A: 0.123 G_A: 0.554 cycle_A: 0.344 idt_A: 0.541 D_B: 0.119 G_B: 0.647 cycle_B: 1.563 idt_B: 0.145 \n",
            "End of epoch 76 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000941 -> 0.0000902\n",
            "(epoch: 77, iters: 100, time: 0.406, data: 0.258) D_A: 0.060 G_A: 0.356 cycle_A: 0.780 idt_A: 0.679 D_B: 0.070 G_B: 0.567 cycle_B: 1.820 idt_B: 0.310 \n",
            "End of epoch 77 / 100 \t Time Taken: 37 sec\n",
            "learning rate 0.0000902 -> 0.0000863\n",
            "(epoch: 78, iters: 100, time: 0.359, data: 0.372) D_A: 0.063 G_A: 0.697 cycle_A: 0.522 idt_A: 0.682 D_B: 0.224 G_B: 0.187 cycle_B: 1.732 idt_B: 0.179 \n",
            "End of epoch 78 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0000863 -> 0.0000824\n",
            "(epoch: 79, iters: 100, time: 0.409, data: 0.301) D_A: 0.062 G_A: 0.536 cycle_A: 0.613 idt_A: 0.822 D_B: 0.091 G_B: 0.682 cycle_B: 2.153 idt_B: 0.282 \n",
            "End of epoch 79 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0000824 -> 0.0000784\n",
            "(epoch: 80, iters: 100, time: 1.162, data: 0.422) D_A: 0.106 G_A: 0.502 cycle_A: 0.554 idt_A: 0.758 D_B: 0.118 G_B: 1.157 cycle_B: 1.829 idt_B: 0.172 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0000784 -> 0.0000745\n",
            "(epoch: 81, iters: 100, time: 0.388, data: 0.289) D_A: 0.163 G_A: 0.309 cycle_A: 0.346 idt_A: 0.610 D_B: 0.103 G_B: 0.310 cycle_B: 1.312 idt_B: 0.118 \n",
            "End of epoch 81 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000745 -> 0.0000706\n",
            "(epoch: 82, iters: 100, time: 0.364, data: 0.568) D_A: 0.041 G_A: 0.275 cycle_A: 0.390 idt_A: 0.755 D_B: 0.058 G_B: 0.852 cycle_B: 1.514 idt_B: 0.122 \n",
            "End of epoch 82 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000706 -> 0.0000667\n",
            "(epoch: 83, iters: 100, time: 0.399, data: 0.268) D_A: 0.280 G_A: 0.115 cycle_A: 0.443 idt_A: 0.869 D_B: 0.111 G_B: 0.124 cycle_B: 2.204 idt_B: 0.157 \n",
            "End of epoch 83 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0000667 -> 0.0000627\n",
            "(epoch: 84, iters: 100, time: 1.123, data: 0.361) D_A: 0.062 G_A: 0.571 cycle_A: 0.374 idt_A: 0.927 D_B: 0.154 G_B: 0.691 cycle_B: 2.080 idt_B: 0.150 \n",
            "End of epoch 84 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0000627 -> 0.0000588\n",
            "(epoch: 85, iters: 100, time: 0.414, data: 0.256) D_A: 0.095 G_A: 0.283 cycle_A: 0.392 idt_A: 0.765 D_B: 0.069 G_B: 0.716 cycle_B: 1.759 idt_B: 0.111 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0000588 -> 0.0000549\n",
            "(epoch: 86, iters: 100, time: 0.360, data: 0.372) D_A: 0.066 G_A: 0.542 cycle_A: 0.497 idt_A: 0.443 D_B: 0.206 G_B: 0.207 cycle_B: 1.238 idt_B: 0.148 \n",
            "End of epoch 86 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000549 -> 0.0000510\n",
            "(epoch: 87, iters: 100, time: 0.404, data: 0.284) D_A: 0.066 G_A: 0.251 cycle_A: 0.498 idt_A: 0.916 D_B: 0.116 G_B: 0.883 cycle_B: 2.267 idt_B: 0.202 \n",
            "End of epoch 87 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0000510 -> 0.0000471\n",
            "(epoch: 88, iters: 100, time: 1.330, data: 0.368) D_A: 0.089 G_A: 0.415 cycle_A: 0.600 idt_A: 0.680 D_B: 0.171 G_B: 0.522 cycle_B: 1.772 idt_B: 0.243 \n",
            "End of epoch 88 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0000471 -> 0.0000431\n",
            "(epoch: 89, iters: 100, time: 0.404, data: 0.259) D_A: 0.070 G_A: 0.917 cycle_A: 0.655 idt_A: 0.631 D_B: 0.054 G_B: 0.548 cycle_B: 2.034 idt_B: 0.273 \n",
            "End of epoch 89 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000431 -> 0.0000392\n",
            "(epoch: 90, iters: 100, time: 0.360, data: 0.362) D_A: 0.050 G_A: 0.391 cycle_A: 0.390 idt_A: 0.718 D_B: 0.047 G_B: 0.778 cycle_B: 1.896 idt_B: 0.137 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0000392 -> 0.0000353\n",
            "(epoch: 91, iters: 100, time: 0.406, data: 0.278) D_A: 0.165 G_A: 0.225 cycle_A: 0.695 idt_A: 0.616 D_B: 0.029 G_B: 0.446 cycle_B: 1.486 idt_B: 0.271 \n",
            "End of epoch 91 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000353 -> 0.0000314\n",
            "(epoch: 92, iters: 100, time: 1.164, data: 0.397) D_A: 0.126 G_A: 0.814 cycle_A: 0.343 idt_A: 0.617 D_B: 0.144 G_B: 0.377 cycle_B: 1.514 idt_B: 0.131 \n",
            "End of epoch 92 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000314 -> 0.0000275\n",
            "(epoch: 93, iters: 100, time: 0.407, data: 0.245) D_A: 0.060 G_A: 0.280 cycle_A: 0.415 idt_A: 0.750 D_B: 0.084 G_B: 0.480 cycle_B: 1.939 idt_B: 0.133 \n",
            "End of epoch 93 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0000275 -> 0.0000235\n",
            "(epoch: 94, iters: 100, time: 0.368, data: 0.382) D_A: 0.153 G_A: 0.316 cycle_A: 0.592 idt_A: 0.704 D_B: 0.060 G_B: 1.111 cycle_B: 1.767 idt_B: 0.263 \n",
            "End of epoch 94 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000235 -> 0.0000196\n",
            "(epoch: 95, iters: 100, time: 0.367, data: 0.276) D_A: 0.107 G_A: 0.272 cycle_A: 0.555 idt_A: 0.499 D_B: 0.103 G_B: 0.663 cycle_B: 1.066 idt_B: 0.208 \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000196 -> 0.0000157\n",
            "(epoch: 96, iters: 100, time: 1.160, data: 0.389) D_A: 0.075 G_A: 0.499 cycle_A: 0.520 idt_A: 0.746 D_B: 0.060 G_B: 0.721 cycle_B: 1.905 idt_B: 0.185 \n",
            "End of epoch 96 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0000157 -> 0.0000118\n",
            "(epoch: 97, iters: 100, time: 0.385, data: 0.249) D_A: 0.157 G_A: 0.717 cycle_A: 0.326 idt_A: 0.725 D_B: 0.061 G_B: 0.925 cycle_B: 1.845 idt_B: 0.149 \n",
            "End of epoch 97 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0000118 -> 0.0000078\n",
            "(epoch: 98, iters: 100, time: 0.362, data: 0.378) D_A: 0.089 G_A: 0.445 cycle_A: 0.669 idt_A: 0.642 D_B: 0.027 G_B: 0.760 cycle_B: 1.776 idt_B: 0.275 \n",
            "End of epoch 98 / 100 \t Time Taken: 39 sec\n",
            "learning rate 0.0000078 -> 0.0000039\n",
            "(epoch: 99, iters: 100, time: 0.362, data: 0.234) D_A: 0.103 G_A: 0.440 cycle_A: 0.352 idt_A: 0.371 D_B: 0.078 G_B: 0.898 cycle_B: 1.324 idt_B: 0.118 \n",
            "End of epoch 99 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0000039 -> 0.0000000\n",
            "(epoch: 100, iters: 100, time: 1.414, data: 0.244) D_A: 0.113 G_A: 0.442 cycle_A: 0.349 idt_A: 0.419 D_B: 0.137 G_B: 0.382 cycle_B: 1.124 idt_B: 0.114 \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 100 \t Time Taken: 41 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2502, 0.2505, 0.2505, 0.2488],\n",
            "        [0.2500, 0.2507, 0.2505, 0.2487],\n",
            "        [0.2502, 0.2508, 0.2506, 0.2484],\n",
            "        [0.2504, 0.2507, 0.2506, 0.2484],\n",
            "        [0.2510, 0.2508, 0.2507, 0.2475]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2505, 0.2511, 0.2510, 0.2474],\n",
            "        [0.2503, 0.2513, 0.2510, 0.2474],\n",
            "        [0.2507, 0.2513, 0.2510, 0.2470],\n",
            "        [0.2510, 0.2510, 0.2509, 0.2472],\n",
            "        [0.2524, 0.2510, 0.2509, 0.2458]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2510, 0.2518, 0.2517, 0.2456],\n",
            "        [0.2513, 0.2518, 0.2513, 0.2456],\n",
            "        [0.2515, 0.2519, 0.2514, 0.2452],\n",
            "        [0.2517, 0.2516, 0.2513, 0.2453],\n",
            "        [0.2537, 0.2517, 0.2514, 0.2432]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2516, 0.2523, 0.2521, 0.2441],\n",
            "        [0.2518, 0.2524, 0.2517, 0.2442],\n",
            "        [0.2521, 0.2525, 0.2518, 0.2437],\n",
            "        [0.2525, 0.2521, 0.2517, 0.2436],\n",
            "        [0.2548, 0.2524, 0.2521, 0.2407]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2519, 0.2528, 0.2525, 0.2428],\n",
            "        [0.2521, 0.2530, 0.2521, 0.2428],\n",
            "        [0.2527, 0.2531, 0.2522, 0.2420],\n",
            "        [0.2533, 0.2527, 0.2521, 0.2419],\n",
            "        [0.2565, 0.2529, 0.2525, 0.2381]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2523, 0.2532, 0.2529, 0.2415],\n",
            "        [0.2526, 0.2535, 0.2525, 0.2415],\n",
            "        [0.2532, 0.2536, 0.2525, 0.2407],\n",
            "        [0.2539, 0.2532, 0.2525, 0.2405],\n",
            "        [0.2572, 0.2535, 0.2530, 0.2363]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2525, 0.2537, 0.2533, 0.2404],\n",
            "        [0.2528, 0.2540, 0.2529, 0.2403],\n",
            "        [0.2537, 0.2540, 0.2528, 0.2395],\n",
            "        [0.2545, 0.2534, 0.2527, 0.2394],\n",
            "        [0.2580, 0.2539, 0.2533, 0.2349]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2528, 0.2542, 0.2538, 0.2392],\n",
            "        [0.2533, 0.2544, 0.2531, 0.2392],\n",
            "        [0.2542, 0.2543, 0.2531, 0.2384],\n",
            "        [0.2550, 0.2537, 0.2530, 0.2383],\n",
            "        [0.2585, 0.2544, 0.2538, 0.2333]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2532, 0.2544, 0.2540, 0.2383],\n",
            "        [0.2534, 0.2548, 0.2535, 0.2383],\n",
            "        [0.2545, 0.2546, 0.2533, 0.2375],\n",
            "        [0.2556, 0.2540, 0.2532, 0.2373],\n",
            "        [0.2598, 0.2544, 0.2537, 0.2321]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2537, 0.2549, 0.2544, 0.2371],\n",
            "        [0.2538, 0.2553, 0.2538, 0.2371],\n",
            "        [0.2552, 0.2550, 0.2535, 0.2363],\n",
            "        [0.2561, 0.2544, 0.2534, 0.2361],\n",
            "        [0.2605, 0.2548, 0.2540, 0.2306]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2538, 0.2553, 0.2547, 0.2362],\n",
            "        [0.2542, 0.2555, 0.2539, 0.2364],\n",
            "        [0.2554, 0.2553, 0.2537, 0.2356],\n",
            "        [0.2565, 0.2545, 0.2536, 0.2353],\n",
            "        [0.2614, 0.2551, 0.2543, 0.2292]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2541, 0.2555, 0.2550, 0.2355],\n",
            "        [0.2545, 0.2558, 0.2542, 0.2355],\n",
            "        [0.2558, 0.2556, 0.2540, 0.2346],\n",
            "        [0.2570, 0.2549, 0.2539, 0.2343],\n",
            "        [0.2623, 0.2553, 0.2545, 0.2279]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2541, 0.2560, 0.2554, 0.2346],\n",
            "        [0.2546, 0.2563, 0.2546, 0.2345],\n",
            "        [0.2561, 0.2560, 0.2543, 0.2336],\n",
            "        [0.2572, 0.2553, 0.2542, 0.2334],\n",
            "        [0.2628, 0.2558, 0.2549, 0.2265]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2543, 0.2562, 0.2556, 0.2338],\n",
            "        [0.2549, 0.2566, 0.2548, 0.2337],\n",
            "        [0.2562, 0.2564, 0.2546, 0.2328],\n",
            "        [0.2575, 0.2556, 0.2545, 0.2324],\n",
            "        [0.2632, 0.2564, 0.2554, 0.2250]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2545, 0.2566, 0.2559, 0.2330],\n",
            "        [0.2552, 0.2570, 0.2551, 0.2328],\n",
            "        [0.2567, 0.2568, 0.2548, 0.2317],\n",
            "        [0.2581, 0.2559, 0.2547, 0.2313],\n",
            "        [0.2642, 0.2566, 0.2556, 0.2236]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2548, 0.2569, 0.2561, 0.2322],\n",
            "        [0.2554, 0.2572, 0.2553, 0.2321],\n",
            "        [0.2571, 0.2570, 0.2550, 0.2309],\n",
            "        [0.2585, 0.2562, 0.2549, 0.2304],\n",
            "        [0.2649, 0.2569, 0.2559, 0.2223]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2548, 0.2572, 0.2565, 0.2314],\n",
            "        [0.2555, 0.2577, 0.2556, 0.2313],\n",
            "        [0.2571, 0.2575, 0.2554, 0.2300],\n",
            "        [0.2586, 0.2567, 0.2553, 0.2294],\n",
            "        [0.2653, 0.2575, 0.2563, 0.2209]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2552, 0.2574, 0.2566, 0.2308],\n",
            "        [0.2557, 0.2580, 0.2558, 0.2305],\n",
            "        [0.2575, 0.2579, 0.2556, 0.2290],\n",
            "        [0.2591, 0.2570, 0.2555, 0.2284],\n",
            "        [0.2663, 0.2576, 0.2564, 0.2197]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2554, 0.2577, 0.2569, 0.2301],\n",
            "        [0.2559, 0.2583, 0.2561, 0.2297],\n",
            "        [0.2576, 0.2584, 0.2560, 0.2280],\n",
            "        [0.2596, 0.2572, 0.2557, 0.2275],\n",
            "        [0.2673, 0.2577, 0.2565, 0.2185]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2557, 0.2578, 0.2570, 0.2294],\n",
            "        [0.2561, 0.2585, 0.2563, 0.2290],\n",
            "        [0.2581, 0.2585, 0.2561, 0.2273],\n",
            "        [0.2600, 0.2574, 0.2559, 0.2267],\n",
            "        [0.2679, 0.2580, 0.2568, 0.2173]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2558, 0.2582, 0.2573, 0.2287],\n",
            "        [0.2567, 0.2587, 0.2564, 0.2282],\n",
            "        [0.2584, 0.2589, 0.2564, 0.2263],\n",
            "        [0.2607, 0.2575, 0.2560, 0.2257],\n",
            "        [0.2686, 0.2582, 0.2570, 0.2162]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2561, 0.2584, 0.2575, 0.2280],\n",
            "        [0.2569, 0.2590, 0.2566, 0.2276],\n",
            "        [0.2585, 0.2592, 0.2566, 0.2256],\n",
            "        [0.2610, 0.2578, 0.2562, 0.2250],\n",
            "        [0.2690, 0.2586, 0.2573, 0.2152]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2563, 0.2585, 0.2576, 0.2275],\n",
            "        [0.2570, 0.2593, 0.2568, 0.2269],\n",
            "        [0.2588, 0.2596, 0.2569, 0.2247],\n",
            "        [0.2615, 0.2580, 0.2564, 0.2240],\n",
            "        [0.2697, 0.2588, 0.2574, 0.2141]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2566, 0.2587, 0.2578, 0.2268],\n",
            "        [0.2575, 0.2595, 0.2569, 0.2261],\n",
            "        [0.2596, 0.2596, 0.2568, 0.2241],\n",
            "        [0.2621, 0.2581, 0.2564, 0.2234],\n",
            "        [0.2707, 0.2588, 0.2574, 0.2131]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2569, 0.2588, 0.2579, 0.2264],\n",
            "        [0.2574, 0.2597, 0.2571, 0.2258],\n",
            "        [0.2597, 0.2598, 0.2570, 0.2235],\n",
            "        [0.2624, 0.2583, 0.2566, 0.2227],\n",
            "        [0.2711, 0.2591, 0.2577, 0.2122]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2571, 0.2589, 0.2580, 0.2260],\n",
            "        [0.2577, 0.2599, 0.2573, 0.2252],\n",
            "        [0.2600, 0.2602, 0.2572, 0.2226],\n",
            "        [0.2629, 0.2585, 0.2567, 0.2219],\n",
            "        [0.2721, 0.2590, 0.2576, 0.2113]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2573, 0.2591, 0.2581, 0.2255],\n",
            "        [0.2578, 0.2602, 0.2575, 0.2246],\n",
            "        [0.2601, 0.2604, 0.2574, 0.2221],\n",
            "        [0.2634, 0.2585, 0.2567, 0.2213],\n",
            "        [0.2728, 0.2592, 0.2577, 0.2103]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2574, 0.2593, 0.2583, 0.2250],\n",
            "        [0.2580, 0.2603, 0.2575, 0.2242],\n",
            "        [0.2603, 0.2606, 0.2576, 0.2216],\n",
            "        [0.2638, 0.2586, 0.2568, 0.2208],\n",
            "        [0.2734, 0.2591, 0.2577, 0.2098]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2576, 0.2594, 0.2584, 0.2246],\n",
            "        [0.2584, 0.2603, 0.2576, 0.2237],\n",
            "        [0.2608, 0.2605, 0.2575, 0.2211],\n",
            "        [0.2642, 0.2587, 0.2569, 0.2202],\n",
            "        [0.2740, 0.2591, 0.2576, 0.2092]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2577, 0.2597, 0.2587, 0.2240],\n",
            "        [0.2585, 0.2605, 0.2577, 0.2232],\n",
            "        [0.2609, 0.2609, 0.2578, 0.2204],\n",
            "        [0.2644, 0.2590, 0.2571, 0.2195],\n",
            "        [0.2743, 0.2594, 0.2578, 0.2085]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2580, 0.2597, 0.2587, 0.2236],\n",
            "        [0.2587, 0.2607, 0.2578, 0.2228],\n",
            "        [0.2611, 0.2611, 0.2579, 0.2198],\n",
            "        [0.2647, 0.2591, 0.2572, 0.2190],\n",
            "        [0.2748, 0.2595, 0.2579, 0.2078]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2583, 0.2598, 0.2587, 0.2232],\n",
            "        [0.2591, 0.2608, 0.2579, 0.2222],\n",
            "        [0.2617, 0.2611, 0.2578, 0.2194],\n",
            "        [0.2652, 0.2591, 0.2571, 0.2185],\n",
            "        [0.2757, 0.2593, 0.2577, 0.2072]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2584, 0.2599, 0.2588, 0.2228],\n",
            "        [0.2591, 0.2609, 0.2581, 0.2219],\n",
            "        [0.2618, 0.2612, 0.2580, 0.2190],\n",
            "        [0.2655, 0.2592, 0.2572, 0.2181],\n",
            "        [0.2764, 0.2593, 0.2577, 0.2067]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2586, 0.2600, 0.2589, 0.2225],\n",
            "        [0.2593, 0.2610, 0.2581, 0.2216],\n",
            "        [0.2619, 0.2614, 0.2581, 0.2187],\n",
            "        [0.2658, 0.2592, 0.2572, 0.2178],\n",
            "        [0.2770, 0.2592, 0.2576, 0.2062]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2587, 0.2601, 0.2591, 0.2221],\n",
            "        [0.2597, 0.2611, 0.2581, 0.2212],\n",
            "        [0.2623, 0.2614, 0.2581, 0.2183],\n",
            "        [0.2660, 0.2594, 0.2573, 0.2173],\n",
            "        [0.2774, 0.2593, 0.2577, 0.2056]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2590, 0.2601, 0.2590, 0.2219],\n",
            "        [0.2597, 0.2611, 0.2582, 0.2209],\n",
            "        [0.2624, 0.2614, 0.2581, 0.2180],\n",
            "        [0.2662, 0.2594, 0.2574, 0.2170],\n",
            "        [0.2778, 0.2593, 0.2577, 0.2053]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2590, 0.2602, 0.2591, 0.2217],\n",
            "        [0.2600, 0.2612, 0.2582, 0.2206],\n",
            "        [0.2628, 0.2615, 0.2581, 0.2177],\n",
            "        [0.2665, 0.2594, 0.2574, 0.2167],\n",
            "        [0.2783, 0.2593, 0.2576, 0.2048]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2593, 0.2602, 0.2591, 0.2215],\n",
            "        [0.2600, 0.2613, 0.2583, 0.2204],\n",
            "        [0.2629, 0.2616, 0.2582, 0.2174],\n",
            "        [0.2667, 0.2595, 0.2574, 0.2163],\n",
            "        [0.2787, 0.2593, 0.2576, 0.2044]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2593, 0.2603, 0.2592, 0.2213],\n",
            "        [0.2601, 0.2613, 0.2584, 0.2201],\n",
            "        [0.2630, 0.2617, 0.2583, 0.2170],\n",
            "        [0.2671, 0.2595, 0.2574, 0.2160],\n",
            "        [0.2790, 0.2593, 0.2576, 0.2040]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2594, 0.2604, 0.2592, 0.2210],\n",
            "        [0.2604, 0.2613, 0.2584, 0.2199],\n",
            "        [0.2633, 0.2617, 0.2582, 0.2168],\n",
            "        [0.2673, 0.2595, 0.2574, 0.2158],\n",
            "        [0.2794, 0.2593, 0.2576, 0.2036]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2595, 0.2604, 0.2593, 0.2208],\n",
            "        [0.2605, 0.2613, 0.2584, 0.2197],\n",
            "        [0.2633, 0.2618, 0.2583, 0.2166],\n",
            "        [0.2675, 0.2595, 0.2574, 0.2155],\n",
            "        [0.2796, 0.2594, 0.2577, 0.2033]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2596, 0.2604, 0.2593, 0.2207],\n",
            "        [0.2606, 0.2614, 0.2584, 0.2196],\n",
            "        [0.2635, 0.2618, 0.2583, 0.2164],\n",
            "        [0.2677, 0.2595, 0.2575, 0.2153],\n",
            "        [0.2799, 0.2594, 0.2577, 0.2031]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2597, 0.2604, 0.2593, 0.2206],\n",
            "        [0.2608, 0.2614, 0.2584, 0.2194],\n",
            "        [0.2636, 0.2618, 0.2584, 0.2162],\n",
            "        [0.2679, 0.2596, 0.2575, 0.2151],\n",
            "        [0.2801, 0.2594, 0.2577, 0.2028]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2597, 0.2605, 0.2594, 0.2205],\n",
            "        [0.2608, 0.2614, 0.2584, 0.2193],\n",
            "        [0.2637, 0.2619, 0.2584, 0.2160],\n",
            "        [0.2680, 0.2596, 0.2575, 0.2149],\n",
            "        [0.2803, 0.2594, 0.2577, 0.2027]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2598, 0.2605, 0.2594, 0.2204],\n",
            "        [0.2608, 0.2615, 0.2585, 0.2192],\n",
            "        [0.2638, 0.2619, 0.2584, 0.2159],\n",
            "        [0.2682, 0.2596, 0.2575, 0.2148],\n",
            "        [0.2805, 0.2593, 0.2577, 0.2025]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2599, 0.2605, 0.2594, 0.2203],\n",
            "        [0.2609, 0.2615, 0.2585, 0.2191],\n",
            "        [0.2639, 0.2620, 0.2585, 0.2157],\n",
            "        [0.2683, 0.2596, 0.2575, 0.2146],\n",
            "        [0.2807, 0.2594, 0.2577, 0.2023]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2599, 0.2606, 0.2594, 0.2201],\n",
            "        [0.2610, 0.2615, 0.2585, 0.2189],\n",
            "        [0.2639, 0.2620, 0.2585, 0.2156],\n",
            "        [0.2685, 0.2596, 0.2575, 0.2145],\n",
            "        [0.2810, 0.2593, 0.2576, 0.2021]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2600, 0.2606, 0.2594, 0.2201],\n",
            "        [0.2611, 0.2615, 0.2585, 0.2189],\n",
            "        [0.2640, 0.2620, 0.2585, 0.2155],\n",
            "        [0.2685, 0.2595, 0.2575, 0.2145],\n",
            "        [0.2811, 0.2593, 0.2576, 0.2021]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2600, 0.2605, 0.2594, 0.2200],\n",
            "        [0.2611, 0.2615, 0.2585, 0.2189],\n",
            "        [0.2641, 0.2620, 0.2585, 0.2155],\n",
            "        [0.2686, 0.2595, 0.2574, 0.2144],\n",
            "        [0.2812, 0.2592, 0.2575, 0.2020]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2600, 0.2606, 0.2594, 0.2200],\n",
            "        [0.2611, 0.2615, 0.2585, 0.2189],\n",
            "        [0.2641, 0.2620, 0.2585, 0.2155],\n",
            "        [0.2686, 0.2595, 0.2574, 0.2144],\n",
            "        [0.2812, 0.2592, 0.2575, 0.2020]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)], 'cell_netG_B': [tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64), tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2502, 0.2504, 0.2503, 0.2491],\n",
            "        [0.2502, 0.2505, 0.2505, 0.2488],\n",
            "        [0.2502, 0.2507, 0.2506, 0.2485],\n",
            "        [0.2505, 0.2505, 0.2504, 0.2486],\n",
            "        [0.2508, 0.2505, 0.2504, 0.2484]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2502, 0.2509, 0.2508, 0.2481],\n",
            "        [0.2501, 0.2513, 0.2512, 0.2475],\n",
            "        [0.2507, 0.2512, 0.2510, 0.2470],\n",
            "        [0.2509, 0.2509, 0.2508, 0.2474],\n",
            "        [0.2516, 0.2509, 0.2507, 0.2467]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2504, 0.2513, 0.2511, 0.2473],\n",
            "        [0.2503, 0.2518, 0.2516, 0.2464],\n",
            "        [0.2510, 0.2518, 0.2515, 0.2458],\n",
            "        [0.2514, 0.2514, 0.2512, 0.2461],\n",
            "        [0.2523, 0.2514, 0.2512, 0.2451]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2506, 0.2516, 0.2514, 0.2464],\n",
            "        [0.2504, 0.2523, 0.2520, 0.2452],\n",
            "        [0.2512, 0.2523, 0.2520, 0.2445],\n",
            "        [0.2514, 0.2520, 0.2517, 0.2449],\n",
            "        [0.2524, 0.2520, 0.2517, 0.2440]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2510, 0.2520, 0.2516, 0.2454],\n",
            "        [0.2510, 0.2527, 0.2523, 0.2439],\n",
            "        [0.2517, 0.2528, 0.2523, 0.2432],\n",
            "        [0.2524, 0.2521, 0.2518, 0.2437],\n",
            "        [0.2533, 0.2522, 0.2518, 0.2426]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2509, 0.2523, 0.2519, 0.2449],\n",
            "        [0.2504, 0.2536, 0.2530, 0.2430],\n",
            "        [0.2519, 0.2535, 0.2529, 0.2418],\n",
            "        [0.2520, 0.2529, 0.2525, 0.2426],\n",
            "        [0.2539, 0.2526, 0.2522, 0.2413]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2510, 0.2525, 0.2520, 0.2445],\n",
            "        [0.2504, 0.2538, 0.2532, 0.2425],\n",
            "        [0.2521, 0.2537, 0.2530, 0.2412],\n",
            "        [0.2525, 0.2530, 0.2525, 0.2421],\n",
            "        [0.2543, 0.2529, 0.2525, 0.2403]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2511, 0.2527, 0.2522, 0.2440],\n",
            "        [0.2505, 0.2542, 0.2535, 0.2418],\n",
            "        [0.2527, 0.2539, 0.2532, 0.2402],\n",
            "        [0.2528, 0.2534, 0.2528, 0.2410],\n",
            "        [0.2551, 0.2533, 0.2528, 0.2389]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2514, 0.2529, 0.2524, 0.2433],\n",
            "        [0.2508, 0.2544, 0.2537, 0.2411],\n",
            "        [0.2532, 0.2542, 0.2534, 0.2391],\n",
            "        [0.2534, 0.2536, 0.2529, 0.2401],\n",
            "        [0.2559, 0.2535, 0.2529, 0.2377]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2513, 0.2532, 0.2526, 0.2430],\n",
            "        [0.2503, 0.2550, 0.2541, 0.2406],\n",
            "        [0.2527, 0.2550, 0.2541, 0.2382],\n",
            "        [0.2537, 0.2538, 0.2531, 0.2394],\n",
            "        [0.2561, 0.2539, 0.2533, 0.2367]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2515, 0.2533, 0.2527, 0.2425],\n",
            "        [0.2508, 0.2552, 0.2542, 0.2398],\n",
            "        [0.2532, 0.2554, 0.2543, 0.2372],\n",
            "        [0.2543, 0.2541, 0.2532, 0.2385],\n",
            "        [0.2571, 0.2540, 0.2533, 0.2357]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2519, 0.2533, 0.2526, 0.2422],\n",
            "        [0.2510, 0.2553, 0.2543, 0.2394],\n",
            "        [0.2543, 0.2551, 0.2539, 0.2367],\n",
            "        [0.2551, 0.2538, 0.2530, 0.2381],\n",
            "        [0.2579, 0.2538, 0.2531, 0.2351]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2524, 0.2533, 0.2526, 0.2417],\n",
            "        [0.2514, 0.2555, 0.2544, 0.2387],\n",
            "        [0.2552, 0.2550, 0.2538, 0.2360],\n",
            "        [0.2556, 0.2540, 0.2531, 0.2373],\n",
            "        [0.2590, 0.2538, 0.2530, 0.2342]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2527, 0.2534, 0.2526, 0.2413],\n",
            "        [0.2518, 0.2556, 0.2545, 0.2381],\n",
            "        [0.2556, 0.2553, 0.2540, 0.2351],\n",
            "        [0.2563, 0.2540, 0.2531, 0.2366],\n",
            "        [0.2599, 0.2537, 0.2529, 0.2335]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2529, 0.2535, 0.2527, 0.2408],\n",
            "        [0.2520, 0.2558, 0.2547, 0.2375],\n",
            "        [0.2565, 0.2553, 0.2539, 0.2342],\n",
            "        [0.2570, 0.2541, 0.2530, 0.2359],\n",
            "        [0.2606, 0.2538, 0.2530, 0.2326]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2532, 0.2536, 0.2528, 0.2403],\n",
            "        [0.2527, 0.2558, 0.2546, 0.2368],\n",
            "        [0.2572, 0.2554, 0.2540, 0.2334],\n",
            "        [0.2578, 0.2540, 0.2529, 0.2353],\n",
            "        [0.2617, 0.2537, 0.2528, 0.2319]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2531, 0.2540, 0.2531, 0.2398],\n",
            "        [0.2526, 0.2563, 0.2550, 0.2361],\n",
            "        [0.2571, 0.2560, 0.2544, 0.2325],\n",
            "        [0.2579, 0.2543, 0.2532, 0.2347],\n",
            "        [0.2620, 0.2539, 0.2530, 0.2311]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2536, 0.2539, 0.2530, 0.2394],\n",
            "        [0.2534, 0.2561, 0.2548, 0.2357],\n",
            "        [0.2581, 0.2557, 0.2542, 0.2320],\n",
            "        [0.2585, 0.2543, 0.2531, 0.2340],\n",
            "        [0.2628, 0.2540, 0.2530, 0.2302]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2540, 0.2540, 0.2531, 0.2390],\n",
            "        [0.2536, 0.2564, 0.2550, 0.2350],\n",
            "        [0.2588, 0.2558, 0.2542, 0.2313],\n",
            "        [0.2591, 0.2543, 0.2531, 0.2334],\n",
            "        [0.2634, 0.2540, 0.2531, 0.2295]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2540, 0.2541, 0.2532, 0.2387],\n",
            "        [0.2538, 0.2565, 0.2551, 0.2346],\n",
            "        [0.2592, 0.2558, 0.2542, 0.2307],\n",
            "        [0.2596, 0.2544, 0.2531, 0.2329],\n",
            "        [0.2640, 0.2541, 0.2531, 0.2288]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2542, 0.2541, 0.2532, 0.2385],\n",
            "        [0.2542, 0.2565, 0.2550, 0.2343],\n",
            "        [0.2595, 0.2560, 0.2542, 0.2302],\n",
            "        [0.2599, 0.2545, 0.2532, 0.2324],\n",
            "        [0.2645, 0.2542, 0.2532, 0.2281]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2544, 0.2542, 0.2532, 0.2383],\n",
            "        [0.2544, 0.2566, 0.2551, 0.2338],\n",
            "        [0.2599, 0.2561, 0.2544, 0.2296],\n",
            "        [0.2607, 0.2544, 0.2531, 0.2318],\n",
            "        [0.2652, 0.2541, 0.2531, 0.2276]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2545, 0.2543, 0.2533, 0.2379],\n",
            "        [0.2547, 0.2568, 0.2552, 0.2333],\n",
            "        [0.2606, 0.2561, 0.2542, 0.2291],\n",
            "        [0.2610, 0.2544, 0.2531, 0.2314],\n",
            "        [0.2659, 0.2541, 0.2530, 0.2270]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2547, 0.2544, 0.2534, 0.2375],\n",
            "        [0.2549, 0.2569, 0.2554, 0.2328],\n",
            "        [0.2611, 0.2562, 0.2543, 0.2284],\n",
            "        [0.2617, 0.2545, 0.2531, 0.2307],\n",
            "        [0.2667, 0.2541, 0.2530, 0.2262]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2549, 0.2544, 0.2534, 0.2373],\n",
            "        [0.2554, 0.2569, 0.2553, 0.2323],\n",
            "        [0.2620, 0.2560, 0.2541, 0.2279],\n",
            "        [0.2622, 0.2545, 0.2531, 0.2302],\n",
            "        [0.2674, 0.2540, 0.2529, 0.2257]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2551, 0.2545, 0.2535, 0.2369],\n",
            "        [0.2558, 0.2570, 0.2554, 0.2317],\n",
            "        [0.2624, 0.2561, 0.2541, 0.2274],\n",
            "        [0.2627, 0.2545, 0.2531, 0.2297],\n",
            "        [0.2681, 0.2540, 0.2529, 0.2251]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2554, 0.2545, 0.2534, 0.2367],\n",
            "        [0.2562, 0.2571, 0.2554, 0.2314],\n",
            "        [0.2630, 0.2561, 0.2541, 0.2268],\n",
            "        [0.2633, 0.2545, 0.2530, 0.2292],\n",
            "        [0.2688, 0.2540, 0.2528, 0.2245]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2555, 0.2547, 0.2535, 0.2363],\n",
            "        [0.2564, 0.2572, 0.2554, 0.2310],\n",
            "        [0.2634, 0.2562, 0.2542, 0.2263],\n",
            "        [0.2635, 0.2547, 0.2531, 0.2287],\n",
            "        [0.2693, 0.2540, 0.2528, 0.2239]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2558, 0.2547, 0.2535, 0.2360],\n",
            "        [0.2566, 0.2573, 0.2556, 0.2305],\n",
            "        [0.2640, 0.2562, 0.2541, 0.2257],\n",
            "        [0.2641, 0.2546, 0.2531, 0.2282],\n",
            "        [0.2700, 0.2540, 0.2527, 0.2233]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2560, 0.2547, 0.2536, 0.2358],\n",
            "        [0.2570, 0.2574, 0.2555, 0.2300],\n",
            "        [0.2642, 0.2563, 0.2541, 0.2253],\n",
            "        [0.2645, 0.2546, 0.2530, 0.2279],\n",
            "        [0.2707, 0.2538, 0.2525, 0.2229]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2563, 0.2547, 0.2535, 0.2356],\n",
            "        [0.2573, 0.2575, 0.2556, 0.2297],\n",
            "        [0.2648, 0.2562, 0.2540, 0.2249],\n",
            "        [0.2651, 0.2545, 0.2529, 0.2276],\n",
            "        [0.2713, 0.2538, 0.2524, 0.2225]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2565, 0.2546, 0.2534, 0.2355],\n",
            "        [0.2577, 0.2573, 0.2554, 0.2296],\n",
            "        [0.2655, 0.2560, 0.2538, 0.2247],\n",
            "        [0.2653, 0.2545, 0.2529, 0.2273],\n",
            "        [0.2720, 0.2536, 0.2523, 0.2222]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2566, 0.2547, 0.2535, 0.2352],\n",
            "        [0.2578, 0.2575, 0.2555, 0.2292],\n",
            "        [0.2655, 0.2561, 0.2539, 0.2244],\n",
            "        [0.2655, 0.2546, 0.2529, 0.2270],\n",
            "        [0.2723, 0.2536, 0.2523, 0.2217]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2570, 0.2546, 0.2534, 0.2350],\n",
            "        [0.2583, 0.2574, 0.2554, 0.2289],\n",
            "        [0.2663, 0.2559, 0.2537, 0.2240],\n",
            "        [0.2663, 0.2543, 0.2527, 0.2267],\n",
            "        [0.2730, 0.2534, 0.2521, 0.2215]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2573, 0.2545, 0.2533, 0.2349],\n",
            "        [0.2586, 0.2573, 0.2553, 0.2287],\n",
            "        [0.2670, 0.2557, 0.2535, 0.2238],\n",
            "        [0.2668, 0.2542, 0.2525, 0.2265],\n",
            "        [0.2734, 0.2534, 0.2520, 0.2212]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2574, 0.2546, 0.2533, 0.2348],\n",
            "        [0.2589, 0.2573, 0.2553, 0.2285],\n",
            "        [0.2673, 0.2558, 0.2534, 0.2235],\n",
            "        [0.2671, 0.2542, 0.2525, 0.2262],\n",
            "        [0.2741, 0.2532, 0.2519, 0.2208]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2576, 0.2545, 0.2533, 0.2346],\n",
            "        [0.2593, 0.2573, 0.2552, 0.2282],\n",
            "        [0.2679, 0.2557, 0.2533, 0.2232],\n",
            "        [0.2677, 0.2541, 0.2524, 0.2259],\n",
            "        [0.2747, 0.2531, 0.2517, 0.2205]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2578, 0.2545, 0.2532, 0.2345],\n",
            "        [0.2596, 0.2572, 0.2552, 0.2280],\n",
            "        [0.2682, 0.2556, 0.2532, 0.2230],\n",
            "        [0.2679, 0.2540, 0.2523, 0.2257],\n",
            "        [0.2751, 0.2530, 0.2516, 0.2202]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2579, 0.2546, 0.2533, 0.2343],\n",
            "        [0.2599, 0.2572, 0.2551, 0.2278],\n",
            "        [0.2686, 0.2555, 0.2531, 0.2227],\n",
            "        [0.2683, 0.2540, 0.2522, 0.2255],\n",
            "        [0.2756, 0.2529, 0.2515, 0.2200]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2581, 0.2545, 0.2532, 0.2342],\n",
            "        [0.2601, 0.2572, 0.2550, 0.2277],\n",
            "        [0.2690, 0.2554, 0.2530, 0.2226],\n",
            "        [0.2687, 0.2539, 0.2521, 0.2253],\n",
            "        [0.2761, 0.2529, 0.2514, 0.2196]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2578, 0.2546, 0.2533, 0.2342],\n",
            "        [0.2599, 0.2573, 0.2552, 0.2276],\n",
            "        [0.2689, 0.2556, 0.2532, 0.2223],\n",
            "        [0.2686, 0.2540, 0.2522, 0.2253],\n",
            "        [0.2760, 0.2530, 0.2516, 0.2195]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2580, 0.2546, 0.2533, 0.2341],\n",
            "        [0.2602, 0.2573, 0.2552, 0.2274],\n",
            "        [0.2692, 0.2555, 0.2532, 0.2221],\n",
            "        [0.2689, 0.2539, 0.2522, 0.2250],\n",
            "        [0.2764, 0.2529, 0.2515, 0.2192]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2582, 0.2546, 0.2533, 0.2340],\n",
            "        [0.2603, 0.2573, 0.2552, 0.2272],\n",
            "        [0.2694, 0.2555, 0.2531, 0.2219],\n",
            "        [0.2691, 0.2539, 0.2522, 0.2248],\n",
            "        [0.2766, 0.2529, 0.2515, 0.2190]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2583, 0.2546, 0.2533, 0.2338],\n",
            "        [0.2605, 0.2573, 0.2552, 0.2270],\n",
            "        [0.2697, 0.2555, 0.2531, 0.2217],\n",
            "        [0.2693, 0.2539, 0.2522, 0.2246],\n",
            "        [0.2770, 0.2528, 0.2514, 0.2188]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2584, 0.2546, 0.2533, 0.2338],\n",
            "        [0.2606, 0.2573, 0.2552, 0.2269],\n",
            "        [0.2698, 0.2555, 0.2531, 0.2216],\n",
            "        [0.2695, 0.2539, 0.2522, 0.2245],\n",
            "        [0.2771, 0.2528, 0.2514, 0.2187]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2584, 0.2545, 0.2532, 0.2338],\n",
            "        [0.2607, 0.2573, 0.2552, 0.2269],\n",
            "        [0.2700, 0.2555, 0.2531, 0.2215],\n",
            "        [0.2696, 0.2539, 0.2521, 0.2244],\n",
            "        [0.2773, 0.2528, 0.2513, 0.2186]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2585, 0.2545, 0.2532, 0.2337],\n",
            "        [0.2607, 0.2573, 0.2551, 0.2268],\n",
            "        [0.2701, 0.2555, 0.2530, 0.2214],\n",
            "        [0.2697, 0.2539, 0.2521, 0.2243],\n",
            "        [0.2775, 0.2527, 0.2513, 0.2185]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2586, 0.2545, 0.2532, 0.2337],\n",
            "        [0.2608, 0.2573, 0.2551, 0.2268],\n",
            "        [0.2702, 0.2554, 0.2530, 0.2214],\n",
            "        [0.2698, 0.2539, 0.2521, 0.2242],\n",
            "        [0.2776, 0.2527, 0.2512, 0.2185]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2586, 0.2545, 0.2532, 0.2337],\n",
            "        [0.2609, 0.2573, 0.2551, 0.2268],\n",
            "        [0.2703, 0.2554, 0.2530, 0.2213],\n",
            "        [0.2698, 0.2539, 0.2521, 0.2242],\n",
            "        [0.2777, 0.2527, 0.2512, 0.2184]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>), tensor([[0.2586, 0.2545, 0.2532, 0.2337],\n",
            "        [0.2609, 0.2573, 0.2551, 0.2267],\n",
            "        [0.2703, 0.2554, 0.2530, 0.2213],\n",
            "        [0.2699, 0.2539, 0.2521, 0.2242],\n",
            "        [0.2777, 0.2527, 0.2512, 0.2184]], device='cuda:0',\n",
            "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN_ReLU_Pool_100_ep --train_name truck_nas_project_layer_types_cycleGAN_ReLU_Pool_100_ep --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 50 --n_epochs 50 --n_epochs_decay 50 --layer_types CycleGan+ReLU+Pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiKqaQtOzP75"
      },
      "source": [
        "## Final Layer Config (ReflectionPad2d_Conv2d)\n",
        "--n_layer_cell: 3\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKtnxi7DzPii",
        "outputId": "2a68e3e0-f5b4-459b-c64b-45624525a470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN_final_3_cell_layer --train_name truck_nas_project_layer_types_cycleGAN_final_3_cell_layer --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 101 --n_epochs 50 --n_epochs_decay 50 --layer_types ReflectionPad2d_Conv2d --n_layers_cell 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTaQnZVZ0Psn"
      },
      "source": [
        "## Final Layer Config (ReflectionPad2d_Conv2d)\n",
        "--n_layer_cell: 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9dqUnG70PKz",
        "outputId": "3009e024-1399-4b6b-b3c5-4cfd02085342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 101                           \t[default: 50]\n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: ReflectionPad2d_Conv2d        \t[default: CycleGan]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_epochs: 50                            \t[default: 100]\n",
            "           n_epochs_decay: 50                            \t[default: 100]\n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_cycleGAN_final_3_cell_layer\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_final_3_cell_layer\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 9.603 M\n",
            "[Network G_B] Total number of parameters : 9.603 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_final_3_cell_layer/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.309, data: 0.252) D_A: 0.357 G_A: 0.320 cycle_A: 1.458 idt_A: 1.439 D_B: 0.532 G_B: 0.594 cycle_B: 3.284 idt_B: 0.739 \n",
            "End of epoch 1 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.316, data: 0.246) D_A: 0.198 G_A: 0.491 cycle_A: 1.166 idt_A: 2.097 D_B: 0.200 G_B: 0.882 cycle_B: 4.067 idt_B: 0.400 \n",
            "End of epoch 2 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.314, data: 0.358) D_A: 0.184 G_A: 0.292 cycle_A: 1.164 idt_A: 1.085 D_B: 0.418 G_B: 0.282 cycle_B: 2.331 idt_B: 0.892 \n",
            "End of epoch 3 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.537, data: 0.360) D_A: 0.130 G_A: 0.514 cycle_A: 1.030 idt_A: 1.271 D_B: 0.125 G_B: 0.494 cycle_B: 2.779 idt_B: 0.419 \n",
            "End of epoch 4 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.309, data: 0.233) D_A: 0.091 G_A: 0.726 cycle_A: 1.076 idt_A: 1.043 D_B: 0.056 G_B: 0.294 cycle_B: 2.543 idt_B: 0.684 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.321, data: 0.230) D_A: 0.187 G_A: 0.978 cycle_A: 1.350 idt_A: 1.155 D_B: 0.079 G_B: 0.223 cycle_B: 2.986 idt_B: 0.761 \n",
            "End of epoch 6 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.325, data: 0.244) D_A: 0.203 G_A: 0.781 cycle_A: 1.475 idt_A: 1.506 D_B: 0.145 G_B: 0.651 cycle_B: 3.672 idt_B: 0.623 \n",
            "End of epoch 7 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.643, data: 0.355) D_A: 0.180 G_A: 0.838 cycle_A: 0.891 idt_A: 1.229 D_B: 0.308 G_B: 0.251 cycle_B: 2.683 idt_B: 0.467 \n",
            "End of epoch 8 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.320, data: 0.395) D_A: 0.161 G_A: 0.431 cycle_A: 1.044 idt_A: 2.188 D_B: 0.192 G_B: 1.226 cycle_B: 3.755 idt_B: 0.561 \n",
            "End of epoch 9 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.315, data: 0.239) D_A: 0.135 G_A: 0.621 cycle_A: 0.676 idt_A: 1.476 D_B: 0.070 G_B: 0.980 cycle_B: 2.677 idt_B: 0.249 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.311, data: 0.257) D_A: 0.114 G_A: 0.617 cycle_A: 0.713 idt_A: 1.866 D_B: 0.360 G_B: 0.665 cycle_B: 3.231 idt_B: 0.294 \n",
            "End of epoch 11 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.588, data: 0.242) D_A: 0.034 G_A: 0.907 cycle_A: 0.702 idt_A: 1.170 D_B: 0.038 G_B: 0.843 cycle_B: 2.833 idt_B: 0.324 \n",
            "End of epoch 12 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.330, data: 0.239) D_A: 0.096 G_A: 0.520 cycle_A: 0.907 idt_A: 0.805 D_B: 0.094 G_B: 0.612 cycle_B: 1.921 idt_B: 0.569 \n",
            "End of epoch 13 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.323, data: 0.342) D_A: 0.245 G_A: 0.388 cycle_A: 0.730 idt_A: 1.316 D_B: 0.034 G_B: 0.461 cycle_B: 2.660 idt_B: 0.292 \n",
            "End of epoch 14 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.313, data: 0.342) D_A: 0.486 G_A: 0.634 cycle_A: 0.773 idt_A: 1.706 D_B: 0.241 G_B: 0.133 cycle_B: 3.274 idt_B: 0.345 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.588, data: 0.225) D_A: 0.224 G_A: 1.072 cycle_A: 0.767 idt_A: 1.506 D_B: 0.131 G_B: 0.515 cycle_B: 2.946 idt_B: 0.249 \n",
            "End of epoch 16 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.321, data: 0.253) D_A: 0.107 G_A: 1.324 cycle_A: 0.745 idt_A: 1.366 D_B: 0.028 G_B: 0.772 cycle_B: 2.785 idt_B: 0.330 \n",
            "End of epoch 17 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.321, data: 0.228) D_A: 0.225 G_A: 0.547 cycle_A: 0.784 idt_A: 1.099 D_B: 0.144 G_B: 0.401 cycle_B: 2.498 idt_B: 0.412 \n",
            "End of epoch 18 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.322, data: 0.252) D_A: 0.107 G_A: 0.773 cycle_A: 0.590 idt_A: 1.263 D_B: 0.019 G_B: 0.994 cycle_B: 3.071 idt_B: 0.290 \n",
            "End of epoch 19 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.861, data: 0.397) D_A: 0.183 G_A: 0.336 cycle_A: 0.764 idt_A: 1.228 D_B: 0.310 G_B: 1.179 cycle_B: 2.956 idt_B: 0.310 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.307, data: 0.345) D_A: 0.139 G_A: 0.878 cycle_A: 1.018 idt_A: 1.081 D_B: 0.226 G_B: 0.231 cycle_B: 2.386 idt_B: 0.524 \n",
            "End of epoch 21 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.288, data: 0.241) D_A: 0.133 G_A: 0.914 cycle_A: 1.141 idt_A: 1.049 D_B: 0.085 G_B: 0.655 cycle_B: 2.946 idt_B: 0.520 \n",
            "End of epoch 22 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.307, data: 0.246) D_A: 0.131 G_A: 0.729 cycle_A: 0.661 idt_A: 1.086 D_B: 0.092 G_B: 0.452 cycle_B: 2.665 idt_B: 0.275 \n",
            "End of epoch 23 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.717, data: 0.381) D_A: 0.084 G_A: 0.624 cycle_A: 1.234 idt_A: 2.282 D_B: 0.131 G_B: 1.060 cycle_B: 3.564 idt_B: 0.587 \n",
            "End of epoch 24 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.303, data: 0.371) D_A: 0.121 G_A: 0.344 cycle_A: 1.036 idt_A: 0.993 D_B: 0.186 G_B: 0.322 cycle_B: 2.025 idt_B: 0.471 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.316, data: 0.231) D_A: 0.235 G_A: 0.210 cycle_A: 0.669 idt_A: 1.127 D_B: 0.233 G_B: 1.400 cycle_B: 2.481 idt_B: 0.266 \n",
            "End of epoch 26 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.314, data: 0.233) D_A: 0.197 G_A: 0.237 cycle_A: 0.637 idt_A: 1.453 D_B: 0.205 G_B: 0.195 cycle_B: 3.895 idt_B: 0.198 \n",
            "End of epoch 27 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.799, data: 0.210) D_A: 0.136 G_A: 0.697 cycle_A: 0.966 idt_A: 1.069 D_B: 0.046 G_B: 0.436 cycle_B: 2.270 idt_B: 0.389 \n",
            "End of epoch 28 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.317, data: 0.409) D_A: 0.116 G_A: 0.146 cycle_A: 1.333 idt_A: 1.166 D_B: 0.022 G_B: 0.976 cycle_B: 3.211 idt_B: 0.284 \n",
            "End of epoch 29 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.311, data: 0.385) D_A: 0.202 G_A: 0.382 cycle_A: 0.954 idt_A: 1.162 D_B: 0.125 G_B: 0.418 cycle_B: 3.029 idt_B: 0.360 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.280, data: 0.392) D_A: 0.256 G_A: 0.774 cycle_A: 0.986 idt_A: 1.446 D_B: 0.214 G_B: 0.219 cycle_B: 4.199 idt_B: 0.430 \n",
            "End of epoch 31 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.767, data: 0.228) D_A: 0.259 G_A: 1.156 cycle_A: 0.854 idt_A: 1.309 D_B: 0.125 G_B: 0.943 cycle_B: 2.939 idt_B: 0.303 \n",
            "End of epoch 32 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.290, data: 0.379) D_A: 0.113 G_A: 0.635 cycle_A: 0.810 idt_A: 1.003 D_B: 0.078 G_B: 0.903 cycle_B: 2.617 idt_B: 0.309 \n",
            "End of epoch 33 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.290, data: 0.255) D_A: 0.175 G_A: 0.546 cycle_A: 1.828 idt_A: 0.678 D_B: 0.039 G_B: 0.865 cycle_B: 2.250 idt_B: 0.493 \n",
            "End of epoch 34 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.283, data: 0.214) D_A: 0.249 G_A: 0.268 cycle_A: 0.429 idt_A: 1.039 D_B: 0.125 G_B: 0.575 cycle_B: 2.803 idt_B: 0.169 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.704, data: 0.362) D_A: 0.270 G_A: 0.776 cycle_A: 1.325 idt_A: 1.735 D_B: 0.089 G_B: 0.623 cycle_B: 2.790 idt_B: 0.707 \n",
            "End of epoch 36 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.286, data: 0.194) D_A: 0.344 G_A: 0.979 cycle_A: 0.920 idt_A: 1.312 D_B: 0.162 G_B: 0.805 cycle_B: 2.745 idt_B: 0.531 \n",
            "End of epoch 37 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.283, data: 0.251) D_A: 0.096 G_A: 0.588 cycle_A: 1.412 idt_A: 1.266 D_B: 0.057 G_B: 0.924 cycle_B: 3.012 idt_B: 0.565 \n",
            "End of epoch 38 / 100 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.297, data: 0.222) D_A: 0.191 G_A: 0.293 cycle_A: 0.720 idt_A: 1.060 D_B: 0.120 G_B: 0.442 cycle_B: 2.149 idt_B: 0.289 \n",
            "End of epoch 39 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.840, data: 0.233) D_A: 0.252 G_A: 0.991 cycle_A: 0.792 idt_A: 0.871 D_B: 0.056 G_B: 0.833 cycle_B: 1.879 idt_B: 0.286 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.280, data: 0.270) D_A: 0.229 G_A: 0.917 cycle_A: 0.670 idt_A: 1.176 D_B: 0.100 G_B: 0.616 cycle_B: 2.931 idt_B: 0.255 \n",
            "End of epoch 41 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.282, data: 0.212) D_A: 0.107 G_A: 0.674 cycle_A: 1.031 idt_A: 1.067 D_B: 0.087 G_B: 0.271 cycle_B: 3.327 idt_B: 0.440 \n",
            "End of epoch 42 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.298, data: 0.235) D_A: 0.136 G_A: 0.606 cycle_A: 0.770 idt_A: 0.776 D_B: 0.071 G_B: 0.629 cycle_B: 1.753 idt_B: 0.299 \n",
            "End of epoch 43 / 100 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.718, data: 0.398) D_A: 0.167 G_A: 0.471 cycle_A: 0.839 idt_A: 1.400 D_B: 0.037 G_B: 0.673 cycle_B: 3.381 idt_B: 0.262 \n",
            "End of epoch 44 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.304, data: 0.238) D_A: 0.067 G_A: 0.251 cycle_A: 1.012 idt_A: 0.937 D_B: 0.095 G_B: 0.828 cycle_B: 2.043 idt_B: 0.380 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.279, data: 0.362) D_A: 0.093 G_A: 0.469 cycle_A: 1.143 idt_A: 0.803 D_B: 0.089 G_B: 0.493 cycle_B: 2.773 idt_B: 0.414 \n",
            "End of epoch 46 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.284, data: 0.226) D_A: 0.168 G_A: 0.415 cycle_A: 0.845 idt_A: 1.369 D_B: 0.158 G_B: 0.678 cycle_B: 2.940 idt_B: 0.318 \n",
            "End of epoch 47 / 100 \t Time Taken: 24 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 0.876, data: 0.238) D_A: 0.078 G_A: 0.526 cycle_A: 1.046 idt_A: 1.362 D_B: 0.067 G_B: 1.223 cycle_B: 3.133 idt_B: 0.471 \n",
            "End of epoch 48 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.280, data: 0.354) D_A: 0.209 G_A: 0.428 cycle_A: 1.341 idt_A: 0.841 D_B: 0.274 G_B: 1.448 cycle_B: 1.781 idt_B: 0.443 \n",
            "End of epoch 49 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0002000 -> 0.0001961\n",
            "(epoch: 50, iters: 100, time: 0.294, data: 0.262) D_A: 0.238 G_A: 0.479 cycle_A: 0.722 idt_A: 1.685 D_B: 0.118 G_B: 0.468 cycle_B: 4.300 idt_B: 0.254 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0001961 -> 0.0001922\n",
            "(epoch: 51, iters: 100, time: 0.320, data: 0.198) D_A: 0.083 G_A: 0.595 cycle_A: 1.283 idt_A: 1.441 D_B: 0.029 G_B: 0.732 cycle_B: 4.140 idt_B: 0.693 \n",
            "End of epoch 51 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0001922 -> 0.0001882\n",
            "(epoch: 52, iters: 100, time: 0.852, data: 0.363) D_A: 0.143 G_A: 0.311 cycle_A: 0.928 idt_A: 1.106 D_B: 0.023 G_B: 1.433 cycle_B: 2.457 idt_B: 0.409 \n",
            "End of epoch 52 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0001882 -> 0.0001843\n",
            "(epoch: 53, iters: 100, time: 0.314, data: 0.252) D_A: 0.142 G_A: 0.371 cycle_A: 0.497 idt_A: 1.093 D_B: 0.038 G_B: 0.651 cycle_B: 2.725 idt_B: 0.231 \n",
            "End of epoch 53 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0001843 -> 0.0001804\n",
            "(epoch: 54, iters: 100, time: 0.333, data: 0.237) D_A: 0.062 G_A: 0.719 cycle_A: 0.838 idt_A: 0.972 D_B: 0.026 G_B: 0.522 cycle_B: 2.223 idt_B: 0.264 \n",
            "End of epoch 54 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0001804 -> 0.0001765\n",
            "(epoch: 55, iters: 100, time: 0.322, data: 0.413) D_A: 0.135 G_A: 0.385 cycle_A: 0.697 idt_A: 0.749 D_B: 0.117 G_B: 1.467 cycle_B: 1.849 idt_B: 0.255 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0001765 -> 0.0001725\n",
            "(epoch: 56, iters: 100, time: 0.836, data: 0.344) D_A: 0.157 G_A: 0.332 cycle_A: 0.944 idt_A: 0.801 D_B: 0.043 G_B: 0.466 cycle_B: 1.692 idt_B: 0.253 \n",
            "End of epoch 56 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0001725 -> 0.0001686\n",
            "(epoch: 57, iters: 100, time: 0.316, data: 0.233) D_A: 0.216 G_A: 0.597 cycle_A: 0.829 idt_A: 1.266 D_B: 0.105 G_B: 0.620 cycle_B: 2.918 idt_B: 0.222 \n",
            "End of epoch 57 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0001686 -> 0.0001647\n",
            "(epoch: 58, iters: 100, time: 0.310, data: 0.197) D_A: 0.164 G_A: 0.280 cycle_A: 1.038 idt_A: 0.968 D_B: 0.068 G_B: 0.709 cycle_B: 1.969 idt_B: 0.420 \n",
            "End of epoch 58 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0001647 -> 0.0001608\n",
            "(epoch: 59, iters: 100, time: 0.315, data: 0.241) D_A: 0.099 G_A: 1.035 cycle_A: 0.685 idt_A: 0.945 D_B: 0.057 G_B: 0.536 cycle_B: 3.345 idt_B: 0.315 \n",
            "End of epoch 59 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0001608 -> 0.0001569\n",
            "(epoch: 60, iters: 100, time: 0.889, data: 0.326) D_A: 0.160 G_A: 0.351 cycle_A: 1.050 idt_A: 0.654 D_B: 0.024 G_B: 0.962 cycle_B: 1.485 idt_B: 0.499 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0001569 -> 0.0001529\n",
            "(epoch: 61, iters: 100, time: 0.284, data: 0.277) D_A: 0.120 G_A: 0.790 cycle_A: 0.811 idt_A: 0.926 D_B: 0.018 G_B: 1.103 cycle_B: 1.684 idt_B: 0.325 \n",
            "End of epoch 61 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0001529 -> 0.0001490\n",
            "(epoch: 62, iters: 100, time: 0.282, data: 0.180) D_A: 0.089 G_A: 0.454 cycle_A: 0.857 idt_A: 1.005 D_B: 0.027 G_B: 0.507 cycle_B: 2.531 idt_B: 0.320 \n",
            "End of epoch 62 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0001490 -> 0.0001451\n",
            "(epoch: 63, iters: 100, time: 0.293, data: 0.344) D_A: 0.207 G_A: 0.669 cycle_A: 0.912 idt_A: 0.756 D_B: 0.063 G_B: 0.515 cycle_B: 2.287 idt_B: 0.427 \n",
            "End of epoch 63 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0001451 -> 0.0001412\n",
            "(epoch: 64, iters: 100, time: 0.952, data: 0.193) D_A: 0.118 G_A: 0.411 cycle_A: 0.819 idt_A: 1.046 D_B: 0.116 G_B: 1.193 cycle_B: 2.476 idt_B: 0.325 \n",
            "End of epoch 64 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0001412 -> 0.0001373\n",
            "(epoch: 65, iters: 100, time: 0.285, data: 0.224) D_A: 0.209 G_A: 0.681 cycle_A: 0.623 idt_A: 1.152 D_B: 0.064 G_B: 0.780 cycle_B: 2.001 idt_B: 0.177 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0001373 -> 0.0001333\n",
            "(epoch: 66, iters: 100, time: 0.308, data: 0.337) D_A: 0.120 G_A: 0.556 cycle_A: 1.007 idt_A: 0.674 D_B: 0.188 G_B: 0.403 cycle_B: 1.688 idt_B: 0.439 \n",
            "End of epoch 66 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0001333 -> 0.0001294\n",
            "(epoch: 67, iters: 100, time: 0.308, data: 0.219) D_A: 0.086 G_A: 0.550 cycle_A: 1.078 idt_A: 1.067 D_B: 0.083 G_B: 1.136 cycle_B: 2.504 idt_B: 0.342 \n",
            "End of epoch 67 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0001294 -> 0.0001255\n",
            "(epoch: 68, iters: 100, time: 0.907, data: 0.219) D_A: 0.052 G_A: 0.679 cycle_A: 0.517 idt_A: 1.258 D_B: 0.036 G_B: 0.670 cycle_B: 2.731 idt_B: 0.197 \n",
            "End of epoch 68 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0001255 -> 0.0001216\n",
            "(epoch: 69, iters: 100, time: 0.315, data: 0.222) D_A: 0.077 G_A: 0.809 cycle_A: 1.267 idt_A: 0.975 D_B: 0.130 G_B: 0.320 cycle_B: 2.111 idt_B: 0.529 \n",
            "End of epoch 69 / 100 \t Time Taken: 27 sec\n",
            "learning rate 0.0001216 -> 0.0001176\n",
            "(epoch: 70, iters: 100, time: 0.310, data: 0.338) D_A: 0.190 G_A: 0.291 cycle_A: 0.655 idt_A: 0.919 D_B: 0.016 G_B: 1.133 cycle_B: 3.794 idt_B: 0.231 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0001176 -> 0.0001137\n",
            "(epoch: 71, iters: 100, time: 0.306, data: 0.395) D_A: 0.136 G_A: 0.729 cycle_A: 0.812 idt_A: 1.143 D_B: 0.034 G_B: 0.690 cycle_B: 2.601 idt_B: 0.364 \n",
            "End of epoch 71 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0001137 -> 0.0001098\n",
            "(epoch: 72, iters: 100, time: 1.160, data: 0.244) D_A: 0.111 G_A: 0.556 cycle_A: 0.677 idt_A: 1.247 D_B: 0.022 G_B: 0.981 cycle_B: 2.668 idt_B: 0.235 \n",
            "End of epoch 72 / 100 \t Time Taken: 28 sec\n",
            "learning rate 0.0001098 -> 0.0001059\n",
            "(epoch: 73, iters: 100, time: 0.311, data: 0.293) D_A: 0.068 G_A: 0.609 cycle_A: 0.834 idt_A: 0.994 D_B: 0.046 G_B: 0.546 cycle_B: 2.509 idt_B: 0.301 \n",
            "End of epoch 73 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0001059 -> 0.0001020\n",
            "(epoch: 74, iters: 100, time: 0.276, data: 0.286) D_A: 0.321 G_A: 0.402 cycle_A: 0.596 idt_A: 0.604 D_B: 0.057 G_B: 0.515 cycle_B: 1.422 idt_B: 0.220 \n",
            "End of epoch 74 / 100 \t Time Taken: 24 sec\n",
            "learning rate 0.0001020 -> 0.0000980\n",
            "(epoch: 75, iters: 100, time: 0.288, data: 0.236) D_A: 0.119 G_A: 0.390 cycle_A: 0.555 idt_A: 1.040 D_B: 0.019 G_B: 0.772 cycle_B: 2.756 idt_B: 0.184 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000980 -> 0.0000941\n",
            "(epoch: 76, iters: 100, time: 1.127, data: 0.229) D_A: 0.392 G_A: 1.519 cycle_A: 0.945 idt_A: 0.835 D_B: 0.049 G_B: 0.697 cycle_B: 1.707 idt_B: 0.279 \n",
            "End of epoch 76 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000941 -> 0.0000902\n",
            "(epoch: 77, iters: 100, time: 0.287, data: 0.339) D_A: 0.146 G_A: 0.607 cycle_A: 0.837 idt_A: 1.218 D_B: 0.020 G_B: 0.649 cycle_B: 2.766 idt_B: 0.339 \n",
            "End of epoch 77 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000902 -> 0.0000863\n",
            "(epoch: 78, iters: 100, time: 0.282, data: 0.190) D_A: 0.060 G_A: 0.583 cycle_A: 0.810 idt_A: 0.819 D_B: 0.036 G_B: 0.635 cycle_B: 2.406 idt_B: 0.273 \n",
            "End of epoch 78 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000863 -> 0.0000824\n",
            "(epoch: 79, iters: 100, time: 0.289, data: 0.352) D_A: 0.028 G_A: 0.728 cycle_A: 0.613 idt_A: 1.156 D_B: 0.058 G_B: 0.627 cycle_B: 2.641 idt_B: 0.272 \n",
            "End of epoch 79 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000824 -> 0.0000784\n",
            "(epoch: 80, iters: 100, time: 0.949, data: 0.191) D_A: 0.028 G_A: 0.336 cycle_A: 0.797 idt_A: 1.052 D_B: 0.027 G_B: 0.675 cycle_B: 2.098 idt_B: 0.368 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000784 -> 0.0000745\n",
            "(epoch: 81, iters: 100, time: 0.295, data: 0.231) D_A: 0.131 G_A: 0.309 cycle_A: 0.692 idt_A: 0.902 D_B: 0.061 G_B: 1.130 cycle_B: 1.920 idt_B: 0.172 \n",
            "End of epoch 81 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000745 -> 0.0000706\n",
            "(epoch: 82, iters: 100, time: 0.283, data: 0.443) D_A: 0.124 G_A: 0.337 cycle_A: 0.570 idt_A: 0.793 D_B: 0.014 G_B: 0.549 cycle_B: 1.890 idt_B: 0.192 \n",
            "End of epoch 82 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000706 -> 0.0000667\n",
            "(epoch: 83, iters: 100, time: 0.286, data: 0.231) D_A: 0.048 G_A: 0.749 cycle_A: 0.642 idt_A: 0.928 D_B: 0.057 G_B: 1.241 cycle_B: 2.045 idt_B: 0.220 \n",
            "End of epoch 83 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000667 -> 0.0000627\n",
            "(epoch: 84, iters: 100, time: 1.029, data: 0.178) D_A: 0.335 G_A: 0.437 cycle_A: 0.666 idt_A: 0.608 D_B: 0.030 G_B: 0.893 cycle_B: 1.350 idt_B: 0.223 \n",
            "End of epoch 84 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000627 -> 0.0000588\n",
            "(epoch: 85, iters: 100, time: 0.305, data: 0.337) D_A: 0.275 G_A: 0.762 cycle_A: 0.430 idt_A: 0.964 D_B: 0.008 G_B: 0.504 cycle_B: 1.559 idt_B: 0.147 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000588 -> 0.0000549\n",
            "(epoch: 86, iters: 100, time: 0.298, data: 0.237) D_A: 0.135 G_A: 0.545 cycle_A: 0.865 idt_A: 0.693 D_B: 0.059 G_B: 0.478 cycle_B: 1.560 idt_B: 0.409 \n",
            "End of epoch 86 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000549 -> 0.0000510\n",
            "(epoch: 87, iters: 100, time: 0.292, data: 0.394) D_A: 0.105 G_A: 0.625 cycle_A: 0.629 idt_A: 1.259 D_B: 0.051 G_B: 0.773 cycle_B: 2.625 idt_B: 0.278 \n",
            "End of epoch 87 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000510 -> 0.0000471\n",
            "(epoch: 88, iters: 100, time: 1.184, data: 0.211) D_A: 0.131 G_A: 0.442 cycle_A: 0.584 idt_A: 0.844 D_B: 0.041 G_B: 0.957 cycle_B: 1.875 idt_B: 0.163 \n",
            "End of epoch 88 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000471 -> 0.0000431\n",
            "(epoch: 89, iters: 100, time: 0.298, data: 0.242) D_A: 0.082 G_A: 0.893 cycle_A: 1.057 idt_A: 0.833 D_B: 0.052 G_B: 0.729 cycle_B: 1.849 idt_B: 0.482 \n",
            "End of epoch 89 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000431 -> 0.0000392\n",
            "(epoch: 90, iters: 100, time: 0.283, data: 0.323) D_A: 0.039 G_A: 0.365 cycle_A: 0.858 idt_A: 1.338 D_B: 0.035 G_B: 1.364 cycle_B: 2.764 idt_B: 0.367 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000392 -> 0.0000353\n",
            "(epoch: 91, iters: 100, time: 0.290, data: 0.232) D_A: 0.121 G_A: 0.565 cycle_A: 0.579 idt_A: 0.876 D_B: 0.025 G_B: 1.076 cycle_B: 2.056 idt_B: 0.197 \n",
            "End of epoch 91 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000353 -> 0.0000314\n",
            "(epoch: 92, iters: 100, time: 1.236, data: 0.245) D_A: 0.126 G_A: 0.955 cycle_A: 0.434 idt_A: 1.142 D_B: 0.023 G_B: 1.136 cycle_B: 2.185 idt_B: 0.147 \n",
            "End of epoch 92 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000314 -> 0.0000275\n",
            "(epoch: 93, iters: 100, time: 0.287, data: 0.337) D_A: 0.144 G_A: 0.855 cycle_A: 0.399 idt_A: 1.216 D_B: 0.012 G_B: 1.000 cycle_B: 2.254 idt_B: 0.191 \n",
            "End of epoch 93 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000275 -> 0.0000235\n",
            "(epoch: 94, iters: 100, time: 0.300, data: 0.243) D_A: 0.096 G_A: 0.715 cycle_A: 0.580 idt_A: 0.505 D_B: 0.040 G_B: 0.600 cycle_B: 1.243 idt_B: 0.155 \n",
            "End of epoch 94 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000235 -> 0.0000196\n",
            "(epoch: 95, iters: 100, time: 0.290, data: 0.317) D_A: 0.112 G_A: 0.515 cycle_A: 0.643 idt_A: 0.687 D_B: 0.028 G_B: 0.491 cycle_B: 1.571 idt_B: 0.238 \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000196 -> 0.0000157\n",
            "(epoch: 96, iters: 100, time: 1.019, data: 0.259) D_A: 0.083 G_A: 0.586 cycle_A: 0.456 idt_A: 1.635 D_B: 0.022 G_B: 0.506 cycle_B: 1.548 idt_B: 0.151 \n",
            "End of epoch 96 / 100 \t Time Taken: 26 sec\n",
            "learning rate 0.0000157 -> 0.0000118\n",
            "(epoch: 97, iters: 100, time: 0.289, data: 0.223) D_A: 0.064 G_A: 0.510 cycle_A: 0.690 idt_A: 1.162 D_B: 0.036 G_B: 0.636 cycle_B: 2.410 idt_B: 0.317 \n",
            "End of epoch 97 / 100 \t Time Taken: 24 sec\n",
            "learning rate 0.0000118 -> 0.0000078\n",
            "(epoch: 98, iters: 100, time: 0.284, data: 0.366) D_A: 0.166 G_A: 0.635 cycle_A: 0.778 idt_A: 1.686 D_B: 0.026 G_B: 0.687 cycle_B: 1.662 idt_B: 0.337 \n",
            "End of epoch 98 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000078 -> 0.0000039\n",
            "(epoch: 99, iters: 100, time: 0.297, data: 0.224) D_A: 0.033 G_A: 0.788 cycle_A: 0.530 idt_A: 1.216 D_B: 0.012 G_B: 0.567 cycle_B: 2.642 idt_B: 0.218 \n",
            "End of epoch 99 / 100 \t Time Taken: 25 sec\n",
            "learning rate 0.0000039 -> 0.0000000\n",
            "(epoch: 100, iters: 100, time: 1.277, data: 0.332) D_A: 0.041 G_A: 0.841 cycle_A: 0.493 idt_A: 0.798 D_B: 0.009 G_B: 0.884 cycle_B: 1.875 idt_B: 0.158 \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 100 \t Time Taken: 27 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)], 'cell_netG_B': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN_final_5_cell_layer --train_name truck_nas_project_layer_types_cycleGAN_final_5_cell_layer --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 101 --n_epochs 50 --n_epochs_decay 50 --layer_types ReflectionPad2d_Conv2d --n_layers_cell 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAEgDsZG03Xp"
      },
      "source": [
        "## Final Layer Config (ReflectionPad2d_Conv2d)\n",
        "- n_layer_cell: 5\n",
        "- n_blocks 6\n",
        "\n",
        "??? 3 is better in one metric..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZBNVvRz03Ew",
        "outputId": "0f331617-afaa-4ec8-b3f1-42aeb13d7791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 101                           \t[default: 50]\n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: ReflectionPad2d_Conv2d+ReLU   \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_blocks: 6                             \n",
            "                 n_epochs: 50                            \t[default: 100]\n",
            "           n_epochs_decay: 50                            \t[default: 100]\n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_6_blocks\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_6_blocks\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_6_blocks/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.496, data: 0.280) D_A: 0.290 G_A: 0.364 cycle_A: 1.050 idt_A: 1.735 D_B: 0.184 G_B: 0.446 cycle_B: 3.965 idt_B: 0.544 \n",
            "End of epoch 1 / 100 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.493, data: 0.364) D_A: 0.188 G_A: 0.482 cycle_A: 1.015 idt_A: 1.878 D_B: 0.136 G_B: 0.554 cycle_B: 3.792 idt_B: 0.482 \n",
            "End of epoch 2 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.493, data: 0.294) D_A: 0.210 G_A: 0.467 cycle_A: 1.004 idt_A: 2.005 D_B: 0.186 G_B: 0.337 cycle_B: 4.280 idt_B: 0.489 \n",
            "End of epoch 3 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 7.292, data: 0.362) D_A: 0.148 G_A: 0.510 cycle_A: 0.808 idt_A: 1.647 D_B: 0.134 G_B: 0.430 cycle_B: 3.165 idt_B: 0.409 \n",
            "End of epoch 4 / 100 \t Time Taken: 54 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.496, data: 0.451) D_A: 0.158 G_A: 0.438 cycle_A: 0.772 idt_A: 0.990 D_B: 0.076 G_B: 0.316 cycle_B: 2.337 idt_B: 0.341 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 100 \t Time Taken: 53 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.502, data: 0.356) D_A: 0.083 G_A: 0.722 cycle_A: 0.742 idt_A: 1.071 D_B: 0.055 G_B: 1.255 cycle_B: 2.164 idt_B: 0.265 \n",
            "End of epoch 6 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.536, data: 0.459) D_A: 0.435 G_A: 1.085 cycle_A: 0.952 idt_A: 1.446 D_B: 0.157 G_B: 0.273 cycle_B: 3.326 idt_B: 0.464 \n",
            "End of epoch 7 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 4.751, data: 0.496) D_A: 0.133 G_A: 0.545 cycle_A: 0.767 idt_A: 1.191 D_B: 0.097 G_B: 0.917 cycle_B: 2.235 idt_B: 0.318 \n",
            "End of epoch 8 / 100 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.492, data: 0.299) D_A: 0.067 G_A: 0.860 cycle_A: 1.177 idt_A: 1.438 D_B: 0.086 G_B: 0.615 cycle_B: 3.334 idt_B: 0.453 \n",
            "End of epoch 9 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.532, data: 0.289) D_A: 0.089 G_A: 0.490 cycle_A: 1.097 idt_A: 2.188 D_B: 0.177 G_B: 0.827 cycle_B: 4.224 idt_B: 0.441 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.518, data: 0.285) D_A: 0.272 G_A: 0.484 cycle_A: 0.975 idt_A: 1.417 D_B: 0.112 G_B: 0.475 cycle_B: 3.460 idt_B: 0.472 \n",
            "End of epoch 11 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 4.781, data: 0.414) D_A: 0.145 G_A: 0.804 cycle_A: 0.878 idt_A: 1.328 D_B: 0.249 G_B: 0.263 cycle_B: 3.113 idt_B: 0.575 \n",
            "End of epoch 12 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.520, data: 0.331) D_A: 0.089 G_A: 0.653 cycle_A: 0.815 idt_A: 1.575 D_B: 0.095 G_B: 1.022 cycle_B: 3.263 idt_B: 0.375 \n",
            "End of epoch 13 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.509, data: 0.493) D_A: 0.122 G_A: 0.504 cycle_A: 0.735 idt_A: 1.508 D_B: 0.052 G_B: 0.488 cycle_B: 3.322 idt_B: 0.343 \n",
            "End of epoch 14 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.635, data: 0.439) D_A: 0.300 G_A: 0.441 cycle_A: 1.408 idt_A: 0.836 D_B: 0.143 G_B: 0.417 cycle_B: 2.068 idt_B: 0.342 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 100 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 4.720, data: 0.531) D_A: 0.044 G_A: 0.920 cycle_A: 1.085 idt_A: 1.038 D_B: 0.175 G_B: 1.755 cycle_B: 2.165 idt_B: 0.401 \n",
            "End of epoch 16 / 100 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.535, data: 0.305) D_A: 0.197 G_A: 0.421 cycle_A: 0.992 idt_A: 1.170 D_B: 0.227 G_B: 0.833 cycle_B: 2.567 idt_B: 0.315 \n",
            "End of epoch 17 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.504, data: 0.275) D_A: 0.080 G_A: 0.693 cycle_A: 0.730 idt_A: 0.943 D_B: 0.142 G_B: 1.289 cycle_B: 2.165 idt_B: 0.326 \n",
            "End of epoch 18 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.530, data: 0.445) D_A: 0.117 G_A: 0.443 cycle_A: 1.225 idt_A: 1.061 D_B: 0.188 G_B: 0.221 cycle_B: 2.502 idt_B: 0.448 \n",
            "End of epoch 19 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 4.724, data: 0.428) D_A: 0.134 G_A: 0.503 cycle_A: 0.606 idt_A: 1.259 D_B: 0.204 G_B: 0.212 cycle_B: 2.712 idt_B: 0.250 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 100 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.488, data: 0.323) D_A: 0.250 G_A: 0.664 cycle_A: 1.328 idt_A: 1.464 D_B: 0.116 G_B: 1.382 cycle_B: 3.105 idt_B: 0.415 \n",
            "End of epoch 21 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.510, data: 0.309) D_A: 0.059 G_A: 0.769 cycle_A: 1.057 idt_A: 1.356 D_B: 0.252 G_B: 0.923 cycle_B: 3.013 idt_B: 0.311 \n",
            "End of epoch 22 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.956, data: 0.596) D_A: 0.233 G_A: 0.284 cycle_A: 0.860 idt_A: 1.716 D_B: 0.200 G_B: 0.445 cycle_B: 3.253 idt_B: 0.300 \n",
            "End of epoch 23 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 4.800, data: 0.424) D_A: 0.115 G_A: 0.593 cycle_A: 0.664 idt_A: 1.252 D_B: 0.027 G_B: 1.329 cycle_B: 2.980 idt_B: 0.300 \n",
            "End of epoch 24 / 100 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.484, data: 0.279) D_A: 0.076 G_A: 0.579 cycle_A: 1.063 idt_A: 1.481 D_B: 0.099 G_B: 0.592 cycle_B: 3.502 idt_B: 0.580 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 100 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.497, data: 0.277) D_A: 0.482 G_A: 0.074 cycle_A: 1.030 idt_A: 1.120 D_B: 0.088 G_B: 0.998 cycle_B: 2.328 idt_B: 0.415 \n",
            "End of epoch 26 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.484, data: 0.276) D_A: 0.146 G_A: 0.559 cycle_A: 0.901 idt_A: 1.138 D_B: 0.107 G_B: 0.887 cycle_B: 2.524 idt_B: 0.393 \n",
            "End of epoch 27 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 5.100, data: 0.295) D_A: 0.104 G_A: 0.446 cycle_A: 0.927 idt_A: 1.579 D_B: 0.093 G_B: 0.417 cycle_B: 3.849 idt_B: 0.335 \n",
            "End of epoch 28 / 100 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.480, data: 0.359) D_A: 0.273 G_A: 0.999 cycle_A: 0.700 idt_A: 1.519 D_B: 0.057 G_B: 0.411 cycle_B: 3.528 idt_B: 0.321 \n",
            "End of epoch 29 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.544, data: 0.262) D_A: 0.094 G_A: 1.312 cycle_A: 1.067 idt_A: 1.931 D_B: 0.092 G_B: 0.602 cycle_B: 4.008 idt_B: 0.495 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 100 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.486, data: 0.338) D_A: 0.321 G_A: 0.356 cycle_A: 1.100 idt_A: 1.121 D_B: 0.168 G_B: 0.717 cycle_B: 2.184 idt_B: 0.401 \n",
            "End of epoch 31 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 3.864, data: 0.319) D_A: 0.160 G_A: 0.523 cycle_A: 0.772 idt_A: 1.297 D_B: 0.111 G_B: 0.445 cycle_B: 2.629 idt_B: 0.361 \n",
            "End of epoch 32 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.488, data: 0.265) D_A: 0.078 G_A: 0.651 cycle_A: 0.922 idt_A: 0.899 D_B: 0.087 G_B: 1.227 cycle_B: 2.240 idt_B: 0.412 \n",
            "End of epoch 33 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.509, data: 0.336) D_A: 0.319 G_A: 0.536 cycle_A: 1.016 idt_A: 1.262 D_B: 0.227 G_B: 0.137 cycle_B: 2.236 idt_B: 0.364 \n",
            "End of epoch 34 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.509, data: 0.419) D_A: 0.243 G_A: 0.313 cycle_A: 0.964 idt_A: 0.935 D_B: 0.220 G_B: 0.242 cycle_B: 2.347 idt_B: 0.470 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 100 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 4.006, data: 0.384) D_A: 0.125 G_A: 0.382 cycle_A: 1.042 idt_A: 1.317 D_B: 0.110 G_B: 0.376 cycle_B: 2.873 idt_B: 0.324 \n",
            "End of epoch 36 / 100 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.485, data: 0.373) D_A: 0.266 G_A: 0.376 cycle_A: 1.371 idt_A: 1.631 D_B: 0.135 G_B: 0.988 cycle_B: 3.633 idt_B: 0.244 \n",
            "End of epoch 37 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.529, data: 0.279) D_A: 0.146 G_A: 0.434 cycle_A: 0.902 idt_A: 0.811 D_B: 0.068 G_B: 1.084 cycle_B: 2.192 idt_B: 0.374 \n",
            "End of epoch 38 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.524, data: 0.489) D_A: 0.237 G_A: 0.255 cycle_A: 0.948 idt_A: 0.806 D_B: 0.115 G_B: 0.398 cycle_B: 1.822 idt_B: 0.448 \n",
            "End of epoch 39 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 4.055, data: 0.443) D_A: 0.157 G_A: 0.908 cycle_A: 0.929 idt_A: 1.044 D_B: 0.466 G_B: 0.066 cycle_B: 2.296 idt_B: 0.414 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 100 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.479, data: 0.359) D_A: 0.282 G_A: 0.564 cycle_A: 1.141 idt_A: 1.385 D_B: 0.050 G_B: 0.895 cycle_B: 3.380 idt_B: 0.496 \n",
            "End of epoch 41 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.512, data: 0.315) D_A: 0.145 G_A: 0.331 cycle_A: 1.052 idt_A: 1.229 D_B: 0.129 G_B: 1.492 cycle_B: 3.343 idt_B: 0.546 \n",
            "End of epoch 42 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.518, data: 0.496) D_A: 0.151 G_A: 0.503 cycle_A: 0.871 idt_A: 1.622 D_B: 0.069 G_B: 0.704 cycle_B: 2.867 idt_B: 0.346 \n",
            "End of epoch 43 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 3.982, data: 0.446) D_A: 0.255 G_A: 0.759 cycle_A: 0.603 idt_A: 1.240 D_B: 0.202 G_B: 0.294 cycle_B: 2.864 idt_B: 0.290 \n",
            "End of epoch 44 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.477, data: 0.414) D_A: 0.142 G_A: 0.195 cycle_A: 1.219 idt_A: 1.657 D_B: 0.081 G_B: 0.451 cycle_B: 3.785 idt_B: 0.589 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.493, data: 0.539) D_A: 0.189 G_A: 0.382 cycle_A: 0.780 idt_A: 1.186 D_B: 0.088 G_B: 1.262 cycle_B: 2.935 idt_B: 0.327 \n",
            "End of epoch 46 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.479, data: 0.354) D_A: 0.116 G_A: 0.524 cycle_A: 0.840 idt_A: 1.134 D_B: 0.155 G_B: 0.251 cycle_B: 2.254 idt_B: 0.330 \n",
            "End of epoch 47 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 4.361, data: 0.331) D_A: 0.091 G_A: 0.712 cycle_A: 1.224 idt_A: 0.882 D_B: 0.222 G_B: 0.302 cycle_B: 2.008 idt_B: 0.371 \n",
            "End of epoch 48 / 100 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.487, data: 0.319) D_A: 0.178 G_A: 0.630 cycle_A: 0.887 idt_A: 0.892 D_B: 0.040 G_B: 1.000 cycle_B: 2.994 idt_B: 0.384 \n",
            "End of epoch 49 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0001961\n",
            "(epoch: 50, iters: 100, time: 0.475, data: 0.311) D_A: 0.102 G_A: 0.512 cycle_A: 0.755 idt_A: 1.481 D_B: 0.126 G_B: 0.564 cycle_B: 3.743 idt_B: 0.423 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 100 \t Time Taken: 54 sec\n",
            "learning rate 0.0001961 -> 0.0001922\n",
            "(epoch: 51, iters: 100, time: 0.499, data: 0.797) D_A: 0.114 G_A: 0.623 cycle_A: 0.757 idt_A: 1.083 D_B: 0.227 G_B: 0.797 cycle_B: 2.451 idt_B: 0.338 \n",
            "End of epoch 51 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0001922 -> 0.0001882\n",
            "(epoch: 52, iters: 100, time: 4.530, data: 0.424) D_A: 0.238 G_A: 0.616 cycle_A: 0.840 idt_A: 0.901 D_B: 0.051 G_B: 0.816 cycle_B: 2.833 idt_B: 0.241 \n",
            "End of epoch 52 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0001882 -> 0.0001843\n",
            "(epoch: 53, iters: 100, time: 0.505, data: 0.459) D_A: 0.108 G_A: 0.546 cycle_A: 0.947 idt_A: 0.970 D_B: 0.043 G_B: 0.954 cycle_B: 2.284 idt_B: 0.266 \n",
            "End of epoch 53 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001843 -> 0.0001804\n",
            "(epoch: 54, iters: 100, time: 0.476, data: 0.444) D_A: 0.141 G_A: 0.488 cycle_A: 1.808 idt_A: 1.297 D_B: 0.086 G_B: 0.578 cycle_B: 2.453 idt_B: 0.660 \n",
            "End of epoch 54 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001804 -> 0.0001765\n",
            "(epoch: 55, iters: 100, time: 0.478, data: 0.514) D_A: 0.132 G_A: 0.585 cycle_A: 0.907 idt_A: 1.167 D_B: 0.042 G_B: 0.268 cycle_B: 2.644 idt_B: 0.429 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 100 \t Time Taken: 51 sec\n",
            "learning rate 0.0001765 -> 0.0001725\n",
            "(epoch: 56, iters: 100, time: 4.131, data: 0.437) D_A: 0.193 G_A: 0.771 cycle_A: 0.519 idt_A: 1.300 D_B: 0.089 G_B: 0.501 cycle_B: 2.816 idt_B: 0.223 \n",
            "End of epoch 56 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0001725 -> 0.0001686\n",
            "(epoch: 57, iters: 100, time: 0.503, data: 0.317) D_A: 0.304 G_A: 0.851 cycle_A: 0.749 idt_A: 1.758 D_B: 0.096 G_B: 0.288 cycle_B: 3.896 idt_B: 0.321 \n",
            "End of epoch 57 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001686 -> 0.0001647\n",
            "(epoch: 58, iters: 100, time: 0.516, data: 0.501) D_A: 0.271 G_A: 0.212 cycle_A: 0.722 idt_A: 0.980 D_B: 0.112 G_B: 0.497 cycle_B: 2.744 idt_B: 0.277 \n",
            "End of epoch 58 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001647 -> 0.0001608\n",
            "(epoch: 59, iters: 100, time: 0.484, data: 0.410) D_A: 0.104 G_A: 0.315 cycle_A: 0.505 idt_A: 1.289 D_B: 0.257 G_B: 0.132 cycle_B: 3.526 idt_B: 0.175 \n",
            "End of epoch 59 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001608 -> 0.0001569\n",
            "(epoch: 60, iters: 100, time: 3.986, data: 0.289) D_A: 0.363 G_A: 0.180 cycle_A: 1.026 idt_A: 0.964 D_B: 0.163 G_B: 0.273 cycle_B: 2.611 idt_B: 0.409 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 100 \t Time Taken: 51 sec\n",
            "learning rate 0.0001569 -> 0.0001529\n",
            "(epoch: 61, iters: 100, time: 0.478, data: 0.427) D_A: 0.141 G_A: 0.479 cycle_A: 0.683 idt_A: 1.110 D_B: 0.126 G_B: 1.457 cycle_B: 2.132 idt_B: 0.268 \n",
            "End of epoch 61 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0001529 -> 0.0001490\n",
            "(epoch: 62, iters: 100, time: 0.476, data: 0.476) D_A: 0.144 G_A: 0.474 cycle_A: 0.899 idt_A: 0.957 D_B: 0.182 G_B: 0.279 cycle_B: 3.627 idt_B: 0.444 \n",
            "End of epoch 62 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001490 -> 0.0001451\n",
            "(epoch: 63, iters: 100, time: 0.480, data: 0.285) D_A: 0.040 G_A: 0.214 cycle_A: 0.897 idt_A: 1.042 D_B: 0.101 G_B: 0.457 cycle_B: 2.139 idt_B: 0.369 \n",
            "End of epoch 63 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001451 -> 0.0001412\n",
            "(epoch: 64, iters: 100, time: 4.272, data: 0.286) D_A: 0.153 G_A: 0.449 cycle_A: 0.748 idt_A: 1.202 D_B: 0.069 G_B: 0.693 cycle_B: 2.691 idt_B: 0.315 \n",
            "End of epoch 64 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0001412 -> 0.0001373\n",
            "(epoch: 65, iters: 100, time: 0.480, data: 0.273) D_A: 0.035 G_A: 0.724 cycle_A: 0.573 idt_A: 0.773 D_B: 0.111 G_B: 0.333 cycle_B: 1.907 idt_B: 0.248 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0001373 -> 0.0001333\n",
            "(epoch: 66, iters: 100, time: 0.471, data: 0.322) D_A: 0.051 G_A: 0.714 cycle_A: 0.781 idt_A: 1.440 D_B: 0.099 G_B: 0.248 cycle_B: 3.455 idt_B: 0.330 \n",
            "End of epoch 66 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0001333 -> 0.0001294\n",
            "(epoch: 67, iters: 100, time: 0.505, data: 0.289) D_A: 0.126 G_A: 0.465 cycle_A: 1.096 idt_A: 1.045 D_B: 0.092 G_B: 0.482 cycle_B: 2.308 idt_B: 0.389 \n",
            "End of epoch 67 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001294 -> 0.0001255\n",
            "(epoch: 68, iters: 100, time: 4.185, data: 0.453) D_A: 0.109 G_A: 0.563 cycle_A: 0.687 idt_A: 0.795 D_B: 0.138 G_B: 1.702 cycle_B: 2.427 idt_B: 0.183 \n",
            "End of epoch 68 / 100 \t Time Taken: 48 sec\n",
            "learning rate 0.0001255 -> 0.0001216\n",
            "(epoch: 69, iters: 100, time: 0.500, data: 0.314) D_A: 0.070 G_A: 0.550 cycle_A: 0.890 idt_A: 1.476 D_B: 0.044 G_B: 0.778 cycle_B: 3.400 idt_B: 0.282 \n",
            "End of epoch 69 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001216 -> 0.0001176\n",
            "(epoch: 70, iters: 100, time: 0.512, data: 0.471) D_A: 0.266 G_A: 0.936 cycle_A: 0.681 idt_A: 0.987 D_B: 0.112 G_B: 0.368 cycle_B: 2.216 idt_B: 0.281 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0001176 -> 0.0001137\n",
            "(epoch: 71, iters: 100, time: 0.521, data: 0.430) D_A: 0.204 G_A: 0.670 cycle_A: 0.562 idt_A: 0.646 D_B: 0.050 G_B: 0.662 cycle_B: 2.009 idt_B: 0.272 \n",
            "End of epoch 71 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0001137 -> 0.0001098\n",
            "(epoch: 72, iters: 100, time: 4.620, data: 0.473) D_A: 0.108 G_A: 0.436 cycle_A: 0.927 idt_A: 0.916 D_B: 0.080 G_B: 0.970 cycle_B: 2.074 idt_B: 0.269 \n",
            "End of epoch 72 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0001098 -> 0.0001059\n",
            "(epoch: 73, iters: 100, time: 0.517, data: 0.488) D_A: 0.079 G_A: 0.503 cycle_A: 0.614 idt_A: 0.794 D_B: 0.036 G_B: 0.875 cycle_B: 1.948 idt_B: 0.269 \n",
            "End of epoch 73 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001059 -> 0.0001020\n",
            "(epoch: 74, iters: 100, time: 0.473, data: 0.450) D_A: 0.187 G_A: 0.333 cycle_A: 0.601 idt_A: 1.189 D_B: 0.082 G_B: 0.108 cycle_B: 2.121 idt_B: 0.287 \n",
            "End of epoch 74 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0001020 -> 0.0000980\n",
            "(epoch: 75, iters: 100, time: 0.475, data: 0.373) D_A: 0.108 G_A: 0.711 cycle_A: 0.490 idt_A: 1.335 D_B: 0.024 G_B: 0.553 cycle_B: 3.189 idt_B: 0.185 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0000980 -> 0.0000941\n",
            "(epoch: 76, iters: 100, time: 4.590, data: 0.350) D_A: 0.077 G_A: 0.296 cycle_A: 0.969 idt_A: 0.873 D_B: 0.053 G_B: 1.068 cycle_B: 2.010 idt_B: 0.548 \n",
            "End of epoch 76 / 100 \t Time Taken: 50 sec\n",
            "learning rate 0.0000941 -> 0.0000902\n",
            "(epoch: 77, iters: 100, time: 0.477, data: 0.411) D_A: 0.074 G_A: 0.416 cycle_A: 0.737 idt_A: 1.386 D_B: 0.133 G_B: 1.609 cycle_B: 2.635 idt_B: 0.244 \n",
            "End of epoch 77 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000902 -> 0.0000863\n",
            "(epoch: 78, iters: 100, time: 0.478, data: 0.330) D_A: 0.166 G_A: 0.268 cycle_A: 0.678 idt_A: 0.994 D_B: 0.202 G_B: 0.943 cycle_B: 2.714 idt_B: 0.237 \n",
            "End of epoch 78 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000863 -> 0.0000824\n",
            "(epoch: 79, iters: 100, time: 0.483, data: 0.285) D_A: 0.072 G_A: 0.414 cycle_A: 0.894 idt_A: 0.962 D_B: 0.058 G_B: 1.169 cycle_B: 2.407 idt_B: 0.378 \n",
            "End of epoch 79 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000824 -> 0.0000784\n",
            "(epoch: 80, iters: 100, time: 4.414, data: 0.295) D_A: 0.163 G_A: 1.014 cycle_A: 0.770 idt_A: 0.668 D_B: 0.075 G_B: 0.421 cycle_B: 1.819 idt_B: 0.304 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 100 \t Time Taken: 50 sec\n",
            "learning rate 0.0000784 -> 0.0000745\n",
            "(epoch: 81, iters: 100, time: 0.476, data: 0.332) D_A: 0.031 G_A: 0.826 cycle_A: 0.878 idt_A: 1.141 D_B: 0.036 G_B: 1.154 cycle_B: 2.553 idt_B: 0.449 \n",
            "End of epoch 81 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0000745 -> 0.0000706\n",
            "(epoch: 82, iters: 100, time: 0.498, data: 0.289) D_A: 0.076 G_A: 0.615 cycle_A: 0.900 idt_A: 0.829 D_B: 0.067 G_B: 0.481 cycle_B: 2.030 idt_B: 0.383 \n",
            "End of epoch 82 / 100 \t Time Taken: 44 sec\n",
            "learning rate 0.0000706 -> 0.0000667\n",
            "(epoch: 83, iters: 100, time: 0.509, data: 0.451) D_A: 0.030 G_A: 0.349 cycle_A: 0.810 idt_A: 1.279 D_B: 0.081 G_B: 0.951 cycle_B: 2.948 idt_B: 0.346 \n",
            "End of epoch 83 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000667 -> 0.0000627\n",
            "(epoch: 84, iters: 100, time: 4.444, data: 0.458) D_A: 0.125 G_A: 0.449 cycle_A: 0.525 idt_A: 1.144 D_B: 0.041 G_B: 0.370 cycle_B: 2.461 idt_B: 0.240 \n",
            "End of epoch 84 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0000627 -> 0.0000588\n",
            "(epoch: 85, iters: 100, time: 0.506, data: 0.522) D_A: 0.035 G_A: 0.567 cycle_A: 0.932 idt_A: 0.845 D_B: 0.077 G_B: 0.508 cycle_B: 2.080 idt_B: 0.393 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0000588 -> 0.0000549\n",
            "(epoch: 86, iters: 100, time: 0.506, data: 0.540) D_A: 0.076 G_A: 0.529 cycle_A: 0.777 idt_A: 0.689 D_B: 0.048 G_B: 0.543 cycle_B: 1.459 idt_B: 0.213 \n",
            "End of epoch 86 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0000549 -> 0.0000510\n",
            "(epoch: 87, iters: 100, time: 0.476, data: 0.581) D_A: 0.090 G_A: 0.599 cycle_A: 0.521 idt_A: 0.787 D_B: 0.020 G_B: 0.442 cycle_B: 1.826 idt_B: 0.187 \n",
            "End of epoch 87 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000510 -> 0.0000471\n",
            "(epoch: 88, iters: 100, time: 4.636, data: 0.385) D_A: 0.066 G_A: 0.364 cycle_A: 0.998 idt_A: 0.815 D_B: 0.108 G_B: 0.618 cycle_B: 1.680 idt_B: 0.455 \n",
            "End of epoch 88 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0000471 -> 0.0000431\n",
            "(epoch: 89, iters: 100, time: 0.473, data: 0.464) D_A: 0.170 G_A: 0.641 cycle_A: 0.935 idt_A: 0.473 D_B: 0.031 G_B: 1.319 cycle_B: 1.352 idt_B: 0.373 \n",
            "End of epoch 89 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000431 -> 0.0000392\n",
            "(epoch: 90, iters: 100, time: 0.478, data: 0.284) D_A: 0.190 G_A: 0.311 cycle_A: 0.417 idt_A: 0.883 D_B: 0.098 G_B: 0.153 cycle_B: 1.993 idt_B: 0.166 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0000392 -> 0.0000353\n",
            "(epoch: 91, iters: 100, time: 0.484, data: 0.316) D_A: 0.157 G_A: 0.272 cycle_A: 0.922 idt_A: 1.029 D_B: 0.120 G_B: 0.899 cycle_B: 2.247 idt_B: 0.463 \n",
            "End of epoch 91 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0000353 -> 0.0000314\n",
            "(epoch: 92, iters: 100, time: 4.378, data: 0.373) D_A: 0.128 G_A: 0.385 cycle_A: 0.946 idt_A: 0.623 D_B: 0.081 G_B: 0.981 cycle_B: 1.690 idt_B: 0.431 \n",
            "End of epoch 92 / 100 \t Time Taken: 49 sec\n",
            "learning rate 0.0000314 -> 0.0000275\n",
            "(epoch: 93, iters: 100, time: 0.472, data: 0.273) D_A: 0.198 G_A: 0.488 cycle_A: 0.942 idt_A: 0.820 D_B: 0.074 G_B: 0.539 cycle_B: 1.533 idt_B: 0.317 \n",
            "End of epoch 93 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000275 -> 0.0000235\n",
            "(epoch: 94, iters: 100, time: 0.474, data: 0.311) D_A: 0.083 G_A: 0.503 cycle_A: 1.047 idt_A: 0.878 D_B: 0.073 G_B: 0.756 cycle_B: 2.071 idt_B: 0.346 \n",
            "End of epoch 94 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000235 -> 0.0000196\n",
            "(epoch: 95, iters: 100, time: 0.514, data: 0.326) D_A: 0.035 G_A: 0.781 cycle_A: 0.592 idt_A: 0.786 D_B: 0.041 G_B: 0.970 cycle_B: 1.535 idt_B: 0.286 \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0000196 -> 0.0000157\n",
            "(epoch: 96, iters: 100, time: 4.563, data: 0.377) D_A: 0.060 G_A: 0.836 cycle_A: 0.668 idt_A: 0.788 D_B: 0.050 G_B: 0.741 cycle_B: 1.819 idt_B: 0.240 \n",
            "End of epoch 96 / 100 \t Time Taken: 50 sec\n",
            "learning rate 0.0000157 -> 0.0000118\n",
            "(epoch: 97, iters: 100, time: 0.511, data: 0.367) D_A: 0.028 G_A: 0.728 cycle_A: 0.605 idt_A: 0.574 D_B: 0.024 G_B: 0.384 cycle_B: 1.308 idt_B: 0.256 \n",
            "End of epoch 97 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000118 -> 0.0000078\n",
            "(epoch: 98, iters: 100, time: 0.503, data: 0.279) D_A: 0.040 G_A: 0.801 cycle_A: 0.519 idt_A: 1.171 D_B: 0.024 G_B: 1.194 cycle_B: 2.336 idt_B: 0.193 \n",
            "End of epoch 98 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000078 -> 0.0000039\n",
            "(epoch: 99, iters: 100, time: 0.503, data: 0.430) D_A: 0.086 G_A: 0.438 cycle_A: 0.870 idt_A: 0.675 D_B: 0.180 G_B: 0.904 cycle_B: 1.523 idt_B: 0.408 \n",
            "End of epoch 99 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0000039 -> 0.0000000\n",
            "(epoch: 100, iters: 100, time: 4.417, data: 0.424) D_A: 0.040 G_A: 0.703 cycle_A: 0.560 idt_A: 1.291 D_B: 0.037 G_B: 1.282 cycle_B: 2.417 idt_B: 0.214 \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 100 \t Time Taken: 57 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)], 'cell_netG_B': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_6_blocks --train_name truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_6_blocks --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 101 --n_epochs 50 --n_epochs_decay 50 --layer_types ReflectionPad2d_Conv2d+ReLU --n_layers_cell 5 --n_blocks 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ycnuWyTR6EF"
      },
      "source": [
        "## Final Layer Config (ReflectionPad2d_Conv2d)\n",
        "- n_layer_cell: 5\n",
        "- n_blocks 9\n",
        "\n",
        "Ausführen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV4Wp0jnSAeI",
        "outputId": "f582b066-f4ee-457b-d0dc-1caa8f9f1e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 101                           \t[default: 50]\n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: ReflectionPad2d_Conv2d+ReLU   \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_blocks: 9                             \t[default: 6]\n",
            "                 n_epochs: 50                            \t[default: 100]\n",
            "           n_epochs_decay: 50                            \t[default: 100]\n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_9_blocks\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_9_blocks\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_9_blocks/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.764, data: 0.533) D_A: 0.669 G_A: 0.818 cycle_A: 1.966 idt_A: 2.012 D_B: 0.409 G_B: 0.938 cycle_B: 4.079 idt_B: 0.801 \n",
            "End of epoch 1 / 100 \t Time Taken: 78 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.796, data: 0.415) D_A: 0.250 G_A: 0.353 cycle_A: 2.794 idt_A: 1.579 D_B: 0.139 G_B: 0.455 cycle_B: 3.910 idt_B: 1.035 \n",
            "End of epoch 2 / 100 \t Time Taken: 76 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.777, data: 0.692) D_A: 0.171 G_A: 0.483 cycle_A: 1.187 idt_A: 1.430 D_B: 0.219 G_B: 0.869 cycle_B: 3.444 idt_B: 0.482 \n",
            "End of epoch 3 / 100 \t Time Taken: 74 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 2.836, data: 0.328) D_A: 0.366 G_A: 0.637 cycle_A: 0.865 idt_A: 1.441 D_B: 0.137 G_B: 0.349 cycle_B: 3.164 idt_B: 0.404 \n",
            "End of epoch 4 / 100 \t Time Taken: 76 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.807, data: 0.272) D_A: 0.249 G_A: 0.675 cycle_A: 1.157 idt_A: 1.314 D_B: 0.154 G_B: 0.159 cycle_B: 3.708 idt_B: 0.522 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 100 \t Time Taken: 79 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.756, data: 0.340) D_A: 0.222 G_A: 0.551 cycle_A: 1.395 idt_A: 1.331 D_B: 0.143 G_B: 0.148 cycle_B: 3.182 idt_B: 0.602 \n",
            "End of epoch 6 / 100 \t Time Taken: 74 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.752, data: 0.464) D_A: 0.256 G_A: 0.332 cycle_A: 0.814 idt_A: 3.047 D_B: 0.105 G_B: 1.147 cycle_B: 6.181 idt_B: 0.389 \n",
            "End of epoch 7 / 100 \t Time Taken: 74 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 2.385, data: 0.277) D_A: 0.207 G_A: 0.397 cycle_A: 1.582 idt_A: 1.199 D_B: 0.270 G_B: 0.691 cycle_B: 2.877 idt_B: 0.614 \n",
            "End of epoch 8 / 100 \t Time Taken: 75 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.750, data: 0.666) D_A: 0.153 G_A: 0.480 cycle_A: 1.286 idt_A: 2.281 D_B: 0.037 G_B: 0.843 cycle_B: 4.762 idt_B: 0.613 \n",
            "End of epoch 9 / 100 \t Time Taken: 74 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.810, data: 0.310) D_A: 0.241 G_A: 0.709 cycle_A: 1.012 idt_A: 1.112 D_B: 0.186 G_B: 1.297 cycle_B: 2.417 idt_B: 0.516 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 100 \t Time Taken: 76 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.687, data: 0.299) D_A: 0.108 G_A: 0.979 cycle_A: 1.787 idt_A: 1.993 D_B: 0.069 G_B: 1.058 cycle_B: 4.335 idt_B: 0.852 \n",
            "End of epoch 11 / 100 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 2.516, data: 0.291) D_A: 0.299 G_A: 0.297 cycle_A: 0.823 idt_A: 1.067 D_B: 0.270 G_B: 0.404 cycle_B: 2.374 idt_B: 0.377 \n",
            "End of epoch 12 / 100 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.671, data: 0.267) D_A: 0.102 G_A: 0.408 cycle_A: 1.056 idt_A: 1.181 D_B: 0.157 G_B: 1.421 cycle_B: 2.907 idt_B: 0.362 \n",
            "End of epoch 13 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.688, data: 0.494) D_A: 0.211 G_A: 0.882 cycle_A: 1.060 idt_A: 1.397 D_B: 0.118 G_B: 1.347 cycle_B: 3.306 idt_B: 0.703 \n",
            "End of epoch 14 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.724, data: 0.270) D_A: 0.143 G_A: 0.354 cycle_A: 0.909 idt_A: 1.299 D_B: 0.229 G_B: 0.445 cycle_B: 3.082 idt_B: 0.341 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 100 \t Time Taken: 70 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 2.577, data: 0.407) D_A: 0.075 G_A: 0.174 cycle_A: 1.215 idt_A: 1.378 D_B: 0.100 G_B: 0.771 cycle_B: 3.206 idt_B: 0.512 \n",
            "End of epoch 16 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.702, data: 0.312) D_A: 0.105 G_A: 0.627 cycle_A: 1.125 idt_A: 1.860 D_B: 0.052 G_B: 0.399 cycle_B: 3.920 idt_B: 0.472 \n",
            "End of epoch 17 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.713, data: 0.421) D_A: 0.121 G_A: 0.441 cycle_A: 0.752 idt_A: 1.279 D_B: 0.080 G_B: 1.479 cycle_B: 2.660 idt_B: 0.284 \n",
            "End of epoch 18 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.717, data: 0.458) D_A: 0.334 G_A: 0.302 cycle_A: 0.768 idt_A: 1.530 D_B: 0.118 G_B: 0.381 cycle_B: 3.353 idt_B: 0.328 \n",
            "End of epoch 19 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 2.666, data: 0.439) D_A: 0.231 G_A: 0.868 cycle_A: 1.075 idt_A: 1.743 D_B: 0.197 G_B: 0.514 cycle_B: 4.351 idt_B: 0.578 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 100 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.658, data: 0.334) D_A: 0.158 G_A: 0.386 cycle_A: 0.883 idt_A: 1.228 D_B: 0.081 G_B: 0.498 cycle_B: 2.916 idt_B: 0.335 \n",
            "End of epoch 21 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.719, data: 0.271) D_A: 0.401 G_A: 0.382 cycle_A: 0.864 idt_A: 1.240 D_B: 0.234 G_B: 0.637 cycle_B: 2.817 idt_B: 0.348 \n",
            "End of epoch 22 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.714, data: 0.346) D_A: 0.284 G_A: 0.693 cycle_A: 0.707 idt_A: 1.381 D_B: 0.046 G_B: 0.413 cycle_B: 3.046 idt_B: 0.268 \n",
            "End of epoch 23 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 2.487, data: 0.435) D_A: 0.160 G_A: 0.608 cycle_A: 0.677 idt_A: 0.907 D_B: 0.080 G_B: 0.630 cycle_B: 2.309 idt_B: 0.367 \n",
            "End of epoch 24 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.695, data: 0.326) D_A: 0.189 G_A: 0.267 cycle_A: 1.164 idt_A: 1.178 D_B: 0.124 G_B: 0.553 cycle_B: 3.007 idt_B: 0.620 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.657, data: 0.270) D_A: 0.170 G_A: 0.371 cycle_A: 0.785 idt_A: 1.723 D_B: 0.119 G_B: 0.430 cycle_B: 3.416 idt_B: 0.329 \n",
            "End of epoch 26 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.711, data: 0.271) D_A: 0.120 G_A: 0.387 cycle_A: 1.097 idt_A: 0.973 D_B: 0.049 G_B: 0.331 cycle_B: 2.739 idt_B: 0.528 \n",
            "End of epoch 27 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 2.608, data: 0.257) D_A: 0.387 G_A: 0.529 cycle_A: 0.984 idt_A: 1.222 D_B: 0.382 G_B: 0.088 cycle_B: 3.341 idt_B: 0.470 \n",
            "End of epoch 28 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.710, data: 0.284) D_A: 0.139 G_A: 0.539 cycle_A: 0.883 idt_A: 1.465 D_B: 0.147 G_B: 0.671 cycle_B: 3.225 idt_B: 0.359 \n",
            "End of epoch 29 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.713, data: 0.435) D_A: 0.362 G_A: 0.868 cycle_A: 0.544 idt_A: 0.650 D_B: 0.274 G_B: 1.654 cycle_B: 2.587 idt_B: 0.223 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.687, data: 0.309) D_A: 0.378 G_A: 0.612 cycle_A: 1.004 idt_A: 2.013 D_B: 0.075 G_B: 0.103 cycle_B: 3.599 idt_B: 0.283 \n",
            "End of epoch 31 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 2.513, data: 0.273) D_A: 0.233 G_A: 0.935 cycle_A: 1.481 idt_A: 1.532 D_B: 0.054 G_B: 0.696 cycle_B: 3.504 idt_B: 0.596 \n",
            "End of epoch 32 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.665, data: 0.248) D_A: 0.113 G_A: 0.181 cycle_A: 0.966 idt_A: 0.930 D_B: 0.117 G_B: 0.376 cycle_B: 2.376 idt_B: 0.475 \n",
            "End of epoch 33 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.667, data: 0.284) D_A: 0.248 G_A: 0.176 cycle_A: 0.958 idt_A: 1.541 D_B: 0.345 G_B: 0.901 cycle_B: 3.445 idt_B: 0.473 \n",
            "End of epoch 34 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.678, data: 0.253) D_A: 0.125 G_A: 0.795 cycle_A: 1.353 idt_A: 0.708 D_B: 0.162 G_B: 0.283 cycle_B: 2.292 idt_B: 0.581 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 2.626, data: 0.319) D_A: 0.196 G_A: 0.673 cycle_A: 1.393 idt_A: 1.282 D_B: 0.094 G_B: 1.067 cycle_B: 2.881 idt_B: 0.315 \n",
            "End of epoch 36 / 100 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.678, data: 0.372) D_A: 0.234 G_A: 0.269 cycle_A: 0.900 idt_A: 1.588 D_B: 0.065 G_B: 0.731 cycle_B: 3.958 idt_B: 0.380 \n",
            "End of epoch 37 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.680, data: 0.270) D_A: 0.201 G_A: 0.744 cycle_A: 0.541 idt_A: 0.988 D_B: 0.034 G_B: 0.739 cycle_B: 3.331 idt_B: 0.287 \n",
            "End of epoch 38 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.659, data: 0.277) D_A: 0.058 G_A: 0.236 cycle_A: 1.349 idt_A: 0.944 D_B: 0.133 G_B: 1.296 cycle_B: 2.202 idt_B: 0.341 \n",
            "End of epoch 39 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 2.621, data: 0.314) D_A: 0.187 G_A: 0.554 cycle_A: 1.693 idt_A: 1.180 D_B: 0.209 G_B: 0.359 cycle_B: 2.993 idt_B: 0.687 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 100 \t Time Taken: 70 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.663, data: 0.314) D_A: 0.255 G_A: 0.973 cycle_A: 0.730 idt_A: 1.633 D_B: 0.114 G_B: 0.352 cycle_B: 3.864 idt_B: 0.236 \n",
            "End of epoch 41 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.659, data: 0.351) D_A: 0.177 G_A: 0.494 cycle_A: 0.776 idt_A: 1.442 D_B: 0.216 G_B: 0.145 cycle_B: 2.623 idt_B: 0.324 \n",
            "End of epoch 42 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.676, data: 0.293) D_A: 0.299 G_A: 0.363 cycle_A: 0.627 idt_A: 1.304 D_B: 0.154 G_B: 0.539 cycle_B: 2.555 idt_B: 0.341 \n",
            "End of epoch 43 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 2.880, data: 0.311) D_A: 0.181 G_A: 0.373 cycle_A: 0.846 idt_A: 1.016 D_B: 0.127 G_B: 1.275 cycle_B: 2.443 idt_B: 0.257 \n",
            "End of epoch 44 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.665, data: 0.290) D_A: 0.114 G_A: 0.660 cycle_A: 1.163 idt_A: 0.886 D_B: 0.229 G_B: 1.102 cycle_B: 1.941 idt_B: 0.570 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 100 \t Time Taken: 70 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.706, data: 0.442) D_A: 0.269 G_A: 0.373 cycle_A: 0.981 idt_A: 1.661 D_B: 0.156 G_B: 0.209 cycle_B: 3.484 idt_B: 0.451 \n",
            "End of epoch 46 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.693, data: 0.511) D_A: 0.126 G_A: 0.832 cycle_A: 1.091 idt_A: 0.987 D_B: 0.027 G_B: 0.695 cycle_B: 2.200 idt_B: 0.517 \n",
            "End of epoch 47 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 2.922, data: 0.443) D_A: 0.058 G_A: 0.789 cycle_A: 1.124 idt_A: 1.152 D_B: 0.019 G_B: 1.169 cycle_B: 2.484 idt_B: 0.512 \n",
            "End of epoch 48 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.700, data: 0.237) D_A: 0.072 G_A: 0.862 cycle_A: 0.691 idt_A: 1.150 D_B: 0.106 G_B: 0.913 cycle_B: 2.439 idt_B: 0.339 \n",
            "End of epoch 49 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0002000 -> 0.0001961\n",
            "(epoch: 50, iters: 100, time: 0.704, data: 0.424) D_A: 0.085 G_A: 0.638 cycle_A: 0.699 idt_A: 0.636 D_B: 0.046 G_B: 0.676 cycle_B: 1.530 idt_B: 0.261 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 100 \t Time Taken: 74 sec\n",
            "learning rate 0.0001961 -> 0.0001922\n",
            "(epoch: 51, iters: 100, time: 0.657, data: 0.274) D_A: 0.197 G_A: 0.356 cycle_A: 1.245 idt_A: 1.568 D_B: 0.178 G_B: 0.566 cycle_B: 3.517 idt_B: 0.469 \n",
            "End of epoch 51 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0001922 -> 0.0001882\n",
            "(epoch: 52, iters: 100, time: 2.545, data: 0.252) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 52 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0001882 -> 0.0001843\n",
            "(epoch: 53, iters: 100, time: 0.660, data: 0.321) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 53 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0001843 -> 0.0001804\n",
            "(epoch: 54, iters: 100, time: 0.676, data: 0.249) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 54 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0001804 -> 0.0001765\n",
            "(epoch: 55, iters: 100, time: 0.665, data: 0.276) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 100 \t Time Taken: 69 sec\n",
            "learning rate 0.0001765 -> 0.0001725\n",
            "(epoch: 56, iters: 100, time: 2.714, data: 0.496) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 56 / 100 \t Time Taken: 68 sec\n",
            "learning rate 0.0001725 -> 0.0001686\n",
            "(epoch: 57, iters: 100, time: 0.707, data: 0.293) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 57 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0001686 -> 0.0001647\n",
            "(epoch: 58, iters: 100, time: 0.714, data: 0.385) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 58 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0001647 -> 0.0001608\n",
            "(epoch: 59, iters: 100, time: 0.732, data: 0.411) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 59 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0001608 -> 0.0001569\n",
            "(epoch: 60, iters: 100, time: 2.730, data: 0.583) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 100 \t Time Taken: 71 sec\n",
            "learning rate 0.0001569 -> 0.0001529\n",
            "(epoch: 61, iters: 100, time: 0.677, data: 0.278) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 61 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0001529 -> 0.0001490\n",
            "(epoch: 62, iters: 100, time: 0.661, data: 0.377) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 62 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0001490 -> 0.0001451\n",
            "(epoch: 63, iters: 100, time: 0.671, data: 0.277) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 63 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0001451 -> 0.0001412\n",
            "(epoch: 64, iters: 100, time: 2.775, data: 0.303) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 64 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0001412 -> 0.0001373\n",
            "(epoch: 65, iters: 100, time: 0.668, data: 0.269) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0001373 -> 0.0001333\n",
            "(epoch: 66, iters: 100, time: 0.681, data: 0.352) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 66 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0001333 -> 0.0001294\n",
            "(epoch: 67, iters: 100, time: 0.670, data: 0.333) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 67 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0001294 -> 0.0001255\n",
            "(epoch: 68, iters: 100, time: 2.579, data: 0.305) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 68 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0001255 -> 0.0001216\n",
            "(epoch: 69, iters: 100, time: 0.673, data: 0.356) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 69 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0001216 -> 0.0001176\n",
            "(epoch: 70, iters: 100, time: 0.675, data: 0.278) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 100 \t Time Taken: 68 sec\n",
            "learning rate 0.0001176 -> 0.0001137\n",
            "(epoch: 71, iters: 100, time: 0.703, data: 0.442) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 71 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0001137 -> 0.0001098\n",
            "(epoch: 72, iters: 100, time: 2.841, data: 0.484) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 72 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0001098 -> 0.0001059\n",
            "(epoch: 73, iters: 100, time: 0.688, data: 0.298) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 73 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0001059 -> 0.0001020\n",
            "(epoch: 74, iters: 100, time: 0.712, data: 0.329) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 74 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0001020 -> 0.0000980\n",
            "(epoch: 75, iters: 100, time: 0.715, data: 0.269) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0000980 -> 0.0000941\n",
            "(epoch: 76, iters: 100, time: 2.788, data: 0.349) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 76 / 100 \t Time Taken: 69 sec\n",
            "learning rate 0.0000941 -> 0.0000902\n",
            "(epoch: 77, iters: 100, time: 0.668, data: 0.339) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 77 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0000902 -> 0.0000863\n",
            "(epoch: 78, iters: 100, time: 0.680, data: 0.394) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 78 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0000863 -> 0.0000824\n",
            "(epoch: 79, iters: 100, time: 0.679, data: 0.259) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 79 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0000824 -> 0.0000784\n",
            "(epoch: 80, iters: 100, time: 2.690, data: 0.276) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 100 \t Time Taken: 70 sec\n",
            "learning rate 0.0000784 -> 0.0000745\n",
            "(epoch: 81, iters: 100, time: 0.724, data: 0.456) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 81 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0000745 -> 0.0000706\n",
            "(epoch: 82, iters: 100, time: 0.696, data: 0.482) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 82 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0000706 -> 0.0000667\n",
            "(epoch: 83, iters: 100, time: 0.667, data: 0.343) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 83 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0000667 -> 0.0000627\n",
            "(epoch: 84, iters: 100, time: 3.033, data: 0.380) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 84 / 100 \t Time Taken: 67 sec\n",
            "learning rate 0.0000627 -> 0.0000588\n",
            "(epoch: 85, iters: 100, time: 0.715, data: 0.412) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 100 \t Time Taken: 71 sec\n",
            "learning rate 0.0000588 -> 0.0000549\n",
            "(epoch: 86, iters: 100, time: 0.673, data: 0.307) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 86 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0000549 -> 0.0000510\n",
            "(epoch: 87, iters: 100, time: 0.666, data: 0.274) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 87 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0000510 -> 0.0000471\n",
            "(epoch: 88, iters: 100, time: 2.818, data: 0.321) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 88 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0000471 -> 0.0000431\n",
            "(epoch: 89, iters: 100, time: 0.667, data: 0.306) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 89 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0000431 -> 0.0000392\n",
            "(epoch: 90, iters: 100, time: 0.684, data: 0.283) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0000392 -> 0.0000353\n",
            "(epoch: 91, iters: 100, time: 0.680, data: 0.481) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 91 / 100 \t Time Taken: 65 sec\n",
            "learning rate 0.0000353 -> 0.0000314\n",
            "(epoch: 92, iters: 100, time: 2.821, data: 0.246) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 92 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0000314 -> 0.0000275\n",
            "(epoch: 93, iters: 100, time: 0.690, data: 0.344) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 93 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0000275 -> 0.0000235\n",
            "(epoch: 94, iters: 100, time: 0.660, data: 0.449) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 94 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0000235 -> 0.0000196\n",
            "(epoch: 95, iters: 100, time: 0.676, data: 0.296) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 100 \t Time Taken: 66 sec\n",
            "learning rate 0.0000196 -> 0.0000157\n",
            "(epoch: 96, iters: 100, time: 3.174, data: 0.306) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 96 / 100 \t Time Taken: 68 sec\n",
            "learning rate 0.0000157 -> 0.0000118\n",
            "(epoch: 97, iters: 100, time: 0.667, data: 0.478) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 97 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0000118 -> 0.0000078\n",
            "(epoch: 98, iters: 100, time: 0.657, data: 0.328) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 98 / 100 \t Time Taken: 63 sec\n",
            "learning rate 0.0000078 -> 0.0000039\n",
            "(epoch: 99, iters: 100, time: 0.713, data: 0.310) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "End of epoch 99 / 100 \t Time Taken: 64 sec\n",
            "learning rate 0.0000039 -> 0.0000000\n",
            "(epoch: 100, iters: 100, time: 2.963, data: 0.458) D_A: nan G_A: nan cycle_A: nan idt_A: nan D_B: nan G_B: nan cycle_B: nan idt_B: nan \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 100 \t Time Taken: 76 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)], 'cell_netG_B': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_9_blocks --train_name truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_9_blocks --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 101 --n_epochs 50 --n_epochs_decay 50 --layer_types ReflectionPad2d_Conv2d+ReLU --n_layers_cell 5 --n_blocks 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWv96W04UO0x"
      },
      "source": [
        "## Final Layer Config (ReflectionPad2d_Conv2d)\n",
        "- n_layer_cell: 3\n",
        "- n_blocks 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iQo2XxtUgZt"
      },
      "source": [
        "## Final Layer Config (ReflectionPad2d_Conv2d)\n",
        "- n_layer_cell: 3\n",
        "- n_blocks 6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el305EDvUhrq",
        "outputId": "b08bbf51-2d6c-46c3-f7e5-052e99f12ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 101                           \t[default: 50]\n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: ReflectionPad2d_Conv2d        \t[default: CycleGan]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_blocks: 9                             \t[default: 6]\n",
            "                 n_epochs: 50                            \t[default: 100]\n",
            "           n_epochs_decay: 50                            \t[default: 100]\n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 3                             \t[default: 5]\n",
            "                     name: truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_9_blocks\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_9_blocks\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_9_blocks/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.543, data: 0.267) D_A: 0.274 G_A: 0.446 cycle_A: 1.708 idt_A: 1.862 D_B: 0.180 G_B: 0.373 cycle_B: 4.600 idt_B: 0.853 \n",
            "End of epoch 1 / 100 \t Time Taken: 48 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.463, data: 0.313) D_A: 0.155 G_A: 0.714 cycle_A: 0.995 idt_A: 1.266 D_B: 0.132 G_B: 0.487 cycle_B: 2.905 idt_B: 0.401 \n",
            "End of epoch 2 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.459, data: 0.320) D_A: 0.138 G_A: 0.552 cycle_A: 1.324 idt_A: 1.287 D_B: 0.140 G_B: 0.390 cycle_B: 2.667 idt_B: 0.755 \n",
            "End of epoch 3 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.787, data: 0.348) D_A: 0.307 G_A: 0.770 cycle_A: 1.520 idt_A: 1.020 D_B: 0.226 G_B: 1.006 cycle_B: 2.489 idt_B: 0.597 \n",
            "End of epoch 4 / 100 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.473, data: 0.459) D_A: 0.181 G_A: 0.339 cycle_A: 0.974 idt_A: 1.406 D_B: 0.195 G_B: 0.638 cycle_B: 3.524 idt_B: 0.410 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.435, data: 0.535) D_A: 0.090 G_A: 0.527 cycle_A: 1.956 idt_A: 0.993 D_B: 0.181 G_B: 0.883 cycle_B: 2.025 idt_B: 1.054 \n",
            "End of epoch 6 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.470, data: 0.335) D_A: 0.090 G_A: 0.540 cycle_A: 0.922 idt_A: 1.413 D_B: 0.151 G_B: 0.543 cycle_B: 3.681 idt_B: 0.423 \n",
            "End of epoch 7 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.712, data: 0.318) D_A: 0.151 G_A: 0.576 cycle_A: 1.451 idt_A: 1.499 D_B: 0.257 G_B: 0.493 cycle_B: 3.707 idt_B: 0.786 \n",
            "End of epoch 8 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.487, data: 0.425) D_A: 0.105 G_A: 0.556 cycle_A: 1.002 idt_A: 1.091 D_B: 0.087 G_B: 0.629 cycle_B: 2.386 idt_B: 0.496 \n",
            "End of epoch 9 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.489, data: 0.300) D_A: 0.284 G_A: 0.481 cycle_A: 1.380 idt_A: 1.498 D_B: 0.122 G_B: 0.249 cycle_B: 3.818 idt_B: 0.742 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.502, data: 0.460) D_A: 0.136 G_A: 0.728 cycle_A: 0.773 idt_A: 1.164 D_B: 0.095 G_B: 0.555 cycle_B: 2.894 idt_B: 0.340 \n",
            "End of epoch 11 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.835, data: 0.678) D_A: 0.060 G_A: 0.801 cycle_A: 0.763 idt_A: 1.093 D_B: 0.276 G_B: 0.705 cycle_B: 2.426 idt_B: 0.338 \n",
            "End of epoch 12 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.451, data: 0.506) D_A: 0.296 G_A: 0.648 cycle_A: 0.840 idt_A: 1.410 D_B: 0.159 G_B: 0.603 cycle_B: 2.827 idt_B: 0.406 \n",
            "End of epoch 13 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.476, data: 0.322) D_A: 0.140 G_A: 0.532 cycle_A: 0.912 idt_A: 1.379 D_B: 0.160 G_B: 0.507 cycle_B: 2.688 idt_B: 0.496 \n",
            "End of epoch 14 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.536, data: 0.301) D_A: 0.086 G_A: 0.487 cycle_A: 0.770 idt_A: 1.045 D_B: 0.175 G_B: 1.327 cycle_B: 2.249 idt_B: 0.376 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 100 \t Time Taken: 47 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.853, data: 0.355) D_A: 0.163 G_A: 0.482 cycle_A: 0.646 idt_A: 2.192 D_B: 0.054 G_B: 1.067 cycle_B: 4.146 idt_B: 0.306 \n",
            "End of epoch 16 / 100 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.445, data: 0.495) D_A: 0.094 G_A: 0.713 cycle_A: 0.785 idt_A: 1.320 D_B: 0.171 G_B: 0.526 cycle_B: 2.747 idt_B: 0.376 \n",
            "End of epoch 17 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.429, data: 0.524) D_A: 0.058 G_A: 0.417 cycle_A: 1.084 idt_A: 0.982 D_B: 0.113 G_B: 0.457 cycle_B: 2.674 idt_B: 0.337 \n",
            "End of epoch 18 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.465, data: 0.308) D_A: 0.098 G_A: 0.315 cycle_A: 0.667 idt_A: 1.575 D_B: 0.059 G_B: 0.760 cycle_B: 3.264 idt_B: 0.257 \n",
            "End of epoch 19 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.775, data: 0.503) D_A: 0.326 G_A: 0.147 cycle_A: 0.878 idt_A: 1.023 D_B: 0.035 G_B: 1.257 cycle_B: 2.174 idt_B: 0.338 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.449, data: 0.319) D_A: 0.137 G_A: 0.613 cycle_A: 0.582 idt_A: 1.097 D_B: 0.095 G_B: 1.170 cycle_B: 2.494 idt_B: 0.263 \n",
            "End of epoch 21 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.469, data: 0.461) D_A: 0.102 G_A: 0.517 cycle_A: 1.196 idt_A: 2.336 D_B: 0.098 G_B: 0.274 cycle_B: 4.325 idt_B: 0.475 \n",
            "End of epoch 22 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.465, data: 0.305) D_A: 0.114 G_A: 0.476 cycle_A: 0.689 idt_A: 1.215 D_B: 0.129 G_B: 1.350 cycle_B: 2.684 idt_B: 0.336 \n",
            "End of epoch 23 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.924, data: 0.477) D_A: 0.177 G_A: 1.505 cycle_A: 0.995 idt_A: 0.925 D_B: 0.060 G_B: 0.859 cycle_B: 1.912 idt_B: 0.398 \n",
            "End of epoch 24 / 100 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.428, data: 0.498) D_A: 0.164 G_A: 0.995 cycle_A: 1.130 idt_A: 0.869 D_B: 0.101 G_B: 0.928 cycle_B: 1.805 idt_B: 0.562 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 100 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.449, data: 0.520) D_A: 0.053 G_A: 0.514 cycle_A: 1.066 idt_A: 1.126 D_B: 0.135 G_B: 0.450 cycle_B: 2.356 idt_B: 0.499 \n",
            "End of epoch 26 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.452, data: 0.318) D_A: 0.058 G_A: 0.701 cycle_A: 0.716 idt_A: 2.128 D_B: 0.066 G_B: 0.632 cycle_B: 3.929 idt_B: 0.282 \n",
            "End of epoch 27 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.911, data: 0.297) D_A: 0.129 G_A: 0.614 cycle_A: 1.398 idt_A: 1.085 D_B: 0.219 G_B: 0.228 cycle_B: 2.381 idt_B: 0.594 \n",
            "End of epoch 28 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.442, data: 0.474) D_A: 0.056 G_A: 0.622 cycle_A: 0.578 idt_A: 1.399 D_B: 0.060 G_B: 0.591 cycle_B: 3.599 idt_B: 0.249 \n",
            "End of epoch 29 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.477, data: 0.275) D_A: 0.187 G_A: 0.625 cycle_A: 1.155 idt_A: 1.001 D_B: 0.212 G_B: 1.018 cycle_B: 2.193 idt_B: 0.385 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.429, data: 0.430) D_A: 0.135 G_A: 0.523 cycle_A: 0.665 idt_A: 1.371 D_B: 0.076 G_B: 1.231 cycle_B: 3.426 idt_B: 0.279 \n",
            "End of epoch 31 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.860, data: 0.391) D_A: 0.063 G_A: 0.360 cycle_A: 0.937 idt_A: 1.127 D_B: 0.163 G_B: 0.964 cycle_B: 2.301 idt_B: 0.514 \n",
            "End of epoch 32 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.435, data: 0.337) D_A: 0.106 G_A: 1.041 cycle_A: 0.997 idt_A: 1.270 D_B: 0.046 G_B: 0.216 cycle_B: 3.447 idt_B: 0.559 \n",
            "End of epoch 33 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.437, data: 0.500) D_A: 0.165 G_A: 1.138 cycle_A: 0.688 idt_A: 0.839 D_B: 0.157 G_B: 0.292 cycle_B: 1.958 idt_B: 0.289 \n",
            "End of epoch 34 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.456, data: 0.337) D_A: 0.073 G_A: 0.706 cycle_A: 0.890 idt_A: 1.505 D_B: 0.097 G_B: 0.753 cycle_B: 3.124 idt_B: 0.457 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.846, data: 0.489) D_A: 0.064 G_A: 0.857 cycle_A: 1.472 idt_A: 1.470 D_B: 0.024 G_B: 0.504 cycle_B: 3.191 idt_B: 0.561 \n",
            "End of epoch 36 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.468, data: 0.310) D_A: 0.065 G_A: 0.299 cycle_A: 1.112 idt_A: 1.317 D_B: 0.026 G_B: 0.188 cycle_B: 2.597 idt_B: 0.456 \n",
            "End of epoch 37 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.430, data: 0.614) D_A: 0.080 G_A: 0.642 cycle_A: 0.853 idt_A: 0.824 D_B: 0.066 G_B: 0.737 cycle_B: 2.134 idt_B: 0.346 \n",
            "End of epoch 38 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.461, data: 0.292) D_A: 0.179 G_A: 0.336 cycle_A: 0.721 idt_A: 1.050 D_B: 0.173 G_B: 0.475 cycle_B: 2.602 idt_B: 0.335 \n",
            "End of epoch 39 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.915, data: 0.517) D_A: 0.137 G_A: 0.620 cycle_A: 0.899 idt_A: 1.146 D_B: 0.095 G_B: 0.839 cycle_B: 2.297 idt_B: 0.247 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.466, data: 0.362) D_A: 0.148 G_A: 0.599 cycle_A: 0.494 idt_A: 1.674 D_B: 0.129 G_B: 0.962 cycle_B: 3.477 idt_B: 0.235 \n",
            "End of epoch 41 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.434, data: 0.288) D_A: 0.088 G_A: 0.063 cycle_A: 0.973 idt_A: 1.467 D_B: 0.129 G_B: 1.321 cycle_B: 3.111 idt_B: 0.486 \n",
            "End of epoch 42 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.436, data: 0.336) D_A: 0.177 G_A: 0.515 cycle_A: 1.447 idt_A: 1.039 D_B: 0.166 G_B: 0.331 cycle_B: 2.793 idt_B: 0.733 \n",
            "End of epoch 43 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.950, data: 0.313) D_A: 0.196 G_A: 0.266 cycle_A: 1.271 idt_A: 1.468 D_B: 0.103 G_B: 0.712 cycle_B: 3.686 idt_B: 0.471 \n",
            "End of epoch 44 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.435, data: 0.460) D_A: 0.095 G_A: 0.632 cycle_A: 0.707 idt_A: 1.005 D_B: 0.101 G_B: 0.512 cycle_B: 2.677 idt_B: 0.275 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.462, data: 0.370) D_A: 0.108 G_A: 0.559 cycle_A: 1.070 idt_A: 1.830 D_B: 0.080 G_B: 0.626 cycle_B: 3.568 idt_B: 0.542 \n",
            "End of epoch 46 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.437, data: 0.546) D_A: 0.293 G_A: 0.658 cycle_A: 0.897 idt_A: 1.231 D_B: 0.083 G_B: 0.287 cycle_B: 3.093 idt_B: 0.363 \n",
            "End of epoch 47 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 1.197, data: 0.345) D_A: 0.213 G_A: 0.335 cycle_A: 5.610 idt_A: 1.066 D_B: 0.220 G_B: 1.225 cycle_B: 2.913 idt_B: 2.805 \n",
            "End of epoch 48 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.438, data: 0.343) D_A: 0.279 G_A: 0.236 cycle_A: 5.217 idt_A: 1.616 D_B: 0.014 G_B: 1.021 cycle_B: 5.248 idt_B: 2.608 \n",
            "End of epoch 49 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0002000 -> 0.0001961\n",
            "(epoch: 50, iters: 100, time: 0.441, data: 0.280) D_A: 0.169 G_A: 0.323 cycle_A: 6.689 idt_A: 0.965 D_B: 0.009 G_B: 1.015 cycle_B: 4.672 idt_B: 3.345 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0001961 -> 0.0001922\n",
            "(epoch: 51, iters: 100, time: 0.458, data: 0.360) D_A: 0.156 G_A: 1.031 cycle_A: 6.258 idt_A: 1.167 D_B: 0.002 G_B: 1.034 cycle_B: 4.875 idt_B: 3.129 \n",
            "End of epoch 51 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0001922 -> 0.0001882\n",
            "(epoch: 52, iters: 100, time: 0.928, data: 0.509) D_A: 0.189 G_A: 0.761 cycle_A: 5.792 idt_A: 1.324 D_B: 0.006 G_B: 0.991 cycle_B: 4.521 idt_B: 2.896 \n",
            "End of epoch 52 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001882 -> 0.0001843\n",
            "(epoch: 53, iters: 100, time: 0.455, data: 0.343) D_A: 0.208 G_A: 0.229 cycle_A: 5.132 idt_A: 1.174 D_B: 0.002 G_B: 1.025 cycle_B: 5.241 idt_B: 2.566 \n",
            "End of epoch 53 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001843 -> 0.0001804\n",
            "(epoch: 54, iters: 100, time: 0.446, data: 0.389) D_A: 0.182 G_A: 1.073 cycle_A: 6.147 idt_A: 0.895 D_B: 0.002 G_B: 1.005 cycle_B: 5.184 idt_B: 3.073 \n",
            "End of epoch 54 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001804 -> 0.0001765\n",
            "(epoch: 55, iters: 100, time: 0.437, data: 0.285) D_A: 0.154 G_A: 0.720 cycle_A: 5.155 idt_A: 1.079 D_B: 0.002 G_B: 1.021 cycle_B: 6.255 idt_B: 2.578 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0001765 -> 0.0001725\n",
            "(epoch: 56, iters: 100, time: 1.289, data: 0.382) D_A: 0.296 G_A: 1.491 cycle_A: 5.670 idt_A: 2.717 D_B: 0.004 G_B: 0.953 cycle_B: 5.433 idt_B: 2.835 \n",
            "End of epoch 56 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0001725 -> 0.0001686\n",
            "(epoch: 57, iters: 100, time: 0.441, data: 0.647) D_A: 0.146 G_A: 0.844 cycle_A: 6.213 idt_A: 2.546 D_B: 0.001 G_B: 0.968 cycle_B: 5.093 idt_B: 3.106 \n",
            "End of epoch 57 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001686 -> 0.0001647\n",
            "(epoch: 58, iters: 100, time: 0.478, data: 0.346) D_A: 0.015 G_A: 1.054 cycle_A: 5.045 idt_A: 2.403 D_B: 0.004 G_B: 0.978 cycle_B: 4.806 idt_B: 2.522 \n",
            "End of epoch 58 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001647 -> 0.0001608\n",
            "(epoch: 59, iters: 100, time: 0.439, data: 0.528) D_A: 0.029 G_A: 0.774 cycle_A: 5.179 idt_A: 2.455 D_B: 0.002 G_B: 0.969 cycle_B: 4.910 idt_B: 2.589 \n",
            "End of epoch 59 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001608 -> 0.0001569\n",
            "(epoch: 60, iters: 100, time: 0.936, data: 0.315) D_A: 0.016 G_A: 0.848 cycle_A: 5.254 idt_A: 2.977 D_B: 0.003 G_B: 1.018 cycle_B: 5.955 idt_B: 2.627 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0001569 -> 0.0001529\n",
            "(epoch: 61, iters: 100, time: 0.455, data: 0.334) D_A: 0.014 G_A: 1.010 cycle_A: 4.917 idt_A: 2.849 D_B: 0.002 G_B: 0.976 cycle_B: 5.699 idt_B: 2.459 \n",
            "End of epoch 61 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0001529 -> 0.0001490\n",
            "(epoch: 62, iters: 100, time: 0.442, data: 0.475) D_A: 0.004 G_A: 0.996 cycle_A: 5.578 idt_A: 3.055 D_B: 0.002 G_B: 1.027 cycle_B: 6.110 idt_B: 2.789 \n",
            "End of epoch 62 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001490 -> 0.0001451\n",
            "(epoch: 63, iters: 100, time: 0.459, data: 0.284) D_A: 0.006 G_A: 0.958 cycle_A: 5.483 idt_A: 2.108 D_B: 0.001 G_B: 1.008 cycle_B: 4.217 idt_B: 2.742 \n",
            "End of epoch 63 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001451 -> 0.0001412\n",
            "(epoch: 64, iters: 100, time: 1.136, data: 0.457) D_A: 0.004 G_A: 0.977 cycle_A: 4.163 idt_A: 1.677 D_B: 0.001 G_B: 1.006 cycle_B: 3.354 idt_B: 2.082 \n",
            "End of epoch 64 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001412 -> 0.0001373\n",
            "(epoch: 65, iters: 100, time: 0.463, data: 0.381) D_A: 0.007 G_A: 1.093 cycle_A: 4.126 idt_A: 2.757 D_B: 0.002 G_B: 1.010 cycle_B: 5.514 idt_B: 2.063 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0001373 -> 0.0001333\n",
            "(epoch: 66, iters: 100, time: 0.463, data: 0.373) D_A: 0.005 G_A: 0.971 cycle_A: 4.656 idt_A: 3.117 D_B: 0.002 G_B: 1.000 cycle_B: 6.235 idt_B: 2.328 \n",
            "End of epoch 66 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001333 -> 0.0001294\n",
            "(epoch: 67, iters: 100, time: 0.433, data: 0.479) D_A: 0.003 G_A: 0.975 cycle_A: 4.380 idt_A: 2.719 D_B: 0.001 G_B: 0.987 cycle_B: 5.439 idt_B: 2.190 \n",
            "End of epoch 67 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001294 -> 0.0001255\n",
            "(epoch: 68, iters: 100, time: 1.136, data: 0.282) D_A: 0.003 G_A: 0.985 cycle_A: 4.739 idt_A: 2.839 D_B: 0.002 G_B: 0.980 cycle_B: 5.678 idt_B: 2.369 \n",
            "End of epoch 68 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001255 -> 0.0001216\n",
            "(epoch: 69, iters: 100, time: 0.434, data: 0.489) D_A: 0.002 G_A: 0.983 cycle_A: 4.719 idt_A: 2.395 D_B: 0.002 G_B: 1.044 cycle_B: 4.789 idt_B: 2.359 \n",
            "End of epoch 69 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001216 -> 0.0001176\n",
            "(epoch: 70, iters: 100, time: 0.459, data: 0.313) D_A: 0.003 G_A: 0.980 cycle_A: 4.536 idt_A: 1.723 D_B: 0.001 G_B: 1.032 cycle_B: 3.446 idt_B: 2.268 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 100 \t Time Taken: 44 sec\n",
            "learning rate 0.0001176 -> 0.0001137\n",
            "(epoch: 71, iters: 100, time: 0.463, data: 0.328) D_A: 0.002 G_A: 0.994 cycle_A: 4.136 idt_A: 2.689 D_B: 0.001 G_B: 1.029 cycle_B: 5.379 idt_B: 2.068 \n",
            "End of epoch 71 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0001137 -> 0.0001098\n",
            "(epoch: 72, iters: 100, time: 0.980, data: 0.528) D_A: 0.003 G_A: 1.037 cycle_A: 4.872 idt_A: 2.926 D_B: 0.002 G_B: 1.009 cycle_B: 5.852 idt_B: 2.436 \n",
            "End of epoch 72 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001098 -> 0.0001059\n",
            "(epoch: 73, iters: 100, time: 0.472, data: 0.294) D_A: 0.004 G_A: 0.962 cycle_A: 4.643 idt_A: 2.072 D_B: 0.001 G_B: 0.996 cycle_B: 4.145 idt_B: 2.322 \n",
            "End of epoch 73 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0001059 -> 0.0001020\n",
            "(epoch: 74, iters: 100, time: 0.438, data: 0.545) D_A: 0.003 G_A: 1.029 cycle_A: 4.547 idt_A: 1.898 D_B: 0.002 G_B: 1.047 cycle_B: 3.796 idt_B: 2.273 \n",
            "End of epoch 74 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0001020 -> 0.0000980\n",
            "(epoch: 75, iters: 100, time: 0.457, data: 0.288) D_A: 0.003 G_A: 1.008 cycle_A: 4.613 idt_A: 2.122 D_B: 0.002 G_B: 1.043 cycle_B: 4.244 idt_B: 2.307 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 100 \t Time Taken: 46 sec\n",
            "learning rate 0.0000980 -> 0.0000941\n",
            "(epoch: 76, iters: 100, time: 1.199, data: 0.363) D_A: 0.002 G_A: 0.990 cycle_A: 4.336 idt_A: 2.810 D_B: 0.003 G_B: 0.984 cycle_B: 5.620 idt_B: 2.168 \n",
            "End of epoch 76 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0000941 -> 0.0000902\n",
            "(epoch: 77, iters: 100, time: 0.434, data: 0.512) D_A: 0.002 G_A: 1.035 cycle_A: 4.212 idt_A: 1.599 D_B: 0.001 G_B: 1.017 cycle_B: 3.199 idt_B: 2.106 \n",
            "End of epoch 77 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0000902 -> 0.0000863\n",
            "(epoch: 78, iters: 100, time: 0.474, data: 0.363) D_A: 0.005 G_A: 0.999 cycle_A: 5.103 idt_A: 2.424 D_B: 0.002 G_B: 1.012 cycle_B: 4.848 idt_B: 2.552 \n",
            "End of epoch 78 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0000863 -> 0.0000824\n",
            "(epoch: 79, iters: 100, time: 0.427, data: 0.508) D_A: 0.002 G_A: 1.001 cycle_A: 4.373 idt_A: 2.739 D_B: 0.001 G_B: 1.017 cycle_B: 5.479 idt_B: 2.186 \n",
            "End of epoch 79 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0000824 -> 0.0000784\n",
            "(epoch: 80, iters: 100, time: 1.217, data: 0.288) D_A: 0.005 G_A: 1.009 cycle_A: 4.732 idt_A: 2.396 D_B: 0.001 G_B: 1.002 cycle_B: 4.792 idt_B: 2.366 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0000784 -> 0.0000745\n",
            "(epoch: 81, iters: 100, time: 0.437, data: 0.345) D_A: 0.002 G_A: 1.019 cycle_A: 4.654 idt_A: 2.118 D_B: 0.001 G_B: 0.999 cycle_B: 4.236 idt_B: 2.327 \n",
            "End of epoch 81 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0000745 -> 0.0000706\n",
            "(epoch: 82, iters: 100, time: 0.423, data: 0.392) D_A: 0.002 G_A: 1.013 cycle_A: 3.778 idt_A: 1.974 D_B: 0.004 G_B: 1.049 cycle_B: 3.948 idt_B: 1.889 \n",
            "End of epoch 82 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0000706 -> 0.0000667\n",
            "(epoch: 83, iters: 100, time: 0.468, data: 0.359) D_A: 0.002 G_A: 0.996 cycle_A: 4.732 idt_A: 2.118 D_B: 0.001 G_B: 1.022 cycle_B: 4.236 idt_B: 2.366 \n",
            "End of epoch 83 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0000667 -> 0.0000627\n",
            "(epoch: 84, iters: 100, time: 1.278, data: 0.501) D_A: 0.002 G_A: 1.011 cycle_A: 4.372 idt_A: 1.690 D_B: 0.002 G_B: 1.003 cycle_B: 3.380 idt_B: 2.186 \n",
            "End of epoch 84 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0000627 -> 0.0000588\n",
            "(epoch: 85, iters: 100, time: 0.444, data: 0.392) D_A: 0.002 G_A: 1.012 cycle_A: 4.146 idt_A: 2.896 D_B: 0.001 G_B: 0.994 cycle_B: 5.793 idt_B: 2.073 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0000588 -> 0.0000549\n",
            "(epoch: 86, iters: 100, time: 0.435, data: 0.336) D_A: 0.002 G_A: 0.978 cycle_A: 4.321 idt_A: 1.533 D_B: 0.000 G_B: 0.998 cycle_B: 3.067 idt_B: 2.161 \n",
            "End of epoch 86 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0000549 -> 0.0000510\n",
            "(epoch: 87, iters: 100, time: 0.431, data: 0.334) D_A: 0.001 G_A: 0.979 cycle_A: 4.128 idt_A: 1.978 D_B: 0.001 G_B: 0.999 cycle_B: 3.956 idt_B: 2.064 \n",
            "End of epoch 87 / 100 \t Time Taken: 40 sec\n",
            "learning rate 0.0000510 -> 0.0000471\n",
            "(epoch: 88, iters: 100, time: 1.307, data: 0.332) D_A: 0.002 G_A: 1.008 cycle_A: 4.894 idt_A: 2.333 D_B: 0.001 G_B: 0.986 cycle_B: 4.667 idt_B: 2.447 \n",
            "End of epoch 88 / 100 \t Time Taken: 43 sec\n",
            "learning rate 0.0000471 -> 0.0000431\n",
            "(epoch: 89, iters: 100, time: 0.444, data: 0.491) D_A: 0.001 G_A: 0.984 cycle_A: 4.661 idt_A: 2.824 D_B: 0.001 G_B: 0.986 cycle_B: 5.649 idt_B: 2.331 \n",
            "End of epoch 89 / 100 \t Time Taken: 41 sec\n",
            "learning rate 0.0000431 -> 0.0000392\n",
            "(epoch: 90, iters: 100, time: 0.453, data: 0.334) D_A: 0.002 G_A: 1.011 cycle_A: 4.129 idt_A: 2.242 D_B: 0.001 G_B: 0.988 cycle_B: 4.484 idt_B: 2.064 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 100 \t Time Taken: 42 sec\n",
            "learning rate 0.0000392 -> 0.0000353\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/repos/pytorch-UniCycleGAN-project/train.py\", line 59, in <module>\n",
            "  File \"/content/drive/MyDrive/repos/pytorch-UniCycleGAN-project/data/__init__.py\", line 90, in __iter__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1345, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1371, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 694, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 2.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/drive/MyDrive/repos/pytorch-UniCycleGAN-project/data/unaligned_dataset.py\", line 57, in __getitem__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3227, in open\n",
            "    fp = builtins.open(filename, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split/trainA/Copy of Copy of src_3_2854__333_349_165.png'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_9_blocks --train_name truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_9_blocks --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 101 --n_epochs 50 --n_epochs_decay 50 --layer_types ReflectionPad2d_Conv2d --n_layers_cell 3 --n_blocks 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK72Xnu8UQMF",
        "outputId": "3aa68f19-2285-43d3-928a-269990d5e085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 101                           \t[default: 50]\n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 10                            \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: ReflectionPad2d_Conv2d+ReLU   \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_blocks: 6                             \t[default: 9]\n",
            "                 n_epochs: 50                            \t[default: 100]\n",
            "           n_epochs_decay: 50                            \t[default: 100]\n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 3                             \t[default: 5]\n",
            "                     name: truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_6_blocks\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_6_blocks\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 100\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_6_blocks/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.345, data: 1.970) D_A: 0.204 G_A: 0.384 cycle_A: 1.145 idt_A: 1.499 D_B: 0.179 G_B: 0.539 cycle_B: 3.177 idt_B: 0.348 \n",
            "End of epoch 1 / 100 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.336, data: 0.622) D_A: 0.158 G_A: 0.153 cycle_A: 0.963 idt_A: 1.175 D_B: 0.274 G_B: 0.350 cycle_B: 2.977 idt_B: 0.486 \n",
            "End of epoch 2 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.426, data: 0.785) D_A: 0.260 G_A: 0.536 cycle_A: 1.601 idt_A: 1.321 D_B: 0.092 G_B: 0.256 cycle_B: 2.326 idt_B: 0.408 \n",
            "End of epoch 3 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 6.816, data: 0.217) D_A: 0.081 G_A: 0.579 cycle_A: 0.593 idt_A: 0.864 D_B: 0.154 G_B: 0.679 cycle_B: 1.784 idt_B: 0.369 \n",
            "End of epoch 4 / 100 \t Time Taken: 38 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.337, data: 0.169) D_A: 0.102 G_A: 0.422 cycle_A: 0.817 idt_A: 2.088 D_B: 0.145 G_B: 0.859 cycle_B: 3.889 idt_B: 0.389 \n",
            "saving the model at the end of epoch 5, iters 500\n",
            "End of epoch 5 / 100 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.350, data: 0.344) D_A: 0.164 G_A: 0.934 cycle_A: 0.711 idt_A: 1.304 D_B: 0.131 G_B: 0.395 cycle_B: 3.232 idt_B: 0.435 \n",
            "End of epoch 6 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.385, data: 0.313) D_A: 0.378 G_A: 0.246 cycle_A: 0.831 idt_A: 1.864 D_B: 0.249 G_B: 1.204 cycle_B: 3.473 idt_B: 0.277 \n",
            "End of epoch 7 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 4.661, data: 0.402) D_A: 0.199 G_A: 0.812 cycle_A: 0.704 idt_A: 1.531 D_B: 0.161 G_B: 0.641 cycle_B: 3.015 idt_B: 0.338 \n",
            "End of epoch 8 / 100 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.360, data: 0.239) D_A: 0.151 G_A: 0.414 cycle_A: 1.683 idt_A: 1.144 D_B: 0.097 G_B: 0.617 cycle_B: 2.937 idt_B: 0.641 \n",
            "End of epoch 9 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.348, data: 0.219) D_A: 0.223 G_A: 0.728 cycle_A: 1.085 idt_A: 1.305 D_B: 0.142 G_B: 0.579 cycle_B: 3.110 idt_B: 0.488 \n",
            "saving the model at the end of epoch 10, iters 1000\n",
            "End of epoch 10 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.355, data: 0.243) D_A: 0.236 G_A: 0.499 cycle_A: 0.950 idt_A: 1.560 D_B: 0.255 G_B: 1.443 cycle_B: 2.827 idt_B: 0.486 \n",
            "End of epoch 11 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 4.432, data: 0.196) D_A: 0.196 G_A: 0.453 cycle_A: 0.581 idt_A: 2.538 D_B: 0.163 G_B: 0.532 cycle_B: 5.072 idt_B: 0.312 \n",
            "End of epoch 12 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.344, data: 0.209) D_A: 0.286 G_A: 0.955 cycle_A: 1.056 idt_A: 1.280 D_B: 0.224 G_B: 0.465 cycle_B: 2.555 idt_B: 0.506 \n",
            "End of epoch 13 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.387, data: 0.215) D_A: 0.153 G_A: 0.359 cycle_A: 0.615 idt_A: 1.192 D_B: 0.196 G_B: 0.808 cycle_B: 2.643 idt_B: 0.215 \n",
            "End of epoch 14 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.334, data: 0.239) D_A: 0.096 G_A: 0.428 cycle_A: 0.879 idt_A: 1.351 D_B: 0.127 G_B: 0.835 cycle_B: 3.195 idt_B: 0.435 \n",
            "saving the model at the end of epoch 15, iters 1500\n",
            "End of epoch 15 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 4.334, data: 0.207) D_A: 0.143 G_A: 1.146 cycle_A: 0.796 idt_A: 0.840 D_B: 0.130 G_B: 0.904 cycle_B: 1.906 idt_B: 0.332 \n",
            "End of epoch 16 / 100 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.379, data: 0.347) D_A: 0.337 G_A: 0.110 cycle_A: 1.225 idt_A: 1.073 D_B: 0.086 G_B: 1.503 cycle_B: 2.498 idt_B: 0.372 \n",
            "End of epoch 17 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.382, data: 0.388) D_A: 0.103 G_A: 0.461 cycle_A: 1.058 idt_A: 0.872 D_B: 0.095 G_B: 1.070 cycle_B: 2.179 idt_B: 0.462 \n",
            "End of epoch 18 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.389, data: 0.304) D_A: 0.119 G_A: 0.280 cycle_A: 1.031 idt_A: 0.821 D_B: 0.156 G_B: 0.495 cycle_B: 1.501 idt_B: 0.261 \n",
            "End of epoch 19 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 4.567, data: 0.304) D_A: 0.163 G_A: 0.389 cycle_A: 0.974 idt_A: 1.037 D_B: 0.036 G_B: 0.202 cycle_B: 2.259 idt_B: 0.512 \n",
            "saving the model at the end of epoch 20, iters 2000\n",
            "End of epoch 20 / 100 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.326, data: 0.235) D_A: 0.238 G_A: 0.888 cycle_A: 0.645 idt_A: 0.921 D_B: 0.179 G_B: 0.231 cycle_B: 2.473 idt_B: 0.321 \n",
            "End of epoch 21 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.341, data: 0.217) D_A: 0.129 G_A: 0.845 cycle_A: 1.086 idt_A: 1.131 D_B: 0.048 G_B: 0.720 cycle_B: 2.700 idt_B: 0.497 \n",
            "End of epoch 22 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.339, data: 0.343) D_A: 0.201 G_A: 0.364 cycle_A: 0.818 idt_A: 0.961 D_B: 0.224 G_B: 1.129 cycle_B: 2.252 idt_B: 0.350 \n",
            "End of epoch 23 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 4.589, data: 0.287) D_A: 0.234 G_A: 0.656 cycle_A: 0.727 idt_A: 1.036 D_B: 0.096 G_B: 0.223 cycle_B: 2.387 idt_B: 0.272 \n",
            "End of epoch 24 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.342, data: 0.343) D_A: 0.103 G_A: 0.561 cycle_A: 0.724 idt_A: 1.011 D_B: 0.097 G_B: 0.099 cycle_B: 2.252 idt_B: 0.291 \n",
            "saving the model at the end of epoch 25, iters 2500\n",
            "End of epoch 25 / 100 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.342, data: 0.424) D_A: 0.174 G_A: 0.613 cycle_A: 0.924 idt_A: 1.223 D_B: 0.293 G_B: 0.339 cycle_B: 2.678 idt_B: 0.467 \n",
            "End of epoch 26 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.322, data: 0.272) D_A: 0.359 G_A: 1.129 cycle_A: 0.677 idt_A: 2.068 D_B: 0.261 G_B: 0.150 cycle_B: 4.609 idt_B: 0.309 \n",
            "End of epoch 27 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 4.448, data: 0.235) D_A: 0.083 G_A: 0.469 cycle_A: 0.966 idt_A: 0.671 D_B: 0.064 G_B: 0.592 cycle_B: 1.638 idt_B: 0.524 \n",
            "End of epoch 28 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.329, data: 0.220) D_A: 0.119 G_A: 0.331 cycle_A: 0.750 idt_A: 0.974 D_B: 0.077 G_B: 1.008 cycle_B: 2.278 idt_B: 0.251 \n",
            "End of epoch 29 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.327, data: 0.230) D_A: 0.181 G_A: 0.597 cycle_A: 1.434 idt_A: 1.403 D_B: 0.079 G_B: 0.437 cycle_B: 2.844 idt_B: 0.376 \n",
            "saving the model at the end of epoch 30, iters 3000\n",
            "End of epoch 30 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.360, data: 0.229) D_A: 0.247 G_A: 0.745 cycle_A: 1.066 idt_A: 1.353 D_B: 0.105 G_B: 0.343 cycle_B: 2.424 idt_B: 0.456 \n",
            "End of epoch 31 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 4.214, data: 0.188) D_A: 0.116 G_A: 0.661 cycle_A: 1.001 idt_A: 1.403 D_B: 0.093 G_B: 0.819 cycle_B: 2.521 idt_B: 0.540 \n",
            "End of epoch 32 / 100 \t Time Taken: 36 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.364, data: 0.193) D_A: 0.199 G_A: 0.577 cycle_A: 1.126 idt_A: 1.056 D_B: 0.166 G_B: 0.319 cycle_B: 2.843 idt_B: 0.594 \n",
            "End of epoch 33 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.341, data: 0.244) D_A: 0.289 G_A: 0.175 cycle_A: 1.260 idt_A: 1.406 D_B: 0.119 G_B: 1.538 cycle_B: 2.803 idt_B: 0.442 \n",
            "End of epoch 34 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.344, data: 0.213) D_A: 0.251 G_A: 0.389 cycle_A: 0.803 idt_A: 0.937 D_B: 0.113 G_B: 0.881 cycle_B: 2.541 idt_B: 0.215 \n",
            "saving the model at the end of epoch 35, iters 3500\n",
            "End of epoch 35 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 4.459, data: 0.238) D_A: 0.099 G_A: 0.190 cycle_A: 1.090 idt_A: 1.394 D_B: 0.088 G_B: 0.087 cycle_B: 3.035 idt_B: 0.340 \n",
            "End of epoch 36 / 100 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.369, data: 0.400) D_A: 0.115 G_A: 0.751 cycle_A: 0.725 idt_A: 1.186 D_B: 0.054 G_B: 0.536 cycle_B: 1.889 idt_B: 0.250 \n",
            "End of epoch 37 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.384, data: 0.397) D_A: 0.163 G_A: 0.239 cycle_A: 0.879 idt_A: 1.398 D_B: 0.178 G_B: 0.517 cycle_B: 3.104 idt_B: 0.376 \n",
            "End of epoch 38 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.391, data: 0.227) D_A: 0.060 G_A: 0.824 cycle_A: 0.891 idt_A: 0.807 D_B: 0.118 G_B: 0.984 cycle_B: 2.937 idt_B: 0.405 \n",
            "End of epoch 39 / 100 \t Time Taken: 32 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 4.712, data: 0.255) D_A: 0.594 G_A: 0.855 cycle_A: 0.973 idt_A: 1.434 D_B: 0.069 G_B: 0.694 cycle_B: 3.000 idt_B: 0.229 \n",
            "saving the model at the end of epoch 40, iters 4000\n",
            "End of epoch 40 / 100 \t Time Taken: 37 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.327, data: 0.200) D_A: 0.070 G_A: 0.705 cycle_A: 1.064 idt_A: 1.631 D_B: 0.352 G_B: 0.125 cycle_B: 2.717 idt_B: 0.386 \n",
            "End of epoch 41 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.330, data: 0.194) D_A: 0.124 G_A: 0.272 cycle_A: 1.023 idt_A: 1.119 D_B: 0.494 G_B: 1.964 cycle_B: 2.792 idt_B: 0.422 \n",
            "End of epoch 42 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.348, data: 0.208) D_A: 0.387 G_A: 0.494 cycle_A: 1.026 idt_A: 1.878 D_B: 0.124 G_B: 0.157 cycle_B: 3.093 idt_B: 0.404 \n",
            "End of epoch 43 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 4.276, data: 0.347) D_A: 0.124 G_A: 0.189 cycle_A: 1.050 idt_A: 1.112 D_B: 0.435 G_B: 0.565 cycle_B: 2.287 idt_B: 0.524 \n",
            "End of epoch 44 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.348, data: 0.225) D_A: 0.231 G_A: 0.470 cycle_A: 0.688 idt_A: 1.139 D_B: 0.136 G_B: 0.565 cycle_B: 2.243 idt_B: 0.297 \n",
            "saving the model at the end of epoch 45, iters 4500\n",
            "End of epoch 45 / 100 \t Time Taken: 31 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.355, data: 0.240) D_A: 0.129 G_A: 0.649 cycle_A: 0.868 idt_A: 1.311 D_B: 0.106 G_B: 0.440 cycle_B: 2.929 idt_B: 0.263 \n",
            "End of epoch 46 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.331, data: 0.438) D_A: 0.193 G_A: 1.006 cycle_A: 1.108 idt_A: 1.223 D_B: 0.037 G_B: 0.821 cycle_B: 3.204 idt_B: 0.408 \n",
            "End of epoch 47 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 4.647, data: 0.237) D_A: 0.245 G_A: 0.706 cycle_A: 0.976 idt_A: 0.687 D_B: 0.486 G_B: 0.213 cycle_B: 1.516 idt_B: 0.459 \n",
            "End of epoch 48 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.327, data: 0.323) D_A: 0.104 G_A: 0.226 cycle_A: 0.781 idt_A: 1.326 D_B: 0.064 G_B: 0.836 cycle_B: 3.994 idt_B: 0.300 \n",
            "End of epoch 49 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0002000 -> 0.0001961\n",
            "(epoch: 50, iters: 100, time: 0.334, data: 0.251) D_A: 0.141 G_A: 0.729 cycle_A: 0.955 idt_A: 1.405 D_B: 0.183 G_B: 0.524 cycle_B: 3.094 idt_B: 0.345 \n",
            "saving the latest model (epoch 50, total_iters 5000)\n",
            "saving the model at the end of epoch 50, iters 5000\n",
            "End of epoch 50 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0001961 -> 0.0001922\n",
            "(epoch: 51, iters: 100, time: 0.324, data: 0.351) D_A: 0.294 G_A: 0.723 cycle_A: 0.906 idt_A: 1.511 D_B: 0.059 G_B: 0.513 cycle_B: 2.988 idt_B: 0.343 \n",
            "End of epoch 51 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0001922 -> 0.0001882\n",
            "(epoch: 52, iters: 100, time: 4.584, data: 0.203) D_A: 0.299 G_A: 0.119 cycle_A: 1.034 idt_A: 0.967 D_B: 0.195 G_B: 0.266 cycle_B: 3.425 idt_B: 0.394 \n",
            "End of epoch 52 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0001882 -> 0.0001843\n",
            "(epoch: 53, iters: 100, time: 0.321, data: 0.230) D_A: 0.149 G_A: 0.526 cycle_A: 0.809 idt_A: 0.771 D_B: 0.046 G_B: 0.454 cycle_B: 2.213 idt_B: 0.304 \n",
            "End of epoch 53 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001843 -> 0.0001804\n",
            "(epoch: 54, iters: 100, time: 0.359, data: 0.229) D_A: 0.061 G_A: 0.633 cycle_A: 0.738 idt_A: 1.134 D_B: 0.120 G_B: 0.867 cycle_B: 2.492 idt_B: 0.258 \n",
            "End of epoch 54 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001804 -> 0.0001765\n",
            "(epoch: 55, iters: 100, time: 0.331, data: 0.206) D_A: 0.225 G_A: 0.292 cycle_A: 0.879 idt_A: 1.039 D_B: 0.070 G_B: 0.262 cycle_B: 2.407 idt_B: 0.398 \n",
            "saving the model at the end of epoch 55, iters 5500\n",
            "End of epoch 55 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0001765 -> 0.0001725\n",
            "(epoch: 56, iters: 100, time: 4.514, data: 0.221) D_A: 0.394 G_A: 0.472 cycle_A: 0.896 idt_A: 0.941 D_B: 0.054 G_B: 0.569 cycle_B: 2.406 idt_B: 0.235 \n",
            "End of epoch 56 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0001725 -> 0.0001686\n",
            "(epoch: 57, iters: 100, time: 0.324, data: 0.310) D_A: 0.076 G_A: 0.562 cycle_A: 0.959 idt_A: 0.773 D_B: 0.102 G_B: 0.286 cycle_B: 1.836 idt_B: 0.375 \n",
            "End of epoch 57 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001686 -> 0.0001647\n",
            "(epoch: 58, iters: 100, time: 0.352, data: 0.189) D_A: 0.195 G_A: 0.460 cycle_A: 0.911 idt_A: 1.301 D_B: 0.054 G_B: 0.408 cycle_B: 3.161 idt_B: 0.366 \n",
            "End of epoch 58 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001647 -> 0.0001608\n",
            "(epoch: 59, iters: 100, time: 0.349, data: 0.405) D_A: 0.106 G_A: 0.299 cycle_A: 1.026 idt_A: 1.013 D_B: 0.125 G_B: 0.682 cycle_B: 2.182 idt_B: 0.423 \n",
            "End of epoch 59 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001608 -> 0.0001569\n",
            "(epoch: 60, iters: 100, time: 4.221, data: 0.389) D_A: 0.219 G_A: 0.881 cycle_A: 0.808 idt_A: 1.090 D_B: 0.083 G_B: 0.537 cycle_B: 2.385 idt_B: 0.375 \n",
            "saving the model at the end of epoch 60, iters 6000\n",
            "End of epoch 60 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0001569 -> 0.0001529\n",
            "(epoch: 61, iters: 100, time: 0.338, data: 0.426) D_A: 0.128 G_A: 0.402 cycle_A: 0.810 idt_A: 0.813 D_B: 0.063 G_B: 0.430 cycle_B: 2.244 idt_B: 0.305 \n",
            "End of epoch 61 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001529 -> 0.0001490\n",
            "(epoch: 62, iters: 100, time: 0.343, data: 0.405) D_A: 0.154 G_A: 0.621 cycle_A: 1.058 idt_A: 0.689 D_B: 0.123 G_B: 0.567 cycle_B: 2.001 idt_B: 0.414 \n",
            "End of epoch 62 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001490 -> 0.0001451\n",
            "(epoch: 63, iters: 100, time: 0.325, data: 0.356) D_A: 0.347 G_A: 0.193 cycle_A: 0.683 idt_A: 1.050 D_B: 0.050 G_B: 0.815 cycle_B: 2.364 idt_B: 0.306 \n",
            "End of epoch 63 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001451 -> 0.0001412\n",
            "(epoch: 64, iters: 100, time: 4.565, data: 0.252) D_A: 0.242 G_A: 0.785 cycle_A: 0.616 idt_A: 0.853 D_B: 0.218 G_B: 0.195 cycle_B: 1.922 idt_B: 0.291 \n",
            "End of epoch 64 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0001412 -> 0.0001373\n",
            "(epoch: 65, iters: 100, time: 0.326, data: 0.191) D_A: 0.048 G_A: 0.523 cycle_A: 0.553 idt_A: 1.159 D_B: 0.096 G_B: 0.852 cycle_B: 2.599 idt_B: 0.236 \n",
            "saving the model at the end of epoch 65, iters 6500\n",
            "End of epoch 65 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0001373 -> 0.0001333\n",
            "(epoch: 66, iters: 100, time: 0.323, data: 0.249) D_A: 0.179 G_A: 0.253 cycle_A: 0.858 idt_A: 1.273 D_B: 0.146 G_B: 0.478 cycle_B: 2.867 idt_B: 0.249 \n",
            "End of epoch 66 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0001333 -> 0.0001294\n",
            "(epoch: 67, iters: 100, time: 0.350, data: 0.264) D_A: 0.218 G_A: 0.258 cycle_A: 0.697 idt_A: 1.017 D_B: 0.093 G_B: 0.510 cycle_B: 2.310 idt_B: 0.275 \n",
            "End of epoch 67 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0001294 -> 0.0001255\n",
            "(epoch: 68, iters: 100, time: 4.394, data: 0.302) D_A: 0.121 G_A: 0.811 cycle_A: 0.488 idt_A: 0.872 D_B: 0.024 G_B: 0.827 cycle_B: 1.970 idt_B: 0.235 \n",
            "End of epoch 68 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0001255 -> 0.0001216\n",
            "(epoch: 69, iters: 100, time: 0.359, data: 0.174) D_A: 0.116 G_A: 0.450 cycle_A: 0.594 idt_A: 0.897 D_B: 0.065 G_B: 0.504 cycle_B: 2.147 idt_B: 0.259 \n",
            "End of epoch 69 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001216 -> 0.0001176\n",
            "(epoch: 70, iters: 100, time: 0.343, data: 0.295) D_A: 0.146 G_A: 0.799 cycle_A: 0.833 idt_A: 0.833 D_B: 0.039 G_B: 1.132 cycle_B: 2.265 idt_B: 0.371 \n",
            "saving the model at the end of epoch 70, iters 7000\n",
            "End of epoch 70 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0001176 -> 0.0001137\n",
            "(epoch: 71, iters: 100, time: 0.338, data: 0.385) D_A: 0.170 G_A: 0.512 cycle_A: 0.707 idt_A: 1.059 D_B: 0.111 G_B: 0.763 cycle_B: 2.922 idt_B: 0.247 \n",
            "End of epoch 71 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001137 -> 0.0001098\n",
            "(epoch: 72, iters: 100, time: 4.527, data: 0.412) D_A: 0.059 G_A: 0.228 cycle_A: 0.723 idt_A: 1.023 D_B: 0.078 G_B: 0.606 cycle_B: 2.145 idt_B: 0.187 \n",
            "End of epoch 72 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0001098 -> 0.0001059\n",
            "(epoch: 73, iters: 100, time: 0.345, data: 0.317) D_A: 0.152 G_A: 0.352 cycle_A: 0.765 idt_A: 0.704 D_B: 0.167 G_B: 0.142 cycle_B: 2.105 idt_B: 0.274 \n",
            "End of epoch 73 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001059 -> 0.0001020\n",
            "(epoch: 74, iters: 100, time: 0.329, data: 0.384) D_A: 0.200 G_A: 0.197 cycle_A: 1.001 idt_A: 0.564 D_B: 0.026 G_B: 0.485 cycle_B: 1.418 idt_B: 0.430 \n",
            "End of epoch 74 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0001020 -> 0.0000980\n",
            "(epoch: 75, iters: 100, time: 0.321, data: 0.258) D_A: 0.125 G_A: 0.477 cycle_A: 0.759 idt_A: 1.212 D_B: 0.112 G_B: 1.437 cycle_B: 2.845 idt_B: 0.372 \n",
            "saving the model at the end of epoch 75, iters 7500\n",
            "End of epoch 75 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0000980 -> 0.0000941\n",
            "(epoch: 76, iters: 100, time: 4.615, data: 0.251) D_A: 0.384 G_A: 0.941 cycle_A: 0.694 idt_A: 1.210 D_B: 0.019 G_B: 0.491 cycle_B: 1.817 idt_B: 0.235 \n",
            "End of epoch 76 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0000941 -> 0.0000902\n",
            "(epoch: 77, iters: 100, time: 0.326, data: 0.267) D_A: 0.075 G_A: 0.601 cycle_A: 0.570 idt_A: 0.656 D_B: 0.030 G_B: 0.954 cycle_B: 1.914 idt_B: 0.259 \n",
            "End of epoch 77 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000902 -> 0.0000863\n",
            "(epoch: 78, iters: 100, time: 0.322, data: 0.219) D_A: 0.198 G_A: 0.710 cycle_A: 0.612 idt_A: 0.865 D_B: 0.076 G_B: 0.279 cycle_B: 2.111 idt_B: 0.241 \n",
            "End of epoch 78 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000863 -> 0.0000824\n",
            "(epoch: 79, iters: 100, time: 0.346, data: 0.214) D_A: 0.050 G_A: 0.226 cycle_A: 0.552 idt_A: 0.819 D_B: 0.036 G_B: 0.893 cycle_B: 2.336 idt_B: 0.196 \n",
            "End of epoch 79 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000824 -> 0.0000784\n",
            "(epoch: 80, iters: 100, time: 4.350, data: 0.345) D_A: 0.044 G_A: 0.777 cycle_A: 0.733 idt_A: 0.941 D_B: 0.082 G_B: 0.876 cycle_B: 2.131 idt_B: 0.259 \n",
            "saving the model at the end of epoch 80, iters 8000\n",
            "End of epoch 80 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0000784 -> 0.0000745\n",
            "(epoch: 81, iters: 100, time: 0.334, data: 0.183) D_A: 0.047 G_A: 0.420 cycle_A: 0.879 idt_A: 1.082 D_B: 0.051 G_B: 0.540 cycle_B: 2.291 idt_B: 0.333 \n",
            "End of epoch 81 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000745 -> 0.0000706\n",
            "(epoch: 82, iters: 100, time: 0.349, data: 0.367) D_A: 0.052 G_A: 0.676 cycle_A: 0.321 idt_A: 0.756 D_B: 0.023 G_B: 0.953 cycle_B: 1.788 idt_B: 0.149 \n",
            "End of epoch 82 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000706 -> 0.0000667\n",
            "(epoch: 83, iters: 100, time: 0.330, data: 0.367) D_A: 0.071 G_A: 0.515 cycle_A: 0.636 idt_A: 0.855 D_B: 0.039 G_B: 0.297 cycle_B: 2.134 idt_B: 0.227 \n",
            "End of epoch 83 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000667 -> 0.0000627\n",
            "(epoch: 84, iters: 100, time: 4.869, data: 0.179) D_A: 0.183 G_A: 0.451 cycle_A: 0.627 idt_A: 0.458 D_B: 0.084 G_B: 0.501 cycle_B: 1.216 idt_B: 0.292 \n",
            "End of epoch 84 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0000627 -> 0.0000588\n",
            "(epoch: 85, iters: 100, time: 0.323, data: 0.374) D_A: 0.099 G_A: 0.462 cycle_A: 0.787 idt_A: 0.895 D_B: 0.082 G_B: 0.817 cycle_B: 2.130 idt_B: 0.213 \n",
            "saving the model at the end of epoch 85, iters 8500\n",
            "End of epoch 85 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0000588 -> 0.0000549\n",
            "(epoch: 86, iters: 100, time: 0.327, data: 0.292) D_A: 0.063 G_A: 0.557 cycle_A: 0.943 idt_A: 0.884 D_B: 0.104 G_B: 0.608 cycle_B: 1.395 idt_B: 0.370 \n",
            "End of epoch 86 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0000549 -> 0.0000510\n",
            "(epoch: 87, iters: 100, time: 0.342, data: 0.217) D_A: 0.053 G_A: 0.386 cycle_A: 0.593 idt_A: 0.757 D_B: 0.028 G_B: 0.893 cycle_B: 2.002 idt_B: 0.207 \n",
            "End of epoch 87 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000510 -> 0.0000471\n",
            "(epoch: 88, iters: 100, time: 4.889, data: 0.314) D_A: 0.072 G_A: 0.382 cycle_A: 0.882 idt_A: 1.070 D_B: 0.178 G_B: 1.311 cycle_B: 2.403 idt_B: 0.295 \n",
            "End of epoch 88 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0000471 -> 0.0000431\n",
            "(epoch: 89, iters: 100, time: 0.326, data: 0.280) D_A: 0.074 G_A: 0.568 cycle_A: 0.463 idt_A: 0.953 D_B: 0.059 G_B: 1.021 cycle_B: 2.091 idt_B: 0.172 \n",
            "End of epoch 89 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000431 -> 0.0000392\n",
            "(epoch: 90, iters: 100, time: 0.327, data: 0.167) D_A: 0.121 G_A: 0.507 cycle_A: 0.490 idt_A: 0.938 D_B: 0.105 G_B: 1.081 cycle_B: 1.993 idt_B: 0.144 \n",
            "saving the model at the end of epoch 90, iters 9000\n",
            "End of epoch 90 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0000392 -> 0.0000353\n",
            "(epoch: 91, iters: 100, time: 0.342, data: 0.242) D_A: 0.101 G_A: 0.802 cycle_A: 0.564 idt_A: 0.608 D_B: 0.038 G_B: 0.927 cycle_B: 1.532 idt_B: 0.210 \n",
            "End of epoch 91 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000353 -> 0.0000314\n",
            "(epoch: 92, iters: 100, time: 4.546, data: 0.448) D_A: 0.095 G_A: 0.572 cycle_A: 0.741 idt_A: 0.553 D_B: 0.105 G_B: 0.516 cycle_B: 1.215 idt_B: 0.298 \n",
            "End of epoch 92 / 100 \t Time Taken: 33 sec\n",
            "learning rate 0.0000314 -> 0.0000275\n",
            "(epoch: 93, iters: 100, time: 0.327, data: 0.195) D_A: 0.050 G_A: 0.463 cycle_A: 0.577 idt_A: 1.088 D_B: 0.020 G_B: 0.419 cycle_B: 2.571 idt_B: 0.171 \n",
            "End of epoch 93 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000275 -> 0.0000235\n",
            "(epoch: 94, iters: 100, time: 0.348, data: 0.368) D_A: 0.113 G_A: 0.423 cycle_A: 0.912 idt_A: 0.616 D_B: 0.042 G_B: 0.956 cycle_B: 1.491 idt_B: 0.370 \n",
            "End of epoch 94 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000235 -> 0.0000196\n",
            "(epoch: 95, iters: 100, time: 0.325, data: 0.351) D_A: 0.285 G_A: 0.291 cycle_A: 0.538 idt_A: 0.904 D_B: 0.152 G_B: 0.346 cycle_B: 2.100 idt_B: 0.189 \n",
            "saving the model at the end of epoch 95, iters 9500\n",
            "End of epoch 95 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0000196 -> 0.0000157\n",
            "(epoch: 96, iters: 100, time: 5.228, data: 0.389) D_A: 0.160 G_A: 0.708 cycle_A: 0.919 idt_A: 1.021 D_B: 0.036 G_B: 0.658 cycle_B: 2.304 idt_B: 0.377 \n",
            "End of epoch 96 / 100 \t Time Taken: 34 sec\n",
            "learning rate 0.0000157 -> 0.0000118\n",
            "(epoch: 97, iters: 100, time: 0.330, data: 0.324) D_A: 0.126 G_A: 0.458 cycle_A: 0.838 idt_A: 0.759 D_B: 0.032 G_B: 0.698 cycle_B: 1.555 idt_B: 0.338 \n",
            "End of epoch 97 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000118 -> 0.0000078\n",
            "(epoch: 98, iters: 100, time: 0.329, data: 0.489) D_A: 0.125 G_A: 0.467 cycle_A: 0.729 idt_A: 1.175 D_B: 0.026 G_B: 0.556 cycle_B: 1.663 idt_B: 0.286 \n",
            "End of epoch 98 / 100 \t Time Taken: 30 sec\n",
            "learning rate 0.0000078 -> 0.0000039\n",
            "(epoch: 99, iters: 100, time: 0.322, data: 0.198) D_A: 0.085 G_A: 0.467 cycle_A: 0.467 idt_A: 0.846 D_B: 0.081 G_B: 0.978 cycle_B: 1.789 idt_B: 0.214 \n",
            "End of epoch 99 / 100 \t Time Taken: 29 sec\n",
            "learning rate 0.0000039 -> 0.0000000\n",
            "(epoch: 100, iters: 100, time: 4.744, data: 0.208) D_A: 0.112 G_A: 0.601 cycle_A: 0.420 idt_A: 0.563 D_B: 0.084 G_B: 0.469 cycle_B: 1.345 idt_B: 0.150 \n",
            "saving the latest model (epoch 100, total_iters 10000)\n",
            "saving the model at the end of epoch 100, iters 10000\n",
            "End of epoch 100 / 100 \t Time Taken: 38 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)], 'cell_netG_B': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)]}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split --name truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_6_blocks --train_name truck_nas_project_layer_types_cycleGAN_final_3_cell_layer_6_blocks --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 101 --n_epochs 50 --n_epochs_decay 50 --layer_types ReflectionPad2d_Conv2d+ReLU --n_layers_cell 3 --n_blocks 6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Training\n",
        "\n"
      ],
      "metadata": {
        "id": "HWNJvTMgOLs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split_200 --name truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final --train_name truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 201 --n_epochs 100 --n_epochs_decay 100 --layer_types ReflectionPad2d_Conv2d+ReLU --n_layers_cell 5 --n_blocks 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyNV4eLVOQ7I",
        "outputId": "95d9d1d3-4a92-4f6a-fdd9-68665cc5a983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 201                           \t[default: 50]\n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/trucks_train_CycleGAN_split_200\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 10                            \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: ReflectionPad2d_Conv2d+ReLU   \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_blocks: 3                             \t[default: 6]\n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \t[default: 3]\n",
            "                     name: truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 200\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "create web directory ./checkpoints/truck_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.327, data: 0.784) D_A: 0.459 G_A: 0.612 cycle_A: 1.426 idt_A: 0.928 D_B: 0.164 G_B: 0.533 cycle_B: 2.010 idt_B: 0.694 \n",
            "(epoch: 1, iters: 200, time: 0.316, data: 0.011) D_A: 0.274 G_A: 0.300 cycle_A: 1.203 idt_A: 0.939 D_B: 0.109 G_B: 0.425 cycle_B: 2.243 idt_B: 0.418 \n",
            "End of epoch 1 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.315, data: 0.236) D_A: 0.105 G_A: 0.472 cycle_A: 1.429 idt_A: 2.482 D_B: 0.157 G_B: 0.523 cycle_B: 5.961 idt_B: 0.555 \n",
            "(epoch: 2, iters: 200, time: 0.556, data: 0.003) D_A: 0.557 G_A: 0.589 cycle_A: 1.118 idt_A: 1.182 D_B: 0.256 G_B: 0.298 cycle_B: 2.043 idt_B: 0.441 \n",
            "End of epoch 2 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.319, data: 0.172) D_A: 0.083 G_A: 0.876 cycle_A: 0.964 idt_A: 0.983 D_B: 0.061 G_B: 1.167 cycle_B: 2.114 idt_B: 0.379 \n",
            "(epoch: 3, iters: 200, time: 0.341, data: 0.011) D_A: 0.282 G_A: 0.718 cycle_A: 1.263 idt_A: 1.629 D_B: 0.139 G_B: 0.745 cycle_B: 3.329 idt_B: 0.655 \n",
            "End of epoch 3 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.331, data: 0.279) D_A: 0.087 G_A: 0.643 cycle_A: 1.723 idt_A: 2.006 D_B: 0.141 G_B: 0.849 cycle_B: 3.701 idt_B: 0.907 \n",
            "(epoch: 4, iters: 200, time: 0.514, data: 0.002) D_A: 0.139 G_A: 0.766 cycle_A: 1.301 idt_A: 1.342 D_B: 0.068 G_B: 0.665 cycle_B: 3.012 idt_B: 0.511 \n",
            "End of epoch 4 / 200 \t Time Taken: 60 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.319, data: 0.211) D_A: 0.338 G_A: 0.374 cycle_A: 0.983 idt_A: 2.954 D_B: 0.093 G_B: 0.180 cycle_B: 6.402 idt_B: 0.657 \n",
            "(epoch: 5, iters: 200, time: 0.328, data: 0.003) D_A: 0.181 G_A: 0.488 cycle_A: 1.155 idt_A: 1.634 D_B: 0.128 G_B: 0.561 cycle_B: 3.451 idt_B: 0.553 \n",
            "saving the model at the end of epoch 5, iters 1000\n",
            "End of epoch 5 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.314, data: 0.214) D_A: 0.132 G_A: 0.331 cycle_A: 1.164 idt_A: 0.976 D_B: 0.136 G_B: 1.153 cycle_B: 2.181 idt_B: 0.503 \n",
            "(epoch: 6, iters: 200, time: 0.554, data: 0.002) D_A: 0.136 G_A: 0.199 cycle_A: 0.716 idt_A: 2.028 D_B: 0.079 G_B: 0.846 cycle_B: 3.600 idt_B: 0.344 \n",
            "End of epoch 6 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.317, data: 0.225) D_A: 0.202 G_A: 0.572 cycle_A: 0.716 idt_A: 1.550 D_B: 0.048 G_B: 0.423 cycle_B: 2.683 idt_B: 0.340 \n",
            "(epoch: 7, iters: 200, time: 0.320, data: 0.003) D_A: 0.327 G_A: 0.897 cycle_A: 0.772 idt_A: 1.171 D_B: 0.173 G_B: 0.177 cycle_B: 2.153 idt_B: 0.378 \n",
            "End of epoch 7 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.331, data: 0.208) D_A: 0.075 G_A: 0.623 cycle_A: 0.941 idt_A: 1.967 D_B: 0.087 G_B: 0.664 cycle_B: 4.446 idt_B: 0.446 \n",
            "(epoch: 8, iters: 200, time: 0.658, data: 0.002) D_A: 0.289 G_A: 0.926 cycle_A: 0.985 idt_A: 1.351 D_B: 0.068 G_B: 0.604 cycle_B: 2.459 idt_B: 0.471 \n",
            "End of epoch 8 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.323, data: 0.326) D_A: 0.251 G_A: 0.261 cycle_A: 0.875 idt_A: 0.958 D_B: 0.060 G_B: 0.275 cycle_B: 2.285 idt_B: 0.431 \n",
            "(epoch: 9, iters: 200, time: 0.326, data: 0.003) D_A: 0.143 G_A: 0.490 cycle_A: 1.086 idt_A: 1.294 D_B: 0.132 G_B: 0.767 cycle_B: 3.069 idt_B: 0.476 \n",
            "End of epoch 9 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.312, data: 0.211) D_A: 0.215 G_A: 0.166 cycle_A: 0.895 idt_A: 1.098 D_B: 0.209 G_B: 0.604 cycle_B: 2.855 idt_B: 0.398 \n",
            "(epoch: 10, iters: 200, time: 0.673, data: 0.003) D_A: 0.067 G_A: 0.575 cycle_A: 0.906 idt_A: 1.170 D_B: 0.070 G_B: 0.584 cycle_B: 2.664 idt_B: 0.371 \n",
            "saving the model at the end of epoch 10, iters 2000\n",
            "End of epoch 10 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.330, data: 0.358) D_A: 0.150 G_A: 0.647 cycle_A: 0.876 idt_A: 0.904 D_B: 0.190 G_B: 0.551 cycle_B: 2.072 idt_B: 0.370 \n",
            "(epoch: 11, iters: 200, time: 0.325, data: 0.004) D_A: 0.209 G_A: 0.376 cycle_A: 1.289 idt_A: 0.821 D_B: 0.154 G_B: 0.456 cycle_B: 2.458 idt_B: 0.430 \n",
            "End of epoch 11 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.314, data: 0.205) D_A: 0.138 G_A: 0.070 cycle_A: 0.879 idt_A: 1.001 D_B: 0.395 G_B: 0.095 cycle_B: 2.285 idt_B: 0.348 \n",
            "(epoch: 12, iters: 200, time: 0.671, data: 0.003) D_A: 0.145 G_A: 0.830 cycle_A: 1.106 idt_A: 1.122 D_B: 0.078 G_B: 0.493 cycle_B: 2.384 idt_B: 0.504 \n",
            "End of epoch 12 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.326, data: 0.224) D_A: 0.203 G_A: 0.467 cycle_A: 1.474 idt_A: 1.261 D_B: 0.313 G_B: 0.309 cycle_B: 2.733 idt_B: 0.418 \n",
            "(epoch: 13, iters: 200, time: 0.317, data: 0.014) D_A: 0.328 G_A: 0.456 cycle_A: 1.295 idt_A: 1.207 D_B: 0.118 G_B: 0.704 cycle_B: 3.688 idt_B: 0.416 \n",
            "End of epoch 13 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.315, data: 0.190) D_A: 0.137 G_A: 0.243 cycle_A: 1.473 idt_A: 1.069 D_B: 0.196 G_B: 1.046 cycle_B: 2.550 idt_B: 0.605 \n",
            "(epoch: 14, iters: 200, time: 0.670, data: 0.003) D_A: 0.377 G_A: 0.253 cycle_A: 0.582 idt_A: 1.239 D_B: 0.025 G_B: 0.468 cycle_B: 2.568 idt_B: 0.264 \n",
            "End of epoch 14 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.329, data: 0.228) D_A: 0.166 G_A: 0.642 cycle_A: 0.718 idt_A: 1.217 D_B: 0.086 G_B: 0.491 cycle_B: 2.558 idt_B: 0.323 \n",
            "(epoch: 15, iters: 200, time: 0.314, data: 0.012) D_A: 0.274 G_A: 0.185 cycle_A: 0.856 idt_A: 0.656 D_B: 0.069 G_B: 0.858 cycle_B: 2.791 idt_B: 0.359 \n",
            "saving the model at the end of epoch 15, iters 3000\n",
            "End of epoch 15 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.310, data: 0.278) D_A: 0.191 G_A: 0.398 cycle_A: 1.052 idt_A: 1.339 D_B: 0.125 G_B: 0.408 cycle_B: 2.850 idt_B: 0.496 \n",
            "(epoch: 16, iters: 200, time: 0.619, data: 0.002) D_A: 0.074 G_A: 0.695 cycle_A: 0.735 idt_A: 1.114 D_B: 0.063 G_B: 0.795 cycle_B: 2.557 idt_B: 0.348 \n",
            "End of epoch 16 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.330, data: 0.228) D_A: 0.206 G_A: 0.565 cycle_A: 0.850 idt_A: 1.652 D_B: 0.060 G_B: 0.669 cycle_B: 2.981 idt_B: 0.349 \n",
            "(epoch: 17, iters: 200, time: 0.318, data: 0.011) D_A: 0.500 G_A: 0.296 cycle_A: 0.864 idt_A: 1.046 D_B: 0.184 G_B: 0.511 cycle_B: 3.214 idt_B: 0.373 \n",
            "End of epoch 17 / 200 \t Time Taken: 55 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.310, data: 0.187) D_A: 0.254 G_A: 0.462 cycle_A: 0.713 idt_A: 1.308 D_B: 0.087 G_B: 0.592 cycle_B: 2.713 idt_B: 0.308 \n",
            "(epoch: 18, iters: 200, time: 0.707, data: 0.003) D_A: 0.113 G_A: 0.360 cycle_A: 1.173 idt_A: 1.243 D_B: 0.064 G_B: 0.972 cycle_B: 3.343 idt_B: 0.485 \n",
            "End of epoch 18 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.325, data: 0.333) D_A: 0.039 G_A: 0.597 cycle_A: 0.865 idt_A: 0.772 D_B: 0.119 G_B: 0.407 cycle_B: 1.483 idt_B: 0.338 \n",
            "(epoch: 19, iters: 200, time: 0.309, data: 0.003) D_A: 0.224 G_A: 0.215 cycle_A: 0.811 idt_A: 2.717 D_B: 0.030 G_B: 0.676 cycle_B: 5.785 idt_B: 0.268 \n",
            "End of epoch 19 / 200 \t Time Taken: 55 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.317, data: 0.214) D_A: 0.165 G_A: 0.381 cycle_A: 1.148 idt_A: 1.372 D_B: 0.199 G_B: 0.202 cycle_B: 2.680 idt_B: 0.436 \n",
            "(epoch: 20, iters: 200, time: 0.733, data: 0.003) D_A: 0.135 G_A: 0.248 cycle_A: 0.830 idt_A: 1.216 D_B: 0.092 G_B: 1.243 cycle_B: 2.551 idt_B: 0.584 \n",
            "saving the model at the end of epoch 20, iters 4000\n",
            "End of epoch 20 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.288, data: 0.338) D_A: 0.195 G_A: 0.325 cycle_A: 0.866 idt_A: 1.403 D_B: 0.318 G_B: 1.360 cycle_B: 3.610 idt_B: 0.390 \n",
            "(epoch: 21, iters: 200, time: 0.295, data: 0.003) D_A: 0.137 G_A: 0.364 cycle_A: 0.751 idt_A: 2.133 D_B: 0.036 G_B: 0.159 cycle_B: 4.551 idt_B: 0.246 \n",
            "End of epoch 21 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.288, data: 0.204) D_A: 0.252 G_A: 0.483 cycle_A: 0.667 idt_A: 0.847 D_B: 0.211 G_B: 0.213 cycle_B: 2.312 idt_B: 0.273 \n",
            "(epoch: 22, iters: 200, time: 0.631, data: 0.003) D_A: 0.242 G_A: 0.316 cycle_A: 0.864 idt_A: 1.708 D_B: 0.433 G_B: 0.040 cycle_B: 3.299 idt_B: 0.381 \n",
            "End of epoch 22 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.286, data: 0.247) D_A: 0.068 G_A: 0.654 cycle_A: 0.615 idt_A: 1.805 D_B: 0.103 G_B: 0.245 cycle_B: 3.994 idt_B: 0.254 \n",
            "(epoch: 23, iters: 200, time: 0.295, data: 0.003) D_A: 0.215 G_A: 0.381 cycle_A: 0.578 idt_A: 1.357 D_B: 0.063 G_B: 0.812 cycle_B: 4.011 idt_B: 0.236 \n",
            "End of epoch 23 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.290, data: 0.216) D_A: 0.269 G_A: 0.534 cycle_A: 0.780 idt_A: 1.450 D_B: 0.102 G_B: 0.424 cycle_B: 2.465 idt_B: 0.339 \n",
            "(epoch: 24, iters: 200, time: 0.650, data: 0.011) D_A: 0.248 G_A: 0.373 cycle_A: 0.741 idt_A: 0.823 D_B: 0.076 G_B: 1.055 cycle_B: 2.362 idt_B: 0.226 \n",
            "End of epoch 24 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.286, data: 0.228) D_A: 0.090 G_A: 0.537 cycle_A: 0.794 idt_A: 0.790 D_B: 0.182 G_B: 0.439 cycle_B: 1.989 idt_B: 0.349 \n",
            "(epoch: 25, iters: 200, time: 0.292, data: 0.010) D_A: 0.074 G_A: 0.680 cycle_A: 1.004 idt_A: 0.765 D_B: 0.105 G_B: 0.332 cycle_B: 2.758 idt_B: 0.455 \n",
            "saving the latest model (epoch 25, total_iters 5000)\n",
            "saving the model at the end of epoch 25, iters 5000\n",
            "End of epoch 25 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.290, data: 0.249) D_A: 0.409 G_A: 0.640 cycle_A: 0.580 idt_A: 1.519 D_B: 0.136 G_B: 0.336 cycle_B: 2.510 idt_B: 0.299 \n",
            "(epoch: 26, iters: 200, time: 0.679, data: 0.003) D_A: 0.174 G_A: 0.948 cycle_A: 0.797 idt_A: 0.820 D_B: 0.158 G_B: 0.523 cycle_B: 1.914 idt_B: 0.326 \n",
            "End of epoch 26 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.296, data: 0.217) D_A: 0.105 G_A: 0.487 cycle_A: 0.721 idt_A: 0.890 D_B: 0.229 G_B: 0.369 cycle_B: 2.606 idt_B: 0.309 \n",
            "(epoch: 27, iters: 200, time: 0.299, data: 0.002) D_A: 0.322 G_A: 0.722 cycle_A: 0.980 idt_A: 1.212 D_B: 0.348 G_B: 0.103 cycle_B: 3.577 idt_B: 0.333 \n",
            "End of epoch 27 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.288, data: 0.336) D_A: 0.264 G_A: 0.348 cycle_A: 0.761 idt_A: 1.578 D_B: 0.106 G_B: 0.414 cycle_B: 3.884 idt_B: 0.294 \n",
            "(epoch: 28, iters: 200, time: 0.787, data: 0.003) D_A: 0.269 G_A: 0.204 cycle_A: 0.992 idt_A: 0.914 D_B: 0.248 G_B: 0.247 cycle_B: 2.131 idt_B: 0.392 \n",
            "End of epoch 28 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.284, data: 0.385) D_A: 0.137 G_A: 0.344 cycle_A: 0.909 idt_A: 1.154 D_B: 0.160 G_B: 0.554 cycle_B: 2.399 idt_B: 0.350 \n",
            "(epoch: 29, iters: 200, time: 0.304, data: 0.003) D_A: 0.211 G_A: 0.193 cycle_A: 0.921 idt_A: 1.060 D_B: 0.101 G_B: 0.616 cycle_B: 2.538 idt_B: 0.427 \n",
            "End of epoch 29 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.288, data: 0.346) D_A: 0.183 G_A: 0.273 cycle_A: 0.633 idt_A: 1.069 D_B: 0.143 G_B: 0.745 cycle_B: 2.233 idt_B: 0.286 \n",
            "(epoch: 30, iters: 200, time: 0.804, data: 0.003) D_A: 0.273 G_A: 0.208 cycle_A: 0.836 idt_A: 1.090 D_B: 0.154 G_B: 0.610 cycle_B: 2.289 idt_B: 0.388 \n",
            "saving the model at the end of epoch 30, iters 6000\n",
            "End of epoch 30 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.303, data: 0.239) D_A: 0.171 G_A: 0.405 cycle_A: 0.942 idt_A: 0.833 D_B: 0.157 G_B: 0.964 cycle_B: 1.815 idt_B: 0.374 \n",
            "(epoch: 31, iters: 200, time: 0.287, data: 0.008) D_A: 0.183 G_A: 0.275 cycle_A: 0.765 idt_A: 0.741 D_B: 0.087 G_B: 0.497 cycle_B: 2.709 idt_B: 0.379 \n",
            "End of epoch 31 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.287, data: 0.181) D_A: 0.276 G_A: 0.298 cycle_A: 0.866 idt_A: 1.082 D_B: 0.038 G_B: 0.331 cycle_B: 2.206 idt_B: 0.336 \n",
            "(epoch: 32, iters: 200, time: 0.802, data: 0.013) D_A: 0.217 G_A: 0.061 cycle_A: 0.947 idt_A: 1.113 D_B: 0.029 G_B: 0.188 cycle_B: 2.226 idt_B: 0.368 \n",
            "End of epoch 32 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.286, data: 0.354) D_A: 0.275 G_A: 0.155 cycle_A: 1.042 idt_A: 1.176 D_B: 0.176 G_B: 1.050 cycle_B: 2.641 idt_B: 0.433 \n",
            "(epoch: 33, iters: 200, time: 0.285, data: 0.015) D_A: 0.269 G_A: 0.914 cycle_A: 0.844 idt_A: 0.801 D_B: 0.058 G_B: 0.281 cycle_B: 1.830 idt_B: 0.311 \n",
            "End of epoch 33 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.295, data: 0.258) D_A: 0.315 G_A: 0.488 cycle_A: 0.983 idt_A: 1.735 D_B: 0.242 G_B: 0.343 cycle_B: 3.719 idt_B: 0.325 \n",
            "(epoch: 34, iters: 200, time: 0.737, data: 0.014) D_A: 0.180 G_A: 0.485 cycle_A: 0.714 idt_A: 1.113 D_B: 0.170 G_B: 0.242 cycle_B: 2.809 idt_B: 0.374 \n",
            "End of epoch 34 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.287, data: 0.247) D_A: 0.144 G_A: 0.262 cycle_A: 0.547 idt_A: 0.738 D_B: 0.121 G_B: 0.700 cycle_B: 2.760 idt_B: 0.239 \n",
            "(epoch: 35, iters: 200, time: 0.291, data: 0.003) D_A: 0.347 G_A: 0.485 cycle_A: 0.538 idt_A: 1.141 D_B: 0.140 G_B: 0.234 cycle_B: 2.466 idt_B: 0.226 \n",
            "saving the model at the end of epoch 35, iters 7000\n",
            "End of epoch 35 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.287, data: 0.311) D_A: 0.226 G_A: 0.203 cycle_A: 0.486 idt_A: 0.938 D_B: 0.140 G_B: 1.252 cycle_B: 2.581 idt_B: 0.189 \n",
            "(epoch: 36, iters: 200, time: 0.871, data: 0.003) D_A: 0.621 G_A: 1.339 cycle_A: 0.883 idt_A: 1.300 D_B: 0.119 G_B: 0.203 cycle_B: 3.696 idt_B: 0.357 \n",
            "End of epoch 36 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.288, data: 0.334) D_A: 0.208 G_A: 0.348 cycle_A: 0.444 idt_A: 0.619 D_B: 0.142 G_B: 1.161 cycle_B: 1.860 idt_B: 0.206 \n",
            "(epoch: 37, iters: 200, time: 0.303, data: 0.003) D_A: 0.114 G_A: 0.491 cycle_A: 0.759 idt_A: 1.363 D_B: 0.075 G_B: 0.786 cycle_B: 2.730 idt_B: 0.267 \n",
            "End of epoch 37 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.286, data: 0.411) D_A: 0.328 G_A: 0.250 cycle_A: 0.576 idt_A: 1.155 D_B: 0.061 G_B: 0.788 cycle_B: 2.477 idt_B: 0.201 \n",
            "(epoch: 38, iters: 200, time: 0.918, data: 0.003) D_A: 0.203 G_A: 0.560 cycle_A: 0.660 idt_A: 1.005 D_B: 0.068 G_B: 0.774 cycle_B: 2.169 idt_B: 0.220 \n",
            "End of epoch 38 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.288, data: 0.237) D_A: 0.140 G_A: 0.288 cycle_A: 1.089 idt_A: 1.332 D_B: 0.146 G_B: 0.482 cycle_B: 3.204 idt_B: 0.464 \n",
            "(epoch: 39, iters: 200, time: 0.288, data: 0.002) D_A: 0.095 G_A: 0.692 cycle_A: 1.008 idt_A: 0.983 D_B: 0.185 G_B: 1.503 cycle_B: 1.969 idt_B: 0.373 \n",
            "End of epoch 39 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.301, data: 0.217) D_A: 0.144 G_A: 0.358 cycle_A: 0.615 idt_A: 0.752 D_B: 0.092 G_B: 0.754 cycle_B: 1.852 idt_B: 0.261 \n",
            "(epoch: 40, iters: 200, time: 0.749, data: 0.011) D_A: 0.137 G_A: 0.719 cycle_A: 0.579 idt_A: 0.755 D_B: 0.023 G_B: 0.390 cycle_B: 2.632 idt_B: 0.239 \n",
            "saving the model at the end of epoch 40, iters 8000\n",
            "End of epoch 40 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.287, data: 0.253) D_A: 0.079 G_A: 0.707 cycle_A: 0.913 idt_A: 0.811 D_B: 0.100 G_B: 0.826 cycle_B: 1.645 idt_B: 0.412 \n",
            "(epoch: 41, iters: 200, time: 0.290, data: 0.003) D_A: 0.158 G_A: 0.562 cycle_A: 1.007 idt_A: 0.887 D_B: 0.130 G_B: 0.463 cycle_B: 1.936 idt_B: 0.406 \n",
            "End of epoch 41 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.290, data: 0.238) D_A: 0.251 G_A: 1.020 cycle_A: 0.823 idt_A: 1.421 D_B: 0.231 G_B: 0.172 cycle_B: 3.332 idt_B: 0.496 \n",
            "(epoch: 42, iters: 200, time: 1.012, data: 0.003) D_A: 0.328 G_A: 0.186 cycle_A: 0.476 idt_A: 0.624 D_B: 0.081 G_B: 0.737 cycle_B: 1.854 idt_B: 0.196 \n",
            "End of epoch 42 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.295, data: 0.391) D_A: 0.125 G_A: 0.496 cycle_A: 0.650 idt_A: 0.436 D_B: 0.242 G_B: 0.405 cycle_B: 1.527 idt_B: 0.250 \n",
            "(epoch: 43, iters: 200, time: 0.301, data: 0.003) D_A: 0.248 G_A: 0.339 cycle_A: 0.943 idt_A: 0.922 D_B: 0.227 G_B: 0.211 cycle_B: 3.189 idt_B: 0.222 \n",
            "End of epoch 43 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.292, data: 0.336) D_A: 0.162 G_A: 0.634 cycle_A: 0.675 idt_A: 0.968 D_B: 0.182 G_B: 0.634 cycle_B: 2.217 idt_B: 0.268 \n",
            "(epoch: 44, iters: 200, time: 0.801, data: 0.003) D_A: 0.207 G_A: 0.279 cycle_A: 0.579 idt_A: 0.853 D_B: 0.258 G_B: 0.237 cycle_B: 1.816 idt_B: 0.264 \n",
            "End of epoch 44 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.292, data: 0.253) D_A: 0.064 G_A: 0.354 cycle_A: 0.869 idt_A: 0.729 D_B: 0.214 G_B: 0.340 cycle_B: 1.966 idt_B: 0.340 \n",
            "(epoch: 45, iters: 200, time: 0.287, data: 0.002) D_A: 0.070 G_A: 0.519 cycle_A: 0.680 idt_A: 0.808 D_B: 0.088 G_B: 0.565 cycle_B: 1.356 idt_B: 0.272 \n",
            "saving the model at the end of epoch 45, iters 9000\n",
            "End of epoch 45 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.294, data: 0.271) D_A: 0.151 G_A: 0.918 cycle_A: 0.664 idt_A: 0.721 D_B: 0.182 G_B: 0.157 cycle_B: 1.798 idt_B: 0.345 \n",
            "(epoch: 46, iters: 200, time: 0.767, data: 0.010) D_A: 0.087 G_A: 0.325 cycle_A: 0.761 idt_A: 1.340 D_B: 0.137 G_B: 0.194 cycle_B: 2.776 idt_B: 0.216 \n",
            "End of epoch 46 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.289, data: 0.318) D_A: 0.128 G_A: 0.414 cycle_A: 0.618 idt_A: 0.718 D_B: 0.216 G_B: 0.391 cycle_B: 1.526 idt_B: 0.195 \n",
            "(epoch: 47, iters: 200, time: 0.308, data: 0.003) D_A: 0.247 G_A: 0.136 cycle_A: 0.814 idt_A: 0.685 D_B: 0.186 G_B: 0.248 cycle_B: 1.582 idt_B: 0.301 \n",
            "End of epoch 47 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 0.290, data: 0.350) D_A: 0.221 G_A: 0.227 cycle_A: 0.651 idt_A: 0.721 D_B: 0.142 G_B: 1.259 cycle_B: 2.023 idt_B: 0.279 \n",
            "(epoch: 48, iters: 200, time: 0.938, data: 0.003) D_A: 0.189 G_A: 0.530 cycle_A: 0.865 idt_A: 1.060 D_B: 0.293 G_B: 0.313 cycle_B: 2.393 idt_B: 0.380 \n",
            "End of epoch 48 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.286, data: 0.371) D_A: 0.156 G_A: 0.381 cycle_A: 0.716 idt_A: 1.235 D_B: 0.132 G_B: 0.936 cycle_B: 2.518 idt_B: 0.263 \n",
            "(epoch: 49, iters: 200, time: 0.295, data: 0.003) D_A: 0.189 G_A: 0.540 cycle_A: 0.747 idt_A: 1.298 D_B: 0.206 G_B: 0.576 cycle_B: 4.209 idt_B: 0.275 \n",
            "End of epoch 49 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.285, data: 0.236) D_A: 0.098 G_A: 0.201 cycle_A: 0.785 idt_A: 0.670 D_B: 0.139 G_B: 0.646 cycle_B: 1.712 idt_B: 0.280 \n",
            "(epoch: 50, iters: 200, time: 0.811, data: 0.003) D_A: 0.308 G_A: 0.194 cycle_A: 0.862 idt_A: 0.624 D_B: 0.113 G_B: 0.361 cycle_B: 1.968 idt_B: 0.359 \n",
            "saving the latest model (epoch 50, total_iters 10000)\n",
            "saving the model at the end of epoch 50, iters 10000\n",
            "End of epoch 50 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.291, data: 0.261) D_A: 0.287 G_A: 0.242 cycle_A: 0.603 idt_A: 0.736 D_B: 0.027 G_B: 0.788 cycle_B: 2.244 idt_B: 0.204 \n",
            "(epoch: 51, iters: 200, time: 0.286, data: 0.011) D_A: 0.323 G_A: 0.469 cycle_A: 0.622 idt_A: 0.978 D_B: 0.050 G_B: 0.604 cycle_B: 2.801 idt_B: 0.265 \n",
            "End of epoch 51 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 0.292, data: 0.208) D_A: 0.115 G_A: 0.548 cycle_A: 0.467 idt_A: 0.991 D_B: 0.081 G_B: 0.801 cycle_B: 2.351 idt_B: 0.203 \n",
            "(epoch: 52, iters: 200, time: 1.011, data: 0.003) D_A: 0.204 G_A: 0.412 cycle_A: 0.977 idt_A: 0.621 D_B: 0.069 G_B: 0.660 cycle_B: 1.717 idt_B: 0.414 \n",
            "End of epoch 52 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.286, data: 0.380) D_A: 0.116 G_A: 0.649 cycle_A: 0.984 idt_A: 0.924 D_B: 0.249 G_B: 0.179 cycle_B: 3.975 idt_B: 0.319 \n",
            "(epoch: 53, iters: 200, time: 0.304, data: 0.004) D_A: 0.124 G_A: 0.379 cycle_A: 0.551 idt_A: 0.778 D_B: 0.275 G_B: 0.588 cycle_B: 1.733 idt_B: 0.327 \n",
            "End of epoch 53 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.286, data: 0.362) D_A: 0.175 G_A: 0.763 cycle_A: 0.720 idt_A: 0.932 D_B: 0.280 G_B: 0.220 cycle_B: 3.842 idt_B: 0.461 \n",
            "(epoch: 54, iters: 200, time: 0.909, data: 0.003) D_A: 0.070 G_A: 0.756 cycle_A: 0.909 idt_A: 1.824 D_B: 0.116 G_B: 0.727 cycle_B: 4.278 idt_B: 0.310 \n",
            "End of epoch 54 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.291, data: 0.347) D_A: 0.165 G_A: 0.723 cycle_A: 0.804 idt_A: 0.902 D_B: 0.070 G_B: 0.888 cycle_B: 2.140 idt_B: 0.319 \n",
            "(epoch: 55, iters: 200, time: 0.283, data: 0.003) D_A: 0.148 G_A: 0.891 cycle_A: 0.748 idt_A: 0.710 D_B: 0.058 G_B: 0.579 cycle_B: 2.175 idt_B: 0.305 \n",
            "saving the model at the end of epoch 55, iters 11000\n",
            "End of epoch 55 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 100, time: 0.298, data: 0.222) D_A: 0.171 G_A: 0.647 cycle_A: 0.904 idt_A: 0.865 D_B: 0.238 G_B: 0.268 cycle_B: 1.993 idt_B: 0.378 \n",
            "(epoch: 56, iters: 200, time: 0.879, data: 0.014) D_A: 0.181 G_A: 0.275 cycle_A: 0.858 idt_A: 1.013 D_B: 0.183 G_B: 0.943 cycle_B: 2.798 idt_B: 0.359 \n",
            "End of epoch 56 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.302, data: 0.210) D_A: 0.108 G_A: 0.451 cycle_A: 0.683 idt_A: 1.186 D_B: 0.077 G_B: 0.503 cycle_B: 2.615 idt_B: 0.287 \n",
            "(epoch: 57, iters: 200, time: 0.294, data: 0.002) D_A: 0.356 G_A: 0.082 cycle_A: 1.057 idt_A: 0.513 D_B: 0.242 G_B: 0.919 cycle_B: 1.766 idt_B: 0.277 \n",
            "End of epoch 57 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.286, data: 0.386) D_A: 0.259 G_A: 0.291 cycle_A: 0.749 idt_A: 0.531 D_B: 0.135 G_B: 0.797 cycle_B: 1.639 idt_B: 0.222 \n",
            "(epoch: 58, iters: 200, time: 0.911, data: 0.003) D_A: 0.256 G_A: 0.180 cycle_A: 0.649 idt_A: 0.965 D_B: 0.223 G_B: 0.873 cycle_B: 2.600 idt_B: 0.274 \n",
            "End of epoch 58 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.291, data: 0.362) D_A: 0.132 G_A: 0.574 cycle_A: 0.711 idt_A: 1.061 D_B: 0.185 G_B: 0.363 cycle_B: 2.193 idt_B: 0.256 \n",
            "(epoch: 59, iters: 200, time: 0.304, data: 0.002) D_A: 0.155 G_A: 0.967 cycle_A: 0.680 idt_A: 0.889 D_B: 0.056 G_B: 0.707 cycle_B: 2.341 idt_B: 0.284 \n",
            "End of epoch 59 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.289, data: 0.350) D_A: 0.197 G_A: 0.246 cycle_A: 0.971 idt_A: 0.884 D_B: 0.465 G_B: 1.677 cycle_B: 1.979 idt_B: 0.267 \n",
            "(epoch: 60, iters: 200, time: 0.883, data: 0.004) D_A: 0.140 G_A: 0.204 cycle_A: 0.643 idt_A: 0.911 D_B: 0.046 G_B: 0.800 cycle_B: 2.619 idt_B: 0.184 \n",
            "saving the model at the end of epoch 60, iters 12000\n",
            "End of epoch 60 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.301, data: 0.266) D_A: 0.203 G_A: 0.332 cycle_A: 0.688 idt_A: 0.767 D_B: 0.068 G_B: 0.507 cycle_B: 1.968 idt_B: 0.215 \n",
            "(epoch: 61, iters: 200, time: 0.283, data: 0.011) D_A: 0.144 G_A: 0.514 cycle_A: 0.617 idt_A: 0.535 D_B: 0.089 G_B: 0.869 cycle_B: 2.004 idt_B: 0.219 \n",
            "End of epoch 61 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.318, data: 0.202) D_A: 0.046 G_A: 0.559 cycle_A: 0.629 idt_A: 1.341 D_B: 0.118 G_B: 0.456 cycle_B: 2.488 idt_B: 0.267 \n",
            "(epoch: 62, iters: 200, time: 0.874, data: 0.002) D_A: 0.231 G_A: 0.797 cycle_A: 0.864 idt_A: 0.924 D_B: 0.152 G_B: 0.719 cycle_B: 1.998 idt_B: 0.348 \n",
            "End of epoch 62 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.306, data: 0.197) D_A: 0.131 G_A: 0.297 cycle_A: 0.704 idt_A: 1.016 D_B: 0.152 G_B: 1.173 cycle_B: 2.225 idt_B: 0.306 \n",
            "(epoch: 63, iters: 200, time: 0.289, data: 0.002) D_A: 0.213 G_A: 0.177 cycle_A: 0.775 idt_A: 0.777 D_B: 0.030 G_B: 0.685 cycle_B: 2.105 idt_B: 0.321 \n",
            "End of epoch 63 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 100, time: 0.303, data: 0.248) D_A: 0.226 G_A: 0.176 cycle_A: 0.974 idt_A: 0.905 D_B: 0.237 G_B: 0.850 cycle_B: 2.414 idt_B: 0.395 \n",
            "(epoch: 64, iters: 200, time: 0.850, data: 0.012) D_A: 0.378 G_A: 0.210 cycle_A: 0.775 idt_A: 0.826 D_B: 0.266 G_B: 0.275 cycle_B: 3.189 idt_B: 0.285 \n",
            "End of epoch 64 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.295, data: 0.197) D_A: 0.072 G_A: 0.576 cycle_A: 0.881 idt_A: 0.814 D_B: 0.096 G_B: 1.541 cycle_B: 2.605 idt_B: 0.333 \n",
            "(epoch: 65, iters: 200, time: 0.285, data: 0.012) D_A: 0.288 G_A: 0.403 cycle_A: 0.730 idt_A: 0.735 D_B: 0.172 G_B: 0.266 cycle_B: 1.782 idt_B: 0.238 \n",
            "saving the model at the end of epoch 65, iters 13000\n",
            "End of epoch 65 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.290, data: 0.236) D_A: 0.166 G_A: 0.252 cycle_A: 0.586 idt_A: 0.847 D_B: 0.160 G_B: 0.583 cycle_B: 1.941 idt_B: 0.229 \n",
            "(epoch: 66, iters: 200, time: 1.064, data: 0.002) D_A: 0.397 G_A: 0.066 cycle_A: 0.571 idt_A: 0.956 D_B: 0.142 G_B: 0.585 cycle_B: 2.253 idt_B: 0.220 \n",
            "End of epoch 66 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.289, data: 0.495) D_A: 0.142 G_A: 0.433 cycle_A: 0.589 idt_A: 0.584 D_B: 0.043 G_B: 0.474 cycle_B: 1.556 idt_B: 0.192 \n",
            "(epoch: 67, iters: 200, time: 0.301, data: 0.003) D_A: 0.112 G_A: 0.593 cycle_A: 0.525 idt_A: 0.710 D_B: 0.258 G_B: 1.181 cycle_B: 3.001 idt_B: 0.226 \n",
            "End of epoch 67 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 100, time: 0.293, data: 0.424) D_A: 0.158 G_A: 0.454 cycle_A: 0.622 idt_A: 0.506 D_B: 0.117 G_B: 0.351 cycle_B: 1.240 idt_B: 0.233 \n",
            "(epoch: 68, iters: 200, time: 1.102, data: 0.003) D_A: 0.071 G_A: 0.403 cycle_A: 0.582 idt_A: 1.035 D_B: 0.177 G_B: 1.054 cycle_B: 2.382 idt_B: 0.246 \n",
            "End of epoch 68 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.288, data: 0.325) D_A: 0.263 G_A: 0.585 cycle_A: 0.659 idt_A: 0.914 D_B: 0.285 G_B: 0.093 cycle_B: 2.910 idt_B: 0.259 \n",
            "(epoch: 69, iters: 200, time: 0.289, data: 0.004) D_A: 0.204 G_A: 1.576 cycle_A: 0.521 idt_A: 0.518 D_B: 0.035 G_B: 0.097 cycle_B: 1.777 idt_B: 0.208 \n",
            "End of epoch 69 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.288, data: 0.208) D_A: 0.205 G_A: 1.050 cycle_A: 0.691 idt_A: 0.567 D_B: 0.146 G_B: 0.362 cycle_B: 1.765 idt_B: 0.310 \n",
            "(epoch: 70, iters: 200, time: 0.922, data: 0.003) D_A: 0.105 G_A: 0.408 cycle_A: 0.956 idt_A: 0.462 D_B: 0.159 G_B: 0.466 cycle_B: 1.102 idt_B: 0.368 \n",
            "saving the model at the end of epoch 70, iters 14000\n",
            "End of epoch 70 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.283, data: 0.212) D_A: 0.175 G_A: 0.842 cycle_A: 0.973 idt_A: 0.973 D_B: 0.102 G_B: 0.450 cycle_B: 2.125 idt_B: 0.374 \n",
            "(epoch: 71, iters: 200, time: 0.292, data: 0.011) D_A: 0.188 G_A: 0.291 cycle_A: 0.648 idt_A: 0.881 D_B: 0.060 G_B: 0.525 cycle_B: 2.081 idt_B: 0.252 \n",
            "End of epoch 71 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 100, time: 0.295, data: 0.274) D_A: 0.224 G_A: 0.757 cycle_A: 0.916 idt_A: 0.744 D_B: 0.284 G_B: 1.419 cycle_B: 2.115 idt_B: 0.354 \n",
            "(epoch: 72, iters: 200, time: 1.091, data: 0.015) D_A: 0.224 G_A: 1.173 cycle_A: 0.667 idt_A: 1.278 D_B: 0.056 G_B: 0.736 cycle_B: 2.747 idt_B: 0.306 \n",
            "End of epoch 72 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.284, data: 0.207) D_A: 0.126 G_A: 0.103 cycle_A: 0.945 idt_A: 0.856 D_B: 0.255 G_B: 1.430 cycle_B: 2.324 idt_B: 0.281 \n",
            "(epoch: 73, iters: 200, time: 0.289, data: 0.007) D_A: 0.204 G_A: 0.293 cycle_A: 0.520 idt_A: 0.779 D_B: 0.081 G_B: 0.623 cycle_B: 1.547 idt_B: 0.191 \n",
            "End of epoch 73 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.294, data: 0.251) D_A: 0.264 G_A: 0.118 cycle_A: 0.714 idt_A: 0.634 D_B: 0.189 G_B: 0.242 cycle_B: 1.425 idt_B: 0.323 \n",
            "(epoch: 74, iters: 200, time: 1.033, data: 0.005) D_A: 0.225 G_A: 0.261 cycle_A: 0.657 idt_A: 0.567 D_B: 0.157 G_B: 0.287 cycle_B: 1.617 idt_B: 0.242 \n",
            "End of epoch 74 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.291, data: 0.312) D_A: 0.090 G_A: 0.232 cycle_A: 0.435 idt_A: 0.926 D_B: 0.081 G_B: 0.703 cycle_B: 2.381 idt_B: 0.177 \n",
            "(epoch: 75, iters: 200, time: 0.307, data: 0.003) D_A: 0.174 G_A: 0.222 cycle_A: 1.137 idt_A: 0.735 D_B: 0.035 G_B: 0.975 cycle_B: 1.926 idt_B: 0.282 \n",
            "saving the latest model (epoch 75, total_iters 15000)\n",
            "saving the model at the end of epoch 75, iters 15000\n",
            "End of epoch 75 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 100, time: 0.294, data: 0.410) D_A: 0.163 G_A: 0.611 cycle_A: 0.632 idt_A: 1.001 D_B: 0.181 G_B: 0.696 cycle_B: 2.237 idt_B: 0.265 \n",
            "(epoch: 76, iters: 200, time: 0.983, data: 0.003) D_A: 0.074 G_A: 0.398 cycle_A: 0.633 idt_A: 1.098 D_B: 0.030 G_B: 0.630 cycle_B: 2.941 idt_B: 0.276 \n",
            "End of epoch 76 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.298, data: 0.344) D_A: 0.294 G_A: 0.926 cycle_A: 0.571 idt_A: 0.682 D_B: 0.071 G_B: 0.679 cycle_B: 1.586 idt_B: 0.195 \n",
            "(epoch: 77, iters: 200, time: 0.289, data: 0.002) D_A: 0.183 G_A: 0.491 cycle_A: 0.756 idt_A: 0.706 D_B: 0.184 G_B: 1.755 cycle_B: 2.323 idt_B: 0.320 \n",
            "End of epoch 77 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.311, data: 0.213) D_A: 0.258 G_A: 0.795 cycle_A: 0.704 idt_A: 0.549 D_B: 0.023 G_B: 0.492 cycle_B: 1.891 idt_B: 0.268 \n",
            "(epoch: 78, iters: 200, time: 1.009, data: 0.016) D_A: 0.089 G_A: 0.613 cycle_A: 0.638 idt_A: 0.695 D_B: 0.072 G_B: 0.540 cycle_B: 1.866 idt_B: 0.221 \n",
            "End of epoch 78 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.303, data: 0.245) D_A: 0.215 G_A: 0.318 cycle_A: 0.536 idt_A: 1.054 D_B: 0.094 G_B: 0.277 cycle_B: 2.465 idt_B: 0.191 \n",
            "(epoch: 79, iters: 200, time: 0.298, data: 0.010) D_A: 0.306 G_A: 0.379 cycle_A: 0.607 idt_A: 1.229 D_B: 0.161 G_B: 0.400 cycle_B: 3.091 idt_B: 0.231 \n",
            "End of epoch 79 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 100, time: 0.284, data: 0.265) D_A: 0.232 G_A: 0.346 cycle_A: 0.673 idt_A: 1.155 D_B: 0.068 G_B: 0.419 cycle_B: 2.631 idt_B: 0.268 \n",
            "(epoch: 80, iters: 200, time: 0.991, data: 0.003) D_A: 0.092 G_A: 0.711 cycle_A: 0.623 idt_A: 0.605 D_B: 0.099 G_B: 0.464 cycle_B: 1.534 idt_B: 0.244 \n",
            "saving the model at the end of epoch 80, iters 16000\n",
            "End of epoch 80 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.288, data: 0.380) D_A: 0.077 G_A: 0.136 cycle_A: 0.593 idt_A: 0.520 D_B: 0.056 G_B: 0.638 cycle_B: 1.658 idt_B: 0.285 \n",
            "(epoch: 81, iters: 200, time: 0.297, data: 0.003) D_A: 0.134 G_A: 0.488 cycle_A: 0.488 idt_A: 0.739 D_B: 0.063 G_B: 0.618 cycle_B: 1.827 idt_B: 0.162 \n",
            "End of epoch 81 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.292, data: 0.276) D_A: 0.210 G_A: 0.489 cycle_A: 0.999 idt_A: 0.864 D_B: 0.182 G_B: 0.428 cycle_B: 2.428 idt_B: 0.353 \n",
            "(epoch: 82, iters: 200, time: 1.022, data: 0.003) D_A: 0.074 G_A: 0.482 cycle_A: 0.624 idt_A: 1.070 D_B: 0.107 G_B: 0.757 cycle_B: 2.676 idt_B: 0.229 \n",
            "End of epoch 82 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.294, data: 0.266) D_A: 0.256 G_A: 0.371 cycle_A: 0.714 idt_A: 0.999 D_B: 0.098 G_B: 0.768 cycle_B: 2.254 idt_B: 0.232 \n",
            "(epoch: 83, iters: 200, time: 0.289, data: 0.003) D_A: 0.078 G_A: 0.495 cycle_A: 0.842 idt_A: 0.879 D_B: 0.028 G_B: 0.345 cycle_B: 1.894 idt_B: 0.339 \n",
            "End of epoch 83 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 100, time: 0.293, data: 0.269) D_A: 0.360 G_A: 0.503 cycle_A: 0.734 idt_A: 1.028 D_B: 0.162 G_B: 0.367 cycle_B: 2.529 idt_B: 0.299 \n",
            "(epoch: 84, iters: 200, time: 0.981, data: 0.002) D_A: 0.115 G_A: 0.535 cycle_A: 0.844 idt_A: 1.034 D_B: 0.074 G_B: 0.528 cycle_B: 2.495 idt_B: 0.301 \n",
            "End of epoch 84 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.288, data: 0.206) D_A: 0.151 G_A: 0.173 cycle_A: 0.736 idt_A: 0.919 D_B: 0.124 G_B: 0.148 cycle_B: 1.767 idt_B: 0.229 \n",
            "(epoch: 85, iters: 200, time: 0.290, data: 0.014) D_A: 0.349 G_A: 0.184 cycle_A: 0.656 idt_A: 0.573 D_B: 0.138 G_B: 0.555 cycle_B: 2.002 idt_B: 0.180 \n",
            "saving the model at the end of epoch 85, iters 17000\n",
            "End of epoch 85 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.290, data: 0.247) D_A: 0.109 G_A: 0.380 cycle_A: 0.792 idt_A: 1.119 D_B: 0.036 G_B: 0.832 cycle_B: 1.729 idt_B: 0.247 \n",
            "(epoch: 86, iters: 200, time: 1.216, data: 0.002) D_A: 0.260 G_A: 0.956 cycle_A: 0.589 idt_A: 1.012 D_B: 0.083 G_B: 0.213 cycle_B: 2.844 idt_B: 0.221 \n",
            "End of epoch 86 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.290, data: 0.331) D_A: 0.168 G_A: 0.695 cycle_A: 0.877 idt_A: 1.055 D_B: 0.060 G_B: 0.790 cycle_B: 2.347 idt_B: 0.351 \n",
            "(epoch: 87, iters: 200, time: 0.292, data: 0.002) D_A: 0.124 G_A: 0.178 cycle_A: 0.613 idt_A: 0.873 D_B: 0.080 G_B: 0.455 cycle_B: 1.995 idt_B: 0.197 \n",
            "End of epoch 87 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 100, time: 0.292, data: 0.355) D_A: 0.126 G_A: 0.461 cycle_A: 0.574 idt_A: 0.711 D_B: 0.023 G_B: 0.890 cycle_B: 2.094 idt_B: 0.157 \n",
            "(epoch: 88, iters: 200, time: 1.685, data: 0.003) D_A: 0.252 G_A: 0.398 cycle_A: 0.829 idt_A: 0.743 D_B: 0.263 G_B: 0.125 cycle_B: 1.477 idt_B: 0.345 \n",
            "End of epoch 88 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.291, data: 0.544) D_A: 0.160 G_A: 0.170 cycle_A: 0.603 idt_A: 0.793 D_B: 0.049 G_B: 0.892 cycle_B: 2.534 idt_B: 0.259 \n",
            "(epoch: 89, iters: 200, time: 0.288, data: 0.004) D_A: 0.107 G_A: 0.809 cycle_A: 0.706 idt_A: 0.600 D_B: 0.082 G_B: 0.542 cycle_B: 1.247 idt_B: 0.247 \n",
            "End of epoch 89 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.285, data: 0.241) D_A: 0.181 G_A: 0.470 cycle_A: 0.553 idt_A: 0.800 D_B: 0.057 G_B: 0.244 cycle_B: 2.020 idt_B: 0.201 \n",
            "(epoch: 90, iters: 200, time: 1.029, data: 0.002) D_A: 0.063 G_A: 0.391 cycle_A: 0.612 idt_A: 0.763 D_B: 0.248 G_B: 0.396 cycle_B: 1.742 idt_B: 0.193 \n",
            "saving the model at the end of epoch 90, iters 18000\n",
            "End of epoch 90 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.297, data: 0.253) D_A: 0.418 G_A: 0.145 cycle_A: 0.613 idt_A: 0.790 D_B: 0.189 G_B: 0.637 cycle_B: 2.065 idt_B: 0.227 \n",
            "(epoch: 91, iters: 200, time: 0.284, data: 0.013) D_A: 0.091 G_A: 0.357 cycle_A: 0.607 idt_A: 0.936 D_B: 0.291 G_B: 0.511 cycle_B: 2.079 idt_B: 0.252 \n",
            "End of epoch 91 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 100, time: 0.296, data: 0.232) D_A: 0.157 G_A: 0.507 cycle_A: 0.624 idt_A: 0.860 D_B: 0.162 G_B: 1.052 cycle_B: 2.078 idt_B: 0.229 \n",
            "(epoch: 92, iters: 200, time: 1.090, data: 0.010) D_A: 0.185 G_A: 0.236 cycle_A: 0.788 idt_A: 1.072 D_B: 0.207 G_B: 0.400 cycle_B: 2.277 idt_B: 0.258 \n",
            "End of epoch 92 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.291, data: 0.254) D_A: 0.081 G_A: 0.367 cycle_A: 0.677 idt_A: 0.421 D_B: 0.148 G_B: 0.299 cycle_B: 1.092 idt_B: 0.225 \n",
            "(epoch: 93, iters: 200, time: 0.290, data: 0.003) D_A: 0.243 G_A: 0.154 cycle_A: 0.534 idt_A: 1.078 D_B: 0.164 G_B: 0.306 cycle_B: 3.494 idt_B: 0.204 \n",
            "End of epoch 93 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.286, data: 0.359) D_A: 0.121 G_A: 0.360 cycle_A: 0.592 idt_A: 0.692 D_B: 0.131 G_B: 0.393 cycle_B: 1.805 idt_B: 0.213 \n",
            "(epoch: 94, iters: 200, time: 1.244, data: 0.003) D_A: 0.074 G_A: 0.418 cycle_A: 0.623 idt_A: 0.896 D_B: 0.181 G_B: 0.642 cycle_B: 2.122 idt_B: 0.332 \n",
            "End of epoch 94 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.284, data: 0.355) D_A: 0.437 G_A: 0.801 cycle_A: 0.513 idt_A: 0.714 D_B: 0.112 G_B: 0.862 cycle_B: 2.039 idt_B: 0.268 \n",
            "(epoch: 95, iters: 200, time: 0.303, data: 0.003) D_A: 0.145 G_A: 0.907 cycle_A: 0.867 idt_A: 0.524 D_B: 0.028 G_B: 0.419 cycle_B: 1.632 idt_B: 0.318 \n",
            "saving the model at the end of epoch 95, iters 19000\n",
            "End of epoch 95 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 100, time: 0.291, data: 0.368) D_A: 0.326 G_A: 0.628 cycle_A: 0.710 idt_A: 0.535 D_B: 0.183 G_B: 0.470 cycle_B: 1.620 idt_B: 0.286 \n",
            "(epoch: 96, iters: 200, time: 1.263, data: 0.003) D_A: 0.138 G_A: 0.282 cycle_A: 0.514 idt_A: 0.569 D_B: 0.304 G_B: 0.532 cycle_B: 1.398 idt_B: 0.212 \n",
            "End of epoch 96 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.297, data: 0.194) D_A: 0.133 G_A: 0.507 cycle_A: 0.467 idt_A: 0.613 D_B: 0.079 G_B: 0.758 cycle_B: 1.445 idt_B: 0.188 \n",
            "(epoch: 97, iters: 200, time: 0.291, data: 0.002) D_A: 0.252 G_A: 0.176 cycle_A: 0.743 idt_A: 0.404 D_B: 0.165 G_B: 1.688 cycle_B: 1.031 idt_B: 0.294 \n",
            "End of epoch 97 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.291, data: 0.197) D_A: 0.075 G_A: 0.806 cycle_A: 1.016 idt_A: 0.879 D_B: 0.394 G_B: 2.400 cycle_B: 2.336 idt_B: 0.430 \n",
            "(epoch: 98, iters: 200, time: 1.061, data: 0.002) D_A: 0.103 G_A: 0.779 cycle_A: 0.537 idt_A: 0.380 D_B: 0.053 G_B: 0.606 cycle_B: 1.401 idt_B: 0.221 \n",
            "End of epoch 98 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.295, data: 0.247) D_A: 0.223 G_A: 1.067 cycle_A: 0.515 idt_A: 0.647 D_B: 0.190 G_B: 0.246 cycle_B: 1.583 idt_B: 0.172 \n",
            "(epoch: 99, iters: 200, time: 0.293, data: 0.002) D_A: 0.265 G_A: 0.576 cycle_A: 0.567 idt_A: 0.546 D_B: 0.045 G_B: 0.630 cycle_B: 1.590 idt_B: 0.195 \n",
            "End of epoch 99 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 100, time: 0.291, data: 0.394) D_A: 0.182 G_A: 0.593 cycle_A: 0.888 idt_A: 0.676 D_B: 0.121 G_B: 0.240 cycle_B: 1.862 idt_B: 0.275 \n",
            "(epoch: 100, iters: 200, time: 1.286, data: 0.003) D_A: 0.044 G_A: 0.789 cycle_A: 0.661 idt_A: 0.968 D_B: 0.163 G_B: 0.930 cycle_B: 1.901 idt_B: 0.268 \n",
            "saving the latest model (epoch 100, total_iters 20000)\n",
            "saving the model at the end of epoch 100, iters 20000\n",
            "End of epoch 100 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.296, data: 0.245) D_A: 0.153 G_A: 0.340 cycle_A: 0.676 idt_A: 0.802 D_B: 0.099 G_B: 0.859 cycle_B: 1.846 idt_B: 0.227 \n",
            "(epoch: 101, iters: 200, time: 0.284, data: 0.003) D_A: 0.052 G_A: 0.338 cycle_A: 0.630 idt_A: 0.604 D_B: 0.141 G_B: 0.410 cycle_B: 1.409 idt_B: 0.209 \n",
            "End of epoch 101 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 100, time: 0.291, data: 0.183) D_A: 0.043 G_A: 0.692 cycle_A: 0.594 idt_A: 0.995 D_B: 0.181 G_B: 0.200 cycle_B: 2.250 idt_B: 0.254 \n",
            "(epoch: 102, iters: 200, time: 1.276, data: 0.010) D_A: 0.086 G_A: 0.027 cycle_A: 0.751 idt_A: 0.594 D_B: 0.096 G_B: 0.073 cycle_B: 1.857 idt_B: 0.311 \n",
            "End of epoch 102 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 100, time: 0.301, data: 0.200) D_A: 0.225 G_A: 0.346 cycle_A: 0.584 idt_A: 0.638 D_B: 0.095 G_B: 0.320 cycle_B: 1.708 idt_B: 0.256 \n",
            "(epoch: 103, iters: 200, time: 0.294, data: 0.004) D_A: 0.247 G_A: 0.950 cycle_A: 0.591 idt_A: 0.435 D_B: 0.094 G_B: 1.143 cycle_B: 1.385 idt_B: 0.238 \n",
            "End of epoch 103 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 100, time: 0.287, data: 0.203) D_A: 0.064 G_A: 0.410 cycle_A: 0.544 idt_A: 0.554 D_B: 0.179 G_B: 0.894 cycle_B: 1.533 idt_B: 0.211 \n",
            "(epoch: 104, iters: 200, time: 1.311, data: 0.002) D_A: 0.096 G_A: 0.283 cycle_A: 0.642 idt_A: 1.080 D_B: 0.103 G_B: 0.940 cycle_B: 2.048 idt_B: 0.213 \n",
            "End of epoch 104 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 100, time: 0.286, data: 0.317) D_A: 0.129 G_A: 0.327 cycle_A: 0.556 idt_A: 0.663 D_B: 0.168 G_B: 0.386 cycle_B: 1.936 idt_B: 0.194 \n",
            "(epoch: 105, iters: 200, time: 0.303, data: 0.002) D_A: 0.312 G_A: 1.245 cycle_A: 0.960 idt_A: 0.741 D_B: 0.039 G_B: 0.477 cycle_B: 1.590 idt_B: 0.201 \n",
            "saving the model at the end of epoch 105, iters 21000\n",
            "End of epoch 105 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 100, time: 0.283, data: 0.241) D_A: 0.163 G_A: 0.434 cycle_A: 0.594 idt_A: 0.913 D_B: 0.106 G_B: 0.314 cycle_B: 1.816 idt_B: 0.212 \n",
            "(epoch: 106, iters: 200, time: 1.245, data: 0.002) D_A: 0.129 G_A: 0.554 cycle_A: 0.589 idt_A: 0.833 D_B: 0.170 G_B: 0.301 cycle_B: 2.067 idt_B: 0.225 \n",
            "End of epoch 106 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 100, time: 0.302, data: 0.238) D_A: 0.099 G_A: 0.630 cycle_A: 0.543 idt_A: 0.608 D_B: 0.084 G_B: 0.480 cycle_B: 1.256 idt_B: 0.267 \n",
            "(epoch: 107, iters: 200, time: 0.287, data: 0.017) D_A: 0.112 G_A: 1.224 cycle_A: 0.518 idt_A: 1.021 D_B: 0.204 G_B: 0.187 cycle_B: 2.668 idt_B: 0.182 \n",
            "End of epoch 107 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 100, time: 0.299, data: 0.251) D_A: 0.040 G_A: 0.658 cycle_A: 0.745 idt_A: 0.597 D_B: 0.066 G_B: 0.679 cycle_B: 1.555 idt_B: 0.246 \n",
            "(epoch: 108, iters: 200, time: 1.121, data: 0.020) D_A: 0.132 G_A: 0.353 cycle_A: 0.623 idt_A: 1.005 D_B: 0.111 G_B: 1.223 cycle_B: 2.300 idt_B: 0.228 \n",
            "End of epoch 108 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 100, time: 0.285, data: 0.248) D_A: 0.363 G_A: 0.124 cycle_A: 0.409 idt_A: 0.567 D_B: 0.037 G_B: 0.497 cycle_B: 1.201 idt_B: 0.133 \n",
            "(epoch: 109, iters: 200, time: 0.290, data: 0.004) D_A: 0.186 G_A: 0.586 cycle_A: 0.590 idt_A: 0.857 D_B: 0.041 G_B: 0.828 cycle_B: 1.756 idt_B: 0.198 \n",
            "End of epoch 109 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.288, data: 0.206) D_A: 0.203 G_A: 0.289 cycle_A: 0.470 idt_A: 0.687 D_B: 0.079 G_B: 0.914 cycle_B: 1.752 idt_B: 0.192 \n",
            "(epoch: 110, iters: 200, time: 1.611, data: 0.003) D_A: 0.225 G_A: 0.757 cycle_A: 0.736 idt_A: 1.038 D_B: 0.094 G_B: 0.723 cycle_B: 2.414 idt_B: 0.260 \n",
            "saving the model at the end of epoch 110, iters 22000\n",
            "End of epoch 110 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 100, time: 0.288, data: 0.339) D_A: 0.105 G_A: 0.482 cycle_A: 0.880 idt_A: 0.846 D_B: 0.325 G_B: 0.073 cycle_B: 1.268 idt_B: 0.275 \n",
            "(epoch: 111, iters: 200, time: 0.287, data: 0.003) D_A: 0.167 G_A: 0.484 cycle_A: 0.598 idt_A: 0.733 D_B: 0.178 G_B: 0.882 cycle_B: 2.817 idt_B: 0.207 \n",
            "End of epoch 111 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 100, time: 0.298, data: 0.235) D_A: 0.189 G_A: 0.724 cycle_A: 0.767 idt_A: 1.067 D_B: 0.214 G_B: 0.958 cycle_B: 2.277 idt_B: 0.272 \n",
            "(epoch: 112, iters: 200, time: 1.128, data: 0.002) D_A: 0.183 G_A: 0.984 cycle_A: 0.566 idt_A: 0.521 D_B: 0.033 G_B: 0.262 cycle_B: 1.296 idt_B: 0.191 \n",
            "End of epoch 112 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 100, time: 0.296, data: 0.312) D_A: 0.093 G_A: 0.445 cycle_A: 0.713 idt_A: 1.192 D_B: 0.102 G_B: 0.828 cycle_B: 2.784 idt_B: 0.241 \n",
            "(epoch: 113, iters: 200, time: 0.288, data: 0.002) D_A: 0.101 G_A: 0.496 cycle_A: 0.403 idt_A: 0.534 D_B: 0.206 G_B: 0.532 cycle_B: 1.096 idt_B: 0.161 \n",
            "End of epoch 113 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 100, time: 0.292, data: 0.268) D_A: 0.084 G_A: 0.985 cycle_A: 0.431 idt_A: 0.550 D_B: 0.087 G_B: 0.582 cycle_B: 1.946 idt_B: 0.154 \n",
            "(epoch: 114, iters: 200, time: 1.132, data: 0.012) D_A: 0.183 G_A: 0.224 cycle_A: 0.469 idt_A: 0.764 D_B: 0.069 G_B: 0.688 cycle_B: 1.862 idt_B: 0.198 \n",
            "End of epoch 114 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 100, time: 0.287, data: 0.248) D_A: 0.098 G_A: 0.501 cycle_A: 0.755 idt_A: 0.382 D_B: 0.250 G_B: 1.414 cycle_B: 0.889 idt_B: 0.290 \n",
            "(epoch: 115, iters: 200, time: 0.298, data: 0.003) D_A: 0.122 G_A: 0.391 cycle_A: 0.637 idt_A: 1.027 D_B: 0.106 G_B: 1.059 cycle_B: 2.339 idt_B: 0.262 \n",
            "saving the model at the end of epoch 115, iters 23000\n",
            "End of epoch 115 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 100, time: 0.295, data: 0.345) D_A: 0.070 G_A: 0.449 cycle_A: 0.604 idt_A: 0.876 D_B: 0.125 G_B: 0.710 cycle_B: 2.048 idt_B: 0.242 \n",
            "(epoch: 116, iters: 200, time: 1.670, data: 0.003) D_A: 0.066 G_A: 0.393 cycle_A: 0.639 idt_A: 1.096 D_B: 0.041 G_B: 0.955 cycle_B: 2.318 idt_B: 0.219 \n",
            "End of epoch 116 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 100, time: 0.296, data: 0.219) D_A: 0.213 G_A: 0.539 cycle_A: 0.691 idt_A: 0.909 D_B: 0.069 G_B: 0.415 cycle_B: 2.189 idt_B: 0.237 \n",
            "(epoch: 117, iters: 200, time: 0.287, data: 0.003) D_A: 0.182 G_A: 0.362 cycle_A: 0.579 idt_A: 0.682 D_B: 0.119 G_B: 0.570 cycle_B: 1.789 idt_B: 0.231 \n",
            "End of epoch 117 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 100, time: 0.290, data: 0.192) D_A: 0.109 G_A: 0.379 cycle_A: 0.587 idt_A: 0.849 D_B: 0.044 G_B: 0.641 cycle_B: 1.917 idt_B: 0.199 \n",
            "(epoch: 118, iters: 200, time: 1.163, data: 0.003) D_A: 0.104 G_A: 0.405 cycle_A: 0.694 idt_A: 0.897 D_B: 0.043 G_B: 0.676 cycle_B: 1.993 idt_B: 0.250 \n",
            "End of epoch 118 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 100, time: 0.298, data: 0.264) D_A: 0.142 G_A: 0.394 cycle_A: 0.481 idt_A: 1.059 D_B: 0.118 G_B: 0.957 cycle_B: 2.617 idt_B: 0.184 \n",
            "(epoch: 119, iters: 200, time: 0.287, data: 0.002) D_A: 0.183 G_A: 0.735 cycle_A: 0.540 idt_A: 0.540 D_B: 0.039 G_B: 0.375 cycle_B: 2.971 idt_B: 0.161 \n",
            "End of epoch 119 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 100, time: 0.281, data: 0.241) D_A: 0.148 G_A: 0.255 cycle_A: 0.510 idt_A: 0.805 D_B: 0.197 G_B: 0.489 cycle_B: 1.992 idt_B: 0.167 \n",
            "(epoch: 120, iters: 200, time: 1.244, data: 0.018) D_A: 0.064 G_A: 0.593 cycle_A: 0.508 idt_A: 1.251 D_B: 0.049 G_B: 0.767 cycle_B: 2.719 idt_B: 0.150 \n",
            "saving the model at the end of epoch 120, iters 24000\n",
            "End of epoch 120 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 100, time: 0.297, data: 0.367) D_A: 0.131 G_A: 0.208 cycle_A: 0.563 idt_A: 0.725 D_B: 0.129 G_B: 0.977 cycle_B: 1.612 idt_B: 0.231 \n",
            "(epoch: 121, iters: 200, time: 0.284, data: 0.003) D_A: 0.158 G_A: 0.620 cycle_A: 0.794 idt_A: 0.616 D_B: 0.133 G_B: 0.658 cycle_B: 1.528 idt_B: 0.313 \n",
            "End of epoch 121 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 100, time: 0.283, data: 0.200) D_A: 0.065 G_A: 0.526 cycle_A: 0.581 idt_A: 0.813 D_B: 0.163 G_B: 0.366 cycle_B: 2.046 idt_B: 0.223 \n",
            "(epoch: 122, iters: 200, time: 1.643, data: 0.003) D_A: 0.093 G_A: 0.694 cycle_A: 0.902 idt_A: 0.602 D_B: 0.036 G_B: 0.864 cycle_B: 3.908 idt_B: 0.261 \n",
            "End of epoch 122 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 100, time: 0.284, data: 0.341) D_A: 0.183 G_A: 0.231 cycle_A: 0.715 idt_A: 0.477 D_B: 0.095 G_B: 0.439 cycle_B: 1.244 idt_B: 0.223 \n",
            "(epoch: 123, iters: 200, time: 0.293, data: 0.003) D_A: 0.026 G_A: 0.742 cycle_A: 0.728 idt_A: 1.524 D_B: 0.104 G_B: 0.542 cycle_B: 3.489 idt_B: 0.208 \n",
            "End of epoch 123 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 100, time: 0.295, data: 0.327) D_A: 0.246 G_A: 1.308 cycle_A: 0.568 idt_A: 0.625 D_B: 0.134 G_B: 0.394 cycle_B: 1.636 idt_B: 0.229 \n",
            "(epoch: 124, iters: 200, time: 1.279, data: 0.003) D_A: 0.093 G_A: 0.432 cycle_A: 0.823 idt_A: 0.702 D_B: 0.111 G_B: 0.358 cycle_B: 1.965 idt_B: 0.320 \n",
            "End of epoch 124 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 100, time: 0.285, data: 0.240) D_A: 0.336 G_A: 0.188 cycle_A: 0.516 idt_A: 1.326 D_B: 0.041 G_B: 0.599 cycle_B: 2.736 idt_B: 0.175 \n",
            "(epoch: 125, iters: 200, time: 0.285, data: 0.002) D_A: 0.090 G_A: 0.367 cycle_A: 0.718 idt_A: 0.630 D_B: 0.129 G_B: 0.364 cycle_B: 1.759 idt_B: 0.290 \n",
            "saving the latest model (epoch 125, total_iters 25000)\n",
            "saving the model at the end of epoch 125, iters 25000\n",
            "End of epoch 125 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 100, time: 0.297, data: 0.259) D_A: 0.133 G_A: 0.420 cycle_A: 0.609 idt_A: 0.892 D_B: 0.087 G_B: 0.444 cycle_B: 2.090 idt_B: 0.244 \n",
            "(epoch: 126, iters: 200, time: 1.411, data: 0.002) D_A: 0.071 G_A: 0.477 cycle_A: 0.472 idt_A: 0.562 D_B: 0.301 G_B: 1.454 cycle_B: 1.571 idt_B: 0.163 \n",
            "End of epoch 126 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 100, time: 0.287, data: 0.233) D_A: 0.064 G_A: 0.349 cycle_A: 0.536 idt_A: 0.624 D_B: 0.177 G_B: 0.306 cycle_B: 1.676 idt_B: 0.189 \n",
            "(epoch: 127, iters: 200, time: 0.296, data: 0.002) D_A: 0.218 G_A: 0.355 cycle_A: 0.894 idt_A: 0.811 D_B: 0.028 G_B: 0.290 cycle_B: 1.960 idt_B: 0.292 \n",
            "End of epoch 127 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 100, time: 0.290, data: 0.226) D_A: 0.123 G_A: 0.730 cycle_A: 1.330 idt_A: 0.740 D_B: 0.025 G_B: 0.448 cycle_B: 1.687 idt_B: 0.178 \n",
            "(epoch: 128, iters: 200, time: 1.512, data: 0.003) D_A: 0.108 G_A: 0.690 cycle_A: 0.466 idt_A: 0.588 D_B: 0.085 G_B: 0.680 cycle_B: 1.557 idt_B: 0.171 \n",
            "End of epoch 128 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 100, time: 0.287, data: 0.328) D_A: 0.207 G_A: 0.276 cycle_A: 0.811 idt_A: 0.471 D_B: 0.068 G_B: 0.623 cycle_B: 1.463 idt_B: 0.244 \n",
            "(epoch: 129, iters: 200, time: 0.310, data: 0.003) D_A: 0.201 G_A: 0.277 cycle_A: 0.622 idt_A: 0.789 D_B: 0.071 G_B: 0.388 cycle_B: 1.846 idt_B: 0.247 \n",
            "End of epoch 129 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 100, time: 0.285, data: 0.406) D_A: 0.236 G_A: 0.034 cycle_A: 0.739 idt_A: 0.443 D_B: 0.149 G_B: 0.264 cycle_B: 1.263 idt_B: 0.227 \n",
            "(epoch: 130, iters: 200, time: 1.237, data: 0.003) D_A: 0.073 G_A: 0.276 cycle_A: 0.471 idt_A: 1.194 D_B: 0.120 G_B: 0.955 cycle_B: 2.589 idt_B: 0.181 \n",
            "saving the model at the end of epoch 130, iters 26000\n",
            "End of epoch 130 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 100, time: 0.293, data: 0.211) D_A: 0.155 G_A: 0.300 cycle_A: 0.526 idt_A: 0.408 D_B: 0.183 G_B: 0.733 cycle_B: 0.946 idt_B: 0.335 \n",
            "(epoch: 131, iters: 200, time: 0.295, data: 0.003) D_A: 0.232 G_A: 0.189 cycle_A: 0.660 idt_A: 1.003 D_B: 0.099 G_B: 0.400 cycle_B: 2.458 idt_B: 0.170 \n",
            "End of epoch 131 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 100, time: 0.301, data: 0.208) D_A: 0.072 G_A: 0.583 cycle_A: 0.796 idt_A: 0.333 D_B: 0.061 G_B: 0.568 cycle_B: 0.963 idt_B: 0.239 \n",
            "(epoch: 132, iters: 200, time: 1.477, data: 0.016) D_A: 0.075 G_A: 0.531 cycle_A: 0.856 idt_A: 0.938 D_B: 0.095 G_B: 0.651 cycle_B: 2.221 idt_B: 0.216 \n",
            "End of epoch 132 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 100, time: 0.300, data: 0.205) D_A: 0.151 G_A: 0.204 cycle_A: 0.841 idt_A: 0.462 D_B: 0.316 G_B: 0.074 cycle_B: 1.061 idt_B: 0.299 \n",
            "(epoch: 133, iters: 200, time: 0.288, data: 0.002) D_A: 0.266 G_A: 0.363 cycle_A: 0.539 idt_A: 0.799 D_B: 0.082 G_B: 0.541 cycle_B: 2.053 idt_B: 0.143 \n",
            "End of epoch 133 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 100, time: 0.286, data: 0.186) D_A: 0.117 G_A: 0.606 cycle_A: 0.428 idt_A: 1.099 D_B: 0.061 G_B: 0.517 cycle_B: 2.486 idt_B: 0.167 \n",
            "(epoch: 134, iters: 200, time: 1.578, data: 0.003) D_A: 0.107 G_A: 0.497 cycle_A: 0.765 idt_A: 0.538 D_B: 0.071 G_B: 1.501 cycle_B: 2.018 idt_B: 0.285 \n",
            "End of epoch 134 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 100, time: 0.292, data: 0.387) D_A: 0.090 G_A: 0.229 cycle_A: 0.509 idt_A: 0.657 D_B: 0.119 G_B: 0.386 cycle_B: 1.778 idt_B: 0.209 \n",
            "(epoch: 135, iters: 200, time: 0.306, data: 0.003) D_A: 0.074 G_A: 0.121 cycle_A: 0.507 idt_A: 0.768 D_B: 0.044 G_B: 0.661 cycle_B: 1.888 idt_B: 0.178 \n",
            "saving the model at the end of epoch 135, iters 27000\n",
            "End of epoch 135 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 100, time: 0.291, data: 0.374) D_A: 0.230 G_A: 0.825 cycle_A: 0.553 idt_A: 0.689 D_B: 0.091 G_B: 0.556 cycle_B: 1.669 idt_B: 0.196 \n",
            "(epoch: 136, iters: 200, time: 1.267, data: 0.003) D_A: 0.199 G_A: 0.278 cycle_A: 0.665 idt_A: 0.550 D_B: 0.225 G_B: 0.156 cycle_B: 1.270 idt_B: 0.255 \n",
            "End of epoch 136 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 100, time: 0.297, data: 0.226) D_A: 0.214 G_A: 0.224 cycle_A: 0.636 idt_A: 0.570 D_B: 0.103 G_B: 0.475 cycle_B: 1.555 idt_B: 0.230 \n",
            "(epoch: 137, iters: 200, time: 0.287, data: 0.002) D_A: 0.138 G_A: 0.538 cycle_A: 1.127 idt_A: 0.848 D_B: 0.103 G_B: 0.818 cycle_B: 1.859 idt_B: 0.242 \n",
            "End of epoch 137 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 100, time: 0.294, data: 0.197) D_A: 0.078 G_A: 0.630 cycle_A: 0.578 idt_A: 0.712 D_B: 0.139 G_B: 1.511 cycle_B: 1.652 idt_B: 0.214 \n",
            "(epoch: 138, iters: 200, time: 1.465, data: 0.003) D_A: 0.111 G_A: 0.857 cycle_A: 0.483 idt_A: 0.249 D_B: 0.047 G_B: 0.324 cycle_B: 0.981 idt_B: 0.171 \n",
            "End of epoch 138 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 100, time: 0.298, data: 0.234) D_A: 0.157 G_A: 0.483 cycle_A: 0.673 idt_A: 0.755 D_B: 0.039 G_B: 0.564 cycle_B: 1.597 idt_B: 0.181 \n",
            "(epoch: 139, iters: 200, time: 0.289, data: 0.003) D_A: 0.077 G_A: 0.940 cycle_A: 0.650 idt_A: 0.661 D_B: 0.201 G_B: 0.473 cycle_B: 1.697 idt_B: 0.302 \n",
            "End of epoch 139 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 100, time: 0.303, data: 0.195) D_A: 0.066 G_A: 0.271 cycle_A: 0.719 idt_A: 0.923 D_B: 0.215 G_B: 0.199 cycle_B: 2.210 idt_B: 0.217 \n",
            "(epoch: 140, iters: 200, time: 1.315, data: 0.002) D_A: 0.110 G_A: 0.468 cycle_A: 0.647 idt_A: 0.977 D_B: 0.202 G_B: 1.173 cycle_B: 1.901 idt_B: 0.241 \n",
            "saving the model at the end of epoch 140, iters 28000\n",
            "End of epoch 140 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 0.287, data: 0.340) D_A: 0.111 G_A: 0.834 cycle_A: 0.467 idt_A: 0.531 D_B: 0.155 G_B: 0.280 cycle_B: 1.249 idt_B: 0.178 \n",
            "(epoch: 141, iters: 200, time: 0.293, data: 0.003) D_A: 0.129 G_A: 0.368 cycle_A: 0.578 idt_A: 0.844 D_B: 0.067 G_B: 0.733 cycle_B: 2.026 idt_B: 0.219 \n",
            "End of epoch 141 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 100, time: 0.291, data: 0.432) D_A: 0.227 G_A: 0.163 cycle_A: 0.637 idt_A: 0.994 D_B: 0.088 G_B: 0.839 cycle_B: 2.361 idt_B: 0.208 \n",
            "(epoch: 142, iters: 200, time: 1.610, data: 0.003) D_A: 0.115 G_A: 0.604 cycle_A: 0.584 idt_A: 0.370 D_B: 0.043 G_B: 1.251 cycle_B: 1.119 idt_B: 0.197 \n",
            "End of epoch 142 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 100, time: 0.288, data: 0.260) D_A: 0.049 G_A: 0.814 cycle_A: 0.456 idt_A: 1.093 D_B: 0.108 G_B: 0.403 cycle_B: 2.526 idt_B: 0.145 \n",
            "(epoch: 143, iters: 200, time: 0.292, data: 0.003) D_A: 0.167 G_A: 0.595 cycle_A: 0.607 idt_A: 0.547 D_B: 0.284 G_B: 0.164 cycle_B: 1.517 idt_B: 0.234 \n",
            "End of epoch 143 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 100, time: 0.299, data: 0.263) D_A: 0.101 G_A: 0.595 cycle_A: 1.239 idt_A: 0.946 D_B: 0.065 G_B: 0.553 cycle_B: 2.199 idt_B: 0.152 \n",
            "(epoch: 144, iters: 200, time: 1.410, data: 0.004) D_A: 0.071 G_A: 0.717 cycle_A: 0.536 idt_A: 0.420 D_B: 0.048 G_B: 1.115 cycle_B: 0.976 idt_B: 0.196 \n",
            "End of epoch 144 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 100, time: 0.324, data: 0.241) D_A: 0.146 G_A: 0.316 cycle_A: 0.463 idt_A: 0.288 D_B: 0.086 G_B: 0.431 cycle_B: 0.989 idt_B: 0.189 \n",
            "(epoch: 145, iters: 200, time: 0.293, data: 0.002) D_A: 0.198 G_A: 0.503 cycle_A: 0.542 idt_A: 0.712 D_B: 0.116 G_B: 0.390 cycle_B: 2.002 idt_B: 0.156 \n",
            "saving the model at the end of epoch 145, iters 29000\n",
            "End of epoch 145 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 100, time: 0.299, data: 0.281) D_A: 0.259 G_A: 0.700 cycle_A: 0.665 idt_A: 0.615 D_B: 0.129 G_B: 0.967 cycle_B: 1.740 idt_B: 0.225 \n",
            "(epoch: 146, iters: 200, time: 1.975, data: 0.003) D_A: 0.296 G_A: 0.122 cycle_A: 0.614 idt_A: 0.636 D_B: 0.107 G_B: 0.477 cycle_B: 1.532 idt_B: 0.208 \n",
            "End of epoch 146 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 100, time: 0.289, data: 0.429) D_A: 0.228 G_A: 0.277 cycle_A: 0.536 idt_A: 0.920 D_B: 0.161 G_B: 0.698 cycle_B: 1.993 idt_B: 0.161 \n",
            "(epoch: 147, iters: 200, time: 0.297, data: 0.003) D_A: 0.216 G_A: 0.615 cycle_A: 0.531 idt_A: 0.632 D_B: 0.139 G_B: 0.289 cycle_B: 1.793 idt_B: 0.195 \n",
            "End of epoch 147 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 100, time: 0.287, data: 0.385) D_A: 0.160 G_A: 0.326 cycle_A: 0.484 idt_A: 0.393 D_B: 0.068 G_B: 0.547 cycle_B: 1.078 idt_B: 0.197 \n",
            "(epoch: 148, iters: 200, time: 1.357, data: 0.003) D_A: 0.103 G_A: 0.474 cycle_A: 0.524 idt_A: 0.804 D_B: 0.082 G_B: 1.012 cycle_B: 1.979 idt_B: 0.173 \n",
            "End of epoch 148 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 100, time: 0.308, data: 0.275) D_A: 0.118 G_A: 0.371 cycle_A: 0.468 idt_A: 0.452 D_B: 0.170 G_B: 0.040 cycle_B: 1.171 idt_B: 0.147 \n",
            "(epoch: 149, iters: 200, time: 0.299, data: 0.015) D_A: 0.099 G_A: 0.536 cycle_A: 0.443 idt_A: 0.787 D_B: 0.134 G_B: 0.507 cycle_B: 2.038 idt_B: 0.152 \n",
            "End of epoch 149 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 100, time: 0.306, data: 0.236) D_A: 0.204 G_A: 0.201 cycle_A: 0.393 idt_A: 0.490 D_B: 0.063 G_B: 0.829 cycle_B: 1.087 idt_B: 0.130 \n",
            "(epoch: 150, iters: 200, time: 1.380, data: 0.003) D_A: 0.140 G_A: 0.362 cycle_A: 0.596 idt_A: 0.274 D_B: 0.080 G_B: 0.451 cycle_B: 0.860 idt_B: 0.182 \n",
            "saving the latest model (epoch 150, total_iters 30000)\n",
            "saving the model at the end of epoch 150, iters 30000\n",
            "End of epoch 150 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 100, time: 0.303, data: 0.301) D_A: 0.186 G_A: 0.362 cycle_A: 0.562 idt_A: 0.461 D_B: 0.113 G_B: 0.351 cycle_B: 1.327 idt_B: 0.212 \n",
            "(epoch: 151, iters: 200, time: 0.286, data: 0.003) D_A: 0.254 G_A: 0.736 cycle_A: 0.497 idt_A: 0.827 D_B: 0.035 G_B: 0.531 cycle_B: 2.027 idt_B: 0.194 \n",
            "End of epoch 151 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 100, time: 0.288, data: 0.354) D_A: 0.070 G_A: 0.199 cycle_A: 0.568 idt_A: 1.231 D_B: 0.058 G_B: 0.971 cycle_B: 2.598 idt_B: 0.190 \n",
            "(epoch: 152, iters: 200, time: 1.933, data: 0.003) D_A: 0.115 G_A: 0.424 cycle_A: 0.573 idt_A: 0.941 D_B: 0.026 G_B: 0.496 cycle_B: 2.299 idt_B: 0.179 \n",
            "End of epoch 152 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 100, time: 0.283, data: 0.362) D_A: 0.087 G_A: 0.911 cycle_A: 0.572 idt_A: 0.944 D_B: 0.044 G_B: 1.341 cycle_B: 2.140 idt_B: 0.180 \n",
            "(epoch: 153, iters: 200, time: 0.292, data: 0.003) D_A: 0.086 G_A: 0.582 cycle_A: 0.735 idt_A: 0.659 D_B: 0.043 G_B: 1.215 cycle_B: 1.657 idt_B: 0.275 \n",
            "End of epoch 153 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 100, time: 0.293, data: 0.215) D_A: 0.135 G_A: 0.348 cycle_A: 0.570 idt_A: 0.243 D_B: 0.115 G_B: 1.106 cycle_B: 0.790 idt_B: 0.151 \n",
            "(epoch: 154, iters: 200, time: 1.361, data: 0.005) D_A: 0.220 G_A: 0.394 cycle_A: 0.546 idt_A: 0.688 D_B: 0.078 G_B: 0.546 cycle_B: 1.671 idt_B: 0.159 \n",
            "End of epoch 154 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 100, time: 0.299, data: 0.248) D_A: 0.102 G_A: 0.418 cycle_A: 0.484 idt_A: 0.645 D_B: 0.048 G_B: 0.573 cycle_B: 1.466 idt_B: 0.144 \n",
            "(epoch: 155, iters: 200, time: 0.287, data: 0.003) D_A: 0.071 G_A: 0.378 cycle_A: 0.654 idt_A: 1.077 D_B: 0.068 G_B: 0.333 cycle_B: 2.481 idt_B: 0.234 \n",
            "saving the model at the end of epoch 155, iters 31000\n",
            "End of epoch 155 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 100, time: 0.291, data: 0.229) D_A: 0.116 G_A: 0.458 cycle_A: 0.837 idt_A: 0.860 D_B: 0.152 G_B: 1.155 cycle_B: 2.101 idt_B: 0.254 \n",
            "(epoch: 156, iters: 200, time: 1.579, data: 0.002) D_A: 0.259 G_A: 0.123 cycle_A: 0.706 idt_A: 0.703 D_B: 0.103 G_B: 0.700 cycle_B: 1.730 idt_B: 0.237 \n",
            "End of epoch 156 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 100, time: 0.289, data: 0.290) D_A: 0.091 G_A: 0.628 cycle_A: 0.506 idt_A: 0.933 D_B: 0.089 G_B: 0.847 cycle_B: 2.021 idt_B: 0.147 \n",
            "(epoch: 157, iters: 200, time: 0.297, data: 0.003) D_A: 0.078 G_A: 0.653 cycle_A: 0.659 idt_A: 0.852 D_B: 0.097 G_B: 1.334 cycle_B: 2.139 idt_B: 0.203 \n",
            "End of epoch 157 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 100, time: 0.283, data: 0.404) D_A: 0.170 G_A: 0.328 cycle_A: 0.400 idt_A: 0.940 D_B: 0.038 G_B: 0.659 cycle_B: 1.946 idt_B: 0.127 \n",
            "(epoch: 158, iters: 200, time: 1.709, data: 0.003) D_A: 0.033 G_A: 0.351 cycle_A: 0.576 idt_A: 0.458 D_B: 0.058 G_B: 0.856 cycle_B: 1.358 idt_B: 0.181 \n",
            "End of epoch 158 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 100, time: 0.290, data: 0.369) D_A: 0.240 G_A: 0.369 cycle_A: 0.590 idt_A: 0.982 D_B: 0.034 G_B: 0.609 cycle_B: 2.142 idt_B: 0.204 \n",
            "(epoch: 159, iters: 200, time: 0.302, data: 0.003) D_A: 0.121 G_A: 0.359 cycle_A: 0.874 idt_A: 0.856 D_B: 0.080 G_B: 0.593 cycle_B: 2.270 idt_B: 0.134 \n",
            "End of epoch 159 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 0.290, data: 0.267) D_A: 0.115 G_A: 0.466 cycle_A: 0.754 idt_A: 0.639 D_B: 0.033 G_B: 0.330 cycle_B: 2.689 idt_B: 0.242 \n",
            "(epoch: 160, iters: 200, time: 1.692, data: 0.003) D_A: 0.067 G_A: 0.708 cycle_A: 0.533 idt_A: 0.838 D_B: 0.056 G_B: 1.135 cycle_B: 2.017 idt_B: 0.157 \n",
            "saving the model at the end of epoch 160, iters 32000\n",
            "End of epoch 160 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 100, time: 0.292, data: 0.265) D_A: 0.195 G_A: 0.299 cycle_A: 0.717 idt_A: 0.360 D_B: 0.086 G_B: 0.406 cycle_B: 0.917 idt_B: 0.241 \n",
            "(epoch: 161, iters: 200, time: 0.289, data: 0.003) D_A: 0.218 G_A: 0.212 cycle_A: 0.501 idt_A: 0.418 D_B: 0.023 G_B: 0.375 cycle_B: 1.120 idt_B: 0.150 \n",
            "End of epoch 161 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 100, time: 0.292, data: 0.256) D_A: 0.210 G_A: 0.170 cycle_A: 0.483 idt_A: 0.388 D_B: 0.045 G_B: 0.388 cycle_B: 1.009 idt_B: 0.168 \n",
            "(epoch: 162, iters: 200, time: 1.385, data: 0.010) D_A: 0.099 G_A: 0.408 cycle_A: 0.428 idt_A: 0.502 D_B: 0.067 G_B: 0.551 cycle_B: 1.289 idt_B: 0.176 \n",
            "End of epoch 162 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 100, time: 0.294, data: 0.256) D_A: 0.037 G_A: 0.716 cycle_A: 0.528 idt_A: 0.354 D_B: 0.071 G_B: 1.473 cycle_B: 1.063 idt_B: 0.201 \n",
            "(epoch: 163, iters: 200, time: 0.286, data: 0.012) D_A: 0.250 G_A: 0.142 cycle_A: 0.767 idt_A: 0.977 D_B: 0.146 G_B: 0.610 cycle_B: 2.111 idt_B: 0.246 \n",
            "End of epoch 163 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 100, time: 0.285, data: 0.225) D_A: 0.030 G_A: 0.522 cycle_A: 0.731 idt_A: 0.676 D_B: 0.049 G_B: 0.918 cycle_B: 1.526 idt_B: 0.151 \n",
            "(epoch: 164, iters: 200, time: 1.601, data: 0.002) D_A: 0.166 G_A: 0.399 cycle_A: 0.456 idt_A: 0.877 D_B: 0.121 G_B: 0.631 cycle_B: 1.910 idt_B: 0.153 \n",
            "End of epoch 164 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 100, time: 0.284, data: 0.375) D_A: 0.134 G_A: 0.492 cycle_A: 0.423 idt_A: 0.516 D_B: 0.021 G_B: 0.919 cycle_B: 1.441 idt_B: 0.170 \n",
            "(epoch: 165, iters: 200, time: 0.327, data: 0.003) D_A: 0.220 G_A: 0.259 cycle_A: 0.533 idt_A: 0.483 D_B: 0.155 G_B: 0.477 cycle_B: 1.304 idt_B: 0.183 \n",
            "saving the model at the end of epoch 165, iters 33000\n",
            "End of epoch 165 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 0.288, data: 0.457) D_A: 0.140 G_A: 0.431 cycle_A: 0.469 idt_A: 0.501 D_B: 0.019 G_B: 1.096 cycle_B: 1.339 idt_B: 0.162 \n",
            "(epoch: 166, iters: 200, time: 1.982, data: 0.002) D_A: 0.371 G_A: 0.196 cycle_A: 0.656 idt_A: 0.974 D_B: 0.077 G_B: 0.471 cycle_B: 2.208 idt_B: 0.209 \n",
            "End of epoch 166 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 100, time: 0.290, data: 0.367) D_A: 0.047 G_A: 0.461 cycle_A: 0.644 idt_A: 0.483 D_B: 0.090 G_B: 0.590 cycle_B: 1.154 idt_B: 0.200 \n",
            "(epoch: 167, iters: 200, time: 0.289, data: 0.003) D_A: 0.087 G_A: 0.410 cycle_A: 0.479 idt_A: 0.889 D_B: 0.027 G_B: 0.945 cycle_B: 2.027 idt_B: 0.142 \n",
            "End of epoch 167 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 100, time: 0.289, data: 0.247) D_A: 0.247 G_A: 0.983 cycle_A: 0.570 idt_A: 0.354 D_B: 0.092 G_B: 0.429 cycle_B: 0.839 idt_B: 0.227 \n",
            "(epoch: 168, iters: 200, time: 1.428, data: 0.003) D_A: 0.119 G_A: 0.488 cycle_A: 0.557 idt_A: 0.424 D_B: 0.112 G_B: 0.709 cycle_B: 1.139 idt_B: 0.175 \n",
            "End of epoch 168 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 100, time: 0.301, data: 0.262) D_A: 0.157 G_A: 0.401 cycle_A: 0.557 idt_A: 0.236 D_B: 0.072 G_B: 0.476 cycle_B: 0.885 idt_B: 0.171 \n",
            "(epoch: 169, iters: 200, time: 0.287, data: 0.004) D_A: 0.245 G_A: 0.619 cycle_A: 0.542 idt_A: 0.694 D_B: 0.064 G_B: 0.639 cycle_B: 2.007 idt_B: 0.160 \n",
            "End of epoch 169 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 100, time: 0.286, data: 0.207) D_A: 0.071 G_A: 0.822 cycle_A: 0.415 idt_A: 0.893 D_B: 0.072 G_B: 1.792 cycle_B: 2.043 idt_B: 0.126 \n",
            "(epoch: 170, iters: 200, time: 1.549, data: 0.002) D_A: 0.091 G_A: 0.338 cycle_A: 0.619 idt_A: 0.974 D_B: 0.085 G_B: 0.453 cycle_B: 2.102 idt_B: 0.159 \n",
            "saving the model at the end of epoch 170, iters 34000\n",
            "End of epoch 170 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 100, time: 0.286, data: 0.305) D_A: 0.097 G_A: 0.635 cycle_A: 0.483 idt_A: 0.769 D_B: 0.170 G_B: 0.292 cycle_B: 1.677 idt_B: 0.167 \n",
            "(epoch: 171, iters: 200, time: 0.298, data: 0.003) D_A: 0.193 G_A: 0.628 cycle_A: 0.586 idt_A: 0.990 D_B: 0.058 G_B: 0.547 cycle_B: 2.098 idt_B: 0.201 \n",
            "End of epoch 171 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 100, time: 0.284, data: 0.486) D_A: 0.139 G_A: 0.342 cycle_A: 0.616 idt_A: 0.862 D_B: 0.073 G_B: 1.207 cycle_B: 1.865 idt_B: 0.177 \n",
            "(epoch: 172, iters: 200, time: 1.450, data: 0.003) D_A: 0.120 G_A: 0.581 cycle_A: 0.399 idt_A: 0.663 D_B: 0.039 G_B: 0.963 cycle_B: 1.611 idt_B: 0.139 \n",
            "End of epoch 172 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 100, time: 0.308, data: 0.234) D_A: 0.037 G_A: 0.569 cycle_A: 0.528 idt_A: 0.906 D_B: 0.022 G_B: 1.375 cycle_B: 1.922 idt_B: 0.159 \n",
            "(epoch: 173, iters: 200, time: 0.287, data: 0.003) D_A: 0.117 G_A: 0.292 cycle_A: 0.481 idt_A: 0.354 D_B: 0.059 G_B: 0.383 cycle_B: 0.814 idt_B: 0.209 \n",
            "End of epoch 173 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 100, time: 0.298, data: 0.230) D_A: 0.082 G_A: 0.571 cycle_A: 0.661 idt_A: 0.464 D_B: 0.105 G_B: 1.469 cycle_B: 1.297 idt_B: 0.179 \n",
            "(epoch: 174, iters: 200, time: 1.485, data: 0.014) D_A: 0.152 G_A: 0.389 cycle_A: 0.454 idt_A: 1.138 D_B: 0.016 G_B: 0.883 cycle_B: 2.545 idt_B: 0.152 \n",
            "End of epoch 174 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 100, time: 0.295, data: 0.240) D_A: 0.168 G_A: 0.373 cycle_A: 0.431 idt_A: 0.651 D_B: 0.035 G_B: 0.422 cycle_B: 1.544 idt_B: 0.109 \n",
            "(epoch: 175, iters: 200, time: 0.283, data: 0.003) D_A: 0.289 G_A: 0.130 cycle_A: 0.563 idt_A: 0.547 D_B: 0.079 G_B: 0.650 cycle_B: 1.315 idt_B: 0.171 \n",
            "saving the latest model (epoch 175, total_iters 35000)\n",
            "saving the model at the end of epoch 175, iters 35000\n",
            "End of epoch 175 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 100, time: 0.288, data: 0.339) D_A: 0.053 G_A: 0.707 cycle_A: 0.522 idt_A: 0.861 D_B: 0.015 G_B: 0.982 cycle_B: 1.905 idt_B: 0.166 \n",
            "(epoch: 176, iters: 200, time: 2.089, data: 0.002) D_A: 0.069 G_A: 0.514 cycle_A: 0.537 idt_A: 0.421 D_B: 0.065 G_B: 0.714 cycle_B: 1.338 idt_B: 0.146 \n",
            "End of epoch 176 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 100, time: 0.302, data: 0.429) D_A: 0.102 G_A: 0.405 cycle_A: 0.510 idt_A: 0.655 D_B: 0.017 G_B: 1.037 cycle_B: 1.661 idt_B: 0.147 \n",
            "(epoch: 177, iters: 200, time: 0.287, data: 0.002) D_A: 0.165 G_A: 0.368 cycle_A: 0.613 idt_A: 0.956 D_B: 0.109 G_B: 0.461 cycle_B: 2.052 idt_B: 0.211 \n",
            "End of epoch 177 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 100, time: 0.311, data: 0.211) D_A: 0.218 G_A: 0.382 cycle_A: 0.587 idt_A: 1.424 D_B: 0.070 G_B: 0.350 cycle_B: 3.105 idt_B: 0.194 \n",
            "(epoch: 178, iters: 200, time: 1.580, data: 0.011) D_A: 0.050 G_A: 0.312 cycle_A: 0.500 idt_A: 0.861 D_B: 0.016 G_B: 0.883 cycle_B: 1.957 idt_B: 0.164 \n",
            "End of epoch 178 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 100, time: 0.283, data: 0.227) D_A: 0.124 G_A: 0.477 cycle_A: 0.603 idt_A: 0.496 D_B: 0.021 G_B: 0.879 cycle_B: 1.566 idt_B: 0.156 \n",
            "(epoch: 179, iters: 200, time: 0.288, data: 0.009) D_A: 0.069 G_A: 0.450 cycle_A: 0.510 idt_A: 0.804 D_B: 0.022 G_B: 0.832 cycle_B: 1.834 idt_B: 0.176 \n",
            "End of epoch 179 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 100, time: 0.296, data: 0.236) D_A: 0.104 G_A: 0.651 cycle_A: 0.638 idt_A: 0.492 D_B: 0.103 G_B: 1.318 cycle_B: 1.389 idt_B: 0.209 \n",
            "(epoch: 180, iters: 200, time: 1.571, data: 0.003) D_A: 0.095 G_A: 0.906 cycle_A: 0.551 idt_A: 0.881 D_B: 0.076 G_B: 0.451 cycle_B: 1.831 idt_B: 0.183 \n",
            "saving the model at the end of epoch 180, iters 36000\n",
            "End of epoch 180 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 100, time: 0.287, data: 0.349) D_A: 0.087 G_A: 0.769 cycle_A: 0.483 idt_A: 0.647 D_B: 0.037 G_B: 0.467 cycle_B: 1.605 idt_B: 0.184 \n",
            "(epoch: 181, iters: 200, time: 0.299, data: 0.003) D_A: 0.083 G_A: 0.519 cycle_A: 0.458 idt_A: 0.796 D_B: 0.017 G_B: 1.163 cycle_B: 1.980 idt_B: 0.150 \n",
            "End of epoch 181 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 100, time: 0.288, data: 0.396) D_A: 0.061 G_A: 0.604 cycle_A: 0.456 idt_A: 0.401 D_B: 0.038 G_B: 0.590 cycle_B: 1.116 idt_B: 0.170 \n",
            "(epoch: 182, iters: 200, time: 1.509, data: 0.003) D_A: 0.025 G_A: 0.538 cycle_A: 0.707 idt_A: 1.010 D_B: 0.076 G_B: 0.898 cycle_B: 2.125 idt_B: 0.235 \n",
            "End of epoch 182 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 100, time: 0.297, data: 0.216) D_A: 0.081 G_A: 0.252 cycle_A: 0.662 idt_A: 1.450 D_B: 0.093 G_B: 0.348 cycle_B: 3.282 idt_B: 0.203 \n",
            "(epoch: 183, iters: 200, time: 0.286, data: 0.011) D_A: 0.134 G_A: 0.511 cycle_A: 0.452 idt_A: 0.253 D_B: 0.053 G_B: 0.570 cycle_B: 0.680 idt_B: 0.144 \n",
            "End of epoch 183 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 100, time: 0.295, data: 0.242) D_A: 0.234 G_A: 0.636 cycle_A: 0.556 idt_A: 1.501 D_B: 0.145 G_B: 0.292 cycle_B: 3.244 idt_B: 0.179 \n",
            "(epoch: 184, iters: 200, time: 1.688, data: 0.003) D_A: 0.131 G_A: 0.327 cycle_A: 0.506 idt_A: 0.758 D_B: 0.039 G_B: 1.142 cycle_B: 1.811 idt_B: 0.165 \n",
            "End of epoch 184 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 100, time: 0.294, data: 0.201) D_A: 0.100 G_A: 0.327 cycle_A: 0.550 idt_A: 0.574 D_B: 0.055 G_B: 0.458 cycle_B: 1.379 idt_B: 0.159 \n",
            "(epoch: 185, iters: 200, time: 0.288, data: 0.002) D_A: 0.163 G_A: 0.121 cycle_A: 0.370 idt_A: 0.239 D_B: 0.032 G_B: 0.730 cycle_B: 0.627 idt_B: 0.114 \n",
            "saving the model at the end of epoch 185, iters 37000\n",
            "End of epoch 185 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 100, time: 0.288, data: 0.413) D_A: 0.074 G_A: 0.821 cycle_A: 0.480 idt_A: 0.523 D_B: 0.046 G_B: 0.705 cycle_B: 1.133 idt_B: 0.148 \n",
            "(epoch: 186, iters: 200, time: 1.852, data: 0.003) D_A: 0.222 G_A: 0.566 cycle_A: 0.595 idt_A: 0.953 D_B: 0.106 G_B: 0.658 cycle_B: 2.140 idt_B: 0.207 \n",
            "End of epoch 186 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 100, time: 0.288, data: 0.349) D_A: 0.103 G_A: 0.396 cycle_A: 0.579 idt_A: 0.236 D_B: 0.057 G_B: 0.820 cycle_B: 0.604 idt_B: 0.193 \n",
            "(epoch: 187, iters: 200, time: 0.285, data: 0.003) D_A: 0.094 G_A: 0.416 cycle_A: 0.531 idt_A: 0.557 D_B: 0.154 G_B: 1.280 cycle_B: 1.291 idt_B: 0.185 \n",
            "End of epoch 187 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 100, time: 0.293, data: 0.207) D_A: 0.212 G_A: 0.533 cycle_A: 0.431 idt_A: 0.986 D_B: 0.022 G_B: 0.788 cycle_B: 2.213 idt_B: 0.152 \n",
            "(epoch: 188, iters: 200, time: 1.790, data: 0.016) D_A: 0.080 G_A: 0.327 cycle_A: 0.614 idt_A: 0.437 D_B: 0.075 G_B: 0.688 cycle_B: 1.060 idt_B: 0.180 \n",
            "End of epoch 188 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 100, time: 0.299, data: 0.270) D_A: 0.071 G_A: 0.593 cycle_A: 0.628 idt_A: 0.704 D_B: 0.129 G_B: 0.303 cycle_B: 1.661 idt_B: 0.202 \n",
            "(epoch: 189, iters: 200, time: 0.288, data: 0.003) D_A: 0.086 G_A: 0.493 cycle_A: 0.505 idt_A: 0.497 D_B: 0.020 G_B: 0.305 cycle_B: 1.156 idt_B: 0.205 \n",
            "End of epoch 189 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 100, time: 0.294, data: 0.239) D_A: 0.144 G_A: 0.319 cycle_A: 0.417 idt_A: 0.942 D_B: 0.069 G_B: 1.166 cycle_B: 2.066 idt_B: 0.126 \n",
            "(epoch: 190, iters: 200, time: 1.570, data: 0.012) D_A: 0.106 G_A: 0.375 cycle_A: 0.565 idt_A: 0.425 D_B: 0.052 G_B: 0.585 cycle_B: 0.924 idt_B: 0.165 \n",
            "saving the model at the end of epoch 190, iters 38000\n",
            "End of epoch 190 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 0.291, data: 0.357) D_A: 0.049 G_A: 0.649 cycle_A: 0.700 idt_A: 0.569 D_B: 0.119 G_B: 0.873 cycle_B: 1.433 idt_B: 0.243 \n",
            "(epoch: 191, iters: 200, time: 0.298, data: 0.003) D_A: 0.261 G_A: 0.508 cycle_A: 0.571 idt_A: 0.618 D_B: 0.055 G_B: 0.727 cycle_B: 1.534 idt_B: 0.162 \n",
            "End of epoch 191 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 100, time: 0.283, data: 0.336) D_A: 0.358 G_A: 0.374 cycle_A: 0.506 idt_A: 0.365 D_B: 0.058 G_B: 0.692 cycle_B: 1.173 idt_B: 0.142 \n",
            "(epoch: 192, iters: 200, time: 1.953, data: 0.003) D_A: 0.059 G_A: 0.636 cycle_A: 0.419 idt_A: 0.495 D_B: 0.056 G_B: 0.564 cycle_B: 1.241 idt_B: 0.140 \n",
            "End of epoch 192 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 100, time: 0.284, data: 0.265) D_A: 0.206 G_A: 0.668 cycle_A: 0.365 idt_A: 0.662 D_B: 0.025 G_B: 0.605 cycle_B: 1.564 idt_B: 0.125 \n",
            "(epoch: 193, iters: 200, time: 0.285, data: 0.003) D_A: 0.071 G_A: 0.588 cycle_A: 0.355 idt_A: 0.719 D_B: 0.051 G_B: 0.889 cycle_B: 1.601 idt_B: 0.109 \n",
            "End of epoch 193 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 100, time: 0.281, data: 0.239) D_A: 0.054 G_A: 0.463 cycle_A: 0.508 idt_A: 0.591 D_B: 0.050 G_B: 1.195 cycle_B: 1.478 idt_B: 0.173 \n",
            "(epoch: 194, iters: 200, time: 1.553, data: 0.011) D_A: 0.025 G_A: 0.343 cycle_A: 0.540 idt_A: 0.520 D_B: 0.032 G_B: 0.821 cycle_B: 1.162 idt_B: 0.179 \n",
            "End of epoch 194 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 100, time: 0.292, data: 0.241) D_A: 0.066 G_A: 0.503 cycle_A: 0.484 idt_A: 0.730 D_B: 0.066 G_B: 0.928 cycle_B: 1.807 idt_B: 0.115 \n",
            "(epoch: 195, iters: 200, time: 0.283, data: 0.004) D_A: 0.128 G_A: 0.336 cycle_A: 0.414 idt_A: 0.691 D_B: 0.014 G_B: 0.900 cycle_B: 1.673 idt_B: 0.115 \n",
            "saving the model at the end of epoch 195, iters 39000\n",
            "End of epoch 195 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 100, time: 0.286, data: 0.260) D_A: 0.215 G_A: 0.395 cycle_A: 0.484 idt_A: 0.533 D_B: 0.022 G_B: 0.300 cycle_B: 1.270 idt_B: 0.146 \n",
            "(epoch: 196, iters: 200, time: 1.799, data: 0.011) D_A: 0.166 G_A: 0.448 cycle_A: 0.503 idt_A: 0.393 D_B: 0.036 G_B: 0.868 cycle_B: 1.035 idt_B: 0.153 \n",
            "End of epoch 196 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 100, time: 0.290, data: 0.242) D_A: 0.103 G_A: 0.393 cycle_A: 0.589 idt_A: 0.469 D_B: 0.078 G_B: 1.194 cycle_B: 1.236 idt_B: 0.152 \n",
            "(epoch: 197, iters: 200, time: 0.297, data: 0.003) D_A: 0.037 G_A: 0.430 cycle_A: 0.613 idt_A: 0.420 D_B: 0.056 G_B: 0.818 cycle_B: 1.101 idt_B: 0.207 \n",
            "End of epoch 197 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 100, time: 0.290, data: 0.336) D_A: 0.040 G_A: 0.456 cycle_A: 0.588 idt_A: 1.307 D_B: 0.026 G_B: 1.077 cycle_B: 2.246 idt_B: 0.179 \n",
            "(epoch: 198, iters: 200, time: 1.981, data: 0.002) D_A: 0.023 G_A: 0.487 cycle_A: 0.504 idt_A: 0.244 D_B: 0.070 G_B: 0.903 cycle_B: 0.804 idt_B: 0.167 \n",
            "End of epoch 198 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 100, time: 0.288, data: 0.337) D_A: 0.095 G_A: 0.534 cycle_A: 0.464 idt_A: 0.647 D_B: 0.089 G_B: 0.479 cycle_B: 1.402 idt_B: 0.148 \n",
            "(epoch: 199, iters: 200, time: 0.286, data: 0.003) D_A: 0.137 G_A: 0.560 cycle_A: 0.581 idt_A: 0.793 D_B: 0.042 G_B: 0.543 cycle_B: 1.939 idt_B: 0.172 \n",
            "End of epoch 199 / 200 \t Time Taken: 50 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 100, time: 0.303, data: 0.260) D_A: 0.171 G_A: 0.346 cycle_A: 0.626 idt_A: 0.631 D_B: 0.067 G_B: 0.904 cycle_B: 1.341 idt_B: 0.202 \n",
            "(epoch: 200, iters: 200, time: 1.918, data: 0.002) D_A: 0.192 G_A: 0.377 cycle_A: 0.546 idt_A: 0.335 D_B: 0.127 G_B: 0.295 cycle_B: 0.934 idt_B: 0.148 \n",
            "saving the latest model (epoch 200, total_iters 40000)\n",
            "saving the model at the end of epoch 200, iters 40000\n",
            "End of epoch 200 / 200 \t Time Taken: 54 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)], 'cell_netG_B': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NAS GAN Trains\n",
        "- 200 epochs\n",
        "- 200 images"
      ],
      "metadata": {
        "id": "9cGn_0R78VN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataroot /content/drive/MyDrive/dl_viz_rec/train_train_200_img --name train_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final --train_name train_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final --model uni_cycle_gan --display_id -1 --netG NAS --cell_train_start 201 --n_epochs 100 --n_epochs_decay 100 --layer_types ReflectionPad2d_Conv2d+ReLU --n_layers_cell 5 --n_blocks 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDRmpxHB8btS",
        "outputId": "cb200f40-7663-41bc-e50e-b67342a07625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "         cell_train_start: 201                           \t[default: 50]\n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/dl_viz_rec/train_train_200_img\t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: -1                            \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: 10                            \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "              layer_types: ReflectionPad2d_Conv2d+ReLU   \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: uni_cycle_gan                 \t[default: cycle_gan]\n",
            "                 n_blocks: 3                             \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "            n_layers_cell: 5                             \n",
            "                     name: train_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: NAS                           \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "          skip_connection: False                         \n",
            "                   suffix:                               \n",
            "               train_name: train_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final\t[default: no_name]\n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 200\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [UniCycleGANModel] was created\n",
            "create web directory ./checkpoints/train_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 1, iters: 100, time: 0.348, data: 0.783) D_A: 0.328 G_A: 0.362 cycle_A: 1.191 idt_A: 2.075 D_B: 0.153 G_B: 0.567 cycle_B: 3.693 idt_B: 0.628 \n",
            "(epoch: 1, iters: 200, time: 0.320, data: 0.003) D_A: 0.112 G_A: 0.404 cycle_A: 0.946 idt_A: 1.720 D_B: 0.214 G_B: 0.659 cycle_B: 3.359 idt_B: 0.614 \n",
            "End of epoch 1 / 200 \t Time Taken: 68 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.328, data: 0.351) D_A: 0.440 G_A: 0.870 cycle_A: 0.947 idt_A: 2.235 D_B: 0.119 G_B: 0.741 cycle_B: 4.895 idt_B: 0.417 \n",
            "(epoch: 2, iters: 200, time: 0.541, data: 0.001) D_A: 0.296 G_A: 0.618 cycle_A: 1.114 idt_A: 1.091 D_B: 0.224 G_B: 0.593 cycle_B: 2.633 idt_B: 0.599 \n",
            "End of epoch 2 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.309, data: 0.201) D_A: 0.421 G_A: 0.276 cycle_A: 0.650 idt_A: 1.588 D_B: 0.103 G_B: 0.864 cycle_B: 3.361 idt_B: 0.280 \n",
            "(epoch: 3, iters: 200, time: 0.318, data: 0.011) D_A: 0.096 G_A: 0.476 cycle_A: 1.688 idt_A: 1.529 D_B: 0.147 G_B: 1.487 cycle_B: 3.841 idt_B: 1.082 \n",
            "End of epoch 3 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.322, data: 0.231) D_A: 0.061 G_A: 0.456 cycle_A: 0.662 idt_A: 1.016 D_B: 0.098 G_B: 0.518 cycle_B: 2.171 idt_B: 0.389 \n",
            "(epoch: 4, iters: 200, time: 0.587, data: 0.003) D_A: 0.137 G_A: 0.673 cycle_A: 0.916 idt_A: 1.348 D_B: 0.234 G_B: 0.693 cycle_B: 3.056 idt_B: 0.412 \n",
            "End of epoch 4 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.325, data: 0.253) D_A: 0.101 G_A: 0.435 cycle_A: 3.797 idt_A: 1.044 D_B: 0.070 G_B: 0.596 cycle_B: 2.327 idt_B: 1.924 \n",
            "(epoch: 5, iters: 200, time: 0.322, data: 0.002) D_A: 0.128 G_A: 0.258 cycle_A: 0.947 idt_A: 1.376 D_B: 0.138 G_B: 0.814 cycle_B: 2.659 idt_B: 0.318 \n",
            "saving the model at the end of epoch 5, iters 1000\n",
            "End of epoch 5 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.301, data: 0.419) D_A: 0.288 G_A: 0.522 cycle_A: 1.564 idt_A: 1.224 D_B: 0.201 G_B: 0.236 cycle_B: 2.757 idt_B: 0.767 \n",
            "(epoch: 6, iters: 200, time: 0.581, data: 0.003) D_A: 0.078 G_A: 0.378 cycle_A: 0.751 idt_A: 1.477 D_B: 0.233 G_B: 1.192 cycle_B: 3.138 idt_B: 0.366 \n",
            "End of epoch 6 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.321, data: 0.251) D_A: 0.168 G_A: 0.280 cycle_A: 1.149 idt_A: 1.027 D_B: 0.406 G_B: 0.486 cycle_B: 2.536 idt_B: 0.491 \n",
            "(epoch: 7, iters: 200, time: 0.302, data: 0.002) D_A: 0.223 G_A: 0.704 cycle_A: 0.825 idt_A: 1.000 D_B: 0.133 G_B: 0.390 cycle_B: 2.700 idt_B: 0.364 \n",
            "End of epoch 7 / 200 \t Time Taken: 55 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.300, data: 0.236) D_A: 0.143 G_A: 0.647 cycle_A: 0.898 idt_A: 0.828 D_B: 0.316 G_B: 0.302 cycle_B: 1.969 idt_B: 0.385 \n",
            "(epoch: 8, iters: 200, time: 0.668, data: 0.003) D_A: 0.176 G_A: 0.599 cycle_A: 0.893 idt_A: 1.687 D_B: 0.137 G_B: 0.757 cycle_B: 3.260 idt_B: 0.335 \n",
            "End of epoch 8 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.306, data: 0.370) D_A: 0.191 G_A: 0.278 cycle_A: 0.994 idt_A: 1.601 D_B: 0.513 G_B: 0.077 cycle_B: 3.178 idt_B: 0.407 \n",
            "(epoch: 9, iters: 200, time: 0.316, data: 0.003) D_A: 0.074 G_A: 0.766 cycle_A: 0.696 idt_A: 1.210 D_B: 0.065 G_B: 1.371 cycle_B: 3.082 idt_B: 0.288 \n",
            "End of epoch 9 / 200 \t Time Taken: 55 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.323, data: 0.263) D_A: 0.175 G_A: 0.625 cycle_A: 2.356 idt_A: 2.481 D_B: 0.095 G_B: 0.261 cycle_B: 5.168 idt_B: 0.322 \n",
            "(epoch: 10, iters: 200, time: 0.672, data: 0.003) D_A: 0.092 G_A: 0.535 cycle_A: 0.988 idt_A: 1.934 D_B: 0.186 G_B: 0.635 cycle_B: 4.532 idt_B: 0.411 \n",
            "saving the model at the end of epoch 10, iters 2000\n",
            "End of epoch 10 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.326, data: 0.384) D_A: 0.185 G_A: 0.526 cycle_A: 1.036 idt_A: 1.154 D_B: 0.123 G_B: 0.450 cycle_B: 2.686 idt_B: 0.435 \n",
            "(epoch: 11, iters: 200, time: 0.315, data: 0.003) D_A: 0.086 G_A: 0.130 cycle_A: 0.668 idt_A: 1.064 D_B: 0.051 G_B: 0.415 cycle_B: 2.511 idt_B: 0.213 \n",
            "End of epoch 11 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.303, data: 0.227) D_A: 0.159 G_A: 1.079 cycle_A: 1.691 idt_A: 0.881 D_B: 0.070 G_B: 1.695 cycle_B: 2.303 idt_B: 0.761 \n",
            "(epoch: 12, iters: 200, time: 0.693, data: 0.003) D_A: 0.165 G_A: 0.344 cycle_A: 0.801 idt_A: 1.767 D_B: 0.111 G_B: 1.156 cycle_B: 4.386 idt_B: 0.328 \n",
            "End of epoch 12 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.320, data: 0.361) D_A: 0.221 G_A: 0.412 cycle_A: 0.749 idt_A: 0.928 D_B: 0.061 G_B: 1.103 cycle_B: 2.127 idt_B: 0.359 \n",
            "(epoch: 13, iters: 200, time: 0.319, data: 0.003) D_A: 0.214 G_A: 0.512 cycle_A: 1.053 idt_A: 1.759 D_B: 0.093 G_B: 0.580 cycle_B: 4.306 idt_B: 0.488 \n",
            "End of epoch 13 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.322, data: 0.178) D_A: 0.324 G_A: 0.535 cycle_A: 0.472 idt_A: 1.451 D_B: 0.032 G_B: 0.264 cycle_B: 2.904 idt_B: 0.195 \n",
            "(epoch: 14, iters: 200, time: 0.651, data: 0.002) D_A: 0.306 G_A: 0.716 cycle_A: 0.822 idt_A: 1.068 D_B: 0.160 G_B: 0.473 cycle_B: 2.505 idt_B: 0.408 \n",
            "End of epoch 14 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.313, data: 0.318) D_A: 0.193 G_A: 0.459 cycle_A: 0.977 idt_A: 1.038 D_B: 0.136 G_B: 0.299 cycle_B: 2.387 idt_B: 0.433 \n",
            "(epoch: 15, iters: 200, time: 0.294, data: 0.003) D_A: 0.192 G_A: 0.478 cycle_A: 0.452 idt_A: 0.856 D_B: 0.204 G_B: 0.874 cycle_B: 2.117 idt_B: 0.215 \n",
            "saving the model at the end of epoch 15, iters 3000\n",
            "End of epoch 15 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.315, data: 0.246) D_A: 0.208 G_A: 0.736 cycle_A: 0.746 idt_A: 0.909 D_B: 0.267 G_B: 0.377 cycle_B: 2.569 idt_B: 0.247 \n",
            "(epoch: 16, iters: 200, time: 0.599, data: 0.002) D_A: 0.305 G_A: 0.923 cycle_A: 1.671 idt_A: 0.990 D_B: 0.163 G_B: 0.302 cycle_B: 3.176 idt_B: 0.537 \n",
            "End of epoch 16 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.346, data: 0.198) D_A: 0.226 G_A: 0.666 cycle_A: 1.261 idt_A: 1.786 D_B: 0.116 G_B: 0.801 cycle_B: 4.120 idt_B: 0.504 \n",
            "(epoch: 17, iters: 200, time: 0.344, data: 0.003) D_A: 0.141 G_A: 0.645 cycle_A: 1.136 idt_A: 0.960 D_B: 0.078 G_B: 0.628 cycle_B: 2.555 idt_B: 0.359 \n",
            "End of epoch 17 / 200 \t Time Taken: 55 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.322, data: 0.388) D_A: 0.206 G_A: 0.378 cycle_A: 0.809 idt_A: 1.150 D_B: 0.348 G_B: 0.079 cycle_B: 2.298 idt_B: 0.468 \n",
            "(epoch: 18, iters: 200, time: 0.636, data: 0.002) D_A: 0.187 G_A: 0.306 cycle_A: 1.228 idt_A: 0.836 D_B: 0.081 G_B: 0.333 cycle_B: 3.963 idt_B: 0.285 \n",
            "End of epoch 18 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.323, data: 0.274) D_A: 0.253 G_A: 0.244 cycle_A: 0.665 idt_A: 0.788 D_B: 0.500 G_B: 0.512 cycle_B: 1.792 idt_B: 0.294 \n",
            "(epoch: 19, iters: 200, time: 0.334, data: 0.003) D_A: 0.167 G_A: 0.164 cycle_A: 0.621 idt_A: 0.806 D_B: 0.077 G_B: 0.531 cycle_B: 1.934 idt_B: 0.259 \n",
            "End of epoch 19 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.325, data: 0.411) D_A: 0.303 G_A: 0.209 cycle_A: 0.694 idt_A: 1.019 D_B: 0.111 G_B: 0.568 cycle_B: 2.299 idt_B: 0.312 \n",
            "(epoch: 20, iters: 200, time: 0.670, data: 0.003) D_A: 0.286 G_A: 1.054 cycle_A: 0.883 idt_A: 0.990 D_B: 0.083 G_B: 0.510 cycle_B: 2.512 idt_B: 0.486 \n",
            "saving the model at the end of epoch 20, iters 4000\n",
            "End of epoch 20 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.322, data: 0.225) D_A: 0.117 G_A: 0.325 cycle_A: 1.369 idt_A: 1.018 D_B: 0.105 G_B: 0.869 cycle_B: 2.694 idt_B: 0.849 \n",
            "(epoch: 21, iters: 200, time: 0.318, data: 0.003) D_A: 0.406 G_A: 0.135 cycle_A: 1.056 idt_A: 1.000 D_B: 0.164 G_B: 1.420 cycle_B: 2.332 idt_B: 0.687 \n",
            "End of epoch 21 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.334, data: 0.202) D_A: 0.087 G_A: 0.158 cycle_A: 0.445 idt_A: 1.134 D_B: 0.056 G_B: 0.582 cycle_B: 2.492 idt_B: 0.178 \n",
            "(epoch: 22, iters: 200, time: 0.725, data: 0.005) D_A: 0.399 G_A: 0.252 cycle_A: 1.347 idt_A: 1.405 D_B: 0.159 G_B: 0.384 cycle_B: 2.941 idt_B: 0.439 \n",
            "End of epoch 22 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.319, data: 0.309) D_A: 0.124 G_A: 0.120 cycle_A: 0.791 idt_A: 0.824 D_B: 0.236 G_B: 1.114 cycle_B: 1.844 idt_B: 0.252 \n",
            "(epoch: 23, iters: 200, time: 0.320, data: 0.002) D_A: 0.283 G_A: 0.720 cycle_A: 0.904 idt_A: 0.805 D_B: 0.287 G_B: 0.070 cycle_B: 1.902 idt_B: 0.342 \n",
            "End of epoch 23 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.348, data: 0.251) D_A: 0.182 G_A: 0.657 cycle_A: 0.870 idt_A: 1.430 D_B: 0.117 G_B: 0.595 cycle_B: 2.524 idt_B: 0.331 \n",
            "(epoch: 24, iters: 200, time: 0.828, data: 0.005) D_A: 0.194 G_A: 0.250 cycle_A: 1.955 idt_A: 1.123 D_B: 0.089 G_B: 0.499 cycle_B: 2.831 idt_B: 0.661 \n",
            "End of epoch 24 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.325, data: 0.351) D_A: 0.145 G_A: 0.462 cycle_A: 0.684 idt_A: 0.734 D_B: 0.112 G_B: 0.502 cycle_B: 1.963 idt_B: 0.306 \n",
            "(epoch: 25, iters: 200, time: 0.307, data: 0.004) D_A: 0.056 G_A: 0.699 cycle_A: 1.438 idt_A: 0.750 D_B: 0.067 G_B: 0.829 cycle_B: 2.000 idt_B: 0.620 \n",
            "saving the latest model (epoch 25, total_iters 5000)\n",
            "saving the model at the end of epoch 25, iters 5000\n",
            "End of epoch 25 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.320, data: 0.232) D_A: 0.093 G_A: 0.791 cycle_A: 0.942 idt_A: 1.174 D_B: 0.071 G_B: 0.729 cycle_B: 2.910 idt_B: 0.286 \n",
            "(epoch: 26, iters: 200, time: 0.808, data: 0.003) D_A: 0.263 G_A: 0.192 cycle_A: 0.713 idt_A: 1.063 D_B: 0.172 G_B: 0.732 cycle_B: 2.589 idt_B: 0.303 \n",
            "End of epoch 26 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.326, data: 0.378) D_A: 0.101 G_A: 0.704 cycle_A: 1.735 idt_A: 0.978 D_B: 0.166 G_B: 0.241 cycle_B: 2.376 idt_B: 0.971 \n",
            "(epoch: 27, iters: 200, time: 0.318, data: 0.011) D_A: 0.290 G_A: 0.228 cycle_A: 0.925 idt_A: 0.677 D_B: 0.423 G_B: 0.030 cycle_B: 1.787 idt_B: 0.318 \n",
            "End of epoch 27 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.325, data: 0.205) D_A: 0.094 G_A: 0.673 cycle_A: 0.626 idt_A: 1.045 D_B: 0.116 G_B: 1.372 cycle_B: 2.528 idt_B: 0.270 \n",
            "(epoch: 28, iters: 200, time: 0.789, data: 0.003) D_A: 0.179 G_A: 0.316 cycle_A: 0.577 idt_A: 1.148 D_B: 0.155 G_B: 0.335 cycle_B: 2.585 idt_B: 0.260 \n",
            "End of epoch 28 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.331, data: 0.241) D_A: 0.092 G_A: 0.549 cycle_A: 0.903 idt_A: 1.089 D_B: 0.217 G_B: 0.888 cycle_B: 2.482 idt_B: 0.279 \n",
            "(epoch: 29, iters: 200, time: 0.322, data: 0.013) D_A: 0.209 G_A: 0.693 cycle_A: 1.010 idt_A: 0.817 D_B: 0.082 G_B: 0.338 cycle_B: 2.221 idt_B: 0.307 \n",
            "End of epoch 29 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.315, data: 0.195) D_A: 0.423 G_A: 0.118 cycle_A: 0.618 idt_A: 0.751 D_B: 0.539 G_B: 1.526 cycle_B: 1.880 idt_B: 0.213 \n",
            "(epoch: 30, iters: 200, time: 0.738, data: 0.003) D_A: 0.491 G_A: 0.041 cycle_A: 0.961 idt_A: 1.337 D_B: 0.378 G_B: 1.375 cycle_B: 2.793 idt_B: 0.296 \n",
            "saving the model at the end of epoch 30, iters 6000\n",
            "End of epoch 30 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.316, data: 0.217) D_A: 0.202 G_A: 0.219 cycle_A: 0.705 idt_A: 1.039 D_B: 0.349 G_B: 0.264 cycle_B: 2.557 idt_B: 0.247 \n",
            "(epoch: 31, iters: 200, time: 0.340, data: 0.012) D_A: 0.216 G_A: 0.458 cycle_A: 0.793 idt_A: 1.178 D_B: 0.083 G_B: 0.291 cycle_B: 2.620 idt_B: 0.316 \n",
            "End of epoch 31 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.324, data: 0.406) D_A: 0.212 G_A: 0.227 cycle_A: 0.714 idt_A: 0.778 D_B: 0.219 G_B: 0.368 cycle_B: 2.158 idt_B: 0.293 \n",
            "(epoch: 32, iters: 200, time: 0.743, data: 0.003) D_A: 0.209 G_A: 0.444 cycle_A: 0.551 idt_A: 0.983 D_B: 0.111 G_B: 0.642 cycle_B: 2.625 idt_B: 0.139 \n",
            "End of epoch 32 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.301, data: 0.229) D_A: 0.129 G_A: 0.428 cycle_A: 0.854 idt_A: 0.851 D_B: 0.035 G_B: 0.817 cycle_B: 2.112 idt_B: 0.435 \n",
            "(epoch: 33, iters: 200, time: 0.326, data: 0.003) D_A: 0.157 G_A: 0.426 cycle_A: 2.003 idt_A: 1.153 D_B: 0.214 G_B: 0.846 cycle_B: 2.548 idt_B: 0.993 \n",
            "End of epoch 33 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.318, data: 0.296) D_A: 0.393 G_A: 1.195 cycle_A: 0.820 idt_A: 1.076 D_B: 0.121 G_B: 0.314 cycle_B: 2.543 idt_B: 0.347 \n",
            "(epoch: 34, iters: 200, time: 0.766, data: 0.003) D_A: 0.150 G_A: 0.285 cycle_A: 1.495 idt_A: 1.318 D_B: 0.337 G_B: 0.092 cycle_B: 2.750 idt_B: 0.594 \n",
            "End of epoch 34 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.321, data: 0.276) D_A: 0.246 G_A: 0.456 cycle_A: 0.510 idt_A: 0.554 D_B: 0.139 G_B: 0.835 cycle_B: 2.046 idt_B: 0.168 \n",
            "(epoch: 35, iters: 200, time: 0.332, data: 0.003) D_A: 0.343 G_A: 0.826 cycle_A: 0.834 idt_A: 1.085 D_B: 0.079 G_B: 0.763 cycle_B: 2.668 idt_B: 0.294 \n",
            "saving the model at the end of epoch 35, iters 7000\n",
            "End of epoch 35 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.315, data: 0.362) D_A: 0.115 G_A: 0.374 cycle_A: 0.592 idt_A: 0.754 D_B: 0.118 G_B: 1.982 cycle_B: 2.216 idt_B: 0.224 \n",
            "(epoch: 36, iters: 200, time: 0.758, data: 0.010) D_A: 0.117 G_A: 0.246 cycle_A: 0.786 idt_A: 0.785 D_B: 0.398 G_B: 0.093 cycle_B: 1.909 idt_B: 0.250 \n",
            "End of epoch 36 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.319, data: 0.287) D_A: 0.236 G_A: 0.303 cycle_A: 0.726 idt_A: 0.907 D_B: 0.039 G_B: 0.577 cycle_B: 2.058 idt_B: 0.269 \n",
            "(epoch: 37, iters: 200, time: 0.322, data: 0.003) D_A: 0.423 G_A: 0.190 cycle_A: 0.794 idt_A: 1.100 D_B: 0.101 G_B: 1.599 cycle_B: 2.716 idt_B: 0.268 \n",
            "End of epoch 37 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.336, data: 0.244) D_A: 0.071 G_A: 0.695 cycle_A: 0.771 idt_A: 1.186 D_B: 0.222 G_B: 0.193 cycle_B: 2.326 idt_B: 0.293 \n",
            "(epoch: 38, iters: 200, time: 0.794, data: 0.010) D_A: 0.153 G_A: 0.695 cycle_A: 0.710 idt_A: 0.656 D_B: 0.042 G_B: 0.329 cycle_B: 1.701 idt_B: 0.181 \n",
            "End of epoch 38 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.321, data: 0.371) D_A: 0.069 G_A: 0.574 cycle_A: 0.985 idt_A: 0.669 D_B: 0.162 G_B: 1.793 cycle_B: 2.167 idt_B: 0.482 \n",
            "(epoch: 39, iters: 200, time: 0.317, data: 0.003) D_A: 0.142 G_A: 0.536 cycle_A: 0.493 idt_A: 1.120 D_B: 0.093 G_B: 0.500 cycle_B: 2.496 idt_B: 0.208 \n",
            "End of epoch 39 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.316, data: 0.269) D_A: 0.132 G_A: 0.517 cycle_A: 1.141 idt_A: 0.760 D_B: 0.115 G_B: 0.672 cycle_B: 2.652 idt_B: 0.477 \n",
            "(epoch: 40, iters: 200, time: 0.897, data: 0.004) D_A: 0.212 G_A: 0.555 cycle_A: 0.729 idt_A: 0.934 D_B: 0.067 G_B: 0.048 cycle_B: 2.188 idt_B: 0.299 \n",
            "saving the model at the end of epoch 40, iters 8000\n",
            "End of epoch 40 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.327, data: 0.418) D_A: 0.276 G_A: 0.202 cycle_A: 1.109 idt_A: 0.660 D_B: 0.079 G_B: 0.363 cycle_B: 1.555 idt_B: 0.464 \n",
            "(epoch: 41, iters: 200, time: 0.318, data: 0.002) D_A: 0.027 G_A: 0.433 cycle_A: 0.722 idt_A: 0.653 D_B: 0.122 G_B: 0.442 cycle_B: 1.674 idt_B: 0.316 \n",
            "End of epoch 41 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.323, data: 0.282) D_A: 0.176 G_A: 0.324 cycle_A: 0.742 idt_A: 1.043 D_B: 0.115 G_B: 0.680 cycle_B: 2.466 idt_B: 0.238 \n",
            "(epoch: 42, iters: 200, time: 0.947, data: 0.003) D_A: 0.191 G_A: 0.658 cycle_A: 0.651 idt_A: 1.248 D_B: 0.091 G_B: 0.699 cycle_B: 2.695 idt_B: 0.276 \n",
            "End of epoch 42 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.338, data: 0.220) D_A: 0.153 G_A: 0.569 cycle_A: 0.743 idt_A: 0.883 D_B: 0.050 G_B: 0.427 cycle_B: 2.017 idt_B: 0.328 \n",
            "(epoch: 43, iters: 200, time: 0.316, data: 0.014) D_A: 0.107 G_A: 0.498 cycle_A: 0.553 idt_A: 0.974 D_B: 0.092 G_B: 0.835 cycle_B: 2.467 idt_B: 0.175 \n",
            "End of epoch 43 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.325, data: 0.243) D_A: 0.285 G_A: 0.329 cycle_A: 0.694 idt_A: 1.056 D_B: 0.177 G_B: 0.393 cycle_B: 2.704 idt_B: 0.321 \n",
            "(epoch: 44, iters: 200, time: 0.823, data: 0.003) D_A: 0.217 G_A: 0.225 cycle_A: 0.694 idt_A: 0.779 D_B: 0.225 G_B: 1.683 cycle_B: 1.927 idt_B: 0.262 \n",
            "End of epoch 44 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.309, data: 0.260) D_A: 0.078 G_A: 0.589 cycle_A: 0.357 idt_A: 1.176 D_B: 0.201 G_B: 0.790 cycle_B: 2.463 idt_B: 0.148 \n",
            "(epoch: 45, iters: 200, time: 0.335, data: 0.012) D_A: 0.157 G_A: 0.814 cycle_A: 0.987 idt_A: 1.006 D_B: 0.130 G_B: 0.483 cycle_B: 2.527 idt_B: 0.240 \n",
            "saving the model at the end of epoch 45, iters 9000\n",
            "End of epoch 45 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.331, data: 0.380) D_A: 0.141 G_A: 0.442 cycle_A: 0.675 idt_A: 0.526 D_B: 0.228 G_B: 0.413 cycle_B: 1.609 idt_B: 0.281 \n",
            "(epoch: 46, iters: 200, time: 0.835, data: 0.002) D_A: 0.390 G_A: 0.075 cycle_A: 1.570 idt_A: 1.296 D_B: 0.068 G_B: 1.113 cycle_B: 2.979 idt_B: 0.456 \n",
            "End of epoch 46 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.321, data: 0.336) D_A: 0.171 G_A: 0.332 cycle_A: 0.684 idt_A: 0.666 D_B: 0.161 G_B: 1.136 cycle_B: 1.723 idt_B: 0.207 \n",
            "(epoch: 47, iters: 200, time: 0.335, data: 0.003) D_A: 0.052 G_A: 0.645 cycle_A: 1.429 idt_A: 0.952 D_B: 0.162 G_B: 0.331 cycle_B: 2.266 idt_B: 0.601 \n",
            "End of epoch 47 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 0.318, data: 0.375) D_A: 0.149 G_A: 0.637 cycle_A: 0.826 idt_A: 0.767 D_B: 0.073 G_B: 0.600 cycle_B: 1.838 idt_B: 0.328 \n",
            "(epoch: 48, iters: 200, time: 0.873, data: 0.012) D_A: 0.176 G_A: 0.884 cycle_A: 0.606 idt_A: 0.649 D_B: 0.030 G_B: 0.410 cycle_B: 1.478 idt_B: 0.288 \n",
            "End of epoch 48 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.337, data: 0.246) D_A: 0.048 G_A: 0.477 cycle_A: 0.699 idt_A: 0.835 D_B: 0.139 G_B: 0.959 cycle_B: 1.953 idt_B: 0.282 \n",
            "(epoch: 49, iters: 200, time: 0.338, data: 0.003) D_A: 0.149 G_A: 0.365 cycle_A: 1.534 idt_A: 0.587 D_B: 0.084 G_B: 0.761 cycle_B: 1.126 idt_B: 0.555 \n",
            "End of epoch 49 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.330, data: 0.276) D_A: 0.299 G_A: 0.097 cycle_A: 0.513 idt_A: 1.918 D_B: 0.132 G_B: 0.723 cycle_B: 3.659 idt_B: 0.199 \n",
            "(epoch: 50, iters: 200, time: 1.116, data: 0.004) D_A: 0.216 G_A: 0.257 cycle_A: 0.589 idt_A: 0.546 D_B: 0.155 G_B: 0.615 cycle_B: 1.525 idt_B: 0.254 \n",
            "saving the latest model (epoch 50, total_iters 10000)\n",
            "saving the model at the end of epoch 50, iters 10000\n",
            "End of epoch 50 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.315, data: 0.322) D_A: 0.345 G_A: 0.223 cycle_A: 1.261 idt_A: 0.557 D_B: 0.204 G_B: 0.449 cycle_B: 1.570 idt_B: 0.534 \n",
            "(epoch: 51, iters: 200, time: 0.315, data: 0.003) D_A: 0.064 G_A: 0.160 cycle_A: 0.568 idt_A: 0.550 D_B: 0.128 G_B: 1.004 cycle_B: 2.010 idt_B: 0.233 \n",
            "End of epoch 51 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 0.320, data: 0.419) D_A: 0.126 G_A: 0.997 cycle_A: 0.978 idt_A: 1.229 D_B: 0.084 G_B: 0.535 cycle_B: 2.768 idt_B: 0.550 \n",
            "(epoch: 52, iters: 200, time: 1.014, data: 0.004) D_A: 0.207 G_A: 0.827 cycle_A: 0.806 idt_A: 0.533 D_B: 0.078 G_B: 0.701 cycle_B: 1.654 idt_B: 0.359 \n",
            "End of epoch 52 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.320, data: 0.342) D_A: 0.122 G_A: 0.606 cycle_A: 0.627 idt_A: 0.778 D_B: 0.097 G_B: 0.396 cycle_B: 1.801 idt_B: 0.229 \n",
            "(epoch: 53, iters: 200, time: 0.319, data: 0.003) D_A: 0.076 G_A: 0.403 cycle_A: 0.782 idt_A: 0.899 D_B: 0.076 G_B: 0.520 cycle_B: 2.084 idt_B: 0.334 \n",
            "End of epoch 53 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.315, data: 0.271) D_A: 0.127 G_A: 0.420 cycle_A: 0.621 idt_A: 0.903 D_B: 0.143 G_B: 0.483 cycle_B: 2.075 idt_B: 0.269 \n",
            "(epoch: 54, iters: 200, time: 1.022, data: 0.002) D_A: 0.180 G_A: 0.261 cycle_A: 0.982 idt_A: 0.738 D_B: 0.123 G_B: 0.446 cycle_B: 1.910 idt_B: 0.448 \n",
            "End of epoch 54 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.333, data: 0.361) D_A: 0.041 G_A: 0.462 cycle_A: 1.102 idt_A: 1.043 D_B: 0.169 G_B: 0.730 cycle_B: 2.333 idt_B: 0.440 \n",
            "(epoch: 55, iters: 200, time: 0.323, data: 0.013) D_A: 0.173 G_A: 0.745 cycle_A: 1.137 idt_A: 0.683 D_B: 0.117 G_B: 0.384 cycle_B: 1.744 idt_B: 0.490 \n",
            "saving the model at the end of epoch 55, iters 11000\n",
            "End of epoch 55 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 100, time: 0.315, data: 0.220) D_A: 0.098 G_A: 0.560 cycle_A: 1.186 idt_A: 1.213 D_B: 0.214 G_B: 0.631 cycle_B: 2.517 idt_B: 0.533 \n",
            "(epoch: 56, iters: 200, time: 0.995, data: 0.003) D_A: 0.095 G_A: 0.198 cycle_A: 0.993 idt_A: 0.762 D_B: 0.206 G_B: 0.622 cycle_B: 2.065 idt_B: 0.307 \n",
            "End of epoch 56 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.315, data: 0.270) D_A: 0.147 G_A: 0.469 cycle_A: 0.579 idt_A: 1.034 D_B: 0.056 G_B: 1.014 cycle_B: 2.508 idt_B: 0.258 \n",
            "(epoch: 57, iters: 200, time: 0.319, data: 0.013) D_A: 0.052 G_A: 0.677 cycle_A: 0.650 idt_A: 0.729 D_B: 0.092 G_B: 0.744 cycle_B: 1.548 idt_B: 0.280 \n",
            "End of epoch 57 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.319, data: 0.261) D_A: 0.168 G_A: 0.537 cycle_A: 0.608 idt_A: 0.773 D_B: 0.073 G_B: 0.695 cycle_B: 1.638 idt_B: 0.184 \n",
            "(epoch: 58, iters: 200, time: 0.890, data: 0.003) D_A: 0.273 G_A: 0.233 cycle_A: 0.944 idt_A: 0.872 D_B: 0.073 G_B: 0.188 cycle_B: 2.149 idt_B: 0.323 \n",
            "End of epoch 58 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.327, data: 0.221) D_A: 0.215 G_A: 0.611 cycle_A: 0.818 idt_A: 1.132 D_B: 0.174 G_B: 0.356 cycle_B: 2.594 idt_B: 0.435 \n",
            "(epoch: 59, iters: 200, time: 0.319, data: 0.002) D_A: 0.356 G_A: 0.064 cycle_A: 0.883 idt_A: 0.796 D_B: 0.085 G_B: 0.529 cycle_B: 2.487 idt_B: 0.235 \n",
            "End of epoch 59 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.313, data: 0.234) D_A: 0.161 G_A: 0.315 cycle_A: 0.875 idt_A: 0.573 D_B: 0.102 G_B: 0.431 cycle_B: 1.342 idt_B: 0.212 \n",
            "(epoch: 60, iters: 200, time: 0.882, data: 0.003) D_A: 0.290 G_A: 0.106 cycle_A: 0.741 idt_A: 0.938 D_B: 0.203 G_B: 0.641 cycle_B: 2.099 idt_B: 0.148 \n",
            "saving the model at the end of epoch 60, iters 12000\n",
            "End of epoch 60 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.310, data: 0.271) D_A: 0.248 G_A: 0.192 cycle_A: 0.523 idt_A: 0.849 D_B: 0.137 G_B: 0.345 cycle_B: 2.160 idt_B: 0.196 \n",
            "(epoch: 61, iters: 200, time: 0.323, data: 0.003) D_A: 0.293 G_A: 0.192 cycle_A: 1.357 idt_A: 0.889 D_B: 0.201 G_B: 0.931 cycle_B: 2.020 idt_B: 0.555 \n",
            "End of epoch 61 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.318, data: 0.328) D_A: 0.036 G_A: 0.318 cycle_A: 0.693 idt_A: 0.885 D_B: 0.053 G_B: 0.316 cycle_B: 2.097 idt_B: 0.241 \n",
            "(epoch: 62, iters: 200, time: 1.128, data: 0.003) D_A: 0.228 G_A: 0.665 cycle_A: 0.690 idt_A: 1.030 D_B: 0.153 G_B: 0.321 cycle_B: 2.254 idt_B: 0.319 \n",
            "End of epoch 62 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.319, data: 0.270) D_A: 0.217 G_A: 0.284 cycle_A: 0.863 idt_A: 1.610 D_B: 0.103 G_B: 0.743 cycle_B: 3.055 idt_B: 0.345 \n",
            "(epoch: 63, iters: 200, time: 0.336, data: 0.003) D_A: 0.067 G_A: 0.963 cycle_A: 1.440 idt_A: 0.689 D_B: 0.074 G_B: 1.033 cycle_B: 1.844 idt_B: 0.521 \n",
            "End of epoch 63 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 100, time: 0.336, data: 0.351) D_A: 0.110 G_A: 0.680 cycle_A: 1.034 idt_A: 0.852 D_B: 0.205 G_B: 0.275 cycle_B: 2.016 idt_B: 0.397 \n",
            "(epoch: 64, iters: 200, time: 0.946, data: 0.013) D_A: 0.043 G_A: 1.158 cycle_A: 0.718 idt_A: 0.930 D_B: 0.074 G_B: 1.812 cycle_B: 2.754 idt_B: 0.304 \n",
            "End of epoch 64 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.313, data: 0.212) D_A: 0.041 G_A: 0.412 cycle_A: 0.538 idt_A: 0.769 D_B: 0.072 G_B: 1.084 cycle_B: 2.083 idt_B: 0.174 \n",
            "(epoch: 65, iters: 200, time: 0.321, data: 0.003) D_A: 0.065 G_A: 0.744 cycle_A: 0.520 idt_A: 0.928 D_B: 0.066 G_B: 0.942 cycle_B: 2.827 idt_B: 0.195 \n",
            "saving the model at the end of epoch 65, iters 13000\n",
            "End of epoch 65 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.316, data: 0.252) D_A: 0.119 G_A: 1.186 cycle_A: 1.080 idt_A: 0.646 D_B: 0.226 G_B: 0.229 cycle_B: 1.802 idt_B: 0.237 \n",
            "(epoch: 66, iters: 200, time: 0.933, data: 0.002) D_A: 0.296 G_A: 0.265 cycle_A: 0.590 idt_A: 0.680 D_B: 0.117 G_B: 0.738 cycle_B: 1.645 idt_B: 0.226 \n",
            "End of epoch 66 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.301, data: 0.261) D_A: 0.168 G_A: 0.244 cycle_A: 0.892 idt_A: 1.440 D_B: 0.222 G_B: 1.113 cycle_B: 3.270 idt_B: 0.253 \n",
            "(epoch: 67, iters: 200, time: 0.291, data: 0.003) D_A: 0.158 G_A: 0.267 cycle_A: 0.682 idt_A: 0.739 D_B: 0.115 G_B: 0.951 cycle_B: 1.785 idt_B: 0.267 \n",
            "End of epoch 67 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 100, time: 0.299, data: 0.204) D_A: 0.214 G_A: 0.217 cycle_A: 1.407 idt_A: 0.857 D_B: 0.192 G_B: 1.260 cycle_B: 2.154 idt_B: 0.373 \n",
            "(epoch: 68, iters: 200, time: 1.119, data: 0.003) D_A: 0.040 G_A: 0.862 cycle_A: 0.444 idt_A: 0.668 D_B: 0.151 G_B: 0.426 cycle_B: 1.652 idt_B: 0.175 \n",
            "End of epoch 68 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.297, data: 0.389) D_A: 0.038 G_A: 0.572 cycle_A: 0.863 idt_A: 0.640 D_B: 0.261 G_B: 1.366 cycle_B: 1.629 idt_B: 0.323 \n",
            "(epoch: 69, iters: 200, time: 0.298, data: 0.003) D_A: 0.165 G_A: 0.326 cycle_A: 0.614 idt_A: 0.594 D_B: 0.040 G_B: 0.193 cycle_B: 1.484 idt_B: 0.208 \n",
            "End of epoch 69 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.297, data: 0.359) D_A: 0.122 G_A: 0.647 cycle_A: 0.779 idt_A: 0.828 D_B: 0.153 G_B: 0.455 cycle_B: 2.245 idt_B: 0.276 \n",
            "(epoch: 70, iters: 200, time: 0.963, data: 0.003) D_A: 0.048 G_A: 0.659 cycle_A: 1.168 idt_A: 1.160 D_B: 0.097 G_B: 1.127 cycle_B: 2.611 idt_B: 0.482 \n",
            "saving the model at the end of epoch 70, iters 14000\n",
            "End of epoch 70 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.319, data: 0.255) D_A: 0.112 G_A: 0.628 cycle_A: 0.722 idt_A: 0.598 D_B: 0.100 G_B: 0.583 cycle_B: 1.568 idt_B: 0.281 \n",
            "(epoch: 71, iters: 200, time: 0.330, data: 0.003) D_A: 0.065 G_A: 0.785 cycle_A: 1.110 idt_A: 0.843 D_B: 0.332 G_B: 0.282 cycle_B: 1.938 idt_B: 0.420 \n",
            "End of epoch 71 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 100, time: 0.333, data: 0.474) D_A: 0.152 G_A: 0.755 cycle_A: 0.821 idt_A: 0.786 D_B: 0.075 G_B: 0.501 cycle_B: 2.946 idt_B: 0.210 \n",
            "(epoch: 72, iters: 200, time: 1.187, data: 0.013) D_A: 0.201 G_A: 0.745 cycle_A: 0.883 idt_A: 0.733 D_B: 0.045 G_B: 1.102 cycle_B: 2.047 idt_B: 0.394 \n",
            "End of epoch 72 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.317, data: 0.258) D_A: 0.072 G_A: 0.456 cycle_A: 0.984 idt_A: 1.074 D_B: 0.150 G_B: 1.843 cycle_B: 2.366 idt_B: 0.416 \n",
            "(epoch: 73, iters: 200, time: 0.325, data: 0.003) D_A: 0.081 G_A: 0.481 cycle_A: 1.943 idt_A: 0.615 D_B: 0.081 G_B: 0.961 cycle_B: 1.393 idt_B: 0.753 \n",
            "End of epoch 73 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.328, data: 0.339) D_A: 0.111 G_A: 0.299 cycle_A: 1.073 idt_A: 0.770 D_B: 0.096 G_B: 0.823 cycle_B: 2.127 idt_B: 0.529 \n",
            "(epoch: 74, iters: 200, time: 1.043, data: 0.002) D_A: 0.158 G_A: 0.261 cycle_A: 0.703 idt_A: 0.883 D_B: 0.078 G_B: 0.155 cycle_B: 1.903 idt_B: 0.215 \n",
            "End of epoch 74 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.320, data: 0.274) D_A: 0.342 G_A: 0.672 cycle_A: 0.761 idt_A: 0.760 D_B: 0.260 G_B: 0.339 cycle_B: 1.970 idt_B: 0.303 \n",
            "(epoch: 75, iters: 200, time: 0.323, data: 0.003) D_A: 0.149 G_A: 0.653 cycle_A: 1.011 idt_A: 0.976 D_B: 0.188 G_B: 0.271 cycle_B: 2.044 idt_B: 0.324 \n",
            "saving the latest model (epoch 75, total_iters 15000)\n",
            "saving the model at the end of epoch 75, iters 15000\n",
            "End of epoch 75 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 76, iters: 100, time: 0.342, data: 0.225) D_A: 0.041 G_A: 0.428 cycle_A: 1.203 idt_A: 0.890 D_B: 0.074 G_B: 0.886 cycle_B: 2.017 idt_B: 0.465 \n",
            "(epoch: 76, iters: 200, time: 1.161, data: 0.002) D_A: 0.057 G_A: 0.940 cycle_A: 0.639 idt_A: 1.131 D_B: 0.068 G_B: 0.739 cycle_B: 2.521 idt_B: 0.235 \n",
            "End of epoch 76 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.318, data: 0.322) D_A: 0.045 G_A: 0.647 cycle_A: 1.815 idt_A: 0.883 D_B: 0.066 G_B: 0.517 cycle_B: 2.335 idt_B: 0.880 \n",
            "(epoch: 77, iters: 200, time: 0.321, data: 0.003) D_A: 0.117 G_A: 0.396 cycle_A: 1.090 idt_A: 0.645 D_B: 0.107 G_B: 0.257 cycle_B: 1.845 idt_B: 0.337 \n",
            "End of epoch 77 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.320, data: 0.280) D_A: 0.096 G_A: 0.432 cycle_A: 0.756 idt_A: 0.616 D_B: 0.116 G_B: 0.510 cycle_B: 2.252 idt_B: 0.253 \n",
            "(epoch: 78, iters: 200, time: 1.174, data: 0.003) D_A: 0.367 G_A: 0.549 cycle_A: 0.488 idt_A: 0.704 D_B: 0.455 G_B: 0.031 cycle_B: 1.962 idt_B: 0.194 \n",
            "End of epoch 78 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.338, data: 0.354) D_A: 0.139 G_A: 0.179 cycle_A: 0.559 idt_A: 0.872 D_B: 0.065 G_B: 0.525 cycle_B: 2.099 idt_B: 0.230 \n",
            "(epoch: 79, iters: 200, time: 0.318, data: 0.013) D_A: 0.133 G_A: 0.594 cycle_A: 0.677 idt_A: 0.816 D_B: 0.156 G_B: 0.686 cycle_B: 1.831 idt_B: 0.258 \n",
            "End of epoch 79 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 100, time: 0.321, data: 0.196) D_A: 0.134 G_A: 0.412 cycle_A: 0.503 idt_A: 0.910 D_B: 0.283 G_B: 0.836 cycle_B: 1.954 idt_B: 0.209 \n",
            "(epoch: 80, iters: 200, time: 1.552, data: 0.003) D_A: 0.188 G_A: 0.393 cycle_A: 0.608 idt_A: 0.659 D_B: 0.083 G_B: 1.274 cycle_B: 1.525 idt_B: 0.227 \n",
            "saving the model at the end of epoch 80, iters 16000\n",
            "End of epoch 80 / 200 \t Time Taken: 60 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.332, data: 0.222) D_A: 0.206 G_A: 0.259 cycle_A: 0.595 idt_A: 1.370 D_B: 0.110 G_B: 1.493 cycle_B: 2.682 idt_B: 0.199 \n",
            "(epoch: 81, iters: 200, time: 0.324, data: 0.011) D_A: 0.201 G_A: 0.444 cycle_A: 0.650 idt_A: 0.645 D_B: 0.216 G_B: 0.198 cycle_B: 1.511 idt_B: 0.291 \n",
            "End of epoch 81 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.320, data: 0.217) D_A: 0.137 G_A: 0.370 cycle_A: 0.629 idt_A: 1.406 D_B: 0.029 G_B: 0.872 cycle_B: 2.574 idt_B: 0.294 \n",
            "(epoch: 82, iters: 200, time: 1.109, data: 0.003) D_A: 0.103 G_A: 0.339 cycle_A: 0.818 idt_A: 0.855 D_B: 0.167 G_B: 0.613 cycle_B: 1.842 idt_B: 0.395 \n",
            "End of epoch 82 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.332, data: 0.263) D_A: 0.301 G_A: 0.833 cycle_A: 0.734 idt_A: 0.920 D_B: 0.161 G_B: 0.268 cycle_B: 2.267 idt_B: 0.224 \n",
            "(epoch: 83, iters: 200, time: 0.353, data: 0.002) D_A: 0.068 G_A: 0.322 cycle_A: 1.043 idt_A: 0.633 D_B: 0.032 G_B: 1.191 cycle_B: 1.467 idt_B: 0.446 \n",
            "End of epoch 83 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 84, iters: 100, time: 0.319, data: 0.390) D_A: 0.170 G_A: 0.292 cycle_A: 1.301 idt_A: 1.070 D_B: 0.129 G_B: 1.143 cycle_B: 2.264 idt_B: 0.279 \n",
            "(epoch: 84, iters: 200, time: 1.108, data: 0.003) D_A: 0.096 G_A: 0.424 cycle_A: 0.902 idt_A: 1.017 D_B: 0.123 G_B: 0.541 cycle_B: 2.120 idt_B: 0.374 \n",
            "End of epoch 84 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.328, data: 0.230) D_A: 0.173 G_A: 0.907 cycle_A: 0.477 idt_A: 0.813 D_B: 0.200 G_B: 0.734 cycle_B: 1.877 idt_B: 0.187 \n",
            "(epoch: 85, iters: 200, time: 0.328, data: 0.003) D_A: 0.107 G_A: 0.417 cycle_A: 0.715 idt_A: 0.689 D_B: 0.210 G_B: 0.208 cycle_B: 1.669 idt_B: 0.412 \n",
            "saving the model at the end of epoch 85, iters 17000\n",
            "End of epoch 85 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.310, data: 0.433) D_A: 0.117 G_A: 0.625 cycle_A: 0.701 idt_A: 0.852 D_B: 0.175 G_B: 1.570 cycle_B: 1.889 idt_B: 0.228 \n",
            "(epoch: 86, iters: 200, time: 1.070, data: 0.011) D_A: 0.122 G_A: 0.947 cycle_A: 0.744 idt_A: 1.067 D_B: 0.164 G_B: 0.262 cycle_B: 2.491 idt_B: 0.311 \n",
            "End of epoch 86 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.317, data: 0.419) D_A: 0.160 G_A: 0.232 cycle_A: 0.541 idt_A: 0.974 D_B: 0.321 G_B: 1.116 cycle_B: 2.183 idt_B: 0.181 \n",
            "(epoch: 87, iters: 200, time: 0.324, data: 0.003) D_A: 0.093 G_A: 0.329 cycle_A: 0.533 idt_A: 1.039 D_B: 0.100 G_B: 0.814 cycle_B: 2.391 idt_B: 0.160 \n",
            "End of epoch 87 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 100, time: 0.325, data: 0.373) D_A: 0.088 G_A: 0.958 cycle_A: 0.760 idt_A: 0.967 D_B: 0.203 G_B: 0.712 cycle_B: 2.261 idt_B: 0.321 \n",
            "(epoch: 88, iters: 200, time: 1.335, data: 0.011) D_A: 0.161 G_A: 0.377 cycle_A: 0.646 idt_A: 0.871 D_B: 0.172 G_B: 0.671 cycle_B: 2.099 idt_B: 0.295 \n",
            "End of epoch 88 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.319, data: 0.235) D_A: 0.068 G_A: 0.585 cycle_A: 1.860 idt_A: 0.908 D_B: 0.194 G_B: 0.469 cycle_B: 2.098 idt_B: 0.784 \n",
            "(epoch: 89, iters: 200, time: 0.331, data: 0.003) D_A: 0.067 G_A: 0.574 cycle_A: 0.433 idt_A: 0.835 D_B: 0.039 G_B: 0.383 cycle_B: 2.102 idt_B: 0.159 \n",
            "End of epoch 89 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.340, data: 0.269) D_A: 0.038 G_A: 0.264 cycle_A: 0.949 idt_A: 0.879 D_B: 0.048 G_B: 0.761 cycle_B: 2.023 idt_B: 0.302 \n",
            "(epoch: 90, iters: 200, time: 1.171, data: 0.002) D_A: 0.049 G_A: 0.172 cycle_A: 0.641 idt_A: 0.687 D_B: 0.042 G_B: 1.180 cycle_B: 1.631 idt_B: 0.304 \n",
            "saving the model at the end of epoch 90, iters 18000\n",
            "End of epoch 90 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.293, data: 0.433) D_A: 0.138 G_A: 0.364 cycle_A: 0.620 idt_A: 0.905 D_B: 0.051 G_B: 0.714 cycle_B: 2.106 idt_B: 0.214 \n",
            "(epoch: 91, iters: 200, time: 0.297, data: 0.003) D_A: 0.174 G_A: 0.315 cycle_A: 0.452 idt_A: 0.839 D_B: 0.107 G_B: 0.464 cycle_B: 2.106 idt_B: 0.202 \n",
            "End of epoch 91 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 92, iters: 100, time: 0.292, data: 0.375) D_A: 0.284 G_A: 1.248 cycle_A: 0.413 idt_A: 0.984 D_B: 0.210 G_B: 0.250 cycle_B: 2.248 idt_B: 0.109 \n",
            "(epoch: 92, iters: 200, time: 1.144, data: 0.003) D_A: 0.164 G_A: 0.878 cycle_A: 0.430 idt_A: 0.743 D_B: 0.166 G_B: 0.682 cycle_B: 1.649 idt_B: 0.227 \n",
            "End of epoch 92 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.305, data: 0.252) D_A: 0.199 G_A: 0.251 cycle_A: 0.539 idt_A: 1.094 D_B: 1.824 G_B: 2.230 cycle_B: 2.274 idt_B: 0.198 \n",
            "(epoch: 93, iters: 200, time: 0.296, data: 0.003) D_A: 0.151 G_A: 0.559 cycle_A: 0.594 idt_A: 1.073 D_B: 0.163 G_B: 0.296 cycle_B: 2.125 idt_B: 0.267 \n",
            "End of epoch 93 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.292, data: 0.273) D_A: 0.047 G_A: 0.462 cycle_A: 0.577 idt_A: 1.187 D_B: 0.075 G_B: 0.617 cycle_B: 1.533 idt_B: 0.235 \n",
            "(epoch: 94, iters: 200, time: 1.129, data: 0.011) D_A: 0.113 G_A: 0.470 cycle_A: 0.903 idt_A: 0.992 D_B: 0.151 G_B: 0.624 cycle_B: 2.454 idt_B: 0.217 \n",
            "End of epoch 94 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.292, data: 0.265) D_A: 0.131 G_A: 0.255 cycle_A: 0.662 idt_A: 0.741 D_B: 0.075 G_B: 0.555 cycle_B: 1.833 idt_B: 0.289 \n",
            "(epoch: 95, iters: 200, time: 0.294, data: 0.003) D_A: 0.149 G_A: 0.337 cycle_A: 0.555 idt_A: 0.953 D_B: 0.197 G_B: 0.345 cycle_B: 2.212 idt_B: 0.150 \n",
            "saving the model at the end of epoch 95, iters 19000\n",
            "End of epoch 95 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 100, time: 0.289, data: 0.440) D_A: 0.117 G_A: 0.176 cycle_A: 1.753 idt_A: 0.613 D_B: 0.126 G_B: 0.544 cycle_B: 1.656 idt_B: 0.787 \n",
            "(epoch: 96, iters: 200, time: 1.600, data: 0.003) D_A: 0.146 G_A: 0.432 cycle_A: 2.355 idt_A: 0.821 D_B: 0.068 G_B: 0.665 cycle_B: 1.653 idt_B: 1.040 \n",
            "End of epoch 96 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.292, data: 0.413) D_A: 0.293 G_A: 0.091 cycle_A: 0.445 idt_A: 0.771 D_B: 0.145 G_B: 0.349 cycle_B: 1.959 idt_B: 0.182 \n",
            "(epoch: 97, iters: 200, time: 0.292, data: 0.003) D_A: 0.175 G_A: 0.456 cycle_A: 2.263 idt_A: 1.119 D_B: 0.053 G_B: 0.385 cycle_B: 2.451 idt_B: 1.250 \n",
            "End of epoch 97 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.307, data: 0.239) D_A: 0.030 G_A: 0.371 cycle_A: 0.463 idt_A: 0.488 D_B: 0.326 G_B: 1.279 cycle_B: 1.117 idt_B: 0.191 \n",
            "(epoch: 98, iters: 200, time: 1.174, data: 0.002) D_A: 0.048 G_A: 1.190 cycle_A: 0.933 idt_A: 0.901 D_B: 0.055 G_B: 0.665 cycle_B: 2.391 idt_B: 0.294 \n",
            "End of epoch 98 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.297, data: 0.231) D_A: 0.044 G_A: 0.833 cycle_A: 0.719 idt_A: 0.895 D_B: 0.170 G_B: 0.747 cycle_B: 2.300 idt_B: 0.290 \n",
            "(epoch: 99, iters: 200, time: 0.293, data: 0.011) D_A: 0.353 G_A: 0.836 cycle_A: 0.401 idt_A: 0.946 D_B: 0.256 G_B: 0.219 cycle_B: 2.264 idt_B: 0.144 \n",
            "End of epoch 99 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 100, time: 0.302, data: 0.251) D_A: 0.108 G_A: 0.293 cycle_A: 0.729 idt_A: 0.906 D_B: 0.028 G_B: 0.810 cycle_B: 1.985 idt_B: 0.374 \n",
            "(epoch: 100, iters: 200, time: 1.159, data: 0.013) D_A: 0.104 G_A: 0.761 cycle_A: 0.648 idt_A: 0.723 D_B: 0.259 G_B: 0.183 cycle_B: 1.800 idt_B: 0.236 \n",
            "saving the latest model (epoch 100, total_iters 20000)\n",
            "saving the model at the end of epoch 100, iters 20000\n",
            "End of epoch 100 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "(epoch: 101, iters: 100, time: 0.295, data: 0.369) D_A: 0.028 G_A: 0.732 cycle_A: 0.599 idt_A: 0.622 D_B: 0.113 G_B: 0.652 cycle_B: 1.333 idt_B: 0.261 \n",
            "(epoch: 101, iters: 200, time: 0.309, data: 0.003) D_A: 0.069 G_A: 0.519 cycle_A: 0.583 idt_A: 0.770 D_B: 0.149 G_B: 0.378 cycle_B: 1.916 idt_B: 0.188 \n",
            "End of epoch 101 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 100, time: 0.291, data: 0.381) D_A: 0.048 G_A: 0.739 cycle_A: 0.523 idt_A: 0.897 D_B: 0.057 G_B: 0.594 cycle_B: 1.870 idt_B: 0.205 \n",
            "(epoch: 102, iters: 200, time: 1.403, data: 0.003) D_A: 0.078 G_A: 0.423 cycle_A: 1.780 idt_A: 0.426 D_B: 0.084 G_B: 0.874 cycle_B: 1.143 idt_B: 0.956 \n",
            "End of epoch 102 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 100, time: 0.302, data: 0.182) D_A: 0.072 G_A: 0.544 cycle_A: 1.417 idt_A: 1.139 D_B: 0.149 G_B: 1.220 cycle_B: 2.553 idt_B: 0.617 \n",
            "(epoch: 103, iters: 200, time: 0.290, data: 0.002) D_A: 0.182 G_A: 1.141 cycle_A: 0.452 idt_A: 0.950 D_B: 0.140 G_B: 0.668 cycle_B: 2.303 idt_B: 0.163 \n",
            "End of epoch 103 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 100, time: 0.293, data: 0.268) D_A: 0.131 G_A: 0.454 cycle_A: 0.769 idt_A: 0.789 D_B: 0.041 G_B: 0.757 cycle_B: 1.849 idt_B: 0.321 \n",
            "(epoch: 104, iters: 200, time: 1.166, data: 0.002) D_A: 0.126 G_A: 0.344 cycle_A: 0.688 idt_A: 0.623 D_B: 0.238 G_B: 0.489 cycle_B: 1.551 idt_B: 0.235 \n",
            "End of epoch 104 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 100, time: 0.330, data: 0.230) D_A: 0.215 G_A: 0.781 cycle_A: 0.711 idt_A: 0.812 D_B: 0.096 G_B: 0.530 cycle_B: 2.192 idt_B: 0.279 \n",
            "(epoch: 105, iters: 200, time: 0.326, data: 0.005) D_A: 0.224 G_A: 0.263 cycle_A: 0.355 idt_A: 0.913 D_B: 0.178 G_B: 0.285 cycle_B: 1.992 idt_B: 0.123 \n",
            "saving the model at the end of epoch 105, iters 21000\n",
            "End of epoch 105 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 100, time: 0.339, data: 0.268) D_A: 0.189 G_A: 0.633 cycle_A: 0.818 idt_A: 0.983 D_B: 0.097 G_B: 1.159 cycle_B: 2.246 idt_B: 0.270 \n",
            "(epoch: 106, iters: 200, time: 1.181, data: 0.017) D_A: 0.213 G_A: 0.202 cycle_A: 1.130 idt_A: 0.673 D_B: 0.106 G_B: 0.797 cycle_B: 1.776 idt_B: 0.341 \n",
            "End of epoch 106 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 100, time: 0.316, data: 0.334) D_A: 0.116 G_A: 0.389 cycle_A: 0.583 idt_A: 0.954 D_B: 0.125 G_B: 0.902 cycle_B: 2.184 idt_B: 0.182 \n",
            "(epoch: 107, iters: 200, time: 0.323, data: 0.003) D_A: 0.132 G_A: 0.336 cycle_A: 0.814 idt_A: 0.714 D_B: 0.105 G_B: 0.039 cycle_B: 1.497 idt_B: 0.338 \n",
            "End of epoch 107 / 200 \t Time Taken: 55 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 100, time: 0.287, data: 0.380) D_A: 0.332 G_A: 0.295 cycle_A: 0.551 idt_A: 0.715 D_B: 0.136 G_B: 0.462 cycle_B: 1.826 idt_B: 0.249 \n",
            "(epoch: 108, iters: 200, time: 1.373, data: 0.003) D_A: 0.032 G_A: 0.523 cycle_A: 0.483 idt_A: 1.231 D_B: 0.179 G_B: 0.941 cycle_B: 2.584 idt_B: 0.100 \n",
            "End of epoch 108 / 200 \t Time Taken: 52 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "(epoch: 109, iters: 100, time: 0.291, data: 0.206) D_A: 0.109 G_A: 0.547 cycle_A: 0.644 idt_A: 0.915 D_B: 0.030 G_B: 0.799 cycle_B: 2.067 idt_B: 0.269 \n",
            "(epoch: 109, iters: 200, time: 0.287, data: 0.011) D_A: 0.062 G_A: 0.581 cycle_A: 0.441 idt_A: 1.011 D_B: 0.043 G_B: 0.767 cycle_B: 2.390 idt_B: 0.184 \n",
            "End of epoch 109 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 100, time: 0.307, data: 0.199) D_A: 0.137 G_A: 0.572 cycle_A: 0.470 idt_A: 0.637 D_B: 0.140 G_B: 0.550 cycle_B: 1.473 idt_B: 0.203 \n",
            "(epoch: 110, iters: 200, time: 1.200, data: 0.011) D_A: 0.111 G_A: 0.408 cycle_A: 0.455 idt_A: 0.553 D_B: 0.151 G_B: 0.584 cycle_B: 1.683 idt_B: 0.191 \n",
            "saving the model at the end of epoch 110, iters 22000\n",
            "End of epoch 110 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 100, time: 0.321, data: 0.248) D_A: 0.274 G_A: 1.931 cycle_A: 0.484 idt_A: 0.810 D_B: 0.061 G_B: 0.615 cycle_B: 1.718 idt_B: 0.271 \n",
            "(epoch: 111, iters: 200, time: 0.330, data: 0.003) D_A: 0.105 G_A: 0.316 cycle_A: 0.827 idt_A: 0.708 D_B: 0.143 G_B: 0.387 cycle_B: 1.706 idt_B: 0.244 \n",
            "End of epoch 111 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 100, time: 0.331, data: 0.237) D_A: 0.061 G_A: 1.088 cycle_A: 0.700 idt_A: 0.886 D_B: 0.021 G_B: 1.008 cycle_B: 2.081 idt_B: 0.275 \n",
            "(epoch: 112, iters: 200, time: 1.520, data: 0.017) D_A: 0.121 G_A: 0.823 cycle_A: 0.597 idt_A: 1.014 D_B: 0.072 G_B: 0.339 cycle_B: 2.296 idt_B: 0.221 \n",
            "End of epoch 112 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 100, time: 0.321, data: 0.368) D_A: 0.179 G_A: 0.079 cycle_A: 0.912 idt_A: 0.575 D_B: 0.108 G_B: 1.444 cycle_B: 1.491 idt_B: 0.243 \n",
            "(epoch: 113, iters: 200, time: 0.321, data: 0.003) D_A: 0.077 G_A: 0.897 cycle_A: 0.954 idt_A: 1.000 D_B: 0.207 G_B: 0.156 cycle_B: 2.711 idt_B: 0.341 \n",
            "End of epoch 113 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 100, time: 0.355, data: 0.215) D_A: 0.080 G_A: 0.928 cycle_A: 1.626 idt_A: 0.406 D_B: 0.236 G_B: 0.815 cycle_B: 0.994 idt_B: 0.763 \n",
            "(epoch: 114, iters: 200, time: 1.788, data: 0.002) D_A: 0.061 G_A: 0.634 cycle_A: 0.651 idt_A: 0.645 D_B: 0.058 G_B: 0.557 cycle_B: 1.911 idt_B: 0.226 \n",
            "End of epoch 114 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 100, time: 0.317, data: 0.370) D_A: 0.185 G_A: 0.476 cycle_A: 0.490 idt_A: 0.768 D_B: 0.046 G_B: 0.647 cycle_B: 1.889 idt_B: 0.188 \n",
            "(epoch: 115, iters: 200, time: 0.320, data: 0.003) D_A: 0.277 G_A: 0.662 cycle_A: 0.348 idt_A: 0.689 D_B: 0.094 G_B: 0.436 cycle_B: 1.800 idt_B: 0.120 \n",
            "saving the model at the end of epoch 115, iters 23000\n",
            "End of epoch 115 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 100, time: 0.318, data: 0.274) D_A: 0.062 G_A: 0.567 cycle_A: 0.369 idt_A: 0.525 D_B: 0.154 G_B: 0.320 cycle_B: 1.482 idt_B: 0.134 \n",
            "(epoch: 116, iters: 200, time: 1.265, data: 0.003) D_A: 0.051 G_A: 0.927 cycle_A: 0.881 idt_A: 1.192 D_B: 0.023 G_B: 0.135 cycle_B: 2.405 idt_B: 0.256 \n",
            "End of epoch 116 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "(epoch: 117, iters: 100, time: 0.317, data: 0.267) D_A: 0.048 G_A: 0.696 cycle_A: 1.447 idt_A: 0.760 D_B: 0.269 G_B: 0.130 cycle_B: 2.206 idt_B: 0.583 \n",
            "(epoch: 117, iters: 200, time: 0.327, data: 0.002) D_A: 0.146 G_A: 0.480 cycle_A: 0.434 idt_A: 0.916 D_B: 0.032 G_B: 0.830 cycle_B: 2.188 idt_B: 0.150 \n",
            "End of epoch 117 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 100, time: 0.318, data: 0.422) D_A: 0.154 G_A: 0.772 cycle_A: 0.625 idt_A: 1.356 D_B: 0.119 G_B: 0.870 cycle_B: 1.743 idt_B: 0.221 \n",
            "(epoch: 118, iters: 200, time: 1.275, data: 0.003) D_A: 0.094 G_A: 0.090 cycle_A: 0.451 idt_A: 0.791 D_B: 0.218 G_B: 0.934 cycle_B: 1.911 idt_B: 0.208 \n",
            "End of epoch 118 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 100, time: 0.321, data: 0.280) D_A: 0.028 G_A: 0.292 cycle_A: 0.860 idt_A: 0.761 D_B: 0.156 G_B: 0.442 cycle_B: 1.983 idt_B: 0.292 \n",
            "(epoch: 119, iters: 200, time: 0.332, data: 0.003) D_A: 0.070 G_A: 0.542 cycle_A: 0.959 idt_A: 0.488 D_B: 0.049 G_B: 0.863 cycle_B: 1.464 idt_B: 0.291 \n",
            "End of epoch 119 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 100, time: 0.345, data: 0.381) D_A: 0.044 G_A: 0.615 cycle_A: 0.669 idt_A: 0.912 D_B: 0.086 G_B: 0.442 cycle_B: 1.862 idt_B: 0.265 \n",
            "(epoch: 120, iters: 200, time: 1.524, data: 0.002) D_A: 0.160 G_A: 0.462 cycle_A: 0.316 idt_A: 0.961 D_B: 0.116 G_B: 0.681 cycle_B: 2.224 idt_B: 0.129 \n",
            "saving the model at the end of epoch 120, iters 24000\n",
            "End of epoch 120 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 100, time: 0.325, data: 0.263) D_A: 0.029 G_A: 0.778 cycle_A: 0.456 idt_A: 0.860 D_B: 0.080 G_B: 0.465 cycle_B: 1.834 idt_B: 0.130 \n",
            "(epoch: 121, iters: 200, time: 0.320, data: 0.003) D_A: 0.118 G_A: 0.329 cycle_A: 0.442 idt_A: 1.019 D_B: 0.350 G_B: 0.061 cycle_B: 2.434 idt_B: 0.176 \n",
            "End of epoch 121 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 100, time: 0.313, data: 0.363) D_A: 0.187 G_A: 0.838 cycle_A: 1.175 idt_A: 0.775 D_B: 0.140 G_B: 0.260 cycle_B: 1.964 idt_B: 0.258 \n",
            "(epoch: 122, iters: 200, time: 1.527, data: 0.011) D_A: 0.133 G_A: 0.404 cycle_A: 0.553 idt_A: 1.161 D_B: 0.082 G_B: 0.359 cycle_B: 2.578 idt_B: 0.233 \n",
            "End of epoch 122 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 100, time: 0.319, data: 0.399) D_A: 0.058 G_A: 0.484 cycle_A: 0.503 idt_A: 0.529 D_B: 0.110 G_B: 0.742 cycle_B: 1.373 idt_B: 0.224 \n",
            "(epoch: 123, iters: 200, time: 0.322, data: 0.002) D_A: 0.049 G_A: 0.865 cycle_A: 0.565 idt_A: 0.762 D_B: 0.061 G_B: 0.536 cycle_B: 1.904 idt_B: 0.209 \n",
            "End of epoch 123 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 100, time: 0.315, data: 0.247) D_A: 0.153 G_A: 0.443 cycle_A: 0.329 idt_A: 0.791 D_B: 0.243 G_B: 0.163 cycle_B: 2.019 idt_B: 0.143 \n",
            "(epoch: 124, iters: 200, time: 1.609, data: 0.003) D_A: 0.076 G_A: 0.489 cycle_A: 0.659 idt_A: 0.571 D_B: 0.106 G_B: 0.473 cycle_B: 1.816 idt_B: 0.281 \n",
            "End of epoch 124 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 100, time: 0.324, data: 0.352) D_A: 0.045 G_A: 0.802 cycle_A: 0.628 idt_A: 0.990 D_B: 0.029 G_B: 0.520 cycle_B: 2.194 idt_B: 0.224 \n",
            "(epoch: 125, iters: 200, time: 0.321, data: 0.003) D_A: 0.171 G_A: 0.335 cycle_A: 0.513 idt_A: 1.119 D_B: 0.266 G_B: 1.011 cycle_B: 2.389 idt_B: 0.196 \n",
            "saving the latest model (epoch 125, total_iters 25000)\n",
            "saving the model at the end of epoch 125, iters 25000\n",
            "End of epoch 125 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "(epoch: 126, iters: 100, time: 0.322, data: 0.250) D_A: 0.168 G_A: 0.832 cycle_A: 0.332 idt_A: 0.752 D_B: 0.091 G_B: 0.371 cycle_B: 1.781 idt_B: 0.147 \n",
            "(epoch: 126, iters: 200, time: 1.556, data: 0.003) D_A: 0.058 G_A: 0.326 cycle_A: 0.592 idt_A: 0.506 D_B: 0.083 G_B: 0.804 cycle_B: 1.204 idt_B: 0.214 \n",
            "End of epoch 126 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 100, time: 0.334, data: 0.254) D_A: 0.055 G_A: 0.819 cycle_A: 0.602 idt_A: 0.994 D_B: 0.077 G_B: 0.723 cycle_B: 2.329 idt_B: 0.206 \n",
            "(epoch: 127, iters: 200, time: 0.324, data: 0.011) D_A: 0.175 G_A: 0.372 cycle_A: 0.554 idt_A: 0.579 D_B: 0.091 G_B: 0.905 cycle_B: 1.878 idt_B: 0.146 \n",
            "End of epoch 127 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 100, time: 0.322, data: 0.342) D_A: 0.068 G_A: 0.606 cycle_A: 0.384 idt_A: 0.659 D_B: 0.094 G_B: 1.062 cycle_B: 1.700 idt_B: 0.134 \n",
            "(epoch: 128, iters: 200, time: 1.309, data: 0.003) D_A: 0.022 G_A: 0.585 cycle_A: 0.944 idt_A: 0.820 D_B: 0.215 G_B: 1.058 cycle_B: 1.798 idt_B: 0.473 \n",
            "End of epoch 128 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 100, time: 0.315, data: 0.285) D_A: 0.037 G_A: 0.844 cycle_A: 0.764 idt_A: 0.612 D_B: 0.146 G_B: 0.416 cycle_B: 1.630 idt_B: 0.223 \n",
            "(epoch: 129, iters: 200, time: 0.324, data: 0.003) D_A: 0.087 G_A: 0.569 cycle_A: 0.598 idt_A: 0.511 D_B: 0.086 G_B: 1.418 cycle_B: 1.332 idt_B: 0.132 \n",
            "End of epoch 129 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 100, time: 0.340, data: 0.367) D_A: 0.157 G_A: 0.698 cycle_A: 0.826 idt_A: 0.714 D_B: 0.214 G_B: 0.262 cycle_B: 2.154 idt_B: 0.303 \n",
            "(epoch: 130, iters: 200, time: 1.354, data: 0.002) D_A: 0.073 G_A: 0.781 cycle_A: 1.528 idt_A: 0.597 D_B: 0.024 G_B: 0.819 cycle_B: 1.749 idt_B: 0.434 \n",
            "saving the model at the end of epoch 130, iters 26000\n",
            "End of epoch 130 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 100, time: 0.317, data: 0.230) D_A: 0.217 G_A: 0.294 cycle_A: 0.305 idt_A: 0.573 D_B: 0.087 G_B: 0.531 cycle_B: 1.328 idt_B: 0.113 \n",
            "(epoch: 131, iters: 200, time: 0.316, data: 0.003) D_A: 0.180 G_A: 0.545 cycle_A: 0.284 idt_A: 1.009 D_B: 0.094 G_B: 0.367 cycle_B: 2.149 idt_B: 0.120 \n",
            "End of epoch 131 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 100, time: 0.337, data: 0.334) D_A: 0.062 G_A: 0.623 cycle_A: 0.523 idt_A: 0.509 D_B: 0.195 G_B: 0.603 cycle_B: 1.438 idt_B: 0.209 \n",
            "(epoch: 132, iters: 200, time: 1.691, data: 0.010) D_A: 0.039 G_A: 0.890 cycle_A: 0.979 idt_A: 1.110 D_B: 0.035 G_B: 0.379 cycle_B: 2.510 idt_B: 0.335 \n",
            "End of epoch 132 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 100, time: 0.318, data: 0.367) D_A: 0.171 G_A: 0.305 cycle_A: 0.518 idt_A: 0.628 D_B: 0.137 G_B: 0.522 cycle_B: 1.306 idt_B: 0.208 \n",
            "(epoch: 133, iters: 200, time: 0.315, data: 0.002) D_A: 0.056 G_A: 0.206 cycle_A: 0.397 idt_A: 0.988 D_B: 0.063 G_B: 0.616 cycle_B: 2.081 idt_B: 0.122 \n",
            "End of epoch 133 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "(epoch: 134, iters: 100, time: 0.327, data: 0.253) D_A: 0.154 G_A: 0.278 cycle_A: 0.488 idt_A: 0.842 D_B: 0.127 G_B: 1.094 cycle_B: 2.193 idt_B: 0.194 \n",
            "(epoch: 134, iters: 200, time: 1.587, data: 0.012) D_A: 0.114 G_A: 0.336 cycle_A: 0.494 idt_A: 0.644 D_B: 0.204 G_B: 0.231 cycle_B: 1.529 idt_B: 0.214 \n",
            "End of epoch 134 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 100, time: 0.367, data: 0.392) D_A: 0.043 G_A: 0.544 cycle_A: 0.871 idt_A: 1.003 D_B: 0.067 G_B: 1.181 cycle_B: 1.906 idt_B: 0.307 \n",
            "(epoch: 135, iters: 200, time: 0.315, data: 0.002) D_A: 0.104 G_A: 0.370 cycle_A: 0.453 idt_A: 0.882 D_B: 0.097 G_B: 0.447 cycle_B: 1.918 idt_B: 0.163 \n",
            "saving the model at the end of epoch 135, iters 27000\n",
            "End of epoch 135 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 100, time: 0.306, data: 0.259) D_A: 0.125 G_A: 0.324 cycle_A: 0.401 idt_A: 0.920 D_B: 0.095 G_B: 0.783 cycle_B: 1.950 idt_B: 0.137 \n",
            "(epoch: 136, iters: 200, time: 1.858, data: 0.003) D_A: 0.272 G_A: 0.967 cycle_A: 0.857 idt_A: 0.639 D_B: 0.241 G_B: 0.423 cycle_B: 1.659 idt_B: 0.262 \n",
            "End of epoch 136 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 100, time: 0.319, data: 0.257) D_A: 0.097 G_A: 0.764 cycle_A: 0.538 idt_A: 0.846 D_B: 0.062 G_B: 0.606 cycle_B: 1.931 idt_B: 0.154 \n",
            "(epoch: 137, iters: 200, time: 0.303, data: 0.003) D_A: 0.153 G_A: 0.487 cycle_A: 0.437 idt_A: 0.735 D_B: 0.038 G_B: 0.923 cycle_B: 2.080 idt_B: 0.157 \n",
            "End of epoch 137 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 100, time: 0.305, data: 0.240) D_A: 0.158 G_A: 0.430 cycle_A: 0.492 idt_A: 0.740 D_B: 0.076 G_B: 0.564 cycle_B: 2.200 idt_B: 0.106 \n",
            "(epoch: 138, iters: 200, time: 1.602, data: 0.003) D_A: 0.128 G_A: 0.746 cycle_A: 0.417 idt_A: 0.623 D_B: 0.062 G_B: 0.336 cycle_B: 1.668 idt_B: 0.180 \n",
            "End of epoch 138 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 100, time: 0.304, data: 0.434) D_A: 0.104 G_A: 1.189 cycle_A: 0.491 idt_A: 0.828 D_B: 0.024 G_B: 1.003 cycle_B: 1.892 idt_B: 0.197 \n",
            "(epoch: 139, iters: 200, time: 0.307, data: 0.004) D_A: 0.128 G_A: 0.324 cycle_A: 0.806 idt_A: 0.981 D_B: 0.111 G_B: 1.080 cycle_B: 2.167 idt_B: 0.412 \n",
            "End of epoch 139 / 200 \t Time Taken: 55 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 100, time: 0.329, data: 0.257) D_A: 0.089 G_A: 0.447 cycle_A: 0.425 idt_A: 0.746 D_B: 0.144 G_B: 0.340 cycle_B: 1.965 idt_B: 0.182 \n",
            "(epoch: 140, iters: 200, time: 1.584, data: 0.002) D_A: 0.150 G_A: 0.303 cycle_A: 0.632 idt_A: 0.950 D_B: 0.278 G_B: 1.335 cycle_B: 2.192 idt_B: 0.228 \n",
            "saving the model at the end of epoch 140, iters 28000\n",
            "End of epoch 140 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 100, time: 0.300, data: 0.367) D_A: 0.203 G_A: 0.903 cycle_A: 0.447 idt_A: 0.685 D_B: 0.068 G_B: 0.646 cycle_B: 1.522 idt_B: 0.184 \n",
            "(epoch: 141, iters: 200, time: 0.288, data: 0.003) D_A: 0.032 G_A: 0.759 cycle_A: 1.072 idt_A: 0.577 D_B: 0.125 G_B: 0.044 cycle_B: 1.353 idt_B: 0.727 \n",
            "End of epoch 141 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "(epoch: 142, iters: 100, time: 0.314, data: 0.233) D_A: 0.138 G_A: 0.324 cycle_A: 0.386 idt_A: 0.427 D_B: 0.091 G_B: 0.417 cycle_B: 1.375 idt_B: 0.135 \n",
            "(epoch: 142, iters: 200, time: 1.578, data: 0.011) D_A: 0.073 G_A: 0.560 cycle_A: 0.980 idt_A: 0.713 D_B: 0.118 G_B: 0.373 cycle_B: 1.658 idt_B: 0.239 \n",
            "End of epoch 142 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 100, time: 0.289, data: 0.285) D_A: 0.065 G_A: 0.737 cycle_A: 0.316 idt_A: 0.757 D_B: 0.204 G_B: 0.180 cycle_B: 1.826 idt_B: 0.114 \n",
            "(epoch: 143, iters: 200, time: 0.294, data: 0.012) D_A: 0.118 G_A: 0.323 cycle_A: 1.343 idt_A: 0.611 D_B: 0.039 G_B: 0.321 cycle_B: 1.409 idt_B: 0.444 \n",
            "End of epoch 143 / 200 \t Time Taken: 51 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 100, time: 0.290, data: 0.279) D_A: 0.104 G_A: 1.341 cycle_A: 0.587 idt_A: 0.619 D_B: 0.031 G_B: 0.818 cycle_B: 1.676 idt_B: 0.205 \n",
            "(epoch: 144, iters: 200, time: 1.640, data: 0.002) D_A: 0.145 G_A: 0.431 cycle_A: 0.451 idt_A: 0.777 D_B: 0.047 G_B: 0.325 cycle_B: 1.837 idt_B: 0.153 \n",
            "End of epoch 144 / 200 \t Time Taken: 53 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 100, time: 0.306, data: 0.415) D_A: 0.045 G_A: 0.657 cycle_A: 0.706 idt_A: 0.523 D_B: 0.032 G_B: 0.833 cycle_B: 1.332 idt_B: 0.250 \n",
            "(epoch: 145, iters: 200, time: 0.292, data: 0.003) D_A: 0.051 G_A: 0.414 cycle_A: 0.374 idt_A: 0.887 D_B: 0.119 G_B: 0.407 cycle_B: 1.926 idt_B: 0.142 \n",
            "saving the model at the end of epoch 145, iters 29000\n",
            "End of epoch 145 / 200 \t Time Taken: 54 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 100, time: 0.334, data: 0.285) D_A: 0.072 G_A: 0.689 cycle_A: 0.405 idt_A: 1.093 D_B: 0.016 G_B: 0.900 cycle_B: 2.316 idt_B: 0.132 \n",
            "(epoch: 146, iters: 200, time: 1.813, data: 0.003) D_A: 0.159 G_A: 0.304 cycle_A: 0.609 idt_A: 0.811 D_B: 0.024 G_B: 1.390 cycle_B: 1.669 idt_B: 0.190 \n",
            "End of epoch 146 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 100, time: 0.307, data: 0.368) D_A: 0.129 G_A: 0.621 cycle_A: 0.588 idt_A: 0.888 D_B: 0.118 G_B: 0.317 cycle_B: 1.927 idt_B: 0.246 \n",
            "(epoch: 147, iters: 200, time: 0.304, data: 0.003) D_A: 0.062 G_A: 0.296 cycle_A: 0.376 idt_A: 0.549 D_B: 0.197 G_B: 0.267 cycle_B: 1.217 idt_B: 0.107 \n",
            "End of epoch 147 / 200 \t Time Taken: 55 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 100, time: 0.308, data: 0.236) D_A: 0.029 G_A: 0.467 cycle_A: 0.624 idt_A: 0.998 D_B: 0.094 G_B: 0.511 cycle_B: 2.355 idt_B: 0.249 \n",
            "(epoch: 148, iters: 200, time: 1.530, data: 0.011) D_A: 0.094 G_A: 0.744 cycle_A: 0.838 idt_A: 0.549 D_B: 0.200 G_B: 0.211 cycle_B: 1.467 idt_B: 0.338 \n",
            "End of epoch 148 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 100, time: 0.303, data: 0.389) D_A: 0.063 G_A: 0.522 cycle_A: 0.596 idt_A: 0.689 D_B: 0.206 G_B: 0.791 cycle_B: 1.564 idt_B: 0.189 \n",
            "(epoch: 149, iters: 200, time: 0.304, data: 0.003) D_A: 0.252 G_A: 0.221 cycle_A: 0.412 idt_A: 0.722 D_B: 0.090 G_B: 0.406 cycle_B: 1.723 idt_B: 0.152 \n",
            "End of epoch 149 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 100, time: 0.315, data: 0.185) D_A: 0.029 G_A: 1.018 cycle_A: 0.571 idt_A: 0.948 D_B: 0.078 G_B: 0.812 cycle_B: 2.039 idt_B: 0.179 \n",
            "(epoch: 150, iters: 200, time: 1.556, data: 0.011) D_A: 0.093 G_A: 0.791 cycle_A: 0.440 idt_A: 1.051 D_B: 0.059 G_B: 0.885 cycle_B: 2.254 idt_B: 0.146 \n",
            "saving the latest model (epoch 150, total_iters 30000)\n",
            "saving the model at the end of epoch 150, iters 30000\n",
            "End of epoch 150 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "(epoch: 151, iters: 100, time: 0.324, data: 0.414) D_A: 0.169 G_A: 0.790 cycle_A: 0.460 idt_A: 0.905 D_B: 0.077 G_B: 1.036 cycle_B: 2.011 idt_B: 0.173 \n",
            "(epoch: 151, iters: 200, time: 0.317, data: 0.002) D_A: 0.216 G_A: 0.495 cycle_A: 0.243 idt_A: 0.886 D_B: 0.245 G_B: 0.537 cycle_B: 1.767 idt_B: 0.095 \n",
            "End of epoch 151 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 100, time: 0.319, data: 0.252) D_A: 0.088 G_A: 0.633 cycle_A: 0.338 idt_A: 1.123 D_B: 0.041 G_B: 0.647 cycle_B: 2.418 idt_B: 0.149 \n",
            "(epoch: 152, iters: 200, time: 2.003, data: 0.003) D_A: 0.074 G_A: 0.737 cycle_A: 0.712 idt_A: 0.679 D_B: 0.148 G_B: 0.300 cycle_B: 1.495 idt_B: 0.181 \n",
            "End of epoch 152 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 100, time: 0.317, data: 0.326) D_A: 0.173 G_A: 0.313 cycle_A: 0.261 idt_A: 0.717 D_B: 0.165 G_B: 0.650 cycle_B: 1.690 idt_B: 0.098 \n",
            "(epoch: 153, iters: 200, time: 0.318, data: 0.011) D_A: 0.067 G_A: 0.538 cycle_A: 0.510 idt_A: 1.025 D_B: 0.159 G_B: 0.985 cycle_B: 2.249 idt_B: 0.146 \n",
            "End of epoch 153 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 100, time: 0.316, data: 0.292) D_A: 0.081 G_A: 0.446 cycle_A: 0.448 idt_A: 0.696 D_B: 0.104 G_B: 0.334 cycle_B: 1.729 idt_B: 0.162 \n",
            "(epoch: 154, iters: 200, time: 1.458, data: 0.002) D_A: 0.029 G_A: 0.594 cycle_A: 0.531 idt_A: 0.532 D_B: 0.108 G_B: 0.848 cycle_B: 1.383 idt_B: 0.184 \n",
            "End of epoch 154 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 100, time: 0.322, data: 0.257) D_A: 0.090 G_A: 0.455 cycle_A: 0.321 idt_A: 0.652 D_B: 0.158 G_B: 1.114 cycle_B: 1.565 idt_B: 0.092 \n",
            "(epoch: 155, iters: 200, time: 0.317, data: 0.003) D_A: 0.053 G_A: 0.998 cycle_A: 0.548 idt_A: 0.520 D_B: 0.074 G_B: 0.509 cycle_B: 1.281 idt_B: 0.191 \n",
            "saving the model at the end of epoch 155, iters 31000\n",
            "End of epoch 155 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 100, time: 0.318, data: 0.399) D_A: 0.040 G_A: 0.777 cycle_A: 0.564 idt_A: 0.923 D_B: 0.068 G_B: 0.603 cycle_B: 1.962 idt_B: 0.222 \n",
            "(epoch: 156, iters: 200, time: 1.664, data: 0.002) D_A: 0.016 G_A: 0.452 cycle_A: 0.512 idt_A: 0.933 D_B: 0.192 G_B: 0.419 cycle_B: 1.984 idt_B: 0.169 \n",
            "End of epoch 156 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 100, time: 0.320, data: 0.354) D_A: 0.111 G_A: 0.348 cycle_A: 0.667 idt_A: 0.635 D_B: 0.079 G_B: 1.027 cycle_B: 1.535 idt_B: 0.186 \n",
            "(epoch: 157, iters: 200, time: 0.335, data: 0.003) D_A: 0.139 G_A: 0.327 cycle_A: 0.670 idt_A: 1.112 D_B: 0.111 G_B: 0.337 cycle_B: 2.458 idt_B: 0.247 \n",
            "End of epoch 157 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 100, time: 0.327, data: 0.364) D_A: 0.074 G_A: 0.504 cycle_A: 0.454 idt_A: 0.887 D_B: 0.114 G_B: 0.382 cycle_B: 1.967 idt_B: 0.184 \n",
            "(epoch: 158, iters: 200, time: 1.459, data: 0.002) D_A: 0.124 G_A: 0.555 cycle_A: 0.645 idt_A: 0.716 D_B: 0.038 G_B: 1.467 cycle_B: 1.772 idt_B: 0.209 \n",
            "End of epoch 158 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "(epoch: 159, iters: 100, time: 0.318, data: 0.248) D_A: 0.070 G_A: 0.648 cycle_A: 0.282 idt_A: 0.725 D_B: 0.152 G_B: 0.846 cycle_B: 1.520 idt_B: 0.089 \n",
            "(epoch: 159, iters: 200, time: 0.326, data: 0.003) D_A: 0.044 G_A: 0.405 cycle_A: 0.513 idt_A: 0.594 D_B: 0.028 G_B: 0.950 cycle_B: 1.344 idt_B: 0.208 \n",
            "End of epoch 159 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 100, time: 0.320, data: 0.215) D_A: 0.090 G_A: 0.448 cycle_A: 1.388 idt_A: 0.940 D_B: 0.090 G_B: 0.435 cycle_B: 1.936 idt_B: 0.616 \n",
            "(epoch: 160, iters: 200, time: 1.785, data: 0.002) D_A: 0.052 G_A: 0.630 cycle_A: 0.470 idt_A: 0.940 D_B: 0.027 G_B: 0.309 cycle_B: 2.212 idt_B: 0.144 \n",
            "saving the model at the end of epoch 160, iters 32000\n",
            "End of epoch 160 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 100, time: 0.318, data: 0.355) D_A: 0.060 G_A: 0.732 cycle_A: 0.526 idt_A: 0.696 D_B: 0.055 G_B: 1.135 cycle_B: 1.694 idt_B: 0.163 \n",
            "(epoch: 161, iters: 200, time: 0.318, data: 0.003) D_A: 0.027 G_A: 0.459 cycle_A: 1.030 idt_A: 0.787 D_B: 0.039 G_B: 0.650 cycle_B: 1.756 idt_B: 0.377 \n",
            "End of epoch 161 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 100, time: 0.318, data: 0.213) D_A: 0.136 G_A: 0.598 cycle_A: 0.377 idt_A: 0.557 D_B: 0.062 G_B: 0.492 cycle_B: 1.279 idt_B: 0.142 \n",
            "(epoch: 162, iters: 200, time: 1.797, data: 0.003) D_A: 0.091 G_A: 0.558 cycle_A: 0.724 idt_A: 1.090 D_B: 0.157 G_B: 0.240 cycle_B: 2.376 idt_B: 0.333 \n",
            "End of epoch 162 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 100, time: 0.320, data: 0.400) D_A: 0.072 G_A: 0.317 cycle_A: 0.574 idt_A: 0.568 D_B: 0.028 G_B: 0.964 cycle_B: 1.223 idt_B: 0.170 \n",
            "(epoch: 163, iters: 200, time: 0.320, data: 0.002) D_A: 0.076 G_A: 0.610 cycle_A: 0.728 idt_A: 0.412 D_B: 0.065 G_B: 0.542 cycle_B: 0.883 idt_B: 0.218 \n",
            "End of epoch 163 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 100, time: 0.316, data: 0.434) D_A: 0.051 G_A: 0.473 cycle_A: 0.365 idt_A: 0.677 D_B: 0.184 G_B: 0.210 cycle_B: 1.465 idt_B: 0.136 \n",
            "(epoch: 164, iters: 200, time: 1.911, data: 0.003) D_A: 0.075 G_A: 0.447 cycle_A: 0.621 idt_A: 0.350 D_B: 0.301 G_B: 1.368 cycle_B: 0.859 idt_B: 0.236 \n",
            "End of epoch 164 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 100, time: 0.344, data: 0.239) D_A: 0.017 G_A: 0.434 cycle_A: 0.513 idt_A: 0.960 D_B: 0.115 G_B: 0.781 cycle_B: 2.211 idt_B: 0.156 \n",
            "(epoch: 165, iters: 200, time: 0.321, data: 0.016) D_A: 0.072 G_A: 0.544 cycle_A: 0.825 idt_A: 0.991 D_B: 0.116 G_B: 0.891 cycle_B: 2.136 idt_B: 0.433 \n",
            "saving the model at the end of epoch 165, iters 33000\n",
            "End of epoch 165 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 100, time: 0.317, data: 0.457) D_A: 0.158 G_A: 0.250 cycle_A: 0.481 idt_A: 0.658 D_B: 0.107 G_B: 0.464 cycle_B: 1.569 idt_B: 0.184 \n",
            "(epoch: 166, iters: 200, time: 1.512, data: 0.003) D_A: 0.079 G_A: 0.440 cycle_A: 0.217 idt_A: 0.702 D_B: 0.139 G_B: 0.620 cycle_B: 1.514 idt_B: 0.080 \n",
            "End of epoch 166 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "(epoch: 167, iters: 100, time: 0.316, data: 0.256) D_A: 0.128 G_A: 1.041 cycle_A: 0.756 idt_A: 1.133 D_B: 0.098 G_B: 0.495 cycle_B: 2.539 idt_B: 0.243 \n",
            "(epoch: 167, iters: 200, time: 0.324, data: 0.002) D_A: 0.016 G_A: 0.333 cycle_A: 0.550 idt_A: 0.946 D_B: 0.038 G_B: 0.713 cycle_B: 2.158 idt_B: 0.203 \n",
            "End of epoch 167 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 100, time: 0.342, data: 0.349) D_A: 0.078 G_A: 0.429 cycle_A: 0.416 idt_A: 0.571 D_B: 0.096 G_B: 0.392 cycle_B: 1.337 idt_B: 0.165 \n",
            "(epoch: 168, iters: 200, time: 1.473, data: 0.011) D_A: 0.043 G_A: 0.605 cycle_A: 0.446 idt_A: 1.004 D_B: 0.048 G_B: 1.097 cycle_B: 2.075 idt_B: 0.166 \n",
            "End of epoch 168 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 100, time: 0.324, data: 0.247) D_A: 0.083 G_A: 0.350 cycle_A: 0.714 idt_A: 0.516 D_B: 0.185 G_B: 0.234 cycle_B: 1.217 idt_B: 0.234 \n",
            "(epoch: 169, iters: 200, time: 0.315, data: 0.003) D_A: 0.070 G_A: 0.546 cycle_A: 0.482 idt_A: 0.501 D_B: 0.159 G_B: 0.240 cycle_B: 1.203 idt_B: 0.172 \n",
            "End of epoch 169 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 100, time: 0.331, data: 0.208) D_A: 0.096 G_A: 0.973 cycle_A: 0.599 idt_A: 0.667 D_B: 0.048 G_B: 0.579 cycle_B: 1.449 idt_B: 0.248 \n",
            "(epoch: 170, iters: 200, time: 1.794, data: 0.002) D_A: 0.054 G_A: 0.546 cycle_A: 0.633 idt_A: 0.526 D_B: 0.139 G_B: 0.374 cycle_B: 1.232 idt_B: 0.131 \n",
            "saving the model at the end of epoch 170, iters 34000\n",
            "End of epoch 170 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 100, time: 0.316, data: 0.365) D_A: 0.084 G_A: 0.520 cycle_A: 0.566 idt_A: 0.876 D_B: 0.141 G_B: 0.451 cycle_B: 1.971 idt_B: 0.120 \n",
            "(epoch: 171, iters: 200, time: 0.316, data: 0.003) D_A: 0.056 G_A: 0.398 cycle_A: 0.300 idt_A: 0.643 D_B: 0.033 G_B: 0.878 cycle_B: 1.522 idt_B: 0.097 \n",
            "End of epoch 171 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 100, time: 0.320, data: 0.237) D_A: 0.044 G_A: 0.715 cycle_A: 0.271 idt_A: 0.619 D_B: 0.054 G_B: 0.514 cycle_B: 1.483 idt_B: 0.101 \n",
            "(epoch: 172, iters: 200, time: 1.870, data: 0.003) D_A: 0.016 G_A: 0.816 cycle_A: 0.392 idt_A: 0.532 D_B: 0.132 G_B: 0.291 cycle_B: 1.424 idt_B: 0.131 \n",
            "End of epoch 172 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 100, time: 0.339, data: 0.416) D_A: 0.026 G_A: 0.767 cycle_A: 0.440 idt_A: 0.634 D_B: 0.079 G_B: 1.136 cycle_B: 1.632 idt_B: 0.149 \n",
            "(epoch: 173, iters: 200, time: 0.323, data: 0.011) D_A: 0.182 G_A: 0.487 cycle_A: 0.686 idt_A: 1.085 D_B: 0.055 G_B: 0.289 cycle_B: 2.345 idt_B: 0.202 \n",
            "End of epoch 173 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 100, time: 0.325, data: 0.271) D_A: 0.079 G_A: 0.514 cycle_A: 0.449 idt_A: 0.872 D_B: 0.028 G_B: 1.012 cycle_B: 1.959 idt_B: 0.180 \n",
            "(epoch: 174, iters: 200, time: 1.590, data: 0.003) D_A: 0.129 G_A: 0.800 cycle_A: 0.309 idt_A: 0.850 D_B: 0.072 G_B: 0.544 cycle_B: 1.658 idt_B: 0.114 \n",
            "End of epoch 174 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 100, time: 0.320, data: 0.283) D_A: 0.048 G_A: 0.702 cycle_A: 0.476 idt_A: 0.930 D_B: 0.063 G_B: 1.035 cycle_B: 2.150 idt_B: 0.162 \n",
            "(epoch: 175, iters: 200, time: 0.326, data: 0.012) D_A: 0.047 G_A: 0.826 cycle_A: 0.621 idt_A: 0.859 D_B: 0.251 G_B: 0.346 cycle_B: 1.919 idt_B: 0.213 \n",
            "saving the latest model (epoch 175, total_iters 35000)\n",
            "saving the model at the end of epoch 175, iters 35000\n",
            "End of epoch 175 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "(epoch: 176, iters: 100, time: 0.320, data: 0.379) D_A: 0.057 G_A: 0.723 cycle_A: 0.751 idt_A: 0.615 D_B: 0.054 G_B: 0.534 cycle_B: 1.347 idt_B: 0.258 \n",
            "(epoch: 176, iters: 200, time: 1.761, data: 0.003) D_A: 0.065 G_A: 0.806 cycle_A: 0.490 idt_A: 0.541 D_B: 0.293 G_B: 0.673 cycle_B: 1.272 idt_B: 0.206 \n",
            "End of epoch 176 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 100, time: 0.313, data: 0.259) D_A: 0.132 G_A: 0.294 cycle_A: 1.485 idt_A: 0.923 D_B: 0.030 G_B: 1.335 cycle_B: 1.969 idt_B: 0.662 \n",
            "(epoch: 177, iters: 200, time: 0.347, data: 0.003) D_A: 0.021 G_A: 0.277 cycle_A: 0.426 idt_A: 0.768 D_B: 0.023 G_B: 0.389 cycle_B: 1.528 idt_B: 0.099 \n",
            "End of epoch 177 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 100, time: 0.310, data: 0.375) D_A: 0.068 G_A: 1.084 cycle_A: 0.559 idt_A: 0.592 D_B: 0.091 G_B: 1.145 cycle_B: 1.349 idt_B: 0.187 \n",
            "(epoch: 178, iters: 200, time: 1.550, data: 0.018) D_A: 0.090 G_A: 0.489 cycle_A: 0.343 idt_A: 0.653 D_B: 0.090 G_B: 0.479 cycle_B: 1.590 idt_B: 0.139 \n",
            "End of epoch 178 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 100, time: 0.320, data: 0.239) D_A: 0.040 G_A: 0.668 cycle_A: 0.309 idt_A: 0.891 D_B: 0.092 G_B: 0.644 cycle_B: 2.002 idt_B: 0.103 \n",
            "(epoch: 179, iters: 200, time: 0.307, data: 0.003) D_A: 0.059 G_A: 0.576 cycle_A: 0.374 idt_A: 1.061 D_B: 0.023 G_B: 0.709 cycle_B: 2.216 idt_B: 0.122 \n",
            "End of epoch 179 / 200 \t Time Taken: 56 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 100, time: 0.331, data: 0.279) D_A: 0.040 G_A: 0.625 cycle_A: 0.537 idt_A: 0.519 D_B: 0.045 G_B: 0.732 cycle_B: 1.131 idt_B: 0.181 \n",
            "(epoch: 180, iters: 200, time: 1.553, data: 0.002) D_A: 0.033 G_A: 0.685 cycle_A: 0.890 idt_A: 0.617 D_B: 0.051 G_B: 0.433 cycle_B: 1.373 idt_B: 0.330 \n",
            "saving the model at the end of epoch 180, iters 36000\n",
            "End of epoch 180 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 100, time: 0.317, data: 0.410) D_A: 0.054 G_A: 0.588 cycle_A: 0.644 idt_A: 0.677 D_B: 0.039 G_B: 1.188 cycle_B: 1.519 idt_B: 0.292 \n",
            "(epoch: 181, iters: 200, time: 0.318, data: 0.003) D_A: 0.091 G_A: 0.400 cycle_A: 0.442 idt_A: 0.511 D_B: 0.040 G_B: 0.651 cycle_B: 1.129 idt_B: 0.143 \n",
            "End of epoch 181 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 100, time: 0.322, data: 0.216) D_A: 0.024 G_A: 0.520 cycle_A: 1.123 idt_A: 1.023 D_B: 0.027 G_B: 0.534 cycle_B: 2.136 idt_B: 0.507 \n",
            "(epoch: 182, iters: 200, time: 1.936, data: 0.003) D_A: 0.248 G_A: 1.142 cycle_A: 0.659 idt_A: 0.621 D_B: 0.023 G_B: 0.921 cycle_B: 1.484 idt_B: 0.255 \n",
            "End of epoch 182 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 100, time: 0.326, data: 0.379) D_A: 0.111 G_A: 0.575 cycle_A: 0.390 idt_A: 0.924 D_B: 0.285 G_B: 0.169 cycle_B: 1.929 idt_B: 0.124 \n",
            "(epoch: 183, iters: 200, time: 0.319, data: 0.013) D_A: 0.083 G_A: 0.509 cycle_A: 0.481 idt_A: 0.770 D_B: 0.038 G_B: 0.411 cycle_B: 1.557 idt_B: 0.231 \n",
            "End of epoch 183 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "(epoch: 184, iters: 100, time: 0.320, data: 0.270) D_A: 0.125 G_A: 0.326 cycle_A: 0.540 idt_A: 0.583 D_B: 0.106 G_B: 0.594 cycle_B: 1.421 idt_B: 0.196 \n",
            "(epoch: 184, iters: 200, time: 1.838, data: 0.003) D_A: 0.036 G_A: 0.456 cycle_A: 0.422 idt_A: 0.483 D_B: 0.078 G_B: 0.618 cycle_B: 1.070 idt_B: 0.150 \n",
            "End of epoch 184 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 100, time: 0.333, data: 0.251) D_A: 0.065 G_A: 0.413 cycle_A: 0.490 idt_A: 0.810 D_B: 0.028 G_B: 0.718 cycle_B: 1.723 idt_B: 0.179 \n",
            "(epoch: 185, iters: 200, time: 0.321, data: 0.011) D_A: 0.034 G_A: 0.722 cycle_A: 0.314 idt_A: 0.730 D_B: 0.020 G_B: 0.784 cycle_B: 1.618 idt_B: 0.121 \n",
            "saving the model at the end of epoch 185, iters 37000\n",
            "End of epoch 185 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 100, time: 0.318, data: 0.395) D_A: 0.026 G_A: 0.723 cycle_A: 0.492 idt_A: 0.955 D_B: 0.041 G_B: 1.315 cycle_B: 2.106 idt_B: 0.191 \n",
            "(epoch: 186, iters: 200, time: 1.687, data: 0.003) D_A: 0.084 G_A: 0.702 cycle_A: 0.493 idt_A: 0.647 D_B: 0.074 G_B: 1.588 cycle_B: 1.398 idt_B: 0.161 \n",
            "End of epoch 186 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 100, time: 0.317, data: 0.268) D_A: 0.043 G_A: 0.592 cycle_A: 0.474 idt_A: 0.644 D_B: 0.079 G_B: 0.506 cycle_B: 1.387 idt_B: 0.188 \n",
            "(epoch: 187, iters: 200, time: 0.328, data: 0.003) D_A: 0.096 G_A: 0.800 cycle_A: 0.401 idt_A: 0.971 D_B: 0.027 G_B: 0.505 cycle_B: 2.042 idt_B: 0.118 \n",
            "End of epoch 187 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 100, time: 0.335, data: 0.317) D_A: 0.057 G_A: 0.574 cycle_A: 0.471 idt_A: 0.995 D_B: 0.187 G_B: 1.456 cycle_B: 2.090 idt_B: 0.190 \n",
            "(epoch: 188, iters: 200, time: 1.886, data: 0.002) D_A: 0.074 G_A: 0.459 cycle_A: 0.346 idt_A: 1.027 D_B: 0.100 G_B: 1.069 cycle_B: 2.192 idt_B: 0.110 \n",
            "End of epoch 188 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 100, time: 0.320, data: 0.279) D_A: 0.069 G_A: 0.563 cycle_A: 0.228 idt_A: 0.773 D_B: 0.069 G_B: 1.263 cycle_B: 1.678 idt_B: 0.083 \n",
            "(epoch: 189, iters: 200, time: 0.338, data: 0.003) D_A: 0.036 G_A: 0.527 cycle_A: 0.620 idt_A: 0.476 D_B: 0.042 G_B: 0.638 cycle_B: 1.139 idt_B: 0.255 \n",
            "End of epoch 189 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 100, time: 0.332, data: 0.384) D_A: 0.104 G_A: 0.361 cycle_A: 0.371 idt_A: 0.458 D_B: 0.085 G_B: 0.704 cycle_B: 1.054 idt_B: 0.135 \n",
            "(epoch: 190, iters: 200, time: 1.689, data: 0.011) D_A: 0.027 G_A: 0.336 cycle_A: 0.403 idt_A: 0.902 D_B: 0.034 G_B: 0.785 cycle_B: 2.107 idt_B: 0.118 \n",
            "saving the model at the end of epoch 190, iters 38000\n",
            "End of epoch 190 / 200 \t Time Taken: 60 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 100, time: 0.324, data: 0.402) D_A: 0.077 G_A: 0.609 cycle_A: 0.384 idt_A: 1.055 D_B: 0.062 G_B: 0.820 cycle_B: 2.225 idt_B: 0.138 \n",
            "(epoch: 191, iters: 200, time: 0.324, data: 0.003) D_A: 0.043 G_A: 0.669 cycle_A: 0.454 idt_A: 0.569 D_B: 0.089 G_B: 1.142 cycle_B: 1.283 idt_B: 0.148 \n",
            "End of epoch 191 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "(epoch: 192, iters: 100, time: 0.337, data: 0.242) D_A: 0.166 G_A: 0.641 cycle_A: 0.438 idt_A: 0.798 D_B: 0.094 G_B: 0.426 cycle_B: 1.588 idt_B: 0.153 \n",
            "(epoch: 192, iters: 200, time: 2.137, data: 0.003) D_A: 0.023 G_A: 0.686 cycle_A: 0.496 idt_A: 0.649 D_B: 0.183 G_B: 0.291 cycle_B: 1.478 idt_B: 0.222 \n",
            "End of epoch 192 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 100, time: 0.334, data: 0.492) D_A: 0.048 G_A: 0.582 cycle_A: 0.344 idt_A: 1.138 D_B: 0.104 G_B: 0.700 cycle_B: 2.337 idt_B: 0.138 \n",
            "(epoch: 193, iters: 200, time: 0.320, data: 0.013) D_A: 0.076 G_A: 0.693 cycle_A: 0.716 idt_A: 0.811 D_B: 0.058 G_B: 0.550 cycle_B: 1.728 idt_B: 0.285 \n",
            "End of epoch 193 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 100, time: 0.319, data: 0.406) D_A: 0.238 G_A: 0.399 cycle_A: 0.452 idt_A: 0.822 D_B: 0.057 G_B: 0.809 cycle_B: 1.789 idt_B: 0.130 \n",
            "(epoch: 194, iters: 200, time: 2.123, data: 0.003) D_A: 0.050 G_A: 0.748 cycle_A: 0.433 idt_A: 0.769 D_B: 0.093 G_B: 0.556 cycle_B: 1.674 idt_B: 0.190 \n",
            "End of epoch 194 / 200 \t Time Taken: 59 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 100, time: 0.340, data: 0.275) D_A: 0.144 G_A: 0.732 cycle_A: 0.302 idt_A: 0.807 D_B: 0.024 G_B: 0.607 cycle_B: 1.754 idt_B: 0.115 \n",
            "(epoch: 195, iters: 200, time: 0.319, data: 0.002) D_A: 0.078 G_A: 0.524 cycle_A: 0.354 idt_A: 0.565 D_B: 0.045 G_B: 0.624 cycle_B: 1.235 idt_B: 0.126 \n",
            "saving the model at the end of epoch 195, iters 39000\n",
            "End of epoch 195 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 100, time: 0.310, data: 0.256) D_A: 0.067 G_A: 0.652 cycle_A: 0.269 idt_A: 0.734 D_B: 0.014 G_B: 0.970 cycle_B: 1.788 idt_B: 0.081 \n",
            "(epoch: 196, iters: 200, time: 1.940, data: 0.002) D_A: 0.074 G_A: 0.344 cycle_A: 0.320 idt_A: 0.685 D_B: 0.041 G_B: 1.014 cycle_B: 1.565 idt_B: 0.082 \n",
            "End of epoch 196 / 200 \t Time Taken: 60 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 100, time: 0.320, data: 0.281) D_A: 0.090 G_A: 0.489 cycle_A: 0.400 idt_A: 0.907 D_B: 0.028 G_B: 0.797 cycle_B: 1.908 idt_B: 0.124 \n",
            "(epoch: 197, iters: 200, time: 0.320, data: 0.012) D_A: 0.037 G_A: 0.502 cycle_A: 0.275 idt_A: 0.712 D_B: 0.086 G_B: 1.034 cycle_B: 1.542 idt_B: 0.097 \n",
            "End of epoch 197 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 100, time: 0.306, data: 0.377) D_A: 0.038 G_A: 0.540 cycle_A: 1.384 idt_A: 0.552 D_B: 0.021 G_B: 0.780 cycle_B: 1.227 idt_B: 0.600 \n",
            "(epoch: 198, iters: 200, time: 1.770, data: 0.002) D_A: 0.035 G_A: 0.674 cycle_A: 0.436 idt_A: 0.813 D_B: 0.222 G_B: 0.215 cycle_B: 1.695 idt_B: 0.134 \n",
            "End of epoch 198 / 200 \t Time Taken: 58 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 100, time: 0.372, data: 0.262) D_A: 0.024 G_A: 0.780 cycle_A: 1.393 idt_A: 0.412 D_B: 0.033 G_B: 0.651 cycle_B: 0.975 idt_B: 0.642 \n",
            "(epoch: 199, iters: 200, time: 0.340, data: 0.013) D_A: 0.080 G_A: 0.699 cycle_A: 0.277 idt_A: 0.897 D_B: 0.120 G_B: 0.643 cycle_B: 1.927 idt_B: 0.103 \n",
            "End of epoch 199 / 200 \t Time Taken: 57 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 100, time: 0.310, data: 0.397) D_A: 0.081 G_A: 0.465 cycle_A: 0.346 idt_A: 0.573 D_B: 0.051 G_B: 0.841 cycle_B: 1.192 idt_B: 0.122 \n",
            "(epoch: 200, iters: 200, time: 1.952, data: 0.006) D_A: 0.157 G_A: 0.376 cycle_A: 0.434 idt_A: 0.558 D_B: 0.040 G_B: 1.006 cycle_B: 1.256 idt_B: 0.124 \n",
            "saving the latest model (epoch 200, total_iters 40000)\n",
            "saving the model at the end of epoch 200, iters 40000\n",
            "End of epoch 200 / 200 \t Time Taken: 60 sec\n",
            "cell_weights: {'cell_netG_A': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)], 'cell_netG_B': [tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64), tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], device='cuda:0', dtype=torch.float64)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "change `--dataroot` and `--name` to the path where your data lies and to the previously given name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYEuxRdz6dAN"
      },
      "outputs": [],
      "source": [
        "!python test.py --dataroot /content/drive/MyDrive/dl_viz_rec/train_400_generated --name train_nas_project_layer_types_cycleGAN_final_5_cell_layer_3_blocks_final --model uni_cycle_gan --no_dropout --epoch 50"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "3ryLRt_YnsS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FID and FID-CLIP metrics"
      ],
      "metadata": {
        "id": "2K8mZMouoNOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clean-fid\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "from cleanfid import fid"
      ],
      "metadata": {
        "id": "hu5tPdW-nt1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the path to your real images\n",
        "path_to_real = \"./...\"\n",
        "\n",
        "# the path to the images you want to test\n",
        "path_to_test = \"./...\"\n",
        "\n",
        "real_synth_fid_score = fid.compute_fid(path_to_real, path_to_test)\n",
        "print(f\"real_synth_fid_score: {real_synth_fid_score}\")\n",
        "\n",
        "real_synth_score_fid_clip = fid.compute_fid(path_to_real, path_to_test, mode=\"clean\", model_name=\"clip_vit_b_32\")\n",
        "print(f\"real_synth_score_clip: {real_synth_score_fid_clip}\")"
      ],
      "metadata": {
        "id": "x6lU7Pj5n61L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YOLOv5"
      ],
      "metadata": {
        "id": "5s-NQLWeoTEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "id": "pxneyEK-oVMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/train.py --model yolov5s-cls.pt --data /content/drive/MyDrive/dl_viz_rec/yolo_training_dataset_NAS_GAN_final --epochs 100 --img 224 --cache"
      ],
      "metadata": {
        "id": "mWxYDQuuovJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/val.py --weights runs/train-cls/exp2_NAS_GAN_final_100e/weights/best.pt --data /content/drive/MyDrive/dl_viz_rec/yolo_training_dataset_NAS_GAN_final"
      ],
      "metadata": {
        "id": "QxU2d_qEo0Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights runs/train-cls/exp2/weights/best.pt --img 224 --source im.jpg --save-txt\n",
        "python3 classify/predict.py --weights yolov5l-cls.pt --img 224 --source /home/michi/data/taskcv_2017_classification/train/aeroplane/src_2_02691156_9d65814e1b252fb01636caafca838500__95_349_165.png  --name exp_images --save-txt"
      ],
      "metadata": {
        "id": "ZpRr1Iero3Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv5 🚀 logger {run: 'auto'}\n",
        "logger = 'TensorBoard' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'ClearML':\n",
        "  %pip install -q clearml\n",
        "  import clearml; clearml.browser_login()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir runs/train-cls"
      ],
      "metadata": {
        "id": "JnWmpBDxo6Ae"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yFw1kDQBx3LN",
        "HiKqaQtOzP75",
        "bTaQnZVZ0Psn",
        "RAEgDsZG03Xp",
        "4ycnuWyTR6EF",
        "8iQo2XxtUgZt",
        "HWNJvTMgOLs-",
        "9cGn_0R78VN8"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "environment": {
      "name": "tf2-gpu.2-3.m74",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}